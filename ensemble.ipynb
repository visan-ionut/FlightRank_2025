{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d34b4040",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20250721083807\n",
      "20250724032338\n",
      "20250727084025\n",
      "20250802074816\n",
      "20250807032439\n",
      "20250804001151\n",
      "20250815103211\n",
      "dl_ranker\n",
      "shape: (6_897_776, 16)\n",
      "┌──────────┬───────────┬───────────┬───────────┬───┬───────────┬───────────┬───────────┬───────────┐\n",
      "│ Id       ┆ ranker_id ┆ legs0_dep ┆ legs0_arr ┆ … ┆ confidenc ┆ confidenc ┆ confidenc ┆ confidenc │\n",
      "│ ---      ┆ ---       ┆ artureAt  ┆ ivalAt    ┆   ┆ e_0.52538 ┆ e_0.51244 ┆ e_0.52    ┆ e_0.48755 │\n",
      "│ i64      ┆ str       ┆ ---       ┆ ---       ┆   ┆ ---       ┆ ---       ┆ ---       ┆ ---       │\n",
      "│          ┆           ┆ str       ┆ str       ┆   ┆ f64       ┆ f64       ┆ f64       ┆ f64       │\n",
      "╞══════════╪═══════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪═══════════╡\n",
      "│ 18144679 ┆ c9373e5f7 ┆ 2024-12-1 ┆ 2024-12-1 ┆ … ┆ 0.804672  ┆ 0.705253  ┆ 0.795468  ┆ 0.95544   │\n",
      "│          ┆ 72e43d593 ┆ 9T06:50:0 ┆ 9T11:20:0 ┆   ┆           ┆           ┆           ┆           │\n",
      "│          ┆ dd6ad2fa9 ┆ 0         ┆ 0         ┆   ┆           ┆           ┆           ┆           │\n",
      "│          ┆ 0f6…      ┆           ┆           ┆   ┆           ┆           ┆           ┆           │\n",
      "│ 18144680 ┆ c9373e5f7 ┆ 2024-12-1 ┆ 2024-12-1 ┆ … ┆ 0.673577  ┆ 0.646985  ┆ 0.779562  ┆ 0.557903  │\n",
      "│          ┆ 72e43d593 ┆ 9T06:50:0 ┆ 9T11:20:0 ┆   ┆           ┆           ┆           ┆           │\n",
      "│          ┆ dd6ad2fa9 ┆ 0         ┆ 0         ┆   ┆           ┆           ┆           ┆           │\n",
      "│          ┆ 0f6…      ┆           ┆           ┆   ┆           ┆           ┆           ┆           │\n",
      "│ 18144681 ┆ c9373e5f7 ┆ 2024-12-1 ┆ 2024-12-1 ┆ … ┆ 0.27432   ┆ 0.260488  ┆ 0.303758  ┆ 0.298558  │\n",
      "│          ┆ 72e43d593 ┆ 9T06:50:0 ┆ 9T11:20:0 ┆   ┆           ┆           ┆           ┆           │\n",
      "│          ┆ dd6ad2fa9 ┆ 0         ┆ 0         ┆   ┆           ┆           ┆           ┆           │\n",
      "│          ┆ 0f6…      ┆           ┆           ┆   ┆           ┆           ┆           ┆           │\n",
      "│ 18144682 ┆ c9373e5f7 ┆ 2024-12-1 ┆ 2024-12-1 ┆ … ┆ 0.635834  ┆ 0.681543  ┆ 0.573093  ┆ 0.921594  │\n",
      "│          ┆ 72e43d593 ┆ 9T08:25:0 ┆ 9T12:45:0 ┆   ┆           ┆           ┆           ┆           │\n",
      "│          ┆ dd6ad2fa9 ┆ 0         ┆ 0         ┆   ┆           ┆           ┆           ┆           │\n",
      "│          ┆ 0f6…      ┆           ┆           ┆   ┆           ┆           ┆           ┆           │\n",
      "│ 18144683 ┆ c9373e5f7 ┆ 2024-12-1 ┆ 2024-12-1 ┆ … ┆ 0.625083  ┆ 0.64247   ┆ 0.580795  ┆ 0.638029  │\n",
      "│          ┆ 72e43d593 ┆ 9T08:25:0 ┆ 9T12:45:0 ┆   ┆           ┆           ┆           ┆           │\n",
      "│          ┆ dd6ad2fa9 ┆ 0         ┆ 0         ┆   ┆           ┆           ┆           ┆           │\n",
      "│          ┆ 0f6…      ┆           ┆           ┆   ┆           ┆           ┆           ┆           │\n",
      "│ …        ┆ …         ┆ …         ┆ …         ┆ … ┆ …         ┆ …         ┆ …         ┆ …         │\n",
      "│ 25043143 ┆ c5622e0de ┆ 2025-01-0 ┆ 2025-01-0 ┆ … ┆ 0.176136  ┆ 0.247273  ┆ 0.247273  ┆ 0.176136  │\n",
      "│          ┆ 0594bde95 ┆ 8T09:05:0 ┆ 8T12:50:0 ┆   ┆           ┆           ┆           ┆           │\n",
      "│          ┆ a4dd8c1fc ┆ 0         ┆ 0         ┆   ┆           ┆           ┆           ┆           │\n",
      "│          ┆ ff7…      ┆           ┆           ┆   ┆           ┆           ┆           ┆           │\n",
      "│ 25043144 ┆ c5622e0de ┆ 2025-01-0 ┆ 2025-01-0 ┆ … ┆ 1.0       ┆ 0.797727  ┆ 0.709091  ┆ 1.0       │\n",
      "│          ┆ 0594bde95 ┆ 8T21:25:0 ┆ 9T01:10:0 ┆   ┆           ┆           ┆           ┆           │\n",
      "│          ┆ a4dd8c1fc ┆ 0         ┆ 0         ┆   ┆           ┆           ┆           ┆           │\n",
      "│          ┆ ff7…      ┆           ┆           ┆   ┆           ┆           ┆           ┆           │\n",
      "│ 25043145 ┆ c5622e0de ┆ 2025-01-0 ┆ 2025-01-0 ┆ … ┆ 0.247273  ┆ 0.319481  ┆ 0.176136  ┆ 0.319481  │\n",
      "│          ┆ 0594bde95 ┆ 8T21:25:0 ┆ 9T01:10:0 ┆   ┆           ┆           ┆           ┆           │\n",
      "│          ┆ a4dd8c1fc ┆ 0         ┆ 0         ┆   ┆           ┆           ┆           ┆           │\n",
      "│          ┆ ff7…      ┆           ┆           ┆   ┆           ┆           ┆           ┆           │\n",
      "│ 25043146 ┆ c5622e0de ┆ 2025-01-0 ┆ 2025-01-0 ┆ … ┆ 0.709091  ┆ 0.709091  ┆ 0.893506  ┆ 0.797727  │\n",
      "│          ┆ 0594bde95 ┆ 8T15:10:0 ┆ 8T18:50:0 ┆   ┆           ┆           ┆           ┆           │\n",
      "│          ┆ a4dd8c1fc ┆ 0         ┆ 0         ┆   ┆           ┆           ┆           ┆           │\n",
      "│          ┆ ff7…      ┆           ┆           ┆   ┆           ┆           ┆           ┆           │\n",
      "│ 25043147 ┆ c5622e0de ┆ 2025-01-0 ┆ 2025-01-0 ┆ … ┆ 0.105882  ┆ 0.105882  ┆ 0.105882  ┆ 0.105882  │\n",
      "│          ┆ 0594bde95 ┆ 8T15:10:0 ┆ 8T18:50:0 ┆   ┆           ┆           ┆           ┆           │\n",
      "│          ┆ a4dd8c1fc ┆ 0         ┆ 0         ┆   ┆           ┆           ┆           ┆           │\n",
      "│          ┆ ff7…      ┆           ┆           ┆   ┆           ┆           ┆           ┆           │\n",
      "└──────────┴───────────┴───────────┴───────────┴───┴───────────┴───────────┴───────────┴───────────┘\n"
     ]
    }
   ],
   "source": [
    "import polars as pl\n",
    "\n",
    "\n",
    "def load_submission_with_confidence(tag, alpha=0.7, k=5):\n",
    "    print(tag)\n",
    "    df = pl.read_parquet(f\"./ensemble/submission_{tag}_with_confidence.parquet\")\n",
    "\n",
    "    rrf_max = 1 / (k + 1)\n",
    "    df = df.with_columns(((1 / (k + pl.col(\"selected\"))) / rrf_max).alias(\"rrf_score\"))\n",
    "\n",
    "    df = df.with_columns(\n",
    "        (alpha * pl.col(\"confidence\") + (1 - alpha) * pl.col(\"rrf_score\")).alias(\n",
    "            \"confidence\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "    df = df.drop([\"selected\", \"rrf_score\"])\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def load_submission_with_score(tag, alpha=0.8, k=5):\n",
    "    print(tag)\n",
    "    df = pl.read_parquet(f\"./submission/score/{tag}.parquet\")\n",
    "\n",
    "    df = df.with_columns(\n",
    "        (\n",
    "            (pl.col(\"pred_score\") - pl.min(\"pred_score\").over(\"ranker_id\"))\n",
    "            / (\n",
    "                pl.max(\"pred_score\").over(\"ranker_id\")\n",
    "                - pl.min(\"pred_score\").over(\"ranker_id\")\n",
    "            )\n",
    "        ).alias(\"confidence\")\n",
    "    )\n",
    "\n",
    "    rrf_max = 1 / (k + 1)\n",
    "    df = df.with_columns(((1 / (k + pl.col(\"selected\"))) / rrf_max).alias(\"rrf_score\"))\n",
    "\n",
    "    df = df.with_columns(\n",
    "        (alpha * pl.col(\"confidence\") + (1 - alpha) * pl.col(\"rrf_score\")).alias(\n",
    "            \"confidence\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "    df = df.drop([\"selected\", \"rrf_score\"])\n",
    "\n",
    "    return df.select([\"Id\", \"ranker_id\", \"confidence\"])\n",
    "\n",
    "\n",
    "dfs = []\n",
    "\n",
    "timetag_score = {\n",
    "    # \"20250716132706\": [0, 0.51381],\n",
    "    # \"20250718083308\": [0, 0.51822],\n",
    "    # \"20250719002505\": [0, 0.51859],\n",
    "    # \"20250720003111\": [0, 0.50693],   # lgb\n",
    "    # \"20250721025740\": [0, 0.51960],\n",
    "    # \"20250722050939\": [1, 0.52070],\n",
    "    \"20250721083807\": [1, 0.52244],\n",
    "    \"20250724032338\": [1, 0.51345],  # lgb\n",
    "    # \"20250725040223\": [1, 0.52309],\n",
    "    # \"20250725083055\": [1, 0.52391],\n",
    "    \"20250727084025\": [1, 0.52795],\n",
    "    # \"20250728094305\": [1, 0.52492],\n",
    "    # \"20250731122023\": [1, 0.52015],\n",
    "    # \"20250729084249\": [1, 0.51822],\n",
    "    \"20250802074816\": [1, 0.52603],\n",
    "    \"20250807032439\": [1, 0.52538],\n",
    "    \"20250804001151\": [1, 0.51244],  # lgb\n",
    "    # \"20250809093033\": [1, 0.52612],\n",
    "    # \"20250812094947\": [1, 0.52364],\n",
    "    \"20250815103211\": [1, 0.52000],\n",
    "    \"dl_ranker\": [1, 0.48755],\n",
    "    # \"combined\": [1, 0.51244],\n",
    "    # \"0.49242\": [1, 0.49242],\n",
    "    # \"0.49260\": [1, 0.49260],\n",
    "    # \"0.49380\": [1, 0.49380],\n",
    "}\n",
    "\n",
    "model_quality_dict = {}\n",
    "\n",
    "for timetag, score_list in timetag_score.items():\n",
    "    # df = load_submission_with_confidence(timetag)\n",
    "    if not timetag.startswith(\"2025\"):\n",
    "        df = load_submission_with_confidence(timetag)\n",
    "    else:\n",
    "        df = load_submission_with_confidence(timetag)\n",
    "    weight, score = score_list\n",
    "    df = df.with_columns((pl.col(\"confidence\")).alias(f\"confidence_{score}\")).drop(\n",
    "        \"confidence\"\n",
    "    )\n",
    "    model_quality_dict[f\"confidence_{score}\"] = score\n",
    "    dfs.append(df)\n",
    "\n",
    "test = pl.read_parquet(\"./data/test.parquet\")\n",
    "COLS_TO_COMPARE = [\n",
    "    \"legs0_departureAt\",\n",
    "    \"legs0_arrivalAt\",\n",
    "    \"legs1_departureAt\",\n",
    "    \"legs1_arrivalAt\",\n",
    "    \"legs0_segments0_flightNumber\",\n",
    "    \"legs1_segments0_flightNumber\",\n",
    "]\n",
    "df_combined = test.select([\"Id\", \"ranker_id\"] + COLS_TO_COMPARE)\n",
    "for i in range(0, len(dfs)):\n",
    "    df_combined = df_combined.join(dfs[i], on=[\"Id\", \"ranker_id\"])\n",
    "\n",
    "print(df_combined)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6746ecf",
   "metadata": {},
   "source": [
    "## Group-wise Spearman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d4f1668c",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      7\u001b[39m confidence_cols = [col \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m df_combined.columns \u001b[38;5;28;01mif\u001b[39;00m col.startswith(\u001b[33m\"\u001b[39m\u001b[33mconfidence\u001b[39m\u001b[33m\"\u001b[39m)]\n\u001b[32m      9\u001b[39m df_pd = df_combined.select([\u001b[33m\"\u001b[39m\u001b[33mId\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mranker_id\u001b[39m\u001b[33m\"\u001b[39m] + confidence_cols).to_pandas()\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m groups = \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdf_pd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgroupby\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mranker_id\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# 1. 计算全局权重\u001b[39;00m\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcompute_spearman_weights\u001b[39m(df, confidence_cols):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/FlightRank/lib/python3.11/site-packages/pandas/core/groupby/ops.py:620\u001b[39m, in \u001b[36mBaseGrouper.get_iterator\u001b[39m\u001b[34m(self, data, axis)\u001b[39m\n\u001b[32m    618\u001b[39m splitter = \u001b[38;5;28mself\u001b[39m._get_splitter(data, axis=axis)\n\u001b[32m    619\u001b[39m keys = \u001b[38;5;28mself\u001b[39m.group_keys_seq\n\u001b[32m--> \u001b[39m\u001b[32m620\u001b[39m \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(keys, splitter)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/FlightRank/lib/python3.11/site-packages/pandas/core/groupby/ops.py:1150\u001b[39m, in \u001b[36mDataSplitter.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1149\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__iter__\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> Iterator:\n\u001b[32m-> \u001b[39m\u001b[32m1150\u001b[39m     sdata = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sorted_data\u001b[49m\n\u001b[32m   1152\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.ngroups == \u001b[32m0\u001b[39m:\n\u001b[32m   1153\u001b[39m         \u001b[38;5;66;03m# we are inside a generator, rather than raise StopIteration\u001b[39;00m\n\u001b[32m   1154\u001b[39m         \u001b[38;5;66;03m# we merely return signal the end\u001b[39;00m\n\u001b[32m   1155\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/properties.pyx:36\u001b[39m, in \u001b[36mpandas._libs.properties.CachedProperty.__get__\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/FlightRank/lib/python3.11/site-packages/pandas/core/groupby/ops.py:1164\u001b[39m, in \u001b[36mDataSplitter._sorted_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1162\u001b[39m \u001b[38;5;129m@cache_readonly\u001b[39m\n\u001b[32m   1163\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_sorted_data\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> NDFrameT:\n\u001b[32m-> \u001b[39m\u001b[32m1164\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtake\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sort_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/FlightRank/lib/python3.11/site-packages/pandas/core/generic.py:4152\u001b[39m, in \u001b[36mNDFrame.take\u001b[39m\u001b[34m(self, indices, axis, **kwargs)\u001b[39m\n\u001b[32m   4147\u001b[39m     \u001b[38;5;66;03m# We can get here with a slice via DataFrame.__getitem__\u001b[39;00m\n\u001b[32m   4148\u001b[39m     indices = np.arange(\n\u001b[32m   4149\u001b[39m         indices.start, indices.stop, indices.step, dtype=np.intp\n\u001b[32m   4150\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m4152\u001b[39m new_data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_mgr\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtake\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   4153\u001b[39m \u001b[43m    \u001b[49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4154\u001b[39m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_block_manager_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4155\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverify\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   4156\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4157\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._constructor_from_mgr(new_data, axes=new_data.axes).__finalize__(\n\u001b[32m   4158\u001b[39m     \u001b[38;5;28mself\u001b[39m, method=\u001b[33m\"\u001b[39m\u001b[33mtake\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   4159\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/FlightRank/lib/python3.11/site-packages/pandas/core/internals/managers.py:894\u001b[39m, in \u001b[36mBaseBlockManager.take\u001b[39m\u001b[34m(self, indexer, axis, verify)\u001b[39m\n\u001b[32m    891\u001b[39m indexer = maybe_convert_indices(indexer, n, verify=verify)\n\u001b[32m    893\u001b[39m new_labels = \u001b[38;5;28mself\u001b[39m.axes[axis].take(indexer)\n\u001b[32m--> \u001b[39m\u001b[32m894\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mreindex_indexer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    895\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnew_axis\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnew_labels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    896\u001b[39m \u001b[43m    \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    897\u001b[39m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    898\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_dups\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    899\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    900\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/FlightRank/lib/python3.11/site-packages/pandas/core/internals/managers.py:687\u001b[39m, in \u001b[36mBaseBlockManager.reindex_indexer\u001b[39m\u001b[34m(self, new_axis, indexer, axis, fill_value, allow_dups, copy, only_slice, use_na_proxy)\u001b[39m\n\u001b[32m    680\u001b[39m     new_blocks = \u001b[38;5;28mself\u001b[39m._slice_take_blocks_ax0(\n\u001b[32m    681\u001b[39m         indexer,\n\u001b[32m    682\u001b[39m         fill_value=fill_value,\n\u001b[32m    683\u001b[39m         only_slice=only_slice,\n\u001b[32m    684\u001b[39m         use_na_proxy=use_na_proxy,\n\u001b[32m    685\u001b[39m     )\n\u001b[32m    686\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m687\u001b[39m     new_blocks = \u001b[43m[\u001b[49m\n\u001b[32m    688\u001b[39m \u001b[43m        \u001b[49m\u001b[43mblk\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtake_nd\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    689\u001b[39m \u001b[43m            \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    690\u001b[39m \u001b[43m            \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    691\u001b[39m \u001b[43m            \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    692\u001b[39m \u001b[43m                \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mblk\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfill_value\u001b[49m\n\u001b[32m    693\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    694\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    695\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mblk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mblocks\u001b[49m\n\u001b[32m    696\u001b[39m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m    698\u001b[39m new_axes = \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m.axes)\n\u001b[32m    699\u001b[39m new_axes[axis] = new_axis\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/FlightRank/lib/python3.11/site-packages/pandas/core/internals/managers.py:688\u001b[39m, in \u001b[36m<listcomp>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m    680\u001b[39m     new_blocks = \u001b[38;5;28mself\u001b[39m._slice_take_blocks_ax0(\n\u001b[32m    681\u001b[39m         indexer,\n\u001b[32m    682\u001b[39m         fill_value=fill_value,\n\u001b[32m    683\u001b[39m         only_slice=only_slice,\n\u001b[32m    684\u001b[39m         use_na_proxy=use_na_proxy,\n\u001b[32m    685\u001b[39m     )\n\u001b[32m    686\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    687\u001b[39m     new_blocks = [\n\u001b[32m--> \u001b[39m\u001b[32m688\u001b[39m         \u001b[43mblk\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtake_nd\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    689\u001b[39m \u001b[43m            \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    690\u001b[39m \u001b[43m            \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    691\u001b[39m \u001b[43m            \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    692\u001b[39m \u001b[43m                \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mblk\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfill_value\u001b[49m\n\u001b[32m    693\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    694\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    695\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m blk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.blocks\n\u001b[32m    696\u001b[39m     ]\n\u001b[32m    698\u001b[39m new_axes = \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m.axes)\n\u001b[32m    699\u001b[39m new_axes[axis] = new_axis\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/FlightRank/lib/python3.11/site-packages/pandas/core/internals/blocks.py:1373\u001b[39m, in \u001b[36mBlock.take_nd\u001b[39m\u001b[34m(self, indexer, axis, new_mgr_locs, fill_value)\u001b[39m\n\u001b[32m   1370\u001b[39m     allow_fill = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m   1372\u001b[39m \u001b[38;5;66;03m# Note: algos.take_nd has upcast logic similar to coerce_to_target_dtype\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1373\u001b[39m new_values = \u001b[43malgos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtake_nd\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1374\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_fill\u001b[49m\u001b[43m=\u001b[49m\u001b[43mallow_fill\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfill_value\u001b[49m\n\u001b[32m   1375\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1377\u001b[39m \u001b[38;5;66;03m# Called from three places in managers, all of which satisfy\u001b[39;00m\n\u001b[32m   1378\u001b[39m \u001b[38;5;66;03m#  these assertions\u001b[39;00m\n\u001b[32m   1379\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ExtensionBlock):\n\u001b[32m   1380\u001b[39m     \u001b[38;5;66;03m# NB: in this case, the 'axis' kwarg will be ignored in the\u001b[39;00m\n\u001b[32m   1381\u001b[39m     \u001b[38;5;66;03m#  algos.take_nd call above.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/FlightRank/lib/python3.11/site-packages/pandas/core/array_algos/take.py:117\u001b[39m, in \u001b[36mtake_nd\u001b[39m\u001b[34m(arr, indexer, axis, fill_value, allow_fill)\u001b[39m\n\u001b[32m    114\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m arr.take(indexer, fill_value=fill_value, allow_fill=allow_fill)\n\u001b[32m    116\u001b[39m arr = np.asarray(arr)\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_take_nd_ndarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_fill\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/FlightRank/lib/python3.11/site-packages/pandas/core/array_algos/take.py:157\u001b[39m, in \u001b[36m_take_nd_ndarray\u001b[39m\u001b[34m(arr, indexer, axis, fill_value, allow_fill)\u001b[39m\n\u001b[32m    155\u001b[39m     out = np.empty(out_shape, dtype=dtype, order=\u001b[33m\"\u001b[39m\u001b[33mF\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    156\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m157\u001b[39m     out = \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mempty\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    159\u001b[39m func = _get_take_nd_function(\n\u001b[32m    160\u001b[39m     arr.ndim, arr.dtype, out.dtype, axis=axis, mask_info=mask_info\n\u001b[32m    161\u001b[39m )\n\u001b[32m    162\u001b[39m func(arr, indexer, out, fill_value)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import spearmanr\n",
    "from joblib import Parallel, delayed\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "confidence_cols = [col for col in df_combined.columns if col.startswith(\"confidence\")]\n",
    "\n",
    "df_pd = df_combined.select([\"Id\", \"ranker_id\"] + confidence_cols).to_pandas()\n",
    "groups = list(df_pd.groupby(\"ranker_id\"))\n",
    "\n",
    "\n",
    "# 1. 计算全局权重\n",
    "def compute_spearman_weights(df, confidence_cols):\n",
    "    corr_mat = pd.DataFrame(index=confidence_cols, columns=confidence_cols, dtype=float)\n",
    "    for i in range(len(confidence_cols)):\n",
    "        for j in range(i, len(confidence_cols)):\n",
    "            col_i, col_j = confidence_cols[i], confidence_cols[j]\n",
    "            col_i_vals = df[col_i].fillna(0)\n",
    "            col_j_vals = df[col_j].fillna(0)\n",
    "            # 过滤 NaN 共同有效样本\n",
    "            mask = col_i_vals.notna() & col_j_vals.notna()\n",
    "            if mask.sum() < 2:\n",
    "                corr = 0\n",
    "            else:\n",
    "                corr, _ = spearmanr(col_i_vals[mask], col_j_vals[mask])\n",
    "                if pd.isna(corr):\n",
    "                    corr = 0\n",
    "            corr_mat.loc[col_i, col_j] = corr\n",
    "            corr_mat.loc[col_j, col_i] = corr\n",
    "    mean_corr = corr_mat.apply(lambda row: (row.sum() - 1) / (len(row) - 1), axis=1)\n",
    "    model_uniqueness = 1 - mean_corr.clip(-1, 1)\n",
    "    if model_uniqueness.sum() == 0 or model_uniqueness.isna().any():\n",
    "        weights = pd.Series(\n",
    "            [1 / len(confidence_cols)] * len(confidence_cols), index=confidence_cols\n",
    "        )\n",
    "    else:\n",
    "        weights = model_uniqueness / model_uniqueness.sum()\n",
    "    return weights\n",
    "\n",
    "\n",
    "print(\"计算全局 Spearman 权重...\")\n",
    "global_weights = compute_spearman_weights(df_pd, confidence_cols)\n",
    "print(global_weights)\n",
    "\n",
    "\n",
    "# 2. 计算每个 group 的权重\n",
    "def compute_group_weight(gid, group):\n",
    "    if len(group) <= 10:\n",
    "        return gid, pd.Series(\n",
    "            [1 / len(confidence_cols)] * len(confidence_cols), index=confidence_cols\n",
    "        )\n",
    "    weights = compute_spearman_weights(group, confidence_cols)\n",
    "    return gid, weights\n",
    "\n",
    "\n",
    "print(\"计算每个 group Spearman 权重...\")\n",
    "results = Parallel(n_jobs=32, backend=\"loky\")(\n",
    "    delayed(compute_group_weight)(gid, group) for gid, group in tqdm(groups)\n",
    ")\n",
    "group_weights = dict(results)\n",
    "\n",
    "# 3. 融合权重并对组内数据加权融合 confidence\n",
    "beta = 0.7  # 全局权重占比\n",
    "\n",
    "\n",
    "def fuse_group_rows(rows, group_w, global_w, beta=0.7):\n",
    "    weights = beta * global_w + (1 - beta) * group_w\n",
    "    weights /= weights.sum()\n",
    "\n",
    "    relevant_cols = [col for col in weights.index if col in rows]\n",
    "    rows = rows.copy()\n",
    "    rows[relevant_cols] = rows[relevant_cols].fillna(0)\n",
    "\n",
    "    rows[\"fused_confidence\"] = rows[relevant_cols].dot(weights[relevant_cols])\n",
    "    return rows\n",
    "\n",
    "\n",
    "def parallel_fuse_group(gid_group_pair):\n",
    "    gid, group = gid_group_pair\n",
    "    group_w = group_weights.get(gid, global_weights)\n",
    "    return fuse_group_rows(group, group_w, global_weights, beta)\n",
    "\n",
    "\n",
    "print(\"并行融合组内 confidence ...\")\n",
    "\n",
    "# 多进程融合（确保 groups 是 list of (gid, group_df)）\n",
    "fused_groups = Parallel(n_jobs=32, backend=\"loky\")(\n",
    "    delayed(parallel_fuse_group)(pair) for pair in tqdm(groups)\n",
    ")\n",
    "\n",
    "# 合并所有组\n",
    "df_pd = pd.concat(fused_groups, ignore_index=True)\n",
    "df_fused = df_pd[[\"Id\", \"ranker_id\", \"fused_confidence\"]]\n",
    "\n",
    "print(df_fused.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8b701bc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (5, 3)\n",
      "┌──────────┬─────────────────────────────────┬──────────┐\n",
      "│ Id       ┆ ranker_id                       ┆ selected │\n",
      "│ ---      ┆ ---                             ┆ ---      │\n",
      "│ i64      ┆ str                             ┆ i32      │\n",
      "╞══════════╪═════════════════════════════════╪══════════╡\n",
      "│ 18144679 ┆ c9373e5f772e43d593dd6ad2fa90f6… ┆ 5        │\n",
      "│ 18144680 ┆ c9373e5f772e43d593dd6ad2fa90f6… ┆ 26       │\n",
      "│ 18144681 ┆ c9373e5f772e43d593dd6ad2fa90f6… ┆ 244      │\n",
      "│ 18144682 ┆ c9373e5f772e43d593dd6ad2fa90f6… ┆ 66       │\n",
      "│ 18144683 ┆ c9373e5f772e43d593dd6ad2fa90f6… ┆ 75       │\n",
      "└──────────┴─────────────────────────────────┴──────────┘\n"
     ]
    }
   ],
   "source": [
    "df_ranked = pl.DataFrame(df_fused).with_columns(\n",
    "    [\n",
    "        pl.col(\"fused_confidence\")\n",
    "        .rank(method=\"ordinal\", descending=True)\n",
    "        .over(\"ranker_id\")\n",
    "        .cast(pl.Int32)\n",
    "        .alias(\"selected\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Load original order from one of the submissions\n",
    "df_original = dfs[0].select([\"Id\", \"ranker_id\"])\n",
    "\n",
    "# Join and keep only required columns in original order\n",
    "final_submission = df_original.join(\n",
    "    df_ranked.select([\"Id\", \"ranker_id\", \"selected\"]),\n",
    "    on=[\"Id\", \"ranker_id\"],\n",
    "    how=\"left\",\n",
    ")\n",
    "print(final_submission.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "777dd749",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_submission.write_parquet(\"submission_ensemble_fused.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ea1f7b",
   "metadata": {},
   "source": [
    "## Global spearman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5ef1cd49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    confidence_0.52244  confidence_0.51345  \\\n",
      "confidence_0.52244            1.000000            0.949373   \n",
      "confidence_0.51345            0.949373            1.000000   \n",
      "confidence_0.52795            0.957935            0.939309   \n",
      "confidence_0.52603            0.958322            0.937384   \n",
      "confidence_0.52538            0.957988            0.935733   \n",
      "confidence_0.51244            0.934095            0.945280   \n",
      "confidence_0.52               0.945438            0.924711   \n",
      "confidence_0.48755            0.904576            0.902773   \n",
      "\n",
      "                    confidence_0.52795  confidence_0.52603  \\\n",
      "confidence_0.52244            0.957935            0.958322   \n",
      "confidence_0.51345            0.939309            0.937384   \n",
      "confidence_0.52795            1.000000            0.982414   \n",
      "confidence_0.52603            0.982414            1.000000   \n",
      "confidence_0.52538            0.979736            0.981877   \n",
      "confidence_0.51244            0.955373            0.952257   \n",
      "confidence_0.52               0.966710            0.968852   \n",
      "confidence_0.48755            0.891861            0.892817   \n",
      "\n",
      "                    confidence_0.52538  confidence_0.51244  confidence_0.52  \\\n",
      "confidence_0.52244            0.957988            0.934095         0.945438   \n",
      "confidence_0.51345            0.935733            0.945280         0.924711   \n",
      "confidence_0.52795            0.979736            0.955373         0.966710   \n",
      "confidence_0.52603            0.981877            0.952257         0.968852   \n",
      "confidence_0.52538            1.000000            0.949621         0.971168   \n",
      "confidence_0.51244            0.949621            1.000000         0.941293   \n",
      "confidence_0.52               0.971168            0.941293         1.000000   \n",
      "confidence_0.48755            0.891378            0.886153         0.882570   \n",
      "\n",
      "                    confidence_0.48755  \n",
      "confidence_0.52244            0.904576  \n",
      "confidence_0.51345            0.902773  \n",
      "confidence_0.52795            0.891861  \n",
      "confidence_0.52603            0.892817  \n",
      "confidence_0.52538            0.891378  \n",
      "confidence_0.51244            0.886153  \n",
      "confidence_0.52               0.882570  \n",
      "confidence_0.48755            1.000000  \n"
     ]
    }
   ],
   "source": [
    "confidence_cols = [col for col in df_combined.columns if col.startswith(\"confidence\")]\n",
    "corr_df = df_combined.select(confidence_cols).to_pandas().corr(method=\"spearman\")\n",
    "print(corr_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f44cfdba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confidence_0.52244    0.056039\n",
      "confidence_0.51345    0.066491\n",
      "confidence_0.52795    0.046666\n",
      "confidence_0.52603    0.046582\n",
      "confidence_0.52538    0.047500\n",
      "confidence_0.51244    0.062276\n",
      "confidence_0.52       0.057037\n",
      "confidence_0.48755    0.106839\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "mean_corr = corr_df.apply(lambda row: (row.sum() - 1) / (len(row) - 1), axis=1)\n",
    "\n",
    "model_uniqueness = 1 - mean_corr\n",
    "print(model_uniqueness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ff4950e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confidence_0.52244    0.114499\n",
      "confidence_0.51345    0.135854\n",
      "confidence_0.52795    0.095348\n",
      "confidence_0.52603    0.095177\n",
      "confidence_0.52538    0.097052\n",
      "confidence_0.51244    0.127241\n",
      "confidence_0.52       0.116537\n",
      "confidence_0.48755    0.218292\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "combined_score = model_uniqueness\n",
    "weights = combined_score / combined_score.sum()\n",
    "print(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "61217075",
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted_conf = sum(\n",
    "    df_combined[f].fill_null(0) * w for f, w in zip(confidence_cols, weights.values)\n",
    ")\n",
    "\n",
    "df_combined = df_combined.with_columns(weighted_conf.alias(\"pred_score\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "04a02c73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (5, 3)\n",
      "┌──────────┬─────────────────────────────────┬──────────┐\n",
      "│ Id       ┆ ranker_id                       ┆ selected │\n",
      "│ ---      ┆ ---                             ┆ ---      │\n",
      "│ i64      ┆ str                             ┆ i32      │\n",
      "╞══════════╪═════════════════════════════════╪══════════╡\n",
      "│ 18144679 ┆ c9373e5f772e43d593dd6ad2fa90f6… ┆ 4        │\n",
      "│ 18144680 ┆ c9373e5f772e43d593dd6ad2fa90f6… ┆ 32       │\n",
      "│ 18144681 ┆ c9373e5f772e43d593dd6ad2fa90f6… ┆ 260      │\n",
      "│ 18144682 ┆ c9373e5f772e43d593dd6ad2fa90f6… ┆ 11       │\n",
      "│ 18144683 ┆ c9373e5f772e43d593dd6ad2fa90f6… ┆ 60       │\n",
      "└──────────┴─────────────────────────────────┴──────────┘\n"
     ]
    }
   ],
   "source": [
    "df_ranked = df_combined.with_columns(\n",
    "    [\n",
    "        pl.col(\"pred_score\")\n",
    "        .rank(method=\"ordinal\", descending=True)\n",
    "        .over(\"ranker_id\")\n",
    "        .cast(pl.Int32)\n",
    "        .alias(\"selected\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Load original order from one of the submissions\n",
    "df_original = dfs[0].select([\"Id\", \"ranker_id\"])\n",
    "\n",
    "# Join and keep only required columns in original order\n",
    "final_submission = df_original.join(\n",
    "    df_ranked.select([\"Id\", \"ranker_id\", \"selected\"]),\n",
    "    on=[\"Id\", \"ranker_id\"],\n",
    "    how=\"left\",\n",
    ")\n",
    "print(final_submission.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c1c774df",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_submission.write_parquet(\"./submission_ensemble.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76916400",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c5696aa4",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 52\u001b[39m\n\u001b[32m     50\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(confidence_cols)):\n\u001b[32m     51\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(i, \u001b[38;5;28mlen\u001b[39m(confidence_cols)):\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m         corr, _ = \u001b[43mspearmanr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mj\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     53\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m np.isnan(corr):\n\u001b[32m     54\u001b[39m             corr = \u001b[32m0\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/FlightRank/lib/python3.11/site-packages/scipy/stats/_stats_py.py:5291\u001b[39m, in \u001b[36mspearmanr\u001b[39m\u001b[34m(a, b, axis, nan_policy, alternative)\u001b[39m\n\u001b[32m   5286\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   5287\u001b[39m             \u001b[38;5;66;03m# Keep track of variables with NaNs, set the outputs to NaN\u001b[39;00m\n\u001b[32m   5288\u001b[39m             \u001b[38;5;66;03m# only for those variables\u001b[39;00m\n\u001b[32m   5289\u001b[39m             variable_has_nan = np.isnan(a).any(axis=axisout)\n\u001b[32m-> \u001b[39m\u001b[32m5291\u001b[39m a_ranked = \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mapply_along_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrankdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxisout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   5292\u001b[39m rs = np.corrcoef(a_ranked, rowvar=axisout)\n\u001b[32m   5293\u001b[39m dof = n_obs - \u001b[32m2\u001b[39m  \u001b[38;5;66;03m# degrees of freedom\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/FlightRank/lib/python3.11/site-packages/numpy/lib/_shape_base_impl.py:393\u001b[39m, in \u001b[36mapply_along_axis\u001b[39m\u001b[34m(func1d, axis, arr, *args, **kwargs)\u001b[39m\n\u001b[32m    389\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[32m    390\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    391\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mCannot apply_along_axis when any iteration dimensions are 0\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    392\u001b[39m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m393\u001b[39m res = asanyarray(\u001b[43mfunc1d\u001b[49m\u001b[43m(\u001b[49m\u001b[43minarr_view\u001b[49m\u001b[43m[\u001b[49m\u001b[43mind0\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m    395\u001b[39m \u001b[38;5;66;03m# build a buffer for storing evaluations of func1d.\u001b[39;00m\n\u001b[32m    396\u001b[39m \u001b[38;5;66;03m# remove the requested axis, and add the new ones on the end.\u001b[39;00m\n\u001b[32m    397\u001b[39m \u001b[38;5;66;03m# laid out so that each write is contiguous.\u001b[39;00m\n\u001b[32m    398\u001b[39m \u001b[38;5;66;03m# for a tuple index inds, buff[inds] = func1d(inarr_view[inds])\u001b[39;00m\n\u001b[32m    399\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(res, matrix):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/FlightRank/lib/python3.11/site-packages/scipy/stats/_stats_py.py:10212\u001b[39m, in \u001b[36mrankdata\u001b[39m\u001b[34m(a, method, axis, nan_policy)\u001b[39m\n\u001b[32m  10209\u001b[39m contains_nan, nan_policy = _contains_nan(x, nan_policy)\n\u001b[32m  10211\u001b[39m x = np.swapaxes(x, axis, -\u001b[32m1\u001b[39m)\n\u001b[32m> \u001b[39m\u001b[32m10212\u001b[39m ranks = \u001b[43m_rankdata\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m  10214\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m contains_nan:\n\u001b[32m  10215\u001b[39m     i_nan = (np.isnan(x) \u001b[38;5;28;01mif\u001b[39;00m nan_policy == \u001b[33m'\u001b[39m\u001b[33momit\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m  10216\u001b[39m              \u001b[38;5;28;01melse\u001b[39;00m np.isnan(x).any(axis=-\u001b[32m1\u001b[39m))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/FlightRank/lib/python3.11/site-packages/scipy/stats/_stats_py.py:10237\u001b[39m, in \u001b[36m_rankdata\u001b[39m\u001b[34m(x, method, return_ties)\u001b[39m\n\u001b[32m  10235\u001b[39m \u001b[38;5;66;03m# Get sort order\u001b[39;00m\n\u001b[32m  10236\u001b[39m kind = \u001b[33m'\u001b[39m\u001b[33mmergesort\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m method == \u001b[33m'\u001b[39m\u001b[33mordinal\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33mquicksort\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m> \u001b[39m\u001b[32m10237\u001b[39m j = \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43margsort\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkind\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkind\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m  10238\u001b[39m ordinal_ranks = np.broadcast_to(np.arange(\u001b[32m1\u001b[39m, shape[-\u001b[32m1\u001b[39m]+\u001b[32m1\u001b[39m, dtype=\u001b[38;5;28mint\u001b[39m), shape)\n\u001b[32m  10240\u001b[39m \u001b[38;5;66;03m# Ordinal ranks is very easy because ties don't matter. We're done.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/FlightRank/lib/python3.11/site-packages/numpy/_core/fromnumeric.py:1242\u001b[39m, in \u001b[36margsort\u001b[39m\u001b[34m(a, axis, kind, order, stable)\u001b[39m\n\u001b[32m   1129\u001b[39m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_argsort_dispatcher)\n\u001b[32m   1130\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34margsort\u001b[39m(a, axis=-\u001b[32m1\u001b[39m, kind=\u001b[38;5;28;01mNone\u001b[39;00m, order=\u001b[38;5;28;01mNone\u001b[39;00m, *, stable=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m   1131\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1132\u001b[39m \u001b[33;03m    Returns the indices that would sort an array.\u001b[39;00m\n\u001b[32m   1133\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   1240\u001b[39m \n\u001b[32m   1241\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1242\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_wrapfunc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1243\u001b[39m \u001b[43m        \u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43margsort\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkind\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkind\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[43m=\u001b[49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstable\u001b[49m\n\u001b[32m   1244\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/FlightRank/lib/python3.11/site-packages/numpy/_core/fromnumeric.py:57\u001b[39m, in \u001b[36m_wrapfunc\u001b[39m\u001b[34m(obj, method, *args, **kwds)\u001b[39m\n\u001b[32m     54\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapit(obj, method, *args, **kwds)\n\u001b[32m     56\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m57\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbound\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m     59\u001b[39m     \u001b[38;5;66;03m# A TypeError occurs if the object does have such a method in its\u001b[39;00m\n\u001b[32m     60\u001b[39m     \u001b[38;5;66;03m# class, but its signature is not identical to that of NumPy's. This\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     64\u001b[39m     \u001b[38;5;66;03m# Call _wrapit from within the except clause to ensure a potential\u001b[39;00m\n\u001b[32m     65\u001b[39m     \u001b[38;5;66;03m# exception has a traceback chain.\u001b[39;00m\n\u001b[32m     66\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapit(obj, method, *args, **kwds)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import polars as pl\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import spearmanr\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "def load_submission_with_confidence(tag):\n",
    "    df = pl.read_parquet(f\"./ensemble/submission_{tag}_with_confidence.parquet\").drop(\n",
    "        \"selected\"\n",
    "    )\n",
    "    return df\n",
    "\n",
    "\n",
    "# # 模型和分数配置\n",
    "# timetag_score = {\n",
    "#     \"20250721025740\": [0, 0.51960],\n",
    "#     \"20250722050939\": [1, 0.52070],\n",
    "#     \"20250721083807\": [1, 0.52244],\n",
    "#     \"20250724032338\": [1, 0.51345],  # 注意去除字符串后缀\n",
    "#     \"20250725083055\": [1, 0.52391],\n",
    "#     \"20250727084025\": [1, 0.52795],\n",
    "#     \"20250728094305\": [1, 0.52492],\n",
    "#     \"20250729084249\": [1, 0.51822],\n",
    "#     \"0.49242\": [1, 0.49242],\n",
    "# }\n",
    "\n",
    "# # 载入数据，重命名 confidence 列\n",
    "# dfs = []\n",
    "# for timetag, score_list in timetag_score.items():\n",
    "#     df = load_submission_with_confidence(timetag)\n",
    "#     _, score = score_list\n",
    "#     score = float(score)  # 确保是float\n",
    "#     df = df.with_columns(pl.col(\"confidence\").alias(f\"confidence_{score}\")).drop(\n",
    "#         \"confidence\"\n",
    "#     )\n",
    "#     dfs.append(df)\n",
    "\n",
    "# # 合并所有模型结果\n",
    "# df_combined = dfs[0]\n",
    "# for i in range(1, len(dfs)):\n",
    "#     df_combined = df_combined.join(dfs[i], on=[\"Id\", \"ranker_id\"])\n",
    "\n",
    "# 提取所有 confidence 列名\n",
    "confidence_cols = [col for col in df_combined.columns if col.startswith(\"confidence\")]\n",
    "X = df_combined.select(confidence_cols).to_numpy()\n",
    "\n",
    "# 计算 Spearman 相关性矩阵和权重\n",
    "corr_mat = np.zeros((len(confidence_cols), len(confidence_cols)))\n",
    "for i in range(len(confidence_cols)):\n",
    "    for j in range(i, len(confidence_cols)):\n",
    "        corr, _ = spearmanr(X[:, i], X[:, j])\n",
    "        if np.isnan(corr):\n",
    "            corr = 0\n",
    "        corr_mat[i, j] = corr\n",
    "        corr_mat[j, i] = corr\n",
    "\n",
    "mean_corr = corr_mat.mean(axis=1)\n",
    "model_uniqueness = 1 - mean_corr.clip(-1, 1)\n",
    "spearman_weights = model_uniqueness / model_uniqueness.sum()\n",
    "\n",
    "print(\"Spearman 权重:\")\n",
    "for col, w in zip(confidence_cols, spearman_weights):\n",
    "    print(f\"{col}: {w:.4f}\")\n",
    "\n",
    "# 用 Spearman 权重加权输入矩阵\n",
    "X_weighted = X * spearman_weights\n",
    "\n",
    "# PCA 融合\n",
    "pca = PCA(n_components=1)\n",
    "pc1_scores = pca.fit_transform(X_weighted).flatten()\n",
    "\n",
    "print(\"\\nPCA 各模型权重:\")\n",
    "for col, weight in zip(confidence_cols, pca.components_[0]):\n",
    "    print(f\"{col}: {weight:.4f}\")\n",
    "\n",
    "# 添加融合分数到数据\n",
    "df_combined = df_combined.with_columns(pl.Series(\"ensemble_confidence\", pc1_scores))\n",
    "\n",
    "# 分组内按融合分数排名（越大越好）\n",
    "df_ranked = df_combined.with_columns(\n",
    "    pl.col(\"ensemble_confidence\")\n",
    "    .rank(method=\"ordinal\", descending=True)\n",
    "    .over(\"ranker_id\")\n",
    "    .cast(pl.Int32)\n",
    "    .alias(\"selected\")\n",
    ")\n",
    "\n",
    "# 准备输出\n",
    "df_original = dfs[0].select([\"Id\", \"ranker_id\"])\n",
    "final_submission = df_original.join(\n",
    "    df_ranked.select([\"Id\", \"ranker_id\", \"selected\"]),\n",
    "    on=[\"Id\", \"ranker_id\"],\n",
    "    how=\"left\",\n",
    ")\n",
    "\n",
    "print(\"\\n最终结果示例:\")\n",
    "print(final_submission.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "117754e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_submission.write_parquet(\"submission_ensemble_spearman_pca.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7080d1a8",
   "metadata": {},
   "source": [
    "## Spearman weight as feature & PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f36b5040",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman 权重:\n",
      "confidence_0.5196: 0.0937\n",
      "confidence_0.5207: 0.0915\n",
      "confidence_0.52244: 0.0930\n",
      "confidence_0.51345: 0.1339\n",
      "confidence_0.52391: 0.0949\n",
      "confidence_0.52795: 0.0932\n",
      "confidence_0.52492: 0.0910\n",
      "confidence_0.51822: 0.0970\n",
      "confidence_0.49242: 0.2119\n",
      "\n",
      "PCA 各模型权重（前半段是原始模型列，后半段是权重列）:\n",
      "confidence_0.5196: 0.3358\n",
      "confidence_0.5207: 0.3361\n",
      "confidence_0.52244: 0.3359\n",
      "confidence_0.51345: 0.3300\n",
      "confidence_0.52391: 0.3356\n",
      "confidence_0.52795: 0.3359\n",
      "confidence_0.52492: 0.3362\n",
      "confidence_0.51822: 0.3353\n",
      "confidence_0.49242: 0.3186\n",
      "weight_0: 0.0000\n",
      "weight_1: 0.0000\n",
      "weight_2: -0.0000\n",
      "weight_3: 0.0000\n",
      "weight_4: 0.0000\n",
      "weight_5: 0.0000\n",
      "weight_6: 0.0000\n",
      "weight_7: -0.0000\n",
      "weight_8: -0.0000\n",
      "\n",
      "最终融合排序结果示例:\n",
      "shape: (5, 3)\n",
      "┌──────────┬─────────────────────────────────┬──────────┐\n",
      "│ Id       ┆ ranker_id                       ┆ selected │\n",
      "│ ---      ┆ ---                             ┆ ---      │\n",
      "│ i64      ┆ str                             ┆ i32      │\n",
      "╞══════════╪═════════════════════════════════╪══════════╡\n",
      "│ 18144679 ┆ c9373e5f772e43d593dd6ad2fa90f6… ┆ 7        │\n",
      "│ 18144680 ┆ c9373e5f772e43d593dd6ad2fa90f6… ┆ 19       │\n",
      "│ 18144681 ┆ c9373e5f772e43d593dd6ad2fa90f6… ┆ 245      │\n",
      "│ 18144682 ┆ c9373e5f772e43d593dd6ad2fa90f6… ┆ 69       │\n",
      "│ 18144683 ┆ c9373e5f772e43d593dd6ad2fa90f6… ┆ 78       │\n",
      "└──────────┴─────────────────────────────────┴──────────┘\n"
     ]
    }
   ],
   "source": [
    "import polars as pl\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import spearmanr\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "def load_submission_with_confidence(tag):\n",
    "    df = pl.read_parquet(f\"./ensemble/submission_{tag}_with_confidence.parquet\").drop(\n",
    "        \"selected\"\n",
    "    )\n",
    "    return df\n",
    "\n",
    "\n",
    "# 模型和分数配置\n",
    "timetag_score = {\n",
    "    \"20250721025740\": [0, 0.51960],\n",
    "    \"20250722050939\": [1, 0.52070],\n",
    "    \"20250721083807\": [1, 0.52244],\n",
    "    \"20250724032338\": [1, 0.51345],\n",
    "    \"20250725083055\": [1, 0.52391],\n",
    "    \"20250727084025\": [1, 0.52795],\n",
    "    \"20250728094305\": [1, 0.52492],\n",
    "    \"20250729084249\": [1, 0.51822],\n",
    "    \"0.49242\": [1, 0.49242],\n",
    "}\n",
    "\n",
    "# 载入数据，重命名 confidence 列\n",
    "dfs = []\n",
    "for timetag, score_list in timetag_score.items():\n",
    "    df = load_submission_with_confidence(timetag)\n",
    "    _, score = score_list\n",
    "    score = float(score)\n",
    "    df = df.with_columns(pl.col(\"confidence\").alias(f\"confidence_{score}\")).drop(\n",
    "        \"confidence\"\n",
    "    )\n",
    "    dfs.append(df)\n",
    "\n",
    "# 合并所有模型结果\n",
    "df_combined = dfs[0]\n",
    "for i in range(1, len(dfs)):\n",
    "    df_combined = df_combined.join(dfs[i], on=[\"Id\", \"ranker_id\"])\n",
    "\n",
    "# 提取所有 confidence 列名和对应数据矩阵\n",
    "confidence_cols = [col for col in df_combined.columns if col.startswith(\"confidence\")]\n",
    "X = df_combined.select(confidence_cols).to_numpy()\n",
    "\n",
    "# 计算 Spearman 相关性矩阵和权重\n",
    "corr_mat = np.zeros((len(confidence_cols), len(confidence_cols)))\n",
    "for i in range(len(confidence_cols)):\n",
    "    for j in range(i, len(confidence_cols)):\n",
    "        corr, _ = spearmanr(X[:, i], X[:, j])\n",
    "        if np.isnan(corr):\n",
    "            corr = 0\n",
    "        corr_mat[i, j] = corr\n",
    "        corr_mat[j, i] = corr\n",
    "\n",
    "mean_corr = corr_mat.mean(axis=1)\n",
    "model_uniqueness = 1 - mean_corr.clip(-1, 1)\n",
    "spearman_weights = model_uniqueness / model_uniqueness.sum()\n",
    "\n",
    "print(\"Spearman 权重:\")\n",
    "for col, w in zip(confidence_cols, spearman_weights):\n",
    "    print(f\"{col}: {w:.4f}\")\n",
    "\n",
    "# 把 Spearman 权重扩展成和 X 同行数，拼接成增强矩阵\n",
    "weights_repeated = np.tile(spearman_weights, (X.shape[0], 1))\n",
    "X_enhanced = np.hstack([X, weights_repeated])  # shape (样本数, 2 * 模型数)\n",
    "\n",
    "# 用增强特征做 PCA 融合\n",
    "pca = PCA(n_components=1)\n",
    "pc1_scores = pca.fit_transform(X_enhanced).flatten()\n",
    "\n",
    "print(\"\\nPCA 各模型权重（前半段是原始模型列，后半段是权重列）:\")\n",
    "for i, col in enumerate(confidence_cols):\n",
    "    print(f\"{col}: {pca.components_[0][i]:.4f}\")\n",
    "for i in range(len(confidence_cols)):\n",
    "    print(f\"weight_{i}: {pca.components_[0][len(confidence_cols)+i]:.4f}\")\n",
    "\n",
    "# 添加融合得分\n",
    "df_combined = df_combined.with_columns(pl.Series(\"ensemble_confidence\", pc1_scores))\n",
    "\n",
    "# 组内排名（score越大越靠前）\n",
    "df_ranked = df_combined.with_columns(\n",
    "    pl.col(\"ensemble_confidence\")\n",
    "    .rank(method=\"ordinal\", descending=True)\n",
    "    .over(\"ranker_id\")\n",
    "    .cast(pl.Int32)\n",
    "    .alias(\"selected\")\n",
    ")\n",
    "\n",
    "# 输出结果\n",
    "df_original = dfs[0].select([\"Id\", \"ranker_id\"])\n",
    "final_submission = df_original.join(\n",
    "    df_ranked.select([\"Id\", \"ranker_id\", \"selected\"]),\n",
    "    on=[\"Id\", \"ranker_id\"],\n",
    "    how=\"left\",\n",
    ")\n",
    "\n",
    "print(\"\\n最终融合排序结果示例:\")\n",
    "print(final_submission.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fda7ac01",
   "metadata": {},
   "source": [
    "## Ensemble of ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "8d907f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "\n",
    "\n",
    "def load_submission_with_confidence(tag):\n",
    "    df = pl.read_parquet(f\"./ensemble/submission_{tag}_with_confidence.parquet\")\n",
    "    df = df.drop(\"selected\")\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def combine_same_model(timetag_score: dict):\n",
    "    dfs = []\n",
    "    for timetag, score_list in timetag_score.items():\n",
    "        df = load_submission_with_confidence(timetag)\n",
    "        weight, score = score_list\n",
    "        df = df.with_columns((pl.col(\"confidence\")).alias(f\"confidence_{score}\")).drop(\n",
    "            \"confidence\"\n",
    "        )\n",
    "        dfs.append(df)\n",
    "\n",
    "    df_combined = dfs[0]\n",
    "    for i in range(1, len(dfs)):\n",
    "        df_combined = df_combined.join(dfs[i], on=[\"Id\", \"ranker_id\"])\n",
    "\n",
    "    return df_combined, dfs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "9f8e685f",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_score = {\n",
    "    \"20250721083807\": [1, 0.52244],\n",
    "    \"20250725083055\": [1, 0.52391],\n",
    "    \"20250727084025\": [1, 0.52795],\n",
    "    \"20250802074816\": [1, 0.52603],\n",
    "    \"20250807032439\": [1, 0.52538],\n",
    "}\n",
    "\n",
    "lgb_score = {\n",
    "    # \"20250720003111\": [0, 0.50693],\n",
    "    \"20250724032338\": [1, 0.51345],\n",
    "    \"20250804001151\": [1, 0.51244],\n",
    "    # \"20250805032352\": [1, 0.51143],\n",
    "}\n",
    "\n",
    "dlr_score = {\n",
    "    \"dl_ranker\": [1, 0.48755],\n",
    "    # \"0.49380\": [1, 0.49380],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "b3d3ab33",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_combined, anchor = combine_same_model(xgb_score)\n",
    "lgb_combined, _ = combine_same_model(lgb_score)\n",
    "dlr_combined, _ = combine_same_model(dlr_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "5392c53e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (5, 3)\n",
      "┌──────────┬─────────────────────────────────┬──────────────────────┐\n",
      "│ Id       ┆ ranker_id                       ┆ xgb_confidence_fused │\n",
      "│ ---      ┆ ---                             ┆ ---                  │\n",
      "│ i64      ┆ str                             ┆ f64                  │\n",
      "╞══════════╪═════════════════════════════════╪══════════════════════╡\n",
      "│ 18144679 ┆ c9373e5f772e43d593dd6ad2fa90f6… ┆ 0.984909             │\n",
      "│ 18144680 ┆ c9373e5f772e43d593dd6ad2fa90f6… ┆ 0.912308             │\n",
      "│ 18144681 ┆ c9373e5f772e43d593dd6ad2fa90f6… ┆ 0.375555             │\n",
      "│ 18144682 ┆ c9373e5f772e43d593dd6ad2fa90f6… ┆ 0.858067             │\n",
      "│ 18144683 ┆ c9373e5f772e43d593dd6ad2fa90f6… ┆ 0.809281             │\n",
      "└──────────┴─────────────────────────────────┴──────────────────────┘\n",
      "shape: (5, 3)\n",
      "┌──────────┬─────────────────────────────────┬──────────────────────┐\n",
      "│ Id       ┆ ranker_id                       ┆ lgb_confidence_fused │\n",
      "│ ---      ┆ ---                             ┆ ---                  │\n",
      "│ i64      ┆ str                             ┆ f64                  │\n",
      "╞══════════╪═════════════════════════════════╪══════════════════════╡\n",
      "│ 18144679 ┆ c9373e5f772e43d593dd6ad2fa90f6… ┆ 0.958664             │\n",
      "│ 18144680 ┆ c9373e5f772e43d593dd6ad2fa90f6… ┆ 0.905136             │\n",
      "│ 18144681 ┆ c9373e5f772e43d593dd6ad2fa90f6… ┆ 0.425853             │\n",
      "│ 18144682 ┆ c9373e5f772e43d593dd6ad2fa90f6… ┆ 0.936764             │\n",
      "│ 18144683 ┆ c9373e5f772e43d593dd6ad2fa90f6… ┆ 0.839383             │\n",
      "└──────────┴─────────────────────────────────┴──────────────────────┘\n",
      "shape: (5, 3)\n",
      "┌──────────┬─────────────────────────────────┬──────────────────────┐\n",
      "│ Id       ┆ ranker_id                       ┆ dlr_confidence_fused │\n",
      "│ ---      ┆ ---                             ┆ ---                  │\n",
      "│ i64      ┆ str                             ┆ f64                  │\n",
      "╞══════════╪═════════════════════════════════╪══════════════════════╡\n",
      "│ 18144679 ┆ c9373e5f772e43d593dd6ad2fa90f6… ┆ 0.997567             │\n",
      "│ 18144680 ┆ c9373e5f772e43d593dd6ad2fa90f6… ┆ 0.77129              │\n",
      "│ 18144681 ┆ c9373e5f772e43d593dd6ad2fa90f6… ┆ 0.416058             │\n",
      "│ 18144682 ┆ c9373e5f772e43d593dd6ad2fa90f6… ┆ 0.995134             │\n",
      "│ 18144683 ┆ c9373e5f772e43d593dd6ad2fa90f6… ┆ 0.868613             │\n",
      "└──────────┴─────────────────────────────────┴──────────────────────┘\n"
     ]
    }
   ],
   "source": [
    "def weighted_confidence_fusion(df: pl.DataFrame, prefix: str) -> pl.DataFrame:\n",
    "    conf_cols = [col for col in df.columns if col.startswith(\"confidence_\")]\n",
    "\n",
    "    # 建立权重：根据列名中的 public LB 分数\n",
    "    weights = [float(col.split(\"_\")[1]) for col in conf_cols]\n",
    "    weights = [w / sum(weights) for w in weights]\n",
    "\n",
    "    # 加权求和\n",
    "    weighted_sum_expr = sum(\n",
    "        pl.col(col) * weight for col, weight in zip(conf_cols, weights)\n",
    "    )\n",
    "    fused_col = f\"{prefix}_confidence_fused\"\n",
    "\n",
    "    return df.with_columns(weighted_sum_expr.alias(fused_col)).select(\n",
    "        [\"Id\", \"ranker_id\", fused_col]\n",
    "    )\n",
    "\n",
    "\n",
    "xgb_fused = weighted_confidence_fusion(xgb_combined, \"xgb\")\n",
    "lgb_fused = weighted_confidence_fusion(lgb_combined, \"lgb\")\n",
    "dlr_fused = weighted_confidence_fusion(dlr_combined, \"dlr\")\n",
    "print(xgb_fused.head())\n",
    "print(lgb_fused.head())\n",
    "print(dlr_fused.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "eeb6ee85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (5, 6)\n",
      "┌──────────┬─────────────────┬─────────────────┬─────────────────┬────────────────┬────────────────┐\n",
      "│ Id       ┆ ranker_id       ┆ xgb_confidence_ ┆ lgb_confidence_ ┆ dlr_confidence ┆ final_confiden │\n",
      "│ ---      ┆ ---             ┆ fused           ┆ fused           ┆ _fused         ┆ ce             │\n",
      "│ i64      ┆ str             ┆ ---             ┆ ---             ┆ ---            ┆ ---            │\n",
      "│          ┆                 ┆ f64             ┆ f64             ┆ f64            ┆ f64            │\n",
      "╞══════════╪═════════════════╪═════════════════╪═════════════════╪════════════════╪════════════════╡\n",
      "│ 18144679 ┆ c9373e5f772e43d ┆ 0.984909        ┆ 0.958664        ┆ 0.997567       ┆ 0.980833       │\n",
      "│          ┆ 593dd6ad2fa90f6 ┆                 ┆                 ┆                ┆                │\n",
      "│          ┆ …               ┆                 ┆                 ┆                ┆                │\n",
      "│ 18144680 ┆ c9373e5f772e43d ┆ 0.912308        ┆ 0.905136        ┆ 0.77129        ┆ 0.867851       │\n",
      "│          ┆ 593dd6ad2fa90f6 ┆                 ┆                 ┆                ┆                │\n",
      "│          ┆ …               ┆                 ┆                 ┆                ┆                │\n",
      "│ 18144681 ┆ c9373e5f772e43d ┆ 0.375555        ┆ 0.425853        ┆ 0.416058       ┆ 0.402796       │\n",
      "│          ┆ 593dd6ad2fa90f6 ┆                 ┆                 ┆                ┆                │\n",
      "│          ┆ …               ┆                 ┆                 ┆                ┆                │\n",
      "│ 18144682 ┆ c9373e5f772e43d ┆ 0.858067        ┆ 0.936764        ┆ 0.995134       ┆ 0.922796       │\n",
      "│          ┆ 593dd6ad2fa90f6 ┆                 ┆                 ┆                ┆                │\n",
      "│          ┆ …               ┆                 ┆                 ┆                ┆                │\n",
      "│ 18144683 ┆ c9373e5f772e43d ┆ 0.809281        ┆ 0.839383        ┆ 0.868613       ┆ 0.836111       │\n",
      "│          ┆ 593dd6ad2fa90f6 ┆                 ┆                 ┆                ┆                │\n",
      "│          ┆ …               ┆                 ┆                 ┆                ┆                │\n",
      "└──────────┴─────────────────┴─────────────────┴─────────────────┴────────────────┴────────────────┘\n"
     ]
    }
   ],
   "source": [
    "ensemble_df = xgb_fused.join(lgb_fused, on=[\"Id\", \"ranker_id\"]).join(\n",
    "    dlr_fused, on=[\"Id\", \"ranker_id\"]\n",
    ")\n",
    "\n",
    "group_weights = {\n",
    "    \"xgb\": 0.4,\n",
    "    \"lgb\": 0.3,\n",
    "    \"dlr\": 0.3,\n",
    "}\n",
    "\n",
    "ensemble_df = ensemble_df.with_columns(\n",
    "    (\n",
    "        pl.col(\"xgb_confidence_fused\") * group_weights[\"xgb\"]\n",
    "        + pl.col(\"lgb_confidence_fused\") * group_weights[\"lgb\"]\n",
    "        + pl.col(\"dlr_confidence_fused\") * group_weights[\"dlr\"]\n",
    "    ).alias(\"final_confidence\")\n",
    ")\n",
    "print(ensemble_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "0b00cc31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (5, 4)\n",
      "┌──────────┬─────────────────────────────────┬──────────────────┬──────────┐\n",
      "│ Id       ┆ ranker_id                       ┆ final_confidence ┆ selected │\n",
      "│ ---      ┆ ---                             ┆ ---              ┆ ---      │\n",
      "│ i64      ┆ str                             ┆ f64              ┆ i32      │\n",
      "╞══════════╪═════════════════════════════════╪══════════════════╪══════════╡\n",
      "│ 18144679 ┆ c9373e5f772e43d593dd6ad2fa90f6… ┆ 0.980833         ┆ 2        │\n",
      "│ 18144680 ┆ c9373e5f772e43d593dd6ad2fa90f6… ┆ 0.867851         ┆ 36       │\n",
      "│ 18144681 ┆ c9373e5f772e43d593dd6ad2fa90f6… ┆ 0.402796         ┆ 251      │\n",
      "│ 18144682 ┆ c9373e5f772e43d593dd6ad2fa90f6… ┆ 0.922796         ┆ 9        │\n",
      "│ 18144683 ┆ c9373e5f772e43d593dd6ad2fa90f6… ┆ 0.836111         ┆ 50       │\n",
      "└──────────┴─────────────────────────────────┴──────────────────┴──────────┘\n"
     ]
    }
   ],
   "source": [
    "df_fused = ensemble_df.select([\"Id\", \"ranker_id\", \"final_confidence\"])\n",
    "\n",
    "df_ranked = df_fused.with_columns(\n",
    "    pl.col(\"final_confidence\")\n",
    "    .rank(method=\"ordinal\", descending=True)\n",
    "    .over(\"ranker_id\")\n",
    "    .cast(pl.Int32)\n",
    "    .alias(\"selected\")\n",
    ")\n",
    "print(df_ranked.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "821dc53b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (5, 3)\n",
      "┌──────────┬─────────────────────────────────┬──────────┐\n",
      "│ Id       ┆ ranker_id                       ┆ selected │\n",
      "│ ---      ┆ ---                             ┆ ---      │\n",
      "│ i64      ┆ str                             ┆ i32      │\n",
      "╞══════════╪═════════════════════════════════╪══════════╡\n",
      "│ 18144679 ┆ c9373e5f772e43d593dd6ad2fa90f6… ┆ 2        │\n",
      "│ 18144680 ┆ c9373e5f772e43d593dd6ad2fa90f6… ┆ 36       │\n",
      "│ 18144681 ┆ c9373e5f772e43d593dd6ad2fa90f6… ┆ 251      │\n",
      "│ 18144682 ┆ c9373e5f772e43d593dd6ad2fa90f6… ┆ 9        │\n",
      "│ 18144683 ┆ c9373e5f772e43d593dd6ad2fa90f6… ┆ 50       │\n",
      "└──────────┴─────────────────────────────────┴──────────┘\n"
     ]
    }
   ],
   "source": [
    "df_original = anchor.select([\"Id\", \"ranker_id\"])\n",
    "\n",
    "# Join and keep only required columns in original order\n",
    "final_submission = df_original.join(\n",
    "    df_ranked.select([\"Id\", \"ranker_id\", \"selected\"]),\n",
    "    on=[\"Id\", \"ranker_id\"],\n",
    "    how=\"left\",\n",
    ")\n",
    "print(final_submission.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "05b60a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_submission.write_parquet(\"./submission_ensemble_ensemble.parquet\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FlightRank",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
