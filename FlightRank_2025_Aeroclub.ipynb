{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "cry-TK2QTJGq",
        "DjjP98zIPc5h",
        "cVFXqC6lhA4S",
        "-ZCzqZ2oSsZW",
        "H6Of0JvmhD1C",
        "m55y1aYkEuFd",
        "G3CzHTL83-yN",
        "SFrfi9fHZtv1",
        "QyWQ3D2YZ3VP",
        "d_L8L_DcCkcH",
        "IMPtcQCq33sN",
        "20-hwDQkIMoE",
        "6ARgO8-HH0aD"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "https://www.kaggle.com/competitions/aeroclub-recsys-2025/overview"
      ],
      "metadata": {
        "id": "p6_gBe21TGq7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2>Summary for Preprocessing & Imputation:<h2>\n",
        "\n",
        "- I checked which columns had missing values and calculated the percentage of missing data for each.\n",
        "\n",
        "- Where the percentage was very low, I applied simple rules (e.g., replacing with the median, replacing with random values to preserve the distribution, etc.).\n",
        "\n",
        "- Where the percentage was high, I decided to impute the missing values. I tested various techniques using validation imputation, and found that XGBClassifier/XGBRegressor produced very good metrics (96%‚Äì99% accuracy, F1 score).\n",
        "\n",
        "- For each column, I identified the most correlated/informative columns and used them to train an XGBClassifier/XGBRegressor model to impute the missing values.\n",
        "\n",
        "- For the duration-related columns (arrivalAt, departureAt), I used datetime and extracted more informative features such as hour, day, month, minute, etc.\n",
        "\n",
        "- For the column that determines the flight duration, I directly converted the format into minutes to make it easier to use later.\n",
        "\n",
        "- I removed the column legs1_segments0_flightNumber because it contains over 5,000 unique classes and is very memory-intensive for models like XGBClassifier.\n",
        "\n",
        "- I also removed all columns with more than 78% missing values.\n",
        "\n",
        "Considerations:\n",
        "\n",
        "- XGBClassifier/XGBRegressor are not very sensitive to the encoding of categorical numerical values. However, if I were to repeat the process, I would also encode the columns used for imputing missing values in order to take advantage of the additional 1‚Äì2% performance improvement."
      ],
      "metadata": {
        "id": "kIvA42hHhO5q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Preprocessing & Imputation 1**"
      ],
      "metadata": {
        "id": "cry-TK2QTJGq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gjzbk2GES_4z",
        "outputId": "f71e131c-7e06-484b-c32b-9be3faa9132d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting nan_report.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile nan_report.py\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# Function to load a file based on its extension\n",
        "def load_file(filename):\n",
        "    ext = os.path.splitext(filename)[1].lower()\n",
        "    if ext == '.csv':\n",
        "        return pd.read_csv(filename, low_memory=False)\n",
        "    elif ext == '.parquet':\n",
        "        return pd.read_parquet(filename)\n",
        "    else:\n",
        "        raise ValueError(f\"Unsupported file extension: {ext}\")\n",
        "\n",
        "# Function that returns a string with NaN percentages\n",
        "def get_nan_report(df, name):\n",
        "    nan_percent = df.isna().mean() * 100\n",
        "    nan_percent = nan_percent[nan_percent > 0].sort_values(ascending=False)\n",
        "    report = f\"NaN percentage in {name}:\\n\"\n",
        "    report += nan_percent.to_string()\n",
        "    return report\n",
        "\n",
        "# Load files (adjust filenames as needed)\n",
        "train = load_file('train.parquet')  # or 'train.parquet'\n",
        "test = load_file('test.parquet')    # or 'test.parquet'\n",
        "\n",
        "# Generate reports\n",
        "train_report = get_nan_report(train, 'train')\n",
        "test_report = get_nan_report(test, 'test')\n",
        "\n",
        "# Write to .txt file\n",
        "with open('nan_report.txt', 'w') as f:\n",
        "    f.write(train_report + \"\\n\\n\" + test_report)\n",
        "\n",
        "print(\"Report saved to 'nan_report.txt'\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile summary.py\n",
        "import pandas as pd\n",
        "\n",
        "# Column to analyze\n",
        "feature_name = \"legs0_segments0_arrivalTo_airport_iata\"\n",
        "\n",
        "# Load datasets\n",
        "\n",
        "train = pd.read_csv(\"train.csv\", low_memory=False)\n",
        "test = pd.read_csv(\"test.csv\", low_memory=False)\n",
        "\n",
        "report = []\n",
        "\n",
        "def get_feature_report(df, dataset_name):\n",
        "    if feature_name not in df.columns:\n",
        "        return f\"{dataset_name}: Column '{feature_name}' not found.\\n\"\n",
        "\n",
        "    col = df[feature_name]\n",
        "    total = len(col)\n",
        "    missing = col.isna().sum()\n",
        "    pct_missing = missing / total * 100\n",
        "    nunique = col.nunique(dropna=True)\n",
        "    dtype = col.dtype\n",
        "\n",
        "    section = [\n",
        "        f\"üìä Dataset: {dataset_name}\",\n",
        "        f\"Column: {feature_name}\",\n",
        "        f\"Data type: {dtype}\",\n",
        "        f\"Total rows: {total:,}\",\n",
        "        f\"Missing values: {missing:,} ({pct_missing:.6f}%)\",\n",
        "        f\"Unique values (non-null): {nunique:,}\"\n",
        "    ]\n",
        "\n",
        "    if pd.api.types.is_numeric_dtype(col):\n",
        "        section.append(\"\\nüîπ Descriptive statistics:\")\n",
        "        section.append(str(col.describe()))\n",
        "    else:\n",
        "        section.append(\"\\nüîπ Top 5 most frequent values:\")\n",
        "        section.append(str(col.value_counts(dropna=True).head()))\n",
        "\n",
        "    return \"\\n\".join(section)\n",
        "\n",
        "# Build report\n",
        "report.append(get_feature_report(train, \"Train\"))\n",
        "report.append(\"\\n\" + \"=\" * 60 + \"\\n\")\n",
        "report.append(get_feature_report(test, \"Test\"))\n",
        "\n",
        "# Save to file\n",
        "output = \"\\n\".join(report)\n",
        "filename = f\"{feature_name}_summary.txt\"\n",
        "\n",
        "with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(output)\n",
        "\n",
        "print(f\"‚úÖ Summary saved to '{filename}'\")"
      ],
      "metadata": {
        "id": "SPynfo0ITOgY",
        "outputId": "ff9c08b6-d081-4c10-a467-408cdc136465",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing summary.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile summary.py\n",
        "import pandas as pd\n",
        "\n",
        "# Column to analyze\n",
        "feature_name = \"frequentFlyer\"\n",
        "\n",
        "# Load datasets from parquet\n",
        "train = pd.read_parquet(\"train.parquet\")\n",
        "test = pd.read_parquet(\"test.parquet\")\n",
        "\n",
        "report = []\n",
        "\n",
        "def get_feature_report(df, dataset_name):\n",
        "    if feature_name not in df.columns:\n",
        "        return f\"{dataset_name}: Column '{feature_name}' not found.\\n\"\n",
        "\n",
        "    col = df[feature_name]\n",
        "    total = len(col)\n",
        "    missing = col.isna().sum()\n",
        "    pct_missing = missing / total * 100\n",
        "    nunique = col.nunique(dropna=True)\n",
        "    dtype = col.dtype\n",
        "\n",
        "    section = [\n",
        "        f\"üìä Dataset: {dataset_name}\",\n",
        "        f\"Column: {feature_name}\",\n",
        "        f\"Data type: {dtype}\",\n",
        "        f\"Total rows: {total:,}\",\n",
        "        f\"Missing values: {missing:,} ({pct_missing:.6f}%)\",\n",
        "        f\"Unique values (non-null): {nunique:,}\"\n",
        "    ]\n",
        "\n",
        "    if pd.api.types.is_numeric_dtype(col):\n",
        "        section.append(\"\\nüîπ Descriptive statistics:\")\n",
        "        section.append(str(col.describe()))\n",
        "    else:\n",
        "        section.append(\"\\nüîπ All unique values (with counts):\")\n",
        "        section.append(str(col.value_counts(dropna=True).to_string()))\n",
        "\n",
        "    return \"\\n\".join(section)\n",
        "\n",
        "# Build report\n",
        "report.append(get_feature_report(train, \"Train\"))\n",
        "report.append(\"\\n\" + \"=\" * 60 + \"\\n\")\n",
        "report.append(get_feature_report(test, \"Test\"))\n",
        "\n",
        "# Save to file\n",
        "output = \"\\n\".join(report)\n",
        "filename = f\"{feature_name}_summary.txt\"\n",
        "\n",
        "with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(output)\n",
        "\n",
        "print(f\"‚úÖ Summary saved to '{filename}'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O_VbIYKUTRP-",
        "outputId": "8dba5871-dbd2-4082-adc4-62b3275035da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing summary.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile impute_legs0_segments0_arrivalTo_airport_iata.py\n",
        "import pandas as pd\n",
        "\n",
        "# Load train.csv\n",
        "train = pd.read_csv(\"train.csv\", low_memory=False)\n",
        "\n",
        "# Target column\n",
        "col = \"legs0_segments0_arrivalTo_airport_iata\"\n",
        "\n",
        "# Fill missing values with \"MISSING\"\n",
        "train[col] = train[col].fillna(\"MISSING\")\n",
        "\n",
        "# Overwrite the original train.csv file\n",
        "train.to_csv(\"train.csv\", index=False)\n",
        "\n",
        "print(f\"Missing values in '{col}' have been filled with 'MISSING' and saved back to 'train.csv'.\")"
      ],
      "metadata": {
        "id": "O9MlYuLRTPhQ",
        "outputId": "e188af97-9625-4e0e-c14b-33564040be19",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing impute_legs0_segments0_arrivalTo_airport_iata.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile impute_legs0_segments0_aircraft_code.py\n",
        "import pandas as pd\n",
        "\n",
        "# Load train.csv\n",
        "train = pd.read_csv(\"train.csv\", low_memory=False)\n",
        "\n",
        "# Target column\n",
        "col = \"legs0_segments0_aircraft_code\"\n",
        "\n",
        "# Fill missing values with \"MISSING\"\n",
        "train[col] = train[col].fillna(\"MISSING\")\n",
        "\n",
        "# Overwrite the original train.csv file\n",
        "train.to_csv(\"train.csv\", index=False)\n",
        "\n",
        "print(f\"Missing values in '{col}' have been filled with 'MISSING' and saved back to 'train.csv'.\")"
      ],
      "metadata": {
        "id": "dLJ4pHMdTQZ5",
        "outputId": "7c44ce9f-d399-4179-d6f0-4b97fb0f35b0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing impute_legs0_segments0_aircraft_code.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile impute_legs0_segments0_departureFrom_airport_iata.py\n",
        "import pandas as pd\n",
        "\n",
        "# Load train.csv\n",
        "train = pd.read_csv(\"train.csv\", low_memory=False)\n",
        "\n",
        "# Target column\n",
        "col = \"legs0_segments0_departureFrom_airport_iata\"\n",
        "\n",
        "# Fill missing values with \"MISSING\"\n",
        "train[col] = train[col].fillna(\"MISSING\")\n",
        "\n",
        "# Overwrite the original train.csv file\n",
        "train.to_csv(\"train.csv\", index=False)\n",
        "\n",
        "print(f\"Missing values in '{col}' have been filled with 'MISSING' and saved back to 'train.csv'.\")"
      ],
      "metadata": {
        "id": "9DmnHayVTRGo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile impute_legs0_segments0_arrivalTo_airport_city_iata.py\n",
        "import pandas as pd\n",
        "\n",
        "# Load datasets\n",
        "train = pd.read_csv(\"train.csv\", low_memory=False)\n",
        "test = pd.read_csv(\"test.csv\", low_memory=False)\n",
        "\n",
        "# Target column\n",
        "col = \"legs0_segments0_arrivalTo_airport_city_iata\"\n",
        "\n",
        "# Impute missing values with \"MISSING\"\n",
        "train[col] = train[col].fillna(\"MISSING\")\n",
        "test[col] = test[col].fillna(\"MISSING\")\n",
        "\n",
        "# Save back\n",
        "train.to_csv(\"train.csv\", index=False)\n",
        "test.to_csv(\"test.csv\", index=False)\n",
        "\n",
        "print(f\"Missing values in '{col}' have been filled with 'MISSING' in both train and test datasets.\")"
      ],
      "metadata": {
        "id": "zSqsKxk3TRm5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile analyze_baggage_quantity_by_type.py\n",
        "import pandas as pd\n",
        "\n",
        "# Load train.csv (fƒÉrƒÉ modificƒÉri)\n",
        "df = pd.read_csv(\"train.csv\", low_memory=False)\n",
        "\n",
        "# Column names\n",
        "qty_col = \"legs0_segments0_baggageAllowance_quantity\"\n",
        "type_col = \"legs0_segments0_baggageAllowance_weightMeasurementType\"\n",
        "\n",
        "# Filter rows where both values are present\n",
        "df_filtered = df[[qty_col, type_col]].dropna()\n",
        "\n",
        "# Grouped statistics\n",
        "grouped_stats = df_filtered.groupby(type_col)[qty_col].describe()\n",
        "\n",
        "# Format output\n",
        "lines = []\n",
        "lines.append(\"üìä Baggage Allowance Quantity Statistics by Measurement Type\\n\")\n",
        "\n",
        "for measurement_type, stats in grouped_stats.iterrows():\n",
        "    type_label = \"PIECE (0.0)\" if measurement_type == 0.0 else \"WEIGHT (1.0)\"\n",
        "    lines.append(f\"\\n‚ñ∂Ô∏è Type: {type_label}\")\n",
        "    lines.append(stats.to_string())\n",
        "\n",
        "# Save to TXT\n",
        "output_file = \"baggage_quantity_by_type_stats.txt\"\n",
        "with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(\"\\n\".join(lines))\n",
        "\n",
        "print(f\"‚úÖ Analysis saved to '{output_file}'\")"
      ],
      "metadata": {
        "id": "BewDttZTTSbK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile nan_in_the_same_time.py\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"train.csv\", low_memory=False)\n",
        "\n",
        "qty_col = \"legs0_segments0_baggageAllowance_quantity\"\n",
        "type_col = \"legs0_segments0_baggageAllowance_weightMeasurementType\"\n",
        "\n",
        "missing_qty = df[qty_col].isna()\n",
        "missing_type = df[type_col].isna()\n",
        "\n",
        "print(f\"‚ùì Missing only in quantity: {((missing_qty) & (~missing_type)).sum()}\")\n",
        "print(f\"‚ùì Missing only in type:     {((missing_type) & (~missing_qty)).sum()}\")\n",
        "print(f\"‚úÖ Missing in both:         {((missing_qty) & (missing_type)).sum()}\")\n",
        "print(f\"‚ÑπÔ∏è Total missing in quantity: {missing_qty.sum()}\")\n",
        "print(f\"‚ÑπÔ∏è Total missing in type:     {missing_type.sum()}\")"
      ],
      "metadata": {
        "id": "-2i8EHFOTT9h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "‚ùì Missing only in quantity: 0\n",
        "\n",
        "‚ùì Missing only in type:     0\n",
        "\n",
        "‚úÖ Missing in both:         1064\n",
        "\n",
        "‚ÑπÔ∏è Total missing in quantity: 1064\n",
        "\n",
        "‚ÑπÔ∏è Total missing in type:     1064"
      ],
      "metadata": {
        "id": "HkLcuaMETU8T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile add_baggage_missing_flag.py\n",
        "import pandas as pd\n",
        "\n",
        "# Column names\n",
        "qty_col = \"legs0_segments0_baggageAllowance_quantity\"\n",
        "type_col = \"legs0_segments0_baggageAllowance_weightMeasurementType\"\n",
        "flag_col = \"legs0_segments0_baggageAllowance_missing_initially\"\n",
        "\n",
        "def process_file(path, name):\n",
        "    df = pd.read_csv(path, low_memory=False)\n",
        "\n",
        "    # Create flag: 1 if both values are present, 0 if both are missing\n",
        "    df[flag_col] = (~df[qty_col].isna()) & (~df[type_col].isna())\n",
        "    df[flag_col] = df[flag_col].astype(int)\n",
        "\n",
        "    # Stats\n",
        "    total = len(df)\n",
        "    present = df[flag_col].sum()\n",
        "    missing = total - present\n",
        "    pct_present = present / total * 100\n",
        "    pct_missing = missing / total * 100\n",
        "\n",
        "    # Save updated CSV\n",
        "    df.to_csv(path, index=False)\n",
        "\n",
        "    # Return summary text\n",
        "    return f\"\"\"üìÅ {name}\n",
        "Total rows: {total:,}\n",
        "Rows with both values present (flag = 1): {present:,} ({pct_present:.6f}%)\n",
        "Rows with both values missing (flag = 0): {missing:,} ({pct_missing:.6f}%)\n",
        "\"\"\"\n",
        "\n",
        "# Process both files\n",
        "train_report = process_file(\"train.csv\", \"Train\")\n",
        "test_report = process_file(\"test.csv\", \"Test\")\n",
        "\n",
        "# Save report to text file\n",
        "with open(\"baggageAllowance_missing_flag_report.txt\", \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(\"üìä Baggage Allowance Initial Presence Report\\n\\n\")\n",
        "    f.write(train_report)\n",
        "    f.write(\"\\n\" + \"=\"*60 + \"\\n\\n\")\n",
        "    f.write(test_report)\n",
        "\n",
        "print(\"‚úÖ Column added to train.csv and test.csv.\")\n",
        "print(\"üìù Report saved to 'baggageAllowance_missing_flag_report.txt'\")"
      ],
      "metadata": {
        "id": "u8QAAM57TV3A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile impute_legs0_segments0_baggageAllowance.py\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "def impute_baggage(df):\n",
        "    # Columns of interest\n",
        "    quantity_col = 'legs0_segments0_baggageAllowance_quantity'\n",
        "    type_col = 'legs0_segments0_baggageAllowance_weightMeasurementType'\n",
        "\n",
        "    # Identify missing rows\n",
        "    missing_idx = df[df[quantity_col].isna()].index\n",
        "    n_missing = len(missing_idx)\n",
        "\n",
        "    if n_missing == 0:\n",
        "        return df\n",
        "\n",
        "    # 94% PIECE (1 item), 6% WEIGHT (30 kg)\n",
        "    n_piece = int(0.94 * n_missing)\n",
        "    n_weight = n_missing - n_piece\n",
        "\n",
        "    # Randomly assign indices\n",
        "    piece_idx = np.random.choice(missing_idx, size=n_piece, replace=False)\n",
        "    weight_idx = missing_idx.difference(piece_idx)\n",
        "\n",
        "    # Fill values\n",
        "    df.loc[piece_idx, quantity_col] = 1.0\n",
        "    df.loc[piece_idx, type_col] = 0.0\n",
        "\n",
        "    df.loc[weight_idx, quantity_col] = 30.0\n",
        "    df.loc[weight_idx, type_col] = 1.0\n",
        "\n",
        "    return df\n",
        "\n",
        "def report_missing(df, filename):\n",
        "    q_missing = df['legs0_segments0_baggageAllowance_quantity'].isna().sum()\n",
        "    t_missing = df['legs0_segments0_baggageAllowance_weightMeasurementType'].isna().sum()\n",
        "    print(f\"\\n‚úÖ After imputation in {filename}:\")\n",
        "    print(f\" - Missing quantity values: {q_missing}\")\n",
        "    print(f\" - Missing type values: {t_missing}\")\n",
        "\n",
        "# Apply to train.csv\n",
        "train = pd.read_csv(\"train.csv\")\n",
        "train = impute_baggage(train)\n",
        "report_missing(train, \"train.csv\")\n",
        "train.to_csv(\"train.csv\", index=False)\n",
        "\n",
        "# Apply to test.csv\n",
        "test = pd.read_csv(\"test.csv\")\n",
        "test = impute_baggage(test)\n",
        "report_missing(test, \"test.csv\")\n",
        "test.to_csv(\"test.csv\", index=False)"
      ],
      "metadata": {
        "id": "X71foRhiTWtU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile check_mixed_features.py\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"train.csv\", low_memory=False)\n",
        "\n",
        "mixed_type_columns = []\n",
        "\n",
        "for col in df.columns:\n",
        "    types = df[col].map(type).value_counts()\n",
        "    if len(types) > 1:\n",
        "        mixed_type_columns.append((col, types))\n",
        "\n",
        "# Save to a .txt file\n",
        "with open(\"mixed_type_columns_report.txt\", \"w\") as f:\n",
        "    for col, types in mixed_type_columns:\n",
        "        f.write(f\"\\nüîç Column: {col}\\n\")\n",
        "        f.write(types.to_string())\n",
        "        f.write(\"\\n\")"
      ],
      "metadata": {
        "id": "oLBrk7HaTXjZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile seatsAvailable_missing.py\n",
        "import pandas as pd\n",
        "\n",
        "# Load train.csv\n",
        "df = pd.read_csv(\"train.csv\", low_memory=False)\n",
        "\n",
        "# Create indicator column: 1 if value is present, 0 if missing\n",
        "df[\"legs0_segments0_seatsAvailable_missing_initially\"] = df[\"legs0_segments0_seatsAvailable\"].notna().astype(int)\n",
        "\n",
        "# Display distribution of the new column\n",
        "distribution = df[\"legs0_segments0_seatsAvailable_missing_initially\"].value_counts()\n",
        "print(\"üìä Distribution in 'legs0_segments0_seatsAvailable_missing_initially':\")\n",
        "print(distribution)\n",
        "\n",
        "# Save changes back to train.csv\n",
        "df.to_csv(\"train.csv\", index=False)\n",
        "\n",
        "print(\"\\n‚úÖ Column added and saved to train.csv.\")"
      ],
      "metadata": {
        "id": "ONrYPcNbTYbY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "legs0_segments0_seatsAvailable_missing_initially\n",
        "\n",
        "1    18065585\n",
        "\n",
        "0       79787\n",
        "\n",
        "Name: count, dtype: int64"
      ],
      "metadata": {
        "id": "7F9HYmTgTZ9I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile impute_legs0_segments0_seatsAvailable.py\n",
        "import pandas as pd\n",
        "\n",
        "# Load train.csv\n",
        "df = pd.read_csv(\"train.csv\", low_memory=False)\n",
        "\n",
        "# Compute median\n",
        "median_value = df[\"legs0_segments0_seatsAvailable\"].median()\n",
        "\n",
        "# Replace NaN with median\n",
        "df[\"legs0_segments0_seatsAvailable\"].fillna(median_value, inplace=True)\n",
        "\n",
        "# Save changes back to train.csv\n",
        "df.to_csv(\"train.csv\", index=False)\n",
        "\n",
        "print(f\"‚úÖ NaN values replaced with median ({median_value}) in 'legs0_segments0_seatsAvailable'.\")"
      ],
      "metadata": {
        "id": "05nXbnIoTZkf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile corr_pricingInfo_isAccessTP.py\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_selection import mutual_info_classif\n",
        "from multiprocessing import Pool, cpu_count\n",
        "\n",
        "# Load datasets\n",
        "train = pd.read_csv('train.csv')\n",
        "test = pd.read_csv('test.csv')\n",
        "\n",
        "# Target\n",
        "target = 'pricingInfo_isAccessTP'\n",
        "y_train = train[target]\n",
        "y_test = test[target]\n",
        "\n",
        "# Drop irrelevant columns\n",
        "drop_cols = [\n",
        "    'Id', 'profileId', '__index_level_0__', 'requestDate',\n",
        "    'searchRoute', 'legs0_arrivalAt', 'legs0_departureAt',\n",
        "    'legs1_arrivalAt', 'legs1_departureAt'\n",
        "]\n",
        "\n",
        "# Select numeric, common, clean columns\n",
        "common_cols = list(set(train.columns) & set(test.columns))\n",
        "numeric_cols = train[common_cols].select_dtypes(include=['float64', 'int64', 'bool']).columns\n",
        "numeric_cols = [col for col in numeric_cols if col not in drop_cols and col != target]\n",
        "numeric_cols = [\n",
        "    col for col in numeric_cols\n",
        "    if train[col].isnull().sum() == 0 and test[col].isnull().sum() == 0\n",
        "]\n",
        "\n",
        "X_train = train[numeric_cols]\n",
        "X_test = test[numeric_cols]\n",
        "\n",
        "# Fisher Score\n",
        "def fisher_score(X, y):\n",
        "    scores = {}\n",
        "    classes = np.unique(y.dropna())\n",
        "    for col in X.columns:\n",
        "        x = X[col]\n",
        "        mean_overall = x.mean()\n",
        "        numerator = 0\n",
        "        denominator = 0\n",
        "        for cls in classes:\n",
        "            xi = x[y == cls]\n",
        "            ni = len(xi)\n",
        "            mean_i = xi.mean()\n",
        "            var_i = xi.var()\n",
        "            numerator += ni * (mean_i - mean_overall) ** 2\n",
        "            denominator += ni * var_i\n",
        "        scores[col] = numerator / denominator if denominator != 0 else 0\n",
        "    return pd.Series(scores)\n",
        "\n",
        "# Score calculator by ID\n",
        "def compute_score(task_id):\n",
        "    if task_id == 1:\n",
        "        return \"PEARSON_TRAIN\", X_train.corrwith(y_train).sort_values(key=abs, ascending=False)\n",
        "    elif task_id == 2:\n",
        "        return \"FISHER_TRAIN\", fisher_score(X_train, y_train).sort_values(ascending=False)\n",
        "    elif task_id == 3:\n",
        "        return \"MI_TRAIN\", pd.Series(\n",
        "            mutual_info_classif(X_train, y_train.fillna(0), random_state=0),\n",
        "            index=X_train.columns\n",
        "        ).sort_values(ascending=False)\n",
        "    elif task_id == 4:\n",
        "        return \"PEARSON_TEST\", X_test.corrwith(y_test).sort_values(key=abs, ascending=False)\n",
        "    elif task_id == 5:\n",
        "        return \"FISHER_TEST\", fisher_score(X_test, y_test).sort_values(ascending=False)\n",
        "    elif task_id == 6:\n",
        "        return \"MI_TEST\", pd.Series(\n",
        "            mutual_info_classif(X_test, y_test.fillna(0), random_state=0),\n",
        "            index=X_test.columns\n",
        "        ).sort_values(ascending=False)\n",
        "\n",
        "# Launch parallel tasks\n",
        "if __name__ == \"__main__\":\n",
        "    with Pool(processes=min(6, cpu_count())) as pool:\n",
        "        results = pool.map(compute_score, [1, 2, 3, 4, 5, 6])\n",
        "\n",
        "    # Save results to file\n",
        "    with open(\"feature_scores_pricingInfo_isAccessTP.txt\", \"w\") as f:\n",
        "        for name, series in results:\n",
        "            f.write(f\"\\nüîπ TOP 15 FEATURES BY {name.replace('_', ' ')}\\n\")\n",
        "            f.write(series.head(15).to_string())\n",
        "            f.write(\"\\n\")\n",
        "\n",
        "    print(\"‚úÖ Parallel feature score results saved to 'feature_scores_pricingInfo_isAccessTP.txt'\")"
      ],
      "metadata": {
        "id": "FilwzyxnTb-v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile constants.py\n",
        "import pandas as pd\n",
        "\n",
        "# Load datasets with low_memory=False to avoid dtype warnings\n",
        "train = pd.read_csv('train.csv', low_memory=False)\n",
        "test = pd.read_csv('test.csv', low_memory=False)\n",
        "\n",
        "# Find constant columns (only one unique value including NaNs)\n",
        "constant_train = [col for col in train.columns if train[col].nunique(dropna=False) == 1]\n",
        "constant_test = [col for col in test.columns if test[col].nunique(dropna=False) == 1]\n",
        "\n",
        "# Find columns that are constant in both datasets\n",
        "constant_both = list(set(constant_train) & set(constant_test))\n",
        "\n",
        "# Save results to a .txt file\n",
        "with open(\"constant_columns.txt\", \"w\") as f:\n",
        "    f.write(\"üìå Constant columns in train.csv:\\n\")\n",
        "    f.write(\"\\n\".join(constant_train) + \"\\n\\n\")\n",
        "\n",
        "    f.write(\"üìå Constant columns in test.csv:\\n\")\n",
        "    f.write(\"\\n\".join(constant_test) + \"\\n\\n\")\n",
        "\n",
        "    f.write(\"‚úÖ Columns constant in BOTH train and test:\\n\")\n",
        "    f.write(\"\\n\".join(constant_both) + \"\\n\")\n",
        "\n",
        "print(\"‚úÖ Constant column results saved to 'constant_columns.txt'\")"
      ],
      "metadata": {
        "id": "psKDYfByTcw3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile test_imputation.py\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.experimental import enable_iterative_imputer  # noqa\n",
        "from sklearn.impute import IterativeImputer\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
        "import multiprocessing\n",
        "import time\n",
        "\n",
        "# === Start the timer ===\n",
        "start = time.time()\n",
        "\n",
        "# === Load and save a safe copy of the dataset ===\n",
        "train_original = pd.read_csv(\"train.csv\", low_memory=False)\n",
        "train_copy = train_original.copy(deep=True)\n",
        "\n",
        "# === Select relevant columns ===\n",
        "selected_features = [\n",
        "    'totalPrice',\n",
        "    'companyID',\n",
        "    'legs0_segments0_cabinClass',\n",
        "    'isAccess3D',\n",
        "    'isVip',\n",
        "    'legs0_segments0_seatsAvailable',\n",
        "    'legs0_segments0_flightNumber',\n",
        "    'taxes',\n",
        "    'legs0_segments0_baggageAllowance_quantity',\n",
        "    'legs0_segments0_baggageAllowance_weightMeasurementType'\n",
        "]\n",
        "cols_for_imputation = ['pricingInfo_isAccessTP'] + selected_features\n",
        "\n",
        "# === Filter rows with complete data ===\n",
        "df_known = train_copy[cols_for_imputation].dropna(subset=cols_for_imputation).copy()\n",
        "\n",
        "# === Select 10,000 random rows for validation ===\n",
        "sample_original = df_known.sample(n=10000, random_state=42)\n",
        "true_values = sample_original['pricingInfo_isAccessTP'].astype(int).copy()\n",
        "\n",
        "# === Create a masked version (with NaN) for the target column ===\n",
        "sample_masked = sample_original.copy()\n",
        "sample_masked['pricingInfo_isAccessTP'] = np.nan\n",
        "\n",
        "# === Remove these rows from df_known to avoid duplicates ===\n",
        "df_known = df_known.drop(sample_original.index, errors='ignore')\n",
        "\n",
        "# === Combine known + masked data for imputation ===\n",
        "df_for_imputation = pd.concat([df_known, sample_masked])\n",
        "df_for_imputation = df_for_imputation.sort_index()\n",
        "\n",
        "# === Create the imputer using Random Forest (with parallel processing) ===\n",
        "num_cores = 24\n",
        "imputer = IterativeImputer(\n",
        "    estimator=RandomForestRegressor(\n",
        "        n_estimators=100,\n",
        "        max_depth=10,\n",
        "        n_jobs=num_cores,\n",
        "        random_state=42\n",
        "    ),\n",
        "    max_iter=10,\n",
        "    initial_strategy='most_frequent',\n",
        "    random_state=42,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# === Run the imputation ===\n",
        "imputed_array = imputer.fit_transform(df_for_imputation)\n",
        "imputed_df = pd.DataFrame(imputed_array, columns=cols_for_imputation, index=df_for_imputation.index)\n",
        "\n",
        "# === Apply threshold for binary classification ===\n",
        "predicted = (imputed_df.loc[sample_masked.index, 'pricingInfo_isAccessTP'] >= 0.5).astype(int)\n",
        "\n",
        "# === Calculate metrics ===\n",
        "acc = accuracy_score(true_values, predicted)\n",
        "f1 = f1_score(true_values, predicted)\n",
        "cm = confusion_matrix(true_values, predicted)\n",
        "duration = round(time.time() - start, 2)\n",
        "\n",
        "# === Save results to file ===\n",
        "with open(\"imputation_results.txt\", \"w\") as f:\n",
        "    f.write(\"‚úÖ Imputation evaluation results (on sample of 10,000):\\n\")\n",
        "    f.write(f\"Accuracy: {acc:.4f}\\n\")\n",
        "    f.write(f\"F1 Score: {f1:.4f}\\n\")\n",
        "    f.write(\"Confusion Matrix:\\n\")\n",
        "    f.write(np.array2string(cm))\n",
        "    f.write(f\"\\n‚è±Ô∏è Duration: {duration} seconds\\n\")\n",
        "\n",
        "# === Print to console as well ===\n",
        "print(\"‚úÖ Results saved to imputation_results.txt\")\n"
      ],
      "metadata": {
        "id": "Za7N5nSpToa_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "‚úÖ Imputation evaluation results (on sample of 10,000):\n",
        "\n",
        "Accuracy: 0.8188\n",
        "\n",
        "F1 Score: 0.8221\n",
        "\n",
        "Confusion Matrix:\n",
        "\n",
        "[[4002 1079]\n",
        "\n",
        " [ 733 4186]]\n",
        "\n",
        "‚è±Ô∏è Duration: 4708.98 seconds\n"
      ],
      "metadata": {
        "id": "_jm1aMgVTq8X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile test_imputation.py\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.experimental import enable_iterative_imputer  # noqa\n",
        "from sklearn.impute import IterativeImputer\n",
        "from sklearn.ensemble import HistGradientBoostingRegressor\n",
        "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
        "import time\n",
        "\n",
        "# === Start the timer ===\n",
        "start = time.time()\n",
        "\n",
        "# === Load and save a safe copy of the dataset ===\n",
        "train_original = pd.read_csv(\"train.csv\", low_memory=False)\n",
        "train_copy = train_original.copy(deep=True)\n",
        "\n",
        "# === Select relevant columns ===\n",
        "selected_features = [\n",
        "    'totalPrice',\n",
        "    'companyID',\n",
        "    'legs0_segments0_cabinClass',\n",
        "    'isAccess3D',\n",
        "    'isVip',\n",
        "    'legs0_segments0_seatsAvailable',\n",
        "    'legs0_segments0_flightNumber',\n",
        "    'taxes',\n",
        "    'legs0_segments0_baggageAllowance_quantity',\n",
        "    'legs0_segments0_baggageAllowance_weightMeasurementType'\n",
        "]\n",
        "cols_for_imputation = ['pricingInfo_isAccessTP'] + selected_features\n",
        "\n",
        "# === Filter rows with complete data ===\n",
        "df_known = train_copy[cols_for_imputation].dropna(subset=cols_for_imputation).copy()\n",
        "\n",
        "# === Randomly select 10,000 rows for validation ===\n",
        "sample_original = df_known.sample(n=10000, random_state=42)\n",
        "true_values = sample_original['pricingInfo_isAccessTP'].astype(int).copy()\n",
        "\n",
        "# === Create a masked version (with NaN) for the target column ===\n",
        "sample_masked = sample_original.copy()\n",
        "sample_masked['pricingInfo_isAccessTP'] = np.nan\n",
        "\n",
        "# === Remove these rows from df_known to avoid duplicates ===\n",
        "df_known = df_known.drop(sample_original.index, errors='ignore')\n",
        "\n",
        "# === Combine known + masked data for imputation ===\n",
        "df_for_imputation = pd.concat([df_known, sample_masked])\n",
        "df_for_imputation = df_for_imputation.sort_index()\n",
        "\n",
        "# === Create the imputer with HistGradientBoostingRegressor ===\n",
        "imputer = IterativeImputer(\n",
        "    estimator=HistGradientBoostingRegressor(\n",
        "        max_iter=100,\n",
        "        max_depth=10,\n",
        "        random_state=42\n",
        "    ),\n",
        "    max_iter=10,\n",
        "    initial_strategy='most_frequent',\n",
        "    random_state=42,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# === Run the imputation ===\n",
        "imputed_array = imputer.fit_transform(df_for_imputation)\n",
        "imputed_df = pd.DataFrame(imputed_array, columns=cols_for_imputation, index=df_for_imputation.index)\n",
        "\n",
        "# === Apply threshold for binary classification ===\n",
        "predicted = (imputed_df.loc[sample_masked.index, 'pricingInfo_isAccessTP'] >= 0.5).astype(int)\n",
        "\n",
        "# === Calculate evaluation metrics ===\n",
        "acc = accuracy_score(true_values, predicted)\n",
        "f1 = f1_score(true_values, predicted)\n",
        "cm = confusion_matrix(true_values, predicted)\n",
        "duration = round(time.time() - start, 2)\n",
        "\n",
        "# === Save the results to a file ===\n",
        "with open(\"imputation_results.txt\", \"w\") as f:\n",
        "    f.write(\"‚úÖ Imputation evaluation results (HistGradientBoostingRegressor):\\n\")\n",
        "    f.write(f\"Accuracy: {acc:.4f}\\n\")\n",
        "    f.write(f\"F1 Score: {f1:.4f}\\n\")\n",
        "    f.write(\"Confusion Matrix:\\n\")\n",
        "    f.write(np.array2string(cm))\n",
        "    f.write(f\"\\n‚è±Ô∏è Duration: {duration} seconds\\n\")\n",
        "\n",
        "# === Also print the results to the console ===\n",
        "print(\"‚úÖ Results saved to imputation_results.txt\")\n"
      ],
      "metadata": {
        "id": "at_B2earTran"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "‚úÖ Imputation evaluation results (HistGradientBoostingRegressor):\n",
        "\n",
        "Accuracy: 0.8682\n",
        "\n",
        "F1 Score: 0.8671\n",
        "\n",
        "Confusion Matrix:\n",
        "\n",
        "[[4384  697]\n",
        "\n",
        " [ 621 4298]]\n",
        "\n",
        "‚è±Ô∏è Duration: 389.75 seconds"
      ],
      "metadata": {
        "id": "1biNF2p3T---"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile test_imputation.py\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.experimental import enable_iterative_imputer  # noqa\n",
        "from sklearn.impute import IterativeImputer\n",
        "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
        "import time\n",
        "from xgboost import XGBRegressor\n",
        "\n",
        "# === Start the timer ===\n",
        "start = time.time()\n",
        "\n",
        "# === Load and save a safe copy of the dataset ===\n",
        "train_original = pd.read_csv(\"train.csv\", low_memory=False)\n",
        "train_copy = train_original.copy(deep=True)\n",
        "\n",
        "# === Select relevant columns ===\n",
        "selected_features = [\n",
        "    'totalPrice',\n",
        "    'companyID',\n",
        "    'legs0_segments0_cabinClass',\n",
        "    'isAccess3D',\n",
        "    'isVip',\n",
        "    'legs0_segments0_seatsAvailable',\n",
        "    'legs0_segments0_flightNumber',\n",
        "    'taxes',\n",
        "    'legs0_segments0_baggageAllowance_quantity',\n",
        "    'legs0_segments0_baggageAllowance_weightMeasurementType'\n",
        "]\n",
        "cols_for_imputation = ['pricingInfo_isAccessTP'] + selected_features\n",
        "\n",
        "# === Filter rows with complete data ===\n",
        "df_known = train_copy[cols_for_imputation].dropna(subset=cols_for_imputation).copy()\n",
        "\n",
        "# === Randomly select 10,000 rows for validation ===\n",
        "sample_original = df_known.sample(n=10000, random_state=42)\n",
        "true_values = sample_original['pricingInfo_isAccessTP'].astype(int).copy()\n",
        "\n",
        "# === Create a masked version (with NaN) for the target column ===\n",
        "sample_masked = sample_original.copy()\n",
        "sample_masked['pricingInfo_isAccessTP'] = np.nan\n",
        "\n",
        "# === Remove these rows from df_known to avoid duplicates ===\n",
        "df_known = df_known.drop(sample_original.index, errors='ignore')\n",
        "\n",
        "# === Combine known + masked data for imputation ===\n",
        "df_for_imputation = pd.concat([df_known, sample_masked])\n",
        "df_for_imputation = df_for_imputation.sort_index()\n",
        "\n",
        "# === Create the imputer with XGBRegressor ===\n",
        "imputer = IterativeImputer(\n",
        "    estimator=XGBRegressor(\n",
        "        n_estimators=100,\n",
        "        max_depth=10,\n",
        "        learning_rate=0.1,\n",
        "        n_jobs=24,\n",
        "        tree_method='hist',\n",
        "        random_state=42,\n",
        "        verbosity=1\n",
        "    ),\n",
        "    max_iter=10,\n",
        "    initial_strategy='most_frequent',\n",
        "    random_state=42,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# === Run the imputation ===\n",
        "imputed_array = imputer.fit_transform(df_for_imputation)\n",
        "imputed_df = pd.DataFrame(imputed_array, columns=cols_for_imputation, index=df_for_imputation.index)\n",
        "\n",
        "# === Apply threshold for binary classification ===\n",
        "predicted = (imputed_df.loc[sample_masked.index, 'pricingInfo_isAccessTP'] >= 0.5).astype(int)\n",
        "\n",
        "# === Calculate metrics ===\n",
        "acc = accuracy_score(true_values, predicted)\n",
        "f1 = f1_score(true_values, predicted)\n",
        "cm = confusion_matrix(true_values, predicted)\n",
        "duration = round(time.time() - start, 2)\n",
        "\n",
        "# === Save the results to a file ===\n",
        "with open(\"imputation_results.txt\", \"w\") as f:\n",
        "    f.write(\"‚úÖ Imputation evaluation results (XGBRegressor):\\n\")\n",
        "    f.write(f\"Accuracy: {acc:.4f}\\n\")\n",
        "    f.write(f\"F1 Score: {f1:.4f}\\n\")\n",
        "    f.write(\"Confusion Matrix:\\n\")\n",
        "    f.write(np.array2string(cm))\n",
        "    f.write(f\"\\n‚è±Ô∏è Duration: {duration} seconds\\n\")\n",
        "\n",
        "# === Also print to console ===\n",
        "print(\"‚úÖ Results saved to imputation_results.txt\")\n"
      ],
      "metadata": {
        "id": "ZXyr5znMUMIf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "‚úÖ Imputation evaluation results (XGBRegressor):\n",
        "\n",
        "Accuracy: 0.9260\n",
        "\n",
        "F1 Score: 0.9246\n",
        "\n",
        "Confusion Matrix:\n",
        "\n",
        "[[4725  356]\n",
        "\n",
        " [ 384 4535]]\n",
        "\n",
        "‚è±Ô∏è Duration: 443.35 seconds"
      ],
      "metadata": {
        "id": "zqM8KWOXUM_G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile test_imputation.py\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
        "import time\n",
        "\n",
        "# === Start the timer ===\n",
        "start = time.time()\n",
        "\n",
        "# === Load the data ===\n",
        "train_original = pd.read_csv(\"train.csv\", low_memory=False)\n",
        "train_copy = train_original.copy(deep=True)\n",
        "\n",
        "# === Select relevant columns ===\n",
        "selected_features = [\n",
        "    'totalPrice',\n",
        "    'companyID',\n",
        "    'legs0_segments0_cabinClass',\n",
        "    'isAccess3D',\n",
        "    'isVip',\n",
        "    'legs0_segments0_seatsAvailable',\n",
        "    'legs0_segments0_flightNumber',\n",
        "    'taxes',\n",
        "    'legs0_segments0_baggageAllowance_quantity',\n",
        "    'legs0_segments0_baggageAllowance_weightMeasurementType'\n",
        "]\n",
        "\n",
        "target_col = 'pricingInfo_isAccessTP'\n",
        "cols_needed = selected_features + [target_col]\n",
        "\n",
        "# === Filter complete rows for training ===\n",
        "df_full = train_copy[cols_needed].dropna(subset=cols_needed)\n",
        "\n",
        "# === Randomly select 10,000 rows for validation ===\n",
        "sample = df_full.sample(n=10000, random_state=42)\n",
        "X_valid = sample[selected_features]\n",
        "y_valid = sample[target_col].astype(int)\n",
        "\n",
        "# === Remove those rows from the training set ===\n",
        "df_train = df_full.drop(sample.index, errors='ignore')\n",
        "X_train = df_train[selected_features]\n",
        "y_train = df_train[target_col].astype(int)\n",
        "\n",
        "# === Train a classification model ===\n",
        "model = XGBClassifier(\n",
        "    n_estimators=100,\n",
        "    max_depth=10,\n",
        "    learning_rate=0.1,\n",
        "    tree_method='hist',\n",
        "    n_jobs=24,\n",
        "    random_state=42,\n",
        "    use_label_encoder=False,\n",
        "    eval_metric='logloss'\n",
        ")\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# === Predict on the validation set ===\n",
        "predicted = model.predict(X_valid)\n",
        "\n",
        "# === Compute metrics ===\n",
        "acc = accuracy_score(y_valid, predicted)\n",
        "f1 = f1_score(y_valid, predicted)\n",
        "cm = confusion_matrix(y_valid, predicted)\n",
        "duration = round(time.time() - start, 2)\n",
        "\n",
        "# === Save results to file ===\n",
        "with open(\"imputation_results.txt\", \"w\") as f:\n",
        "    f.write(\"‚úÖ Direct prediction results (XGBClassifier):\\n\")\n",
        "    f.write(f\"Accuracy: {acc:.4f}\\n\")\n",
        "    f.write(f\"F1 Score: {f1:.4f}\\n\")\n",
        "    f.write(\"Confusion Matrix:\\n\")\n",
        "    f.write(np.array2string(cm))\n",
        "    f.write(f\"\\n‚è±Ô∏è Duration: {duration} seconds\\n\")\n",
        "\n",
        "# === Print to console ===\n",
        "print(\"‚úÖ Results saved to imputation_results.txt\")\n"
      ],
      "metadata": {
        "id": "xnAVg9jLUXev"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "‚úÖ Direct prediction results (XGBClassifier):\n",
        "\n",
        "Accuracy: 0.9251\n",
        "\n",
        "F1 Score: 0.9236\n",
        "\n",
        "Confusion Matrix:\n",
        "\n",
        "[[4722  359]\n",
        "\n",
        " [ 390 4529]]\n",
        "\n",
        "‚è±Ô∏è Duration: 129.9 seconds"
      ],
      "metadata": {
        "id": "6_um14JoUYsc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile test_imputation.py\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
        "import time\n",
        "\n",
        "# === Start the timer ===\n",
        "start = time.time()\n",
        "\n",
        "# === Load the data ===\n",
        "train_original = pd.read_csv(\"train.csv\", low_memory=False)\n",
        "train_copy = train_original.copy(deep=True)\n",
        "\n",
        "# === Select relevant columns ===\n",
        "selected_features = [\n",
        "    'totalPrice',\n",
        "    'companyID',\n",
        "    'legs0_segments0_cabinClass',\n",
        "    'isAccess3D',\n",
        "    'isVip',\n",
        "    'legs0_segments0_seatsAvailable',\n",
        "    'legs0_segments0_flightNumber',\n",
        "    'taxes',\n",
        "    'legs0_segments0_baggageAllowance_quantity',\n",
        "    'legs0_segments0_baggageAllowance_weightMeasurementType',\n",
        "    'pricingInfo_isAccessTP'\n",
        "]\n",
        "\n",
        "target_col = 'miniRules1_monetaryAmount'\n",
        "cols_needed = selected_features + [target_col]\n",
        "\n",
        "# === Filter complete rows for training ===\n",
        "df_full = train_copy[cols_needed].dropna(subset=cols_needed)\n",
        "\n",
        "# === Randomly select 1,000,000 rows for validation ===\n",
        "sample = df_full.sample(n=1000000, random_state=42)\n",
        "X_valid = sample[selected_features]\n",
        "y_valid = sample[target_col].astype(int)\n",
        "\n",
        "# === Remove these rows from the training data ===\n",
        "df_train = df_full.drop(sample.index, errors='ignore')\n",
        "X_train = df_train[selected_features]\n",
        "y_train = df_train[target_col].astype(int)\n",
        "\n",
        "# === Train a classification model ===\n",
        "model = XGBClassifier(\n",
        "    n_estimators=500,\n",
        "    max_depth=12,\n",
        "    learning_rate=0.1,\n",
        "    tree_method='hist',\n",
        "    n_jobs=24,\n",
        "    random_state=42,\n",
        "    use_label_encoder=False,\n",
        "    eval_metric='logloss'\n",
        ")\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# === Predict on the validation sample ===\n",
        "predicted = model.predict(X_valid)\n",
        "\n",
        "# === Compute evaluation metrics ===\n",
        "acc = accuracy_score(y_valid, predicted)\n",
        "f1 = f1_score(y_valid, predicted)\n",
        "cm = confusion_matrix(y_valid, predicted)\n",
        "duration = round(time.time() - start, 2)\n",
        "\n",
        "# === Save results to a file ===\n",
        "with open(\"imputation_results.txt\", \"w\") as f:\n",
        "    f.write(\"‚úÖ Direct prediction results (XGBClassifier):\\n\")\n",
        "    f.write(f\"Accuracy: {acc:.4f}\\n\")\n",
        "    f.write(f\"F1 Score: {f1:.4f}\\n\")\n",
        "    f.write(\"Confusion Matrix:\\n\")\n",
        "    f.write(np.array2string(cm))\n",
        "    f.write(f\"\\n‚è±Ô∏è Duration: {duration} seconds\\n\")\n",
        "\n",
        "# === Also print to the console ===\n",
        "print(\"‚úÖ Results saved to imputation_results.txt\")"
      ],
      "metadata": {
        "id": "Eeb7qFCzUiKn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "‚úÖ Direct prediction results (XGBClassifier):\n",
        "\n",
        "Accuracy: 0.9635\n",
        "\n",
        "F1 Score: 0.9633\n",
        "\n",
        "Confusion Matrix:\n",
        "\n",
        "[[484867  16174]\n",
        "\n",
        " [ 20340 478619]]\n",
        "\n",
        "‚è±Ô∏è Duration: 251.97 seconds"
      ],
      "metadata": {
        "id": "8fu_0z8GUi3O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile test_imputation.py\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.experimental import enable_iterative_imputer  # noqa\n",
        "from sklearn.impute import IterativeImputer\n",
        "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
        "import time\n",
        "from lightgbm import LGBMRegressor\n",
        "\n",
        "# === Start the timer ===\n",
        "start = time.time()\n",
        "\n",
        "# === Load and save a safe copy of the dataset ===\n",
        "train_original = pd.read_csv(\"train.csv\", low_memory=False)\n",
        "train_copy = train_original.copy(deep=True)\n",
        "\n",
        "# === Select relevant columns ===\n",
        "selected_features = [\n",
        "    'totalPrice',\n",
        "    'companyID',\n",
        "    'legs0_segments0_cabinClass',\n",
        "    'isAccess3D',\n",
        "    'isVip',\n",
        "    'legs0_segments0_seatsAvailable',\n",
        "    'legs0_segments0_flightNumber',\n",
        "    'taxes',\n",
        "    'legs0_segments0_baggageAllowance_quantity',\n",
        "    'legs0_segments0_baggageAllowance_weightMeasurementType'\n",
        "]\n",
        "cols_for_imputation = ['pricingInfo_isAccessTP'] + selected_features\n",
        "\n",
        "# === Filter rows with complete data ===\n",
        "df_known = train_copy[cols_for_imputation].dropna(subset=cols_for_imputation).copy()\n",
        "\n",
        "# === Randomly select 10,000 rows for validation ===\n",
        "sample_original = df_known.sample(n=10000, random_state=42)\n",
        "true_values = sample_original['pricingInfo_isAccessTP'].astype(int).copy()\n",
        "\n",
        "# === Create a masked version (with NaN) for the target column ===\n",
        "sample_masked = sample_original.copy()\n",
        "sample_masked['pricingInfo_isAccessTP'] = np.nan\n",
        "\n",
        "# === Remove these rows from df_known to avoid duplication ===\n",
        "df_known = df_known.drop(sample_original.index, errors='ignore')\n",
        "\n",
        "# === Combine known + masked data for imputation ===\n",
        "df_for_imputation = pd.concat([df_known, sample_masked])\n",
        "df_for_imputation = df_for_imputation.sort_index()\n",
        "\n",
        "# === Create the imputer with LGBMRegressor ===\n",
        "imputer = IterativeImputer(\n",
        "    estimator=LGBMRegressor(\n",
        "        n_estimators=100,\n",
        "        max_depth=10,\n",
        "        learning_rate=0.1,\n",
        "        n_jobs=24,\n",
        "        random_state=42,\n",
        "        verbose=-1  # suppress logging\n",
        "    ),\n",
        "    max_iter=10,\n",
        "    initial_strategy='most_frequent',\n",
        "    random_state=42,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# === Run the imputation ===\n",
        "imputed_array = imputer.fit_transform(df_for_imputation)\n",
        "imputed_df = pd.DataFrame(imputed_array, columns=cols_for_imputation, index=df_for_imputation.index)\n",
        "\n",
        "# === Apply threshold for binary classification ===\n",
        "predicted = (imputed_df.loc[sample_masked.index, 'pricingInfo_isAccessTP'] >= 0.5).astype(int)\n",
        "\n",
        "# === Calculate evaluation metrics ===\n",
        "acc = accuracy_score(true_values, predicted)\n",
        "f1 = f1_score(true_values, predicted)\n",
        "cm = confusion_matrix(true_values, predicted)\n",
        "duration = round(time.time() - start, 2)\n",
        "\n",
        "# === Save results to file ===\n",
        "with open(\"imputation_results.txt\", \"w\") as f:\n",
        "    f.write(\"‚úÖ Imputation evaluation results (LGBMRegressor):\\n\")\n",
        "    f.write(f\"Accuracy: {acc:.4f}\\n\")\n",
        "    f.write(f\"F1 Score: {f1:.4f}\\n\")\n",
        "    f.write(\"Confusion Matrix:\\n\")\n",
        "    f.write(np.array2string(cm))\n",
        "    f.write(f\"\\n‚è±Ô∏è Duration: {duration} seconds\\n\")\n",
        "\n",
        "# === Also print to console ===\n",
        "print(\"‚úÖ Results saved to imputation_results.txt\")\n"
      ],
      "metadata": {
        "id": "bApppUg_UuC2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "‚úÖ Imputation evaluation results (LGBMRegressor):\n",
        "\n",
        "Accuracy: 0.8828\n",
        "\n",
        "F1 Score: 0.8813\n",
        "\n",
        "Confusion Matrix:\n",
        "\n",
        "[[4479  602]\n",
        "\n",
        " [ 570 4349]]\n",
        "\n",
        "‚è±Ô∏è Duration: 229.4 seconds"
      ],
      "metadata": {
        "id": "WTq_O9ccUu1u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile impute_pricingInfo_isAccessTP.py\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from xgboost import XGBClassifier\n",
        "import time\n",
        "\n",
        "# === Start timer ===\n",
        "start = time.time()\n",
        "\n",
        "# === Load files ===\n",
        "train = pd.read_csv(\"train.csv\", low_memory=False)\n",
        "test = pd.read_csv(\"test.csv\", low_memory=False)\n",
        "\n",
        "# === Relevant columns ===\n",
        "features = [\n",
        "    'totalPrice',\n",
        "    'companyID',\n",
        "    'legs0_segments0_cabinClass',\n",
        "    'isAccess3D',\n",
        "    'isVip',\n",
        "    'legs0_segments0_seatsAvailable',\n",
        "    'legs0_segments0_flightNumber',\n",
        "    'taxes',\n",
        "    'legs0_segments0_baggageAllowance_quantity',\n",
        "    'legs0_segments0_baggageAllowance_weightMeasurementType',\n",
        "    'pricingInfo_isAccessTP'\n",
        "]\n",
        "target = 'pricingInfo_isAccessTP'\n",
        "\n",
        "# === Train on complete rows from train ===\n",
        "train_valid = train.dropna(subset=features + [target])\n",
        "X_train = train_valid[features]\n",
        "y_train = train_valid[target].astype(int)\n",
        "\n",
        "# === Train the model ===\n",
        "model = XGBClassifier(\n",
        "    n_estimators=500,\n",
        "    max_depth=12,\n",
        "    learning_rate=0.1,\n",
        "    tree_method='hist',\n",
        "    n_jobs=24,\n",
        "    random_state=42,\n",
        "    use_label_encoder=False,\n",
        "    eval_metric='logloss'\n",
        ")\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# === Imputation function ===\n",
        "def impute_column(df, name=\"train\"):\n",
        "    missing_mask = df[target].isna()\n",
        "    if missing_mask.sum() == 0:\n",
        "        print(f\"‚úÖ {name}: No missing values in '{target}'\")\n",
        "        return df\n",
        "\n",
        "    X_missing = df.loc[missing_mask, features]\n",
        "    preds = model.predict(X_missing)\n",
        "    df.loc[missing_mask, target] = preds\n",
        "    print(f\"‚úÖ {name}: Imputed {missing_mask.sum()} missing values in '{target}'\")\n",
        "    return df\n",
        "\n",
        "# === Perform imputation ===\n",
        "train = impute_column(train, \"train\")\n",
        "test = impute_column(test, \"test\")\n",
        "\n",
        "# === Overwrite the files ===\n",
        "train.to_csv(\"train.csv\", index=False)\n",
        "test.to_csv(\"test.csv\", index=False)\n",
        "\n",
        "# === Post-imputation stats ===\n",
        "def report(df, name):\n",
        "    total = len(df)\n",
        "    missing = df[target].isna().sum()\n",
        "    value_counts = df[target].value_counts(dropna=False).sort_index()\n",
        "    print(f\"\\nüìä {name} ‚Äî '{target}':\")\n",
        "    print(f\"  Total rows: {total}\")\n",
        "    print(f\"  Missing: {missing} ({100 * missing / total:.2f}%)\")\n",
        "    print(\"  Value counts (including imputed):\")\n",
        "    print(value_counts)\n",
        "\n",
        "report(train, \"train\")\n",
        "report(test, \"test\")\n",
        "\n",
        "# === Done ===\n",
        "print(f\"\\n‚è±Ô∏è Total duration: {round(time.time() - start, 2)} seconds\")\n"
      ],
      "metadata": {
        "id": "HeFcuk-YU4V-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Parameters: { \"use_label_encoder\" } are not used.\n",
        "\n",
        "  warnings.warn(smsg, UserWarning)\n",
        "\n",
        "‚úÖ train: Imputed 905045 missing values in 'pricingInfo_isAccessTP'\n",
        "\n",
        "‚úÖ test: Imputed 245155 missing values in 'pricingInfo_isAccessTP'\n",
        "\n",
        "\n",
        "üìä train ‚Äî 'pricingInfo_isAccessTP':\n",
        "\n",
        "  Total rows: 18145372\n",
        "\n",
        "  Missing: 0 (0.00%)\n",
        "\n",
        "  Value counts (including imputed):\n",
        "\n",
        "pricingInfo_isAccessTP\n",
        "\n",
        "0.0    8901943\n",
        "\n",
        "1.0    9243429\n",
        "\n",
        "Name: count, dtype: int64\n",
        "\n",
        "\n",
        "üìä test ‚Äî 'pricingInfo_isAccessTP':\n",
        "\n",
        "  Total rows: 6897776\n",
        "\n",
        "  Missing: 0 (0.00%)\n",
        "\n",
        "  Value counts (including imputed):\n",
        "\n",
        "pricingInfo_isAccessTP\n",
        "\n",
        "0.0    2545795\n",
        "\n",
        "1.0    4351981\n",
        "\n",
        "Name: count, dtype: int64\n",
        "\n",
        "‚è±Ô∏è Total duration: 534.8 seconds"
      ],
      "metadata": {
        "id": "jwhbccbeU61t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile corr_miniRules1_monetaryAmount.py\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_selection import mutual_info_regression\n",
        "from scipy.stats import spearmanr, kendalltau\n",
        "from multiprocessing import Pool, cpu_count\n",
        "\n",
        "# === Load data ===\n",
        "train = pd.read_csv('train.csv')\n",
        "test = pd.read_csv('test.csv')\n",
        "\n",
        "target = 'miniRules1_monetaryAmount'\n",
        "y_train = train[target]\n",
        "y_test = test[target]\n",
        "\n",
        "# === Drop irrelevant columns ===\n",
        "drop_cols = [\n",
        "    'Id', 'profileId', '__index_level_0__', 'requestDate',\n",
        "    'searchRoute', 'legs0_arrivalAt', 'legs0_departureAt',\n",
        "    'legs1_arrivalAt', 'legs1_departureAt'\n",
        "]\n",
        "\n",
        "# === Select numeric columns present in both datasets ===\n",
        "common_cols = list(set(train.columns) & set(test.columns))\n",
        "numeric_cols = train[common_cols].select_dtypes(include=['float64', 'int64', 'bool']).columns\n",
        "numeric_cols = [col for col in numeric_cols if col not in drop_cols and col != target]\n",
        "numeric_cols = [col for col in numeric_cols\n",
        "                if train[col].isnull().sum() == 0 and test[col].isnull().sum() == 0]\n",
        "\n",
        "X_train = train[numeric_cols]\n",
        "X_test = test[numeric_cols]\n",
        "\n",
        "# === Correlation functions ===\n",
        "def kendall_series(X, y):\n",
        "    scores = {}\n",
        "    for col in X.columns:\n",
        "        try:\n",
        "            tau, _ = kendalltau(X[col], y)\n",
        "            scores[col] = tau\n",
        "        except:\n",
        "            scores[col] = 0\n",
        "    return pd.Series(scores)\n",
        "\n",
        "def spearman_series(X, y):\n",
        "    scores = {}\n",
        "    for col in X.columns:\n",
        "        try:\n",
        "            rho, _ = spearmanr(X[col], y)\n",
        "            scores[col] = rho\n",
        "        except:\n",
        "            scores[col] = 0\n",
        "    return pd.Series(scores)\n",
        "\n",
        "# === Parallel computation ===\n",
        "def compute_score(task_id):\n",
        "    if task_id == 1:\n",
        "        return \"PEARSON_TRAIN\", X_train.corrwith(y_train).sort_values(key=abs, ascending=False)\n",
        "    elif task_id == 2:\n",
        "        return \"SPEARMAN_TRAIN\", spearman_series(X_train, y_train).sort_values(key=abs, ascending=False)\n",
        "    elif task_id == 3:\n",
        "        return \"KENDALL_TRAIN\", kendall_series(X_train, y_train).sort_values(key=abs, ascending=False)\n",
        "    elif task_id == 4:\n",
        "        return \"MI_TRAIN\", pd.Series(\n",
        "            mutual_info_regression(X_train, y_train.fillna(0), random_state=0),\n",
        "            index=X_train.columns\n",
        "        ).sort_values(ascending=False)\n",
        "    elif task_id == 5:\n",
        "        return \"PEARSON_TEST\", X_test.corrwith(y_test).sort_values(key=abs, ascending=False)\n",
        "    elif task_id == 6:\n",
        "        return \"SPEARMAN_TEST\", spearman_series(X_test, y_test).sort_values(key=abs, ascending=False)\n",
        "    elif task_id == 7:\n",
        "        return \"KENDALL_TEST\", kendall_series(X_test, y_test).sort_values(key=abs, ascending=False)\n",
        "    elif task_id == 8:\n",
        "        return \"MI_TEST\", pd.Series(\n",
        "            mutual_info_regression(X_test, y_test.fillna(0), random_state=0),\n",
        "            index=X_test.columns\n",
        "        ).sort_values(ascending=False)\n",
        "\n",
        "# === Run computations in parallel ===\n",
        "if __name__ == \"__main__\":\n",
        "    with Pool(processes=min(8, cpu_count())) as pool:\n",
        "        results = pool.map(compute_score, list(range(1, 9)))\n",
        "\n",
        "    # === Save to file ===\n",
        "    with open(\"feature_scores_miniRules1_monetaryAmount.txt\", \"w\", encoding=\"utf-8\") as f:\n",
        "        for name, series in results:\n",
        "            f.write(f\"\\nüîπ TOP 15 FEATURES BY {name.replace('_', ' ')}\\n\")\n",
        "            f.write(series.head(15).to_string())\n",
        "            f.write(\"\\n\")\n",
        "\n",
        "    print(\"‚úÖ Correlation scores saved to 'feature_scores_miniRules1_monetaryAmount.txt'\")\n"
      ],
      "metadata": {
        "id": "yLUeSI26VGhO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile test_imputation.py\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "import time\n",
        "\n",
        "# === Start the timer ===\n",
        "start = time.time()\n",
        "\n",
        "# === Load the data ===\n",
        "train_original = pd.read_csv(\"train.csv\", low_memory=False)\n",
        "train_copy = train_original.copy(deep=True)\n",
        "\n",
        "# === Select relevant columns ===\n",
        "selected_features = [\n",
        "    'totalPrice',\n",
        "    'companyID',\n",
        "    'legs0_segments0_cabinClass',\n",
        "    'isAccess3D',\n",
        "    'isVip',\n",
        "    'legs0_segments0_seatsAvailable',\n",
        "    'legs0_segments0_flightNumber',\n",
        "    'taxes',\n",
        "    'legs0_segments0_baggageAllowance_quantity',\n",
        "    'legs0_segments0_baggageAllowance_weightMeasurementType',\n",
        "    'pricingInfo_isAccessTP'\n",
        "]\n",
        "\n",
        "target_col = 'miniRules1_monetaryAmount'\n",
        "cols_needed = selected_features + [target_col]\n",
        "\n",
        "# === Filter complete rows for training ===\n",
        "df_full = train_copy[cols_needed].dropna(subset=cols_needed)\n",
        "\n",
        "# === Randomly select 1,000,000 rows for validation ===\n",
        "sample = df_full.sample(n=1000000, random_state=42)\n",
        "X_valid = sample[selected_features]\n",
        "y_valid = sample[target_col]\n",
        "\n",
        "# === Remove those rows from the training set ===\n",
        "df_train = df_full.drop(sample.index, errors='ignore')\n",
        "X_train = df_train[selected_features]\n",
        "y_train = df_train[target_col]\n",
        "\n",
        "# === Train the model ===\n",
        "model = XGBRegressor(\n",
        "    n_estimators=500,\n",
        "    max_depth=12,\n",
        "    learning_rate=0.1,\n",
        "    tree_method='hist',\n",
        "    n_jobs=24,\n",
        "    random_state=42\n",
        ")\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# === Predict on the validation sample ===\n",
        "y_pred = model.predict(X_valid)\n",
        "\n",
        "# === Compute evaluation metrics ===\n",
        "mae = mean_absolute_error(y_valid, y_pred)\n",
        "rmse = mean_squared_error(y_valid, y_pred, squared=False)\n",
        "r2 = r2_score(y_valid, y_pred)\n",
        "duration = round(time.time() - start, 2)\n",
        "\n",
        "# === Save results ===\n",
        "with open(\"imputation_results.txt\", \"w\") as f:\n",
        "    f.write(\"‚úÖ Imputation evaluation (XGBRegressor):\\n\")\n",
        "    f.write(f\"MAE: {mae:.2f}\\n\")\n",
        "    f.write(f\"RMSE: {rmse:.2f}\\n\")\n",
        "    f.write(f\"R¬≤ Score: {r2:.4f}\\n\")\n",
        "    f.write(f\"‚è±Ô∏è Duration: {duration} seconds\\n\")\n",
        "\n",
        "print(\"‚úÖ Results saved to imputation_results.txt\")\n"
      ],
      "metadata": {
        "id": "4tbBAVgGVPle"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "‚úÖ Imputation evaluation (XGBRegressor):\n",
        "\n",
        "MAE: 297.19\n",
        "\n",
        "RMSE: 3959.18\n",
        "\n",
        "R¬≤ Score: 0.6505\n",
        "\n",
        "‚è±Ô∏è Duration: 246.37 seconds"
      ],
      "metadata": {
        "id": "EQinawu6VQb2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile test_imputation.py\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "import time\n",
        "\n",
        "# === Start the timer ===\n",
        "start = time.time()\n",
        "\n",
        "# === Load the data ===\n",
        "train_original = pd.read_csv(\"train.csv\", low_memory=False)\n",
        "train_copy = train_original.copy(deep=True)\n",
        "\n",
        "# === Select relevant columns ===\n",
        "selected_features = [\n",
        "    'totalPrice',\n",
        "    'companyID',\n",
        "    'legs0_segments0_cabinClass',\n",
        "    'isAccess3D',\n",
        "    'isVip',\n",
        "    'legs0_segments0_seatsAvailable',\n",
        "    'legs0_segments0_flightNumber',\n",
        "    'taxes',\n",
        "    'legs0_segments0_baggageAllowance_quantity',\n",
        "    'legs0_segments0_baggageAllowance_weightMeasurementType',\n",
        "    'pricingInfo_isAccessTP'\n",
        "]\n",
        "\n",
        "target_col = 'miniRules1_monetaryAmount'\n",
        "cols_needed = selected_features + [target_col]\n",
        "\n",
        "# === Filter complete rows for training ===\n",
        "df_full = train_copy[cols_needed].dropna(subset=cols_needed)\n",
        "\n",
        "# === Randomly select 1,000,000 rows for validation ===\n",
        "sample = df_full.sample(n=1000000, random_state=42)\n",
        "X_valid = sample[selected_features]\n",
        "y_valid = sample[target_col]\n",
        "\n",
        "# === Remove these rows from training data ===\n",
        "df_train = df_full.drop(sample.index, errors='ignore')\n",
        "\n",
        "# === Remove outliers from training target (1st to 99th percentiles) ===\n",
        "q_low = df_train[target_col].quantile(0.01)\n",
        "q_high = df_train[target_col].quantile(0.99)\n",
        "df_train = df_train[(df_train[target_col] >= q_low) & (df_train[target_col] <= q_high)]\n",
        "\n",
        "X_train = df_train[selected_features]\n",
        "y_train = df_train[target_col]\n",
        "\n",
        "# === Train the model ===\n",
        "model = XGBRegressor(\n",
        "    n_estimators=500,\n",
        "    max_depth=12,\n",
        "    learning_rate=0.1,\n",
        "    tree_method='hist',\n",
        "    n_jobs=24,\n",
        "    random_state=42\n",
        ")\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# === Predict on the validation sample ===\n",
        "y_pred = model.predict(X_valid)\n",
        "\n",
        "# === Compute evaluation metrics ===\n",
        "mae = mean_absolute_error(y_valid, y_pred)\n",
        "rmse = mean_squared_error(y_valid, y_pred, squared=False)\n",
        "r2 = r2_score(y_valid, y_pred)\n",
        "duration = round(time.time() - start, 2)\n",
        "\n",
        "# === Save results ===\n",
        "with open(\"imputation_results.txt\", \"w\") as f:\n",
        "    f.write(\"‚úÖ Imputation evaluation (XGBRegressor, with outlier removal):\\n\")\n",
        "    f.write(f\"MAE: {mae:.2f}\\n\")\n",
        "    f.write(f\"RMSE: {rmse:.2f}\\n\")\n",
        "    f.write(f\"R¬≤ Score: {r2:.4f}\\n\")\n",
        "    f.write(f\"‚è±Ô∏è Duration: {duration} seconds\\n\")\n",
        "\n",
        "print(\"‚úÖ Results saved to imputation_results.txt\")"
      ],
      "metadata": {
        "id": "NSCbzZXXVSS-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "‚úÖ Imputation evaluation (XGBRegressor, with outlier removal):\n",
        "\n",
        "MAE: 430.12\n",
        "\n",
        "RMSE: 6263.20\n",
        "\n",
        "R¬≤ Score: 0.1254\n",
        "\n",
        "‚è±Ô∏è Duration: 246.96 seconds"
      ],
      "metadata": {
        "id": "HRngMkW6Vb4V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile test_imputation.py\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "import time\n",
        "\n",
        "# === Start the timer ===\n",
        "start = time.time()\n",
        "\n",
        "# === Load the data ===\n",
        "train_original = pd.read_csv(\"train.csv\", low_memory=False)\n",
        "train_copy = train_original.copy(deep=True)\n",
        "\n",
        "# === Select relevant columns ===\n",
        "selected_features = [\n",
        "    'totalPrice',\n",
        "    'companyID',\n",
        "    'legs0_segments0_cabinClass',\n",
        "    'isAccess3D',\n",
        "    'isVip',\n",
        "    'legs0_segments0_seatsAvailable',\n",
        "    'legs0_segments0_flightNumber',\n",
        "    'taxes',\n",
        "    'legs0_segments0_baggageAllowance_quantity',\n",
        "    'legs0_segments0_baggageAllowance_weightMeasurementType',\n",
        "    'pricingInfo_isAccessTP'\n",
        "]\n",
        "\n",
        "target_col = 'miniRules1_monetaryAmount'\n",
        "cols_needed = selected_features + [target_col]\n",
        "\n",
        "# === Filter complete rows for training ===\n",
        "df_full = train_copy[cols_needed].dropna(subset=cols_needed)\n",
        "\n",
        "# === Randomly select 1,000,000 rows for validation ===\n",
        "sample = df_full.sample(n=1000000, random_state=42)\n",
        "X_valid = sample[selected_features]\n",
        "y_valid_raw = sample[target_col]  # keep for evaluation\n",
        "y_valid = np.log1p(y_valid_raw)   # log-transform the target\n",
        "\n",
        "# === Remove these rows from the training data ===\n",
        "df_train = df_full.drop(sample.index, errors='ignore')\n",
        "X_train = df_train[selected_features]\n",
        "y_train = np.log1p(df_train[target_col])  # log-transform the target\n",
        "\n",
        "# === Train the model ===\n",
        "model = XGBRegressor(\n",
        "    n_estimators=500,\n",
        "    max_depth=12,\n",
        "    learning_rate=0.1,\n",
        "    tree_method='hist',\n",
        "    n_jobs=24,\n",
        "    random_state=42\n",
        ")\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# === Predict on the validation set ===\n",
        "y_pred_log = model.predict(X_valid)\n",
        "y_pred = np.expm1(y_pred_log)  # inverse of log1p\n",
        "\n",
        "# === Compute metrics (compare to raw values) ===\n",
        "mae = mean_absolute_error(y_valid_raw, y_pred)\n",
        "rmse = mean_squared_error(y_valid_raw, y_pred, squared=False)\n",
        "r2 = r2_score(y_valid_raw, y_pred)\n",
        "duration = round(time.time() - start, 2)\n",
        "\n",
        "# === Save results to file ===\n",
        "with open(\"imputation_results.txt\", \"w\") as f:\n",
        "    f.write(\"‚úÖ Imputation evaluation (XGBRegressor, log-transformed target):\\n\")\n",
        "    f.write(f\"MAE: {mae:.2f}\\n\")\n",
        "    f.write(f\"RMSE: {rmse:.2f}\\n\")\n",
        "    f.write(f\"R¬≤ Score: {r2:.4f}\\n\")\n",
        "    f.write(f\"‚è±Ô∏è Duration: {duration} seconds\\n\")\n",
        "\n",
        "print(\"‚úÖ Results saved to imputation_results.txt\")\n"
      ],
      "metadata": {
        "id": "EzTR5wEuVcu2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "‚úÖ Imputation evaluation (XGBRegressor, log-transformed target):\n",
        "\n",
        "MAE: 476.00\n",
        "\n",
        "RMSE: 6041.37\n",
        "\n",
        "R¬≤ Score: 0.1863\n",
        "\n",
        "‚è±Ô∏è Duration: 251.54 seconds"
      ],
      "metadata": {
        "id": "9_5jUhErVt19"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile impute_miniRules1_monetaryAmount.py\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from xgboost import XGBRegressor\n",
        "import time\n",
        "\n",
        "start = time.time()\n",
        "\n",
        "# === Load original data ===\n",
        "train = pd.read_csv(\"train.csv\", low_memory=False)\n",
        "test = pd.read_csv(\"test.csv\", low_memory=False)\n",
        "\n",
        "# === Features for modeling ===\n",
        "selected_features = [\n",
        "    'totalPrice',\n",
        "    'companyID',\n",
        "    'legs0_segments0_cabinClass',\n",
        "    'isAccess3D',\n",
        "    'isVip',\n",
        "    'legs0_segments0_seatsAvailable',\n",
        "    'legs0_segments0_flightNumber',\n",
        "    'taxes',\n",
        "    'legs0_segments0_baggageAllowance_quantity',\n",
        "    'legs0_segments0_baggageAllowance_weightMeasurementType',\n",
        "    'pricingInfo_isAccessTP'\n",
        "]\n",
        "\n",
        "target_col = 'miniRules1_monetaryAmount'\n",
        "cols_needed = selected_features + [target_col]\n",
        "\n",
        "# === Prepare complete rows for training ===\n",
        "train_clean = train[cols_needed].dropna(subset=cols_needed)\n",
        "X_train = train_clean[selected_features]\n",
        "y_train = train_clean[target_col]\n",
        "\n",
        "# === Train the model ===\n",
        "model = XGBRegressor(\n",
        "    n_estimators=500,\n",
        "    max_depth=12,\n",
        "    learning_rate=0.1,\n",
        "    tree_method='hist',\n",
        "    n_jobs=24,\n",
        "    random_state=42\n",
        ")\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# === Function to impute missing values in a DataFrame ===\n",
        "def impute(df, name):\n",
        "    df_result = df.copy()\n",
        "    missing_mask = df_result[target_col].isna()\n",
        "    n_missing = missing_mask.sum()\n",
        "    before_stats = df_result[target_col].describe()\n",
        "\n",
        "    if n_missing > 0:\n",
        "        to_impute = df_result.loc[missing_mask, selected_features]\n",
        "        preds = model.predict(to_impute)\n",
        "        df_result.loc[missing_mask, target_col] = preds\n",
        "        after_stats = df_result[target_col].describe()\n",
        "    else:\n",
        "        after_stats = before_stats\n",
        "\n",
        "    log = (\n",
        "        f\"\\nüìä Dataset: {name}\\n\"\n",
        "        f\"Missing before: {n_missing}\\n\"\n",
        "        f\"Missing after: {df_result[target_col].isna().sum()}\\n\"\n",
        "        f\"\\nüîπ Descriptive statistics after:\\n{after_stats}\\n\"\n",
        "    )\n",
        "    return df_result, log\n",
        "\n",
        "# === Imputation ===\n",
        "train_filled, log_train = impute(train, \"Train\")\n",
        "test_filled, log_test = impute(test, \"Test\")\n",
        "\n",
        "# === Overwrite CSV files ===\n",
        "train_filled.to_csv(\"train.csv\", index=False)\n",
        "test_filled.to_csv(\"test.csv\", index=False)\n",
        "\n",
        "# === Write summary log to file ===\n",
        "duration = round(time.time() - start, 2)\n",
        "with open(\"imputation_summary.txt\", \"w\") as f:\n",
        "    f.write(\"‚úÖ Imputation Summary (XGBRegressor)\\n\")\n",
        "    f.write(log_train)\n",
        "    f.write(log_test)\n",
        "    f.write(f\"\\n‚è±Ô∏è Duration: {duration} seconds\\n\")\n",
        "\n",
        "print(\"‚úÖ Imputation complete. Overwrote 'train.csv', 'test.csv'. Stats in 'imputation_summary.txt'\")\n"
      ],
      "metadata": {
        "id": "WN4XJgZZVuWd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "‚úÖ Imputation Summary (XGBRegressor)\n",
        "\n",
        "üìä Dataset: Train\n",
        "Missing before: 1395743\n",
        "Missing after: 0\n",
        "\n",
        "üîπ Descriptive statistics after:\n",
        "count    1.814537e+07\n",
        "mean     1.343276e+03\n",
        "std      5.734428e+03\n",
        "min     -1.068349e+04\n",
        "25%      0.000000e+00\n",
        "50%      0.000000e+00\n",
        "75%      2.800000e+03\n",
        "max      7.161273e+06\n",
        "Name: miniRules1_monetaryAmount, dtype: float64\n",
        "\n",
        "üìä Dataset: Test\n",
        "Missing before: 504405\n",
        "Missing after: 0\n",
        "\n",
        "üîπ Descriptive statistics after:\n",
        "count    6.897776e+06\n",
        "mean     1.414765e+03\n",
        "std      4.017597e+03\n",
        "min     -8.029313e+03\n",
        "25%      0.000000e+00\n",
        "50%      0.000000e+00\n",
        "75%      2.800000e+03\n",
        "max      4.736350e+05\n",
        "Name: miniRules1_monetaryAmount, dtype: float64\n",
        "\n",
        "‚è±Ô∏è Duration: 542.42 seconds"
      ],
      "metadata": {
        "id": "DDPsSS6JV4_l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile clip_negative_values.py\n",
        "import pandas as pd\n",
        "\n",
        "target_col = \"miniRules1_monetaryAmount\"\n",
        "\n",
        "# Load existing files\n",
        "train = pd.read_csv(\"train.csv\", low_memory=False)\n",
        "test = pd.read_csv(\"test.csv\", low_memory=False)\n",
        "\n",
        "# Replace negative values with 0\n",
        "train[target_col] = train[target_col].clip(lower=0)\n",
        "test[target_col] = test[target_col].clip(lower=0)\n",
        "\n",
        "# Save updated files\n",
        "train.to_csv(\"train.csv\", index=False)\n",
        "test.to_csv(\"test.csv\", index=False)\n",
        "\n",
        "# Save post-transformation statistics\n",
        "with open(\"clip_summary.txt\", \"w\") as f:\n",
        "    f.write(\"‚úÖ Applied clip to miniRules1_monetaryAmount (values < 0 set to 0)\\n\")\n",
        "    f.write(\"\\nüîπ Train statistics:\\n\")\n",
        "    f.write(train[target_col].describe().to_string())\n",
        "    f.write(\"\\n\\nüîπ Test statistics:\\n\")\n",
        "    f.write(test[target_col].describe().to_string())\n",
        "\n",
        "print(\"‚úÖ Negative values clipped. Updated files: train.csv, test.csv. Summary saved in clip_summary.txt.\")\n"
      ],
      "metadata": {
        "id": "Es5EKjGFV--V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "‚úÖ Applied clip to miniRules1_monetaryAmount (values < 0 set to 0)\n",
        "\n",
        "üîπ Train statistics:\n",
        "count    1.814537e+07\n",
        "mean     1.344945e+03\n",
        "std      5.733923e+03\n",
        "min      0.000000e+00\n",
        "25%      0.000000e+00\n",
        "50%      0.000000e+00\n",
        "75%      2.800000e+03\n",
        "max      7.161273e+06\n",
        "\n",
        "üîπ Test statistics:\n",
        "count    6.897776e+06\n",
        "mean     1.416297e+03\n",
        "std      4.016969e+03\n",
        "min      0.000000e+00\n",
        "25%      0.000000e+00\n",
        "50%      0.000000e+00\n",
        "75%      2.800000e+03\n",
        "max      4.736350e+05"
      ],
      "metadata": {
        "id": "3rTDrjXTWCO9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile impute_miniRules0_monetaryAmount.py\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from xgboost import XGBRegressor\n",
        "import time\n",
        "\n",
        "start = time.time()\n",
        "\n",
        "# === Load original datasets ===\n",
        "train = pd.read_csv(\"train.csv\", low_memory=False)\n",
        "test = pd.read_csv(\"test.csv\", low_memory=False)\n",
        "\n",
        "# === Features for modeling ===\n",
        "selected_features = [\n",
        "    'totalPrice',\n",
        "    'companyID',\n",
        "    'legs0_segments0_cabinClass',\n",
        "    'isAccess3D',\n",
        "    'isVip',\n",
        "    'legs0_segments0_seatsAvailable',\n",
        "    'legs0_segments0_flightNumber',\n",
        "    'taxes',\n",
        "    'legs0_segments0_baggageAllowance_quantity',\n",
        "    'legs0_segments0_baggageAllowance_weightMeasurementType',\n",
        "    'pricingInfo_isAccessTP'\n",
        "]\n",
        "\n",
        "target_col = 'miniRules0_monetaryAmount'\n",
        "cols_needed = selected_features + [target_col]\n",
        "\n",
        "# === Prepare complete rows for training ===\n",
        "train_clean = train[cols_needed].dropna(subset=cols_needed)\n",
        "X_train = train_clean[selected_features]\n",
        "y_train = train_clean[target_col]\n",
        "\n",
        "# === Train the model ===\n",
        "model = XGBRegressor(\n",
        "    n_estimators=500,\n",
        "    max_depth=12,\n",
        "    learning_rate=0.1,\n",
        "    tree_method='hist',\n",
        "    n_jobs=24,\n",
        "    random_state=42\n",
        ")\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# === Function to impute missing values in a DataFrame ===\n",
        "def impute(df, name):\n",
        "    df_result = df.copy()\n",
        "    missing_mask = df_result[target_col].isna()\n",
        "    n_missing = missing_mask.sum()\n",
        "    before_stats = df_result[target_col].describe()\n",
        "\n",
        "    if n_missing > 0:\n",
        "        to_impute = df_result.loc[missing_mask, selected_features]\n",
        "        preds = model.predict(to_impute)\n",
        "        df_result.loc[missing_mask, target_col] = preds\n",
        "        after_stats = df_result[target_col].describe()\n",
        "    else:\n",
        "        after_stats = before_stats\n",
        "\n",
        "    log = (\n",
        "        f\"\\nüìä Dataset: {name}\\n\"\n",
        "        f\"Missing before: {n_missing}\\n\"\n",
        "        f\"Missing after: {df_result[target_col].isna().sum()}\\n\"\n",
        "        f\"\\nüîπ Descriptive statistics after:\\n{after_stats}\\n\"\n",
        "    )\n",
        "    return df_result, log\n",
        "\n",
        "# === Perform imputation ===\n",
        "train_filled, log_train = impute(train, \"Train\")\n",
        "test_filled, log_test = impute(test, \"Test\")\n",
        "\n",
        "# === Overwrite CSV files ===\n",
        "train_filled.to_csv(\"train.csv\", index=False)\n",
        "test_filled.to_csv(\"test.csv\", index=False)\n",
        "\n",
        "# === Write log to file ===\n",
        "duration = round(time.time() - start, 2)\n",
        "with open(\"imputation_summary.txt\", \"w\") as f:\n",
        "    f.write(\"‚úÖ Imputation Summary (XGBRegressor)\\n\")\n",
        "    f.write(log_train)\n",
        "    f.write(log_test)\n",
        "    f.write(f\"\\n‚è±Ô∏è Duration: {duration} seconds\\n\")\n",
        "\n",
        "print(\"‚úÖ Imputation complete. Overwrote 'train.csv', 'test.csv'. Stats in 'imputation_summary.txt'\")\n"
      ],
      "metadata": {
        "id": "UCr1bZ6IWNuk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "‚úÖ Imputation Summary (XGBRegressor)\n",
        "\n",
        "üìä Dataset: Train\n",
        "Missing before: 1395743\n",
        "Missing after: 0\n",
        "\n",
        "üîπ Descriptive statistics after:\n",
        "count    1.814537e+07\n",
        "mean     2.534357e+03\n",
        "std      3.341679e+03\n",
        "min     -6.132068e+03\n",
        "25%      0.000000e+00\n",
        "50%      2.800000e+03\n",
        "75%      2.800000e+03\n",
        "max      5.022370e+05\n",
        "Name: miniRules0_monetaryAmount, dtype: float64\n",
        "\n",
        "üìä Dataset: Test\n",
        "Missing before: 504405\n",
        "Missing after: 0\n",
        "\n",
        "üîπ Descriptive statistics after:\n",
        "count    6.897776e+06\n",
        "mean     2.717628e+03\n",
        "std      4.008379e+03\n",
        "min     -7.482827e+03\n",
        "25%      0.000000e+00\n",
        "50%      2.800000e+03\n",
        "75%      2.800000e+03\n",
        "max      2.431870e+05\n",
        "Name: miniRules0_monetaryAmount, dtype: float64\n",
        "\n",
        "‚è±Ô∏è Duration: 548.26 seconds"
      ],
      "metadata": {
        "id": "J34UR_lOWOpm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile clip_negative_values.py\n",
        "import pandas as pd\n",
        "\n",
        "target_col = \"miniRules0_monetaryAmount\"\n",
        "\n",
        "# Load existing files\n",
        "train = pd.read_csv(\"train.csv\", low_memory=False)\n",
        "test = pd.read_csv(\"test.csv\", low_memory=False)\n",
        "\n",
        "# Replace negative values with 0\n",
        "train[target_col] = train[target_col].clip(lower=0)\n",
        "test[target_col] = test[target_col].clip(lower=0)\n",
        "\n",
        "# Save updated files\n",
        "train.to_csv(\"train.csv\", index=False)\n",
        "test.to_csv(\"test.csv\", index=False)\n",
        "\n",
        "# Save post-transformation statistics\n",
        "with open(\"clip_summary.txt\", \"w\") as f:\n",
        "    f.write(\"‚úÖ Applied clip to miniRules0_monetaryAmount (values < 0 set to 0)\\n\")\n",
        "    f.write(\"\\nüîπ Train statistics:\\n\")\n",
        "    f.write(train[target_col].describe().to_string())\n",
        "    f.write(\"\\n\\nüîπ Test statistics:\\n\")\n",
        "    f.write(test[target_col].describe().to_string())\n",
        "\n",
        "print(\"‚úÖ Negative values clipped. Updated files: train.csv, test.csv. Summary saved in clip_summary.txt.\")\n"
      ],
      "metadata": {
        "id": "EU_Q4CJ1WXys"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "‚úÖ Applied clip to miniRules0_monetaryAmount (values < 0 set to 0)\n",
        "\n",
        "üîπ Train statistics:\n",
        "count    1.814537e+07\n",
        "mean     2.535514e+03\n",
        "std      3.340498e+03\n",
        "min      0.000000e+00\n",
        "25%      0.000000e+00\n",
        "50%      2.800000e+03\n",
        "75%      2.800000e+03\n",
        "max      5.022370e+05\n",
        "\n",
        "üîπ Test statistics:\n",
        "count    6.897776e+06\n",
        "mean     2.719365e+03\n",
        "std      4.006758e+03\n",
        "min      0.000000e+00\n",
        "25%      0.000000e+00\n",
        "50%      2.800000e+03\n",
        "75%      2.800000e+03\n",
        "max      2.431870e+05"
      ],
      "metadata": {
        "id": "x1RE8N7RWYl9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile corr_miniRules0_statusInfos.py\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_selection import mutual_info_classif\n",
        "from multiprocessing import Pool, cpu_count\n",
        "\n",
        "# Load datasets\n",
        "train = pd.read_csv('train.csv')\n",
        "test = pd.read_csv('test.csv')\n",
        "\n",
        "# Target column\n",
        "target = 'miniRules0_statusInfos'\n",
        "y_train = train[target]\n",
        "y_test = test[target]\n",
        "\n",
        "# Drop irrelevant columns\n",
        "drop_cols = [\n",
        "    'Id', 'profileId', '__index_level_0__', 'requestDate',\n",
        "    'searchRoute', 'legs0_arrivalAt', 'legs0_departureAt',\n",
        "    'legs1_arrivalAt', 'legs1_departureAt'\n",
        "]\n",
        "\n",
        "# Select numeric, common, non-null columns\n",
        "common_cols = list(set(train.columns) & set(test.columns))\n",
        "numeric_cols = train[common_cols].select_dtypes(include=['float64', 'int64', 'bool']).columns\n",
        "numeric_cols = [col for col in numeric_cols if col not in drop_cols and col != target]\n",
        "numeric_cols = [\n",
        "    col for col in numeric_cols\n",
        "    if train[col].isnull().sum() == 0 and test[col].isnull().sum() == 0\n",
        "]\n",
        "\n",
        "X_train = train[numeric_cols]\n",
        "X_test = test[numeric_cols]\n",
        "\n",
        "# Fisher Score calculation\n",
        "def fisher_score(X, y):\n",
        "    scores = {}\n",
        "    classes = np.unique(y.dropna())\n",
        "    for col in X.columns:\n",
        "        x = X[col]\n",
        "        mean_overall = x.mean()\n",
        "        numerator = 0\n",
        "        denominator = 0\n",
        "        for cls in classes:\n",
        "            xi = x[y == cls]\n",
        "            ni = len(xi)\n",
        "            mean_i = xi.mean()\n",
        "            var_i = xi.var()\n",
        "            numerator += ni * (mean_i - mean_overall) ** 2\n",
        "            denominator += ni * var_i\n",
        "        scores[col] = numerator / denominator if denominator != 0 else 0\n",
        "    return pd.Series(scores)\n",
        "\n",
        "# Score computation based on task ID\n",
        "def compute_score(task_id):\n",
        "    if task_id == 1:\n",
        "        return \"PEARSON_TRAIN\", X_train.corrwith(y_train).sort_values(key=abs, ascending=False)\n",
        "    elif task_id == 2:\n",
        "        return \"FISHER_TRAIN\", fisher_score(X_train, y_train).sort_values(ascending=False)\n",
        "    elif task_id == 3:\n",
        "        return \"MI_TRAIN\", pd.Series(\n",
        "            mutual_info_classif(X_train, y_train.fillna(0), random_state=0),\n",
        "            index=X_train.columns\n",
        "        ).sort_values(ascending=False)\n",
        "    elif task_id == 4:\n",
        "        return \"PEARSON_TEST\", X_test.corrwith(y_test).sort_values(key=abs, ascending=False)\n",
        "    elif task_id == 5:\n",
        "        return \"FISHER_TEST\", fisher_score(X_test, y_test).sort_values(ascending=False)\n",
        "    elif task_id == 6:\n",
        "        return \"MI_TEST\", pd.Series(\n",
        "            mutual_info_classif(X_test, y_test.fillna(0), random_state=0),\n",
        "            index=X_test.columns\n",
        "        ).sort_values(ascending=False)\n",
        "\n",
        "# Run feature importance calculations in parallel\n",
        "if __name__ == \"__main__\":\n",
        "    with Pool(processes=min(6, cpu_count())) as pool:\n",
        "        results = pool.map(compute_score, [1, 2, 3, 4, 5, 6])\n",
        "\n",
        "    # Save results to text file\n",
        "    with open(\"feature_scores_miniRules0_statusInfos.txt\", \"w\") as f:\n",
        "        for name, series in results:\n",
        "            f.write(f\"\\nüîπ TOP 15 FEATURES BY {name.replace('_', ' ')}\\n\")\n",
        "            f.write(series.head(15).to_string())\n",
        "            f.write(\"\\n\")\n",
        "\n",
        "    print(\"‚úÖ Parallel feature score results saved to 'feature_scores_miniRules0_statusInfos.txt'\")\n"
      ],
      "metadata": {
        "id": "QW_p4OhQWk7c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile test_imputation.py\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
        "import time\n",
        "\n",
        "# === Start the timer ===\n",
        "start = time.time()\n",
        "\n",
        "# === Load the data ===\n",
        "train_original = pd.read_csv(\"train.csv\", low_memory=False)\n",
        "train_copy = train_original.copy(deep=True)\n",
        "\n",
        "# === Select relevant columns ===\n",
        "selected_features = [\n",
        "    'totalPrice',\n",
        "    'companyID',\n",
        "    'legs0_segments0_cabinClass',\n",
        "    'isAccess3D',\n",
        "    'isVip',\n",
        "    'legs0_segments0_seatsAvailable',\n",
        "    'legs0_segments0_flightNumber',\n",
        "    'taxes',\n",
        "    'legs0_segments0_baggageAllowance_quantity',\n",
        "    'legs0_segments0_baggageAllowance_weightMeasurementType',\n",
        "    'pricingInfo_isAccessTP',\n",
        "    'miniRules0_monetaryAmount',\n",
        "    'miniRules1_monetaryAmount'\n",
        "]\n",
        "\n",
        "target_col = 'miniRules0_statusInfos'\n",
        "cols_needed = selected_features + [target_col]\n",
        "\n",
        "# === Filter complete rows for training ===\n",
        "df_full = train_copy[cols_needed].dropna(subset=cols_needed)\n",
        "\n",
        "# === Randomly select 1,500,000 rows for validation ===\n",
        "sample = df_full.sample(n=1500000, random_state=42)\n",
        "X_valid = sample[selected_features]\n",
        "y_valid = sample[target_col].astype(int)\n",
        "\n",
        "# === Remove those rows from training data ===\n",
        "df_train = df_full.drop(sample.index, errors='ignore')\n",
        "X_train = df_train[selected_features]\n",
        "y_train = df_train[target_col].astype(int)\n",
        "\n",
        "# === Train a classification model ===\n",
        "model = XGBClassifier(\n",
        "    n_estimators=500,\n",
        "    max_depth=12,\n",
        "    learning_rate=0.1,\n",
        "    tree_method='hist',\n",
        "    n_jobs=24,\n",
        "    random_state=42,\n",
        "    use_label_encoder=False,\n",
        "    eval_metric='logloss'\n",
        ")\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# === Predict on the validation set ===\n",
        "predicted = model.predict(X_valid)\n",
        "\n",
        "# === Compute evaluation metrics ===\n",
        "acc = accuracy_score(y_valid, predicted)\n",
        "f1 = f1_score(y_valid, predicted)\n",
        "cm = confusion_matrix(y_valid, predicted)\n",
        "duration = round(time.time() - start, 2)\n",
        "\n",
        "# === Save results to file ===\n",
        "with open(\"imputation_results.txt\", \"w\") as f:\n",
        "    f.write(\"‚úÖ Direct prediction results (XGBClassifier):\\n\")\n",
        "    f.write(f\"Accuracy: {acc:.4f}\\n\")\n",
        "    f.write(f\"F1 Score: {f1:.4f}\\n\")\n",
        "    f.write(\"Confusion Matrix:\\n\")\n",
        "    f.write(np.array2string(cm))\n",
        "    f.write(f\"\\n‚è±Ô∏è Duration: {duration} seconds\\n\")\n",
        "\n",
        "# === Print to console ===\n",
        "print(\"‚úÖ Results saved to imputation_results.txt\")\n"
      ],
      "metadata": {
        "id": "r_n4VhUIWuCU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "‚úÖ Direct prediction results (XGBClassifier):\n",
        "\n",
        "Accuracy: 0.9999\n",
        "\n",
        "F1 Score: 1.0000\n",
        "\n",
        "Confusion Matrix:\n",
        "\n",
        "[[  38388      40]\n",
        "\n",
        " [     47 1461525]]\n",
        "\n",
        "‚è±Ô∏è Duration: 211.24 seconds"
      ],
      "metadata": {
        "id": "kkzSSXRZWu1V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile test_imputation.py\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
        "import time\n",
        "\n",
        "# === Start the timer ===\n",
        "start = time.time()\n",
        "\n",
        "# === Load the data ===\n",
        "train_original = pd.read_csv(\"train.csv\", low_memory=False)\n",
        "train_copy = train_original.copy(deep=True)\n",
        "\n",
        "# === Select relevant columns ===\n",
        "selected_features = [\n",
        "    'totalPrice',\n",
        "    'companyID',\n",
        "    'legs0_segments0_cabinClass',\n",
        "    'isAccess3D',\n",
        "    'isVip',\n",
        "    'legs0_segments0_seatsAvailable',\n",
        "    'legs0_segments0_flightNumber',\n",
        "    'taxes',\n",
        "    'legs0_segments0_baggageAllowance_quantity',\n",
        "    'legs0_segments0_baggageAllowance_weightMeasurementType',\n",
        "    'pricingInfo_isAccessTP'\n",
        "]\n",
        "\n",
        "target_col = 'miniRules0_statusInfos'\n",
        "cols_needed = selected_features + [target_col]\n",
        "\n",
        "# === Filter complete rows for training ===\n",
        "df_full = train_copy[cols_needed].dropna(subset=cols_needed)\n",
        "\n",
        "# === Randomly select 1,500,000 rows for validation ===\n",
        "sample = df_full.sample(n=1500000, random_state=42)\n",
        "X_valid = sample[selected_features]\n",
        "y_valid = sample[target_col].astype(int)\n",
        "\n",
        "# === Remove these rows from the training data ===\n",
        "df_train = df_full.drop(sample.index, errors='ignore')\n",
        "X_train = df_train[selected_features]\n",
        "y_train = df_train[target_col].astype(int)\n",
        "\n",
        "# === Train a classification model ===\n",
        "model = XGBClassifier(\n",
        "    n_estimators=500,\n",
        "    max_depth=12,\n",
        "    learning_rate=0.1,\n",
        "    tree_method='hist',\n",
        "    n_jobs=24,\n",
        "    random_state=42,\n",
        "    use_label_encoder=False,\n",
        "    eval_metric='logloss'\n",
        ")\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# === Predict on the validation set ===\n",
        "predicted = model.predict(X_valid)\n",
        "\n",
        "# === Compute evaluation metrics ===\n",
        "acc = accuracy_score(y_valid, predicted)\n",
        "f1 = f1_score(y_valid, predicted)\n",
        "cm = confusion_matrix(y_valid, predicted)\n",
        "duration = round(time.time() - start, 2)\n",
        "\n",
        "# === Save results to file ===\n",
        "with open(\"imputation_results.txt\", \"w\") as f:\n",
        "    f.write(\"‚úÖ Direct prediction results (XGBClassifier):\\n\")\n",
        "    f.write(f\"Accuracy: {acc:.4f}\\n\")\n",
        "    f.write(f\"F1 Score: {f1:.4f}\\n\")\n",
        "    f.write(\"Confusion Matrix:\\n\")\n",
        "    f.write(np.array2string(cm))\n",
        "    f.write(f\"\\n‚è±Ô∏è Duration: {duration} seconds\\n\")\n",
        "\n",
        "# === Also print to console ===\n",
        "print(\"‚úÖ Results saved to imputation_results.txt\")\n"
      ],
      "metadata": {
        "id": "TDvZ7PDXW51E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "‚úÖ Direct prediction results (XGBClassifier):\n",
        "\n",
        "Accuracy: 0.9996\n",
        "\n",
        "F1 Score: 0.9998\n",
        "\n",
        "Confusion Matrix:\n",
        "\n",
        "[[  38090     338]\n",
        "\n",
        " [    312 1461260]]\n",
        "\n",
        "‚è±Ô∏è Duration: 231.31 seconds"
      ],
      "metadata": {
        "id": "_56q9GLoW6yM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile missing_miniRules_statusInfo.py\n",
        "import pandas as pd\n",
        "\n",
        "# Load existing files\n",
        "train = pd.read_csv(\"train.csv\", low_memory=False)\n",
        "test = pd.read_csv(\"test.csv\", low_memory=False)\n",
        "\n",
        "# Create binary columns indicating the presence of values\n",
        "train[\"miniRules0_statusInfos_was_missing\"] = train[\"miniRules0_statusInfos\"].notna().astype(int)\n",
        "train[\"miniRules1_statusInfos_was_missing\"] = train[\"miniRules1_statusInfos\"].notna().astype(int)\n",
        "\n",
        "test[\"miniRules0_statusInfos_was_missing\"] = test[\"miniRules0_statusInfos\"].notna().astype(int)\n",
        "test[\"miniRules1_statusInfos_was_missing\"] = test[\"miniRules1_statusInfos\"].notna().astype(int)\n",
        "\n",
        "# Save updated files\n",
        "train.to_csv(\"train.csv\", index=False)\n",
        "test.to_csv(\"test.csv\", index=False)\n",
        "\n",
        "print(\"‚úÖ Columns *_was_missing have been added to 'train.csv' and 'test.csv'.\")\n"
      ],
      "metadata": {
        "id": "-BTJkOj3XALk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile impute_miniRules0_statusInfos.py\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from xgboost import XGBClassifier\n",
        "import time\n",
        "\n",
        "# === Timer ===\n",
        "start = time.time()\n",
        "\n",
        "# === Load files ===\n",
        "train = pd.read_csv(\"train.csv\", low_memory=False)\n",
        "test = pd.read_csv(\"test.csv\", low_memory=False)\n",
        "\n",
        "# === Relevant features ===\n",
        "features = [\n",
        "    'totalPrice',\n",
        "    'companyID',\n",
        "    'legs0_segments0_cabinClass',\n",
        "    'isAccess3D',\n",
        "    'isVip',\n",
        "    'legs0_segments0_seatsAvailable',\n",
        "    'legs0_segments0_flightNumber',\n",
        "    'taxes',\n",
        "    'legs0_segments0_baggageAllowance_quantity',\n",
        "    'legs0_segments0_baggageAllowance_weightMeasurementType',\n",
        "    'pricingInfo_isAccessTP',\n",
        "    'miniRules0_monetaryAmount',\n",
        "    'miniRules1_monetaryAmount'\n",
        "]\n",
        "target = 'miniRules0_statusInfos'\n",
        "\n",
        "# === Train on complete rows from train set ===\n",
        "train_valid = train.dropna(subset=features + [target])\n",
        "X_train = train_valid[features]\n",
        "y_train = train_valid[target].astype(int)\n",
        "\n",
        "# === Train the model ===\n",
        "model = XGBClassifier(\n",
        "    n_estimators=500,\n",
        "    max_depth=12,\n",
        "    learning_rate=0.1,\n",
        "    tree_method='hist',\n",
        "    n_jobs=24,\n",
        "    random_state=42,\n",
        "    use_label_encoder=False,\n",
        "    eval_metric='logloss'\n",
        ")\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# === Imputation function ===\n",
        "def impute_column(df, name=\"train\"):\n",
        "    missing_mask = df[target].isna()\n",
        "    if missing_mask.sum() == 0:\n",
        "        print(f\"‚úÖ {name}: No missing values in '{target}'\")\n",
        "        return df\n",
        "\n",
        "    X_missing = df.loc[missing_mask, features]\n",
        "    preds = model.predict(X_missing)\n",
        "    df.loc[missing_mask, target] = preds\n",
        "    print(f\"‚úÖ {name}: Imputed {missing_mask.sum()} missing values in '{target}'\")\n",
        "    return df\n",
        "\n",
        "# === Perform imputation ===\n",
        "train = impute_column(train, \"train\")\n",
        "test = impute_column(test, \"test\")\n",
        "\n",
        "# === Overwrite updated CSV files ===\n",
        "train.to_csv(\"train.csv\", index=False)\n",
        "test.to_csv(\"test.csv\", index=False)\n",
        "\n",
        "# === Post-imputation statistics ===\n",
        "def report(df, name):\n",
        "    total = len(df)\n",
        "    missing = df[target].isna().sum()\n",
        "    value_counts = df[target].value_counts(dropna=False).sort_index()\n",
        "    print(f\"\\nüìä {name} ‚Äî '{target}':\")\n",
        "    print(f\"  Total rows: {total}\")\n",
        "    print(f\"  Missing: {missing} ({100 * missing / total:.2f}%)\")\n",
        "    print(\"  Value counts (including imputed):\")\n",
        "    print(value_counts)\n",
        "\n",
        "report(train, \"train\")\n",
        "report(test, \"test\")\n",
        "\n",
        "# === Done ===\n",
        "print(f\"\\n‚è±Ô∏è Total duration: {round(time.time() - start, 2)} seconds\")\n"
      ],
      "metadata": {
        "id": "vA8ioHz8XLck"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile impute_miniRules0_statusInfos.py\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from xgboost import XGBClassifier\n",
        "import time\n",
        "\n",
        "# === Timer ===\n",
        "start = time.time()\n",
        "\n",
        "# === Load files ===\n",
        "train = pd.read_csv(\"train.csv\", low_memory=False)\n",
        "test = pd.read_csv(\"test.csv\", low_memory=False)\n",
        "\n",
        "# === Relevant features ===\n",
        "features = [\n",
        "    'totalPrice',\n",
        "    'companyID',\n",
        "    'legs0_segments0_cabinClass',\n",
        "    'isAccess3D',\n",
        "    'isVip',\n",
        "    'legs0_segments0_seatsAvailable',\n",
        "    'legs0_segments0_flightNumber',\n",
        "    'taxes',\n",
        "    'legs0_segments0_baggageAllowance_quantity',\n",
        "    'legs0_segments0_baggageAllowance_weightMeasurementType',\n",
        "    'pricingInfo_isAccessTP',\n",
        "    'miniRules0_monetaryAmount',\n",
        "    'miniRules1_monetaryAmount'\n",
        "]\n",
        "target = 'miniRules0_statusInfos'\n",
        "\n",
        "# === Train on complete rows from train set ===\n",
        "train_valid = train.dropna(subset=features + [target])\n",
        "X_train = train_valid[features]\n",
        "y_train = train_valid[target].astype(int)\n",
        "\n",
        "# === Train the model ===\n",
        "model = XGBClassifier(\n",
        "    n_estimators=500,\n",
        "    max_depth=12,\n",
        "    learning_rate=0.1,\n",
        "    tree_method='hist',\n",
        "    n_jobs=24,\n",
        "    random_state=42,\n",
        "    use_label_encoder=False,\n",
        "    eval_metric='logloss'\n",
        ")\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# === Imputation function ===\n",
        "def impute_column(df, name=\"train\"):\n",
        "    missing_mask = df[target].isna()\n",
        "    if missing_mask.sum() == 0:\n",
        "        print(f\"‚úÖ {name}: No missing values in '{target}'\")\n",
        "        return df\n",
        "\n",
        "    X_missing = df.loc[missing_mask, features]\n",
        "    preds = model.predict(X_missing)\n",
        "    df.loc[missing_mask, target] = preds\n",
        "    print(f\"‚úÖ {name}: Imputed {missing_mask.sum()} missing values in '{target}'\")\n",
        "    return df\n",
        "\n",
        "# === Perform imputation ===\n",
        "train = impute_column(train, \"train\")\n",
        "test = impute_column(test, \"test\")\n",
        "\n",
        "# === Overwrite updated CSV files ===\n",
        "train.to_csv(\"train.csv\", index=False)\n",
        "test.to_csv(\"test.csv\", index=False)\n",
        "\n",
        "# === Post-imputation statistics ===\n",
        "def report(df, name):\n",
        "    total = len(df)\n",
        "    missing = df[target].isna().sum()\n",
        "    value_counts = df[target].value_counts(dropna=False).sort_index()\n",
        "    print(f\"\\nüìä {name} ‚Äî '{target}':\")\n",
        "    print(f\"  Total rows: {total}\")\n",
        "    print(f\"  Missing: {missing} ({100 * missing / total:.2f}%)\")\n",
        "    print(\"  Value counts (including imputed):\")\n",
        "    print(value_counts)\n",
        "\n",
        "report(train, \"train\")\n",
        "report(test, \"test\")\n",
        "\n",
        "# === Done ===\n",
        "print(f\"\\n‚è±Ô∏è Total duration: {round(time.time() - start, 2)} seconds\")\n"
      ],
      "metadata": {
        "id": "bGLUFHgnXSQM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile test_imputation.py\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
        "import time\n",
        "\n",
        "# === Start the timer ===\n",
        "start = time.time()\n",
        "\n",
        "# === Load the data ===\n",
        "train_original = pd.read_csv(\"train.csv\", low_memory=False)\n",
        "train_copy = train_original.copy(deep=True)\n",
        "\n",
        "# === Select relevant columns ===\n",
        "selected_features = [\n",
        "    'totalPrice',\n",
        "    'companyID',\n",
        "    'legs0_segments0_cabinClass',\n",
        "    'isAccess3D',\n",
        "    'isVip',\n",
        "    'legs0_segments0_seatsAvailable',\n",
        "    'legs0_segments0_flightNumber',\n",
        "    'taxes',\n",
        "    'legs0_segments0_baggageAllowance_quantity',\n",
        "    'legs0_segments0_baggageAllowance_weightMeasurementType',\n",
        "    'pricingInfo_isAccessTP',\n",
        "    'miniRules0_monetaryAmount',\n",
        "    'miniRules1_monetaryAmount'\n",
        "]\n",
        "\n",
        "target_col = 'miniRules1_statusInfos'\n",
        "cols_needed = selected_features + [target_col]\n",
        "\n",
        "# === Filter complete rows for training ===\n",
        "df_full = train_copy[cols_needed].dropna(subset=cols_needed)\n",
        "\n",
        "# === Randomly select 1,500,000 rows for validation ===\n",
        "sample = df_full.sample(n=1500000, random_state=42)\n",
        "X_valid = sample[selected_features]\n",
        "y_valid = sample[target_col].astype(int)\n",
        "\n",
        "# === Remove these rows from training data ===\n",
        "df_train = df_full.drop(sample.index, errors='ignore')\n",
        "X_train = df_train[selected_features]\n",
        "y_train = df_train[target_col].astype(int)\n",
        "\n",
        "# === Train a classification model ===\n",
        "model = XGBClassifier(\n",
        "    n_estimators=500,\n",
        "    max_depth=12,\n",
        "    learning_rate=0.1,\n",
        "    tree_method='hist',\n",
        "    n_jobs=24,\n",
        "    random_state=42,\n",
        "    use_label_encoder=False,\n",
        "    eval_metric='logloss'\n",
        ")\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# === Predict missing values from the sample ===\n",
        "predicted = model.predict(X_valid)\n",
        "\n",
        "# === Compute metrics ===\n",
        "acc = accuracy_score(y_valid, predicted)\n",
        "f1 = f1_score(y_valid, predicted)\n",
        "cm = confusion_matrix(y_valid, predicted)\n",
        "duration = round(time.time() - start, 2)\n",
        "\n",
        "# === Save results to file ===\n",
        "with open(\"imputation_results.txt\", \"w\") as f:\n",
        "    f.write(\"‚úÖ Direct prediction results (XGBClassifier):\\n\")\n",
        "    f.write(f\"Accuracy: {acc:.4f}\\n\")\n",
        "    f.write(f\"F1 Score: {f1:.4f}\\n\")\n",
        "    f.write(\"Confusion Matrix:\\n\")\n",
        "    f.write(np.array2string(cm))\n",
        "    f.write(f\"\\n‚è±Ô∏è Duration: {duration} seconds\\n\")\n",
        "\n",
        "# === Also print to console ===\n",
        "print(\"‚úÖ Results saved to imputation_results.txt\")\n"
      ],
      "metadata": {
        "id": "RqQzjSdjXgIr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "‚úÖ Direct prediction results (XGBClassifier):\n",
        "\n",
        "Accuracy: 0.9999\n",
        "\n",
        "F1 Score: 0.9999\n",
        "\n",
        "Confusion Matrix:\n",
        "\n",
        "[[629422     65]\n",
        "\n",
        " [    69 870444]]\n",
        "\n",
        "‚è±Ô∏è Duration: 217.45 seconds"
      ],
      "metadata": {
        "id": "6hud1pMaXhvj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile impute_miniRules1_statusInfos.py\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from xgboost import XGBClassifier\n",
        "import time\n",
        "\n",
        "# === Timer ===\n",
        "start = time.time()\n",
        "\n",
        "# === Load the files ===\n",
        "train = pd.read_csv(\"train.csv\", low_memory=False)\n",
        "test = pd.read_csv(\"test.csv\", low_memory=False)\n",
        "\n",
        "# === Relevant columns ===\n",
        "features = [\n",
        "    'totalPrice',\n",
        "    'companyID',\n",
        "    'legs0_segments0_cabinClass',\n",
        "    'isAccess3D',\n",
        "    'isVip',\n",
        "    'legs0_segments0_seatsAvailable',\n",
        "    'legs0_segments0_flightNumber',\n",
        "    'taxes',\n",
        "    'legs0_segments0_baggageAllowance_quantity',\n",
        "    'legs0_segments0_baggageAllowance_weightMeasurementType',\n",
        "    'pricingInfo_isAccessTP',\n",
        "    'miniRules0_monetaryAmount',\n",
        "    'miniRules1_monetaryAmount'\n",
        "]\n",
        "target = 'miniRules1_statusInfos'\n",
        "\n",
        "# === Train on complete rows from train ===\n",
        "train_valid = train.dropna(subset=features + [target])\n",
        "X_train = train_valid[features]\n",
        "y_train = train_valid[target].astype(int)\n",
        "\n",
        "# === Train the model ===\n",
        "model = XGBClassifier(\n",
        "    n_estimators=500,\n",
        "    max_depth=12,\n",
        "    learning_rate=0.1,\n",
        "    tree_method='hist',\n",
        "    n_jobs=24,\n",
        "    random_state=42,\n",
        "    use_label_encoder=False,\n",
        "    eval_metric='logloss'\n",
        ")\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# === Imputation function ===\n",
        "def impute_column(df, name=\"train\"):\n",
        "    missing_mask = df[target].isna()\n",
        "    if missing_mask.sum() == 0:\n",
        "        print(f\"‚úÖ {name}: No missing values in '{target}'\")\n",
        "        return df\n",
        "\n",
        "    X_missing = df.loc[missing_mask, features]\n",
        "    preds = model.predict(X_missing)\n",
        "    df.loc[missing_mask, target] = preds\n",
        "    print(f\"‚úÖ {name}: Imputed {missing_mask.sum()} missing values in '{target}'\")\n",
        "    return df\n",
        "\n",
        "# === Perform imputation ===\n",
        "train = impute_column(train, \"train\")\n",
        "test = impute_column(test, \"test\")\n",
        "\n",
        "# === Overwrite the CSV files ===\n",
        "train.to_csv(\"train.csv\", index=False)\n",
        "test.to_csv(\"test.csv\", index=False)\n",
        "\n",
        "# === Post-imputation statistics ===\n",
        "def report(df, name):\n",
        "    total = len(df)\n",
        "    missing = df[target].isna().sum()\n",
        "    value_counts = df[target].value_counts(dropna=False).sort_index()\n",
        "    print(f\"\\nüìä {name} ‚Äî '{target}':\")\n",
        "    print(f\"  Total rows: {total}\")\n",
        "    print(f\"  Missing: {missing} ({100 * missing / total:.2f}%)\")\n",
        "    print(\"  Value counts (including imputed):\")\n",
        "    print(value_counts)\n",
        "\n",
        "report(train, \"train\")\n",
        "report(test, \"test\")\n",
        "\n",
        "# === Done ===\n",
        "print(f\"\\n‚è±Ô∏è Total duration: {round(time.time() - start, 2)} seconds\")\n"
      ],
      "metadata": {
        "id": "fk8SVZxJX1sb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Parameters: { \"use_label_encoder\" } are not used.\n",
        "\n",
        "  warnings.warn(smsg, UserWarning)\n",
        "‚úÖ train: Imputed 1518169 missing values in 'miniRules1_statusInfos'\n",
        "‚úÖ test: Imputed 574432 missing values in 'miniRules1_statusInfos'\n",
        "\n",
        "üìä train ‚Äî 'miniRules1_statusInfos':\n",
        "  Total rows: 18145372\n",
        "  Missing: 0 (0.00%)\n",
        "  Value counts (including imputed):\n",
        "miniRules1_statusInfos\n",
        "0.0     7832405\n",
        "1.0    10312967\n",
        "Name: count, dtype: int64\n",
        "\n",
        "üìä test ‚Äî 'miniRules1_statusInfos':\n",
        "  Total rows: 6897776\n",
        "  Missing: 0 (0.00%)\n",
        "  Value counts (including imputed):\n",
        "miniRules1_statusInfos\n",
        "0.0    3173816\n",
        "1.0    3723960\n",
        "Name: count, dtype: int64\n",
        "\n",
        "‚è±Ô∏è Total duration: 518.28 seconds"
      ],
      "metadata": {
        "id": "i8zwcTcmX3bj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile corr_legs1_segments0_flightNumber.py\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_selection import mutual_info_classif\n",
        "from scipy.stats import spearmanr\n",
        "from multiprocessing import Pool, cpu_count\n",
        "\n",
        "# === Load the data ===\n",
        "train = pd.read_csv('train.csv')\n",
        "test = pd.read_csv('test.csv')\n",
        "\n",
        "# === Define the target ===\n",
        "target = 'legs1_segments0_flightNumber'\n",
        "y_train = train[target]\n",
        "y_test = test[target]\n",
        "\n",
        "# === Drop irrelevant columns ===\n",
        "drop_cols = [\n",
        "    'Id', 'profileId', '__index_level_0__', 'requestDate',\n",
        "    'searchRoute', 'legs0_arrivalAt', 'legs0_departureAt',\n",
        "    'legs1_arrivalAt', 'legs1_departureAt'\n",
        "]\n",
        "\n",
        "# === Select common, clean numeric columns ===\n",
        "common_cols = list(set(train.columns) & set(test.columns))\n",
        "numeric_cols = train[common_cols].select_dtypes(include=['float64', 'int64', 'bool']).columns\n",
        "numeric_cols = [col for col in numeric_cols if col not in drop_cols and col != target]\n",
        "numeric_cols = [\n",
        "    col for col in numeric_cols\n",
        "    if train[col].isnull().sum() == 0 and test[col].isnull().sum() == 0\n",
        "]\n",
        "\n",
        "X_train = train[numeric_cols]\n",
        "X_test = test[numeric_cols]\n",
        "\n",
        "# === Fisher Score ===\n",
        "def fisher_score(X, y):\n",
        "    scores = {}\n",
        "    classes = np.unique(y.dropna())\n",
        "    for col in X.columns:\n",
        "        x = X[col]\n",
        "        mean_overall = x.mean()\n",
        "        numerator = 0\n",
        "        denominator = 0\n",
        "        for cls in classes:\n",
        "            xi = x[y == cls]\n",
        "            ni = len(xi)\n",
        "            mean_i = xi.mean()\n",
        "            var_i = xi.var()\n",
        "            numerator += ni * (mean_i - mean_overall) ** 2\n",
        "            denominator += ni * var_i\n",
        "        scores[col] = numerator / denominator if denominator != 0 else 0\n",
        "    return pd.Series(scores)\n",
        "\n",
        "# === Spearman correlation ===\n",
        "def spearman_series(X, y):\n",
        "    scores = {}\n",
        "    for col in X.columns:\n",
        "        try:\n",
        "            rho, _ = spearmanr(X[col], y)\n",
        "            scores[col] = rho\n",
        "        except:\n",
        "            scores[col] = 0\n",
        "    return pd.Series(scores)\n",
        "\n",
        "# === Compute scores ===\n",
        "def compute_score(task_id):\n",
        "    if task_id == 1:\n",
        "        return \"PEARSON_TRAIN\", X_train.corrwith(y_train).sort_values(key=abs, ascending=False)\n",
        "    elif task_id == 2:\n",
        "        return \"FISHER_TRAIN\", fisher_score(X_train, y_train).sort_values(ascending=False)\n",
        "    elif task_id == 3:\n",
        "        return \"MI_TRAIN\", pd.Series(\n",
        "            mutual_info_classif(X_train, y_train.fillna(0), random_state=0),\n",
        "            index=X_train.columns\n",
        "        ).sort_values(ascending=False)\n",
        "    elif task_id == 4:\n",
        "        return \"PEARSON_TEST\", X_test.corrwith(y_test).sort_values(key=abs, ascending=False)\n",
        "    elif task_id == 5:\n",
        "        return \"FISHER_TEST\", fisher_score(X_test, y_test).sort_values(ascending=False)\n",
        "    elif task_id == 6:\n",
        "        return \"MI_TEST\", pd.Series(\n",
        "            mutual_info_classif(X_test, y_test.fillna(0), random_state=0),\n",
        "            index=X_test.columns\n",
        "        ).sort_values(ascending=False)\n",
        "    elif task_id == 7:\n",
        "        return \"SPEARMAN_TRAIN\", spearman_series(X_train, y_train).sort_values(key=abs, ascending=False)\n",
        "    elif task_id == 8:\n",
        "        return \"SPEARMAN_TEST\", spearman_series(X_test, y_test).sort_values(key=abs, ascending=False)\n",
        "\n",
        "# === Run in parallel ===\n",
        "if __name__ == \"__main__\":\n",
        "    tasks = list(range(1, 9))  # Include Spearman as well\n",
        "    with Pool(processes=min(len(tasks), cpu_count())) as pool:\n",
        "        results = pool.map(compute_score, tasks)\n",
        "\n",
        "    with open(\"feature_scores_legs1_segments0_flightNumber.txt\", \"w\", encoding=\"utf-8\") as f:\n",
        "        for name, series in results:\n",
        "            f.write(f\"\\nüîπ TOP 15 FEATURES BY {name.replace('_', ' ')}\\n\")\n",
        "            f.write(series.head(15).to_string())\n",
        "            f.write(\"\\n\")\n",
        "\n",
        "    print(\"‚úÖ Feature score results saved to 'feature_scores_legs1_segments0_flightNumber.txt'\")\n"
      ],
      "metadata": {
        "id": "sylx1_KBYQyL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile check_frequencies.py\n",
        "import pandas as pd\n",
        "\n",
        "# === Load the files ===\n",
        "train_df = pd.read_csv(\"train.csv\", usecols=['legs1_segments0_flightNumber'])\n",
        "test_df = pd.read_csv(\"test.csv\", usecols=['legs1_segments0_flightNumber'])\n",
        "\n",
        "# === Frequencies ===\n",
        "train_counts = train_df['legs1_segments0_flightNumber'].value_counts().rename(\"train_count\")\n",
        "test_counts = test_df['legs1_segments0_flightNumber'].value_counts().rename(\"test_count\")\n",
        "\n",
        "# === Combine frequencies into a single DataFrame ===\n",
        "freq_df = pd.concat([train_counts, test_counts], axis=1).fillna(0).astype(int)\n",
        "freq_df.index.name = 'flight_number'\n",
        "freq_df = freq_df.sort_values(by='train_count', ascending=False)\n",
        "\n",
        "# === Write to text file ===\n",
        "with open(\"class_frequencies.txt\", \"w\") as f:\n",
        "    f.write(\"üìä Class frequencies in 'train.csv' and 'test.csv'\\n\\n\")\n",
        "    f.write(f\"{'Flight Number':<20}{'Train Count':<15}{'Test Count':<15}\\n\")\n",
        "    f.write(\"=\" * 50 + \"\\n\")\n",
        "    for idx, row in freq_df.iterrows():\n",
        "        f.write(f\"{str(idx):<20}{row['train_count']:<15}{row['test_count']:<15}\\n\")\n",
        "\n",
        "print(\"‚úÖ Class frequencies saved to 'class_frequencies.txt'\")\n"
      ],
      "metadata": {
        "id": "Z14PBYTjYW6T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile test_imputation.py\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time\n",
        "from collections import Counter\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
        "\n",
        "start = time.time()\n",
        "\n",
        "# === Load data ===\n",
        "df = pd.read_csv(\"train.csv\", low_memory=False)\n",
        "\n",
        "# === Select columns ===\n",
        "features = [\n",
        "    'totalPrice', 'companyID', 'legs0_segments0_cabinClass',\n",
        "    'isAccess3D', 'isVip', 'legs0_segments0_seatsAvailable',\n",
        "    'legs0_segments0_flightNumber', 'taxes',\n",
        "    'legs0_segments0_baggageAllowance_quantity',\n",
        "    'legs0_segments0_baggageAllowance_weightMeasurementType',\n",
        "    'pricingInfo_isAccessTP', 'miniRules0_monetaryAmount',\n",
        "    'miniRules1_monetaryAmount', 'miniRules0_statusInfos',\n",
        "    'miniRules1_statusInfos'\n",
        "]\n",
        "target = 'legs1_segments0_flightNumber'\n",
        "df = df[features + [target]].dropna()\n",
        "\n",
        "# === Sample for validation ===\n",
        "valid_sample = df.sample(n=100000, random_state=42)\n",
        "train_df = df.drop(index=valid_sample.index, errors='ignore')\n",
        "\n",
        "# === Separate X and y ===\n",
        "X_train = train_df[features]\n",
        "X_valid = valid_sample[features]\n",
        "\n",
        "# === Label Encoding on target ===\n",
        "le = LabelEncoder()\n",
        "y_train_raw = train_df[target]\n",
        "y_valid_raw = valid_sample[target]\n",
        "\n",
        "# Fit encoder only on y_train\n",
        "le.fit(y_train_raw)\n",
        "y_train = le.transform(y_train_raw)\n",
        "\n",
        "# Filter validation ‚Äî only classes present in y_train\n",
        "mask = y_valid_raw.isin(le.classes_)\n",
        "X_valid = X_valid[mask]\n",
        "y_valid = y_valid_raw[mask]\n",
        "y_valid = le.transform(y_valid)\n",
        "\n",
        "# === Model ===\n",
        "model = XGBClassifier(\n",
        "    n_estimators=100,\n",
        "    max_depth=6,\n",
        "    learning_rate=0.1,\n",
        "    tree_method='hist',\n",
        "    n_jobs=12,\n",
        "    random_state=42,\n",
        "    use_label_encoder=False,\n",
        "    eval_metric='logloss'\n",
        ")\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# === Predictions ===\n",
        "y_pred = model.predict(X_valid)\n",
        "\n",
        "# === Metrics ===\n",
        "acc = accuracy_score(y_valid, y_pred)\n",
        "f1 = f1_score(y_valid, y_pred, average='weighted')\n",
        "cm_shape = confusion_matrix(y_valid, y_pred).shape\n",
        "duration = round(time.time() - start, 2)\n",
        "\n",
        "# === Output ===\n",
        "with open(\"imputation_results.txt\", \"w\") as f:\n",
        "    f.write(\"‚úÖ Direct prediction results (XGBClassifier + LabelEncoder):\\n\")\n",
        "    f.write(f\"Train examples: {len(X_train)}\\n\")\n",
        "    f.write(f\"Validation examples: {len(X_valid)}\\n\")\n",
        "    f.write(f\"Accuracy: {acc:.4f}\\n\")\n",
        "    f.write(f\"Weighted F1 Score: {f1:.4f}\\n\")\n",
        "    f.write(f\"Confusion Matrix shape: {cm_shape}\\n\")\n",
        "    top_preds = Counter(y_pred).most_common(10)\n",
        "    f.write(\"Top 10 predicted labels (encoded):\\n\")\n",
        "    for cls, count in top_preds:\n",
        "        original_label = le.inverse_transform([cls])[0]\n",
        "        f.write(f\"{cls} (raw: {original_label}): {count} predictions\\n\")\n",
        "    f.write(f\"\\n‚è±Ô∏è Duration: {duration} seconds\\n\")\n",
        "\n",
        "print(\"‚úÖ Results saved to imputation_results.txt\")\n"
      ],
      "metadata": {
        "id": "N8Wd_3S-YjNy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile summary_folder.py\n",
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "# === Config ===\n",
        "columns_to_analyze = [\n",
        "    \"legs1_segments0_duration\", \"legs1_segments0_aircraft_code\", \"legs1_arrivalAt\",\n",
        "    \"legs1_departureAt\", \"legs1_segments0_marketingCarrier_code\", \"legs1_duration\",\n",
        "    \"legs1_segments0_operatingCarrier_code\", \"legs1_segments0_arrivalTo_airport_iata\",\n",
        "    \"legs1_segments0_departureFrom_airport_iata\", \"legs1_segments0_arrivalTo_airport_city_iata\",\n",
        "    \"legs1_segments0_cabinClass\", \"legs1_segments0_baggageAllowance_weightMeasurementType\",\n",
        "    \"legs1_segments0_baggageAllowance_quantity\", \"legs1_segments0_seatsAvailable\",\n",
        "    \"corporateTariffCode\", \"frequentFlyer\"\n",
        "]\n",
        "\n",
        "datasets = {\n",
        "    \"Train\": pd.read_csv(\"train.csv\", low_memory=False),\n",
        "    \"Test\": pd.read_csv(\"test.csv\", low_memory=False)\n",
        "}\n",
        "\n",
        "# === Output folder ===\n",
        "output_dir = \"results\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# === Analysis function ===\n",
        "def get_feature_report(df, dataset_name, feature_name):\n",
        "    if feature_name not in df.columns:\n",
        "        return f\"{dataset_name}: Column '{feature_name}' not found.\\n\"\n",
        "\n",
        "    col = df[feature_name]\n",
        "    total = len(col)\n",
        "    missing = col.isna().sum()\n",
        "    pct_missing = missing / total * 100\n",
        "    nunique = col.nunique(dropna=True)\n",
        "    dtype = col.dtype\n",
        "\n",
        "    section = [\n",
        "        f\"üìä Dataset: {dataset_name}\",\n",
        "        f\"Column: {feature_name}\",\n",
        "        f\"Data type: {dtype}\",\n",
        "        f\"Total rows: {total:,}\",\n",
        "        f\"Missing values: {missing:,} ({pct_missing:.6f}%)\",\n",
        "        f\"Unique values (non-null): {nunique:,}\"\n",
        "    ]\n",
        "\n",
        "    if pd.api.types.is_numeric_dtype(col):\n",
        "        section.append(\"\\nüîπ Descriptive statistics:\")\n",
        "        section.append(str(col.describe()))\n",
        "    else:\n",
        "        section.append(\"\\nüîπ All unique non-null values:\")\n",
        "        unique_vals = col.dropna().unique()\n",
        "        # Show max 100 unique values to avoid overload\n",
        "        if len(unique_vals) > 100:\n",
        "            section.append(\", \".join(map(str, unique_vals[:100])) + \", ...\")\n",
        "        else:\n",
        "            section.append(\", \".join(map(str, unique_vals)))\n",
        "\n",
        "    return \"\\n\".join(section)\n",
        "\n",
        "# === Generate reports ===\n",
        "for feature in columns_to_analyze:\n",
        "    report = []\n",
        "    for name, df in datasets.items():\n",
        "        report.append(get_feature_report(df, name, feature))\n",
        "        report.append(\"\\n\" + \"=\" * 60 + \"\\n\")\n",
        "\n",
        "    output_text = \"\\n\".join(report)\n",
        "    output_file = os.path.join(output_dir, f\"{feature}_summary.txt\")\n",
        "    with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
        "        f.write(output_text)\n",
        "    print(f\"‚úÖ Saved: {output_file}\")"
      ],
      "metadata": {
        "id": "P6oEuNrAYme7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile corr_object_categorics.py\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_selection import mutual_info_classif\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from multiprocessing import Pool, cpu_count\n",
        "import os\n",
        "\n",
        "# === Ensure folder for results ===\n",
        "os.makedirs(\"results\", exist_ok=True)\n",
        "\n",
        "# === Load data and create copies ===\n",
        "train_orig = pd.read_csv('train.csv', low_memory=False)\n",
        "test_orig = pd.read_csv('test.csv', low_memory=False)\n",
        "train = train_orig.copy()\n",
        "test = test_orig.copy()\n",
        "\n",
        "# === List of categorical targets ===\n",
        "categorical_targets = [\n",
        "    \"legs1_segments0_aircraft_code\",\n",
        "    \"legs1_segments0_marketingCarrier_code\",\n",
        "    \"legs1_segments0_operatingCarrier_code\",\n",
        "    \"legs1_segments0_departureFrom_airport_iata\",\n",
        "    \"legs1_segments0_arrivalTo_airport_city_iata\"\n",
        "]\n",
        "\n",
        "# === Columns to ignore ===\n",
        "drop_cols = [\n",
        "    'Id', 'profileId', '__index_level_0__', 'requestDate',\n",
        "    'searchRoute', 'legs0_arrivalAt', 'legs0_departureAt',\n",
        "    'legs1_arrivalAt', 'legs1_departureAt'\n",
        "]\n",
        "\n",
        "# === Select common, clean numeric columns ===\n",
        "common_cols = list(set(train.columns) & set(test.columns))\n",
        "numeric_cols = train[common_cols].select_dtypes(include=['float64', 'int64', 'bool']).columns.tolist()\n",
        "numeric_cols = [col for col in numeric_cols if col not in drop_cols]\n",
        "numeric_cols = [\n",
        "    col for col in numeric_cols\n",
        "    if train[col].isnull().sum() == 0 and test[col].isnull().sum() == 0\n",
        "]\n",
        "\n",
        "X_train = train[numeric_cols]\n",
        "X_test = test[numeric_cols]\n",
        "\n",
        "# === Fisher Score ===\n",
        "def fisher_score(X, y):\n",
        "    scores = {}\n",
        "    classes = np.unique(y)\n",
        "    for col in X.columns:\n",
        "        x = X[col]\n",
        "        mean_overall = x.mean()\n",
        "        numerator = 0\n",
        "        denominator = 0\n",
        "        for cls in classes:\n",
        "            xi = x[y == cls]\n",
        "            ni = len(xi)\n",
        "            mean_i = xi.mean()\n",
        "            var_i = xi.var()\n",
        "            numerator += ni * (mean_i - mean_overall) ** 2\n",
        "            denominator += ni * var_i\n",
        "        scores[col] = numerator / denominator if denominator != 0 else 0\n",
        "    return pd.Series(scores)\n",
        "\n",
        "# === Function for parallel processing ===\n",
        "def process_target(target):\n",
        "    try:\n",
        "        print(f\"üîç Processing: {target}\")\n",
        "\n",
        "        # Encode target\n",
        "        combined = pd.concat([train[target], test[target]], axis=0).fillna(\"MISSING\")\n",
        "        le = LabelEncoder().fit(combined)\n",
        "\n",
        "        y_train = le.transform(train[target].fillna(\"MISSING\"))\n",
        "        y_test = le.transform(test[target].fillna(\"MISSING\"))\n",
        "\n",
        "        # Scores\n",
        "        fisher_train = fisher_score(X_train, y_train).sort_values(ascending=False)\n",
        "        fisher_test = fisher_score(X_test, y_test).sort_values(ascending=False)\n",
        "\n",
        "        mi_train = pd.Series(\n",
        "            mutual_info_classif(X_train, y_train, random_state=0),\n",
        "            index=X_train.columns\n",
        "        ).sort_values(ascending=False)\n",
        "\n",
        "        mi_test = pd.Series(\n",
        "            mutual_info_classif(X_test, y_test, random_state=0),\n",
        "            index=X_test.columns\n",
        "        ).sort_values(ascending=False)\n",
        "\n",
        "        # Save results\n",
        "        file_path = f\"results/corr_numerics_vs_{target}.txt\"\n",
        "        with open(file_path, \"w\", encoding=\"utf-8\") as f:\n",
        "            f.write(f\"üîπ TARGET: {target}\\n\")\n",
        "            f.write(f\"\\nüìä TOP 25 FEATURES BY FISHER (TRAIN)\\n\")\n",
        "            f.write(fisher_train.head(25).to_string())\n",
        "            f.write(f\"\\n\\nüìä TOP 25 FEATURES BY FISHER (TEST)\\n\")\n",
        "            f.write(fisher_test.head(25).to_string())\n",
        "            f.write(f\"\\n\\nüìä TOP 25 FEATURES BY MUTUAL INFO (TRAIN)\\n\")\n",
        "            f.write(mi_train.head(25).to_string())\n",
        "            f.write(f\"\\n\\nüìä TOP 25 FEATURES BY MUTUAL INFO (TEST)\\n\")\n",
        "            f.write(mi_test.head(25).to_string())\n",
        "\n",
        "        print(f\"‚úÖ Saved: {file_path}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error with {target}: {e}\")\n",
        "\n",
        "# === Parallel execution ===\n",
        "if __name__ == \"__main__\":\n",
        "    with Pool(processes=min(cpu_count(), len(categorical_targets))) as pool:\n",
        "        pool.map(process_target, categorical_targets)\n"
      ],
      "metadata": {
        "id": "8GYOi4KCZEAc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile test_imputation.py\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time\n",
        "from collections import Counter\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
        "\n",
        "start = time.time()\n",
        "\n",
        "# === Load the data ===\n",
        "df = pd.read_csv(\"train.csv\", low_memory=False)\n",
        "\n",
        "# === Select columns ===\n",
        "features = [\n",
        "    'totalPrice', 'companyID', 'legs0_segments0_cabinClass',\n",
        "    'isAccess3D', 'isVip', 'legs0_segments0_seatsAvailable',\n",
        "    'legs0_segments0_flightNumber', 'taxes',\n",
        "    'legs0_segments0_baggageAllowance_quantity',\n",
        "    'legs0_segments0_baggageAllowance_weightMeasurementType',\n",
        "    'pricingInfo_isAccessTP', 'miniRules0_monetaryAmount',\n",
        "    'miniRules1_monetaryAmount', 'miniRules0_statusInfos',\n",
        "    'miniRules1_statusInfos'\n",
        "]\n",
        "target = 'legs1_segments0_aircraft_code'\n",
        "df = df[features + [target]].dropna()\n",
        "\n",
        "# === Validation sample ===\n",
        "valid_sample = df.sample(n=1_000_000, random_state=42)\n",
        "train_df = df.drop(index=valid_sample.index, errors='ignore')\n",
        "\n",
        "# === Split X and y ===\n",
        "X_train = train_df[features]\n",
        "X_valid = valid_sample[features]\n",
        "\n",
        "# === Label Encoding on target ===\n",
        "le = LabelEncoder()\n",
        "y_train_raw = train_df[target]\n",
        "y_valid_raw = valid_sample[target]\n",
        "\n",
        "# Fit encoder only on y_train\n",
        "le.fit(y_train_raw)\n",
        "y_train = le.transform(y_train_raw)\n",
        "\n",
        "# Filter validation ‚Äî only classes present in y_train\n",
        "mask = y_valid_raw.isin(le.classes_)\n",
        "X_valid = X_valid[mask]\n",
        "y_valid = y_valid_raw[mask]\n",
        "y_valid = le.transform(y_valid)\n",
        "\n",
        "# === Model ===\n",
        "model = XGBClassifier(\n",
        "    n_estimators=100,\n",
        "    max_depth=6,\n",
        "    learning_rate=0.1,\n",
        "    tree_method='hist',\n",
        "    n_jobs=12,\n",
        "    random_state=42,\n",
        "    use_label_encoder=False,\n",
        "    eval_metric='logloss'\n",
        ")\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# === Predictions ===\n",
        "y_pred = model.predict(X_valid)\n",
        "\n",
        "# === Metrics ===\n",
        "acc = accuracy_score(y_valid, y_pred)\n",
        "f1 = f1_score(y_valid, y_pred, average='weighted')\n",
        "cm_shape = confusion_matrix(y_valid, y_pred).shape\n",
        "duration = round(time.time() - start, 2)\n",
        "\n",
        "# === Output ===\n",
        "with open(\"imputation_results.txt\", \"w\") as f:\n",
        "    f.write(\"‚úÖ Direct prediction results (XGBClassifier + LabelEncoder):\\n\")\n",
        "    f.write(f\"Train examples: {len(X_train)}\\n\")\n",
        "    f.write(f\"Validation examples: {len(X_valid)}\\n\")\n",
        "    f.write(f\"Accuracy: {acc:.4f}\\n\")\n",
        "    f.write(f\"Weighted F1 Score: {f1:.4f}\\n\")\n",
        "    f.write(f\"Confusion Matrix shape: {cm_shape}\\n\")\n",
        "    top_preds = Counter(y_pred).most_common(10)\n",
        "    f.write(\"Top 10 predicted labels (encoded):\\n\")\n",
        "    for cls, count in top_preds:\n",
        "        original_label = le.inverse_transform([cls])[0]\n",
        "        f.write(f\"{cls} (raw: {original_label}): {count} predictions\\n\")\n",
        "    f.write(f\"\\n‚è±Ô∏è Duration: {duration} seconds\\n\")\n",
        "\n",
        "print(\"‚úÖ Results saved to imputation_results.txt\")\n"
      ],
      "metadata": {
        "id": "ZdVBRr3sZPES"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "‚úÖ Direct prediction results (XGBClassifier + LabelEncoder):\n",
        "Train examples: 12758171\n",
        "Validation examples: 1000000\n",
        "Accuracy: 0.6711\n",
        "Weighted F1 Score: 0.6538\n",
        "Confusion Matrix shape: (89, 89)\n",
        "Top 10 predicted labels (encoded):\n",
        "87 (raw: SU9): 428925 predictions\n",
        "10 (raw: 32A): 140160 predictions\n",
        "11 (raw: 32B): 115466 predictions\n",
        "8 (raw: 320): 81614 predictions\n",
        "34 (raw: 73H): 72774 predictions\n",
        "9 (raw: 321): 25888 predictions\n",
        "75 (raw: E70): 22667 predictions\n",
        "30 (raw: 738): 21992 predictions\n",
        "51 (raw: 77W): 14813 predictions\n",
        "18 (raw: 333): 14485 predictions\n",
        "\n",
        "‚è±Ô∏è Duration: 1312.76 seconds"
      ],
      "metadata": {
        "id": "tzM2SFbVZQKa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile test_imputation.py\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time\n",
        "from collections import Counter\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
        "\n",
        "start = time.time()\n",
        "\n",
        "# === Load the data ===\n",
        "df = pd.read_csv(\"train.csv\", low_memory=False)\n",
        "\n",
        "# === Select columns ===\n",
        "features = [\n",
        "    'totalPrice', 'companyID', 'legs0_segments0_cabinClass',\n",
        "    'isAccess3D', 'isVip', 'legs0_segments0_seatsAvailable',\n",
        "    'legs0_segments0_flightNumber', 'taxes',\n",
        "    'legs0_segments0_baggageAllowance_quantity',\n",
        "    'legs0_segments0_baggageAllowance_weightMeasurementType',\n",
        "    'pricingInfo_isAccessTP', 'miniRules0_monetaryAmount',\n",
        "    'miniRules1_monetaryAmount', 'miniRules0_statusInfos',\n",
        "    'miniRules1_statusInfos'\n",
        "]\n",
        "target = 'legs1_segments0_aircraft_code'\n",
        "df = df[features + [target]].dropna()\n",
        "\n",
        "# === Sample for validation ===\n",
        "valid_sample = df.sample(n=1_000_000, random_state=42)\n",
        "train_df = df.drop(index=valid_sample.index, errors='ignore')\n",
        "\n",
        "# === Split X and y ===\n",
        "X_train = train_df[features]\n",
        "X_valid = valid_sample[features]\n",
        "\n",
        "# === Label Encoding for the target ===\n",
        "le = LabelEncoder()\n",
        "y_train_raw = train_df[target]\n",
        "y_valid_raw = valid_sample[target]\n",
        "\n",
        "# Fit encoder only on y_train\n",
        "le.fit(y_train_raw)\n",
        "y_train = le.transform(y_train_raw)\n",
        "\n",
        "# Filter validation ‚Äî only keep classes present in y_train\n",
        "mask = y_valid_raw.isin(le.classes_)\n",
        "X_valid = X_valid[mask]\n",
        "y_valid = y_valid_raw[mask]\n",
        "y_valid = le.transform(y_valid)\n",
        "\n",
        "# === Model ===\n",
        "model = XGBClassifier(\n",
        "    n_estimators=500,\n",
        "    max_depth=12,\n",
        "    learning_rate=0.1,\n",
        "    tree_method='hist',\n",
        "    n_jobs=24,\n",
        "    random_state=42,\n",
        "    use_label_encoder=False,\n",
        "    eval_metric='logloss'\n",
        ")\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# === Predictions ===\n",
        "y_pred = model.predict(X_valid)\n",
        "\n",
        "# === Metrics ===\n",
        "acc = accuracy_score(y_valid, y_pred)\n",
        "f1 = f1_score(y_valid, y_pred, average='weighted')\n",
        "cm_shape = confusion_matrix(y_valid, y_pred).shape\n",
        "duration = round(time.time() - start, 2)\n",
        "\n",
        "# === Output ===\n",
        "with open(\"imputation_results.txt\", \"w\") as f:\n",
        "    f.write(\"‚úÖ Direct prediction results (XGBClassifier + LabelEncoder):\\n\")\n",
        "    f.write(f\"Train examples: {len(X_train)}\\n\")\n",
        "    f.write(f\"Validation examples: {len(X_valid)}\\n\")\n",
        "    f.write(f\"Accuracy: {acc:.4f}\\n\")\n",
        "    f.write(f\"Weighted F1 Score: {f1:.4f}\\n\")\n",
        "    f.write(f\"Confusion Matrix shape: {cm_shape}\\n\")\n",
        "    top_preds = Counter(y_pred).most_common(10)\n",
        "    f.write(\"Top 10 predicted labels (encoded):\\n\")\n",
        "    for cls, count in top_preds:\n",
        "        original_label = le.inverse_transform([cls])[0]\n",
        "        f.write(f\"{cls} (raw: {original_label}): {count} predictions\\n\")\n",
        "    f.write(f\"\\n‚è±Ô∏è Duration: {duration} seconds\\n\")\n",
        "\n",
        "print(\"‚úÖ Results saved to imputation_results.txt\")\n"
      ],
      "metadata": {
        "id": "jQS0_U8yZbma"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "‚úÖ Direct prediction results (XGBClassifier + LabelEncoder):\n",
        "Train examples: 12758171\n",
        "Validation examples: 1000000\n",
        "Accuracy: 0.7599\n",
        "Weighted F1 Score: 0.7537\n",
        "Confusion Matrix shape: (90, 90)\n",
        "Top 10 predicted labels (encoded):\n",
        "87 (raw: SU9): 415296 predictions\n",
        "10 (raw: 32A): 137331 predictions\n",
        "11 (raw: 32B): 114387 predictions\n",
        "8 (raw: 320): 81964 predictions\n",
        "34 (raw: 73H): 70497 predictions\n",
        "9 (raw: 321): 31346 predictions\n",
        "30 (raw: 738): 19720 predictions\n",
        "75 (raw: E70): 16976 predictions\n",
        "51 (raw: 77W): 14871 predictions\n",
        "6 (raw: 319): 14477 predictions\n",
        "\n",
        "‚è±Ô∏è Duration: 8050.71 seconds"
      ],
      "metadata": {
        "id": "ciuPJX6HZety"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile add_column_legs1_segments0_aircraft_code_was_missing.py\n",
        "import pandas as pd\n",
        "\n",
        "# === Load the files ===\n",
        "train_df = pd.read_csv(\"train.csv\", low_memory=False)\n",
        "test_df = pd.read_csv(\"test.csv\", low_memory=False)\n",
        "\n",
        "# === Target column ===\n",
        "target_col = 'legs1_segments0_aircraft_code'\n",
        "flag_col = 'legs1_segments0_aircraft_code_was_missing'\n",
        "\n",
        "# === Add flag in TRAIN ===\n",
        "train_df[flag_col] = train_df[target_col].notna().astype(int)\n",
        "\n",
        "# === Add flag in TEST ===\n",
        "test_df[flag_col] = test_df[target_col].notna().astype(int)\n",
        "\n",
        "# === Overwrite original files ===\n",
        "train_df.to_csv(\"train.csv\", index=False)\n",
        "test_df.to_csv(\"test.csv\", index=False)\n",
        "\n",
        "# === Create report file ===\n",
        "with open(\"missing_flag_info.txt\", \"w\") as f:\n",
        "    f.write(\"üõ´ Flag: legs1_segments0_aircraft_code_was_missing\\n\\n\")\n",
        "\n",
        "    f.write(\"üìä TRAIN:\\n\")\n",
        "    f.write(train_df[flag_col].value_counts().rename({1: \"Values present\", 0: \"Values missing\"}).to_string())\n",
        "    f.write(\"\\n\\n\")\n",
        "\n",
        "    f.write(\"üìä TEST:\\n\")\n",
        "    f.write(test_df[flag_col].value_counts().rename({1: \"Values present\", 0: \"Values missing\"}).to_string())\n",
        "    f.write(\"\\n\")\n",
        "\n",
        "print(\"‚úÖ Column has been added to train.csv and test.csv.\")\n",
        "print(\"üìù Details saved in missing_flag_info.txt.\")\n"
      ],
      "metadata": {
        "id": "0rwZd-x8Zpu6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile impute_legs1_segments0_aircraft_code.py\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import time\n",
        "\n",
        "# === Timer ===\n",
        "start = time.time()\n",
        "\n",
        "# === Load files ===\n",
        "train = pd.read_csv(\"train.csv\", low_memory=False)\n",
        "test = pd.read_csv(\"test.csv\", low_memory=False)\n",
        "\n",
        "# === Relevant columns ===\n",
        "features = [\n",
        "    'totalPrice',\n",
        "    'companyID',\n",
        "    'legs0_segments0_cabinClass',\n",
        "    'isAccess3D',\n",
        "    'isVip',\n",
        "    'legs0_segments0_seatsAvailable',\n",
        "    'legs0_segments0_flightNumber',\n",
        "    'taxes',\n",
        "    'legs0_segments0_baggageAllowance_quantity',\n",
        "    'legs0_segments0_baggageAllowance_weightMeasurementType',\n",
        "    'pricingInfo_isAccessTP',\n",
        "    'miniRules0_monetaryAmount',\n",
        "    'miniRules1_monetaryAmount',\n",
        "    'miniRules0_statusInfos',\n",
        "    'miniRules1_statusInfos'\n",
        "]\n",
        "target = 'legs1_segments0_aircraft_code'\n",
        "\n",
        "# === Train on complete rows from train ===\n",
        "train_valid = train.dropna(subset=features + [target])\n",
        "X_train = train_valid[features]\n",
        "y_train_raw = train_valid[target]\n",
        "\n",
        "# === Label encode target ===\n",
        "le = LabelEncoder()\n",
        "y_train = le.fit_transform(y_train_raw)\n",
        "\n",
        "# === Model ===\n",
        "model = XGBClassifier(\n",
        "    n_estimators=500,\n",
        "    max_depth=12,\n",
        "    learning_rate=0.1,\n",
        "    tree_method='hist',\n",
        "    n_jobs=24,\n",
        "    random_state=42,\n",
        "    use_label_encoder=False,\n",
        "    eval_metric='logloss'\n",
        ")\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# === Imputation function ===\n",
        "def impute_column(df, name=\"train\"):\n",
        "    missing_mask = df[target].isna()\n",
        "    if missing_mask.sum() == 0:\n",
        "        print(f\"‚úÖ {name}: No missing values in '{target}'\")\n",
        "        return df\n",
        "\n",
        "    imputable = df.loc[missing_mask, features].dropna()\n",
        "    imputable_indices = imputable.index\n",
        "\n",
        "    if len(imputable_indices) == 0:\n",
        "        print(f\"‚ö†Ô∏è {name}: No imputable rows with all required features.\")\n",
        "        return df\n",
        "\n",
        "    preds = model.predict(imputable)\n",
        "    preds_labels = le.inverse_transform(preds)\n",
        "    df.loc[imputable_indices, target] = preds_labels\n",
        "    print(f\"‚úÖ {name}: Imputed {len(imputable_indices)} missing values in '{target}'\")\n",
        "    return df\n",
        "\n",
        "# === Perform imputation ===\n",
        "train = impute_column(train, \"train\")\n",
        "test = impute_column(test, \"test\")\n",
        "\n",
        "# === Overwrite files ===\n",
        "train.to_csv(\"train.csv\", index=False)\n",
        "test.to_csv(\"test.csv\", index=False)\n",
        "\n",
        "# === Post-imputation stats ===\n",
        "def report(df, name):\n",
        "    total = len(df)\n",
        "    missing = df[target].isna().sum()\n",
        "    value_counts = df[target].value_counts(dropna=False).sort_index()\n",
        "    print(f\"\\nüìä {name} ‚Äî '{target}':\")\n",
        "    print(f\"  Total rows: {total}\")\n",
        "    print(f\"  Missing: {missing} ({100 * missing / total:.2f}%)\")\n",
        "    print(\"  Top 10 value counts (including imputations):\")\n",
        "    print(value_counts.head(10))\n",
        "\n",
        "report(train, \"train\")\n",
        "report(test, \"test\")\n",
        "\n",
        "# === Done ===\n",
        "print(f\"\\n‚è±Ô∏è Total duration: {round(time.time() - start, 2)} seconds\")\n"
      ],
      "metadata": {
        "id": "ODuCnunnZ07x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Parameters: { \"use_label_encoder\" } are not used.\n",
        "\n",
        "  bst.update(dtrain, iteration=i, fobj=obj)\n",
        "‚úÖ train: Imputed 4387201 missing values in 'legs1_segments0_aircraft_code'\n",
        "‚úÖ test: Imputed 1115840 missing values in 'legs1_segments0_aircraft_code'\n",
        "\n",
        "üìä train ‚Äî 'legs1_segments0_aircraft_code':\n",
        "  Total rows: 18145372\n",
        "  Missing: 0 (0.00%)\n",
        "  Top 10 value counts (including imputations):\n",
        "legs1_segments0_aircraft_code\n",
        "220         52\n",
        "221        358\n",
        "223       1235\n",
        "290         39\n",
        "295        356\n",
        "318        112\n",
        "319     430236\n",
        "31N         20\n",
        "320    1373672\n",
        "321     661791\n",
        "Name: count, dtype: int64\n",
        "\n",
        "üìä test ‚Äî 'legs1_segments0_aircraft_code':\n",
        "  Total rows: 6897776\n",
        "  Missing: 0 (0.00%)\n",
        "  Top 10 value counts (including imputations):\n",
        "legs1_segments0_aircraft_code\n",
        "0          65\n",
        "220         2\n",
        "221        78\n",
        "223       897\n",
        "290        27\n",
        "295        56\n",
        "318         1\n",
        "319    114766\n",
        "31N         8\n",
        "320    542247\n",
        "Name: count, dtype: int64\n",
        "\n",
        "‚è±Ô∏è Total duration: 9255.26 seconds"
      ],
      "metadata": {
        "id": "XgHkaqqBZ4gw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile impute_legs1_segments0_marketingCarrier_code.py\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import time\n",
        "\n",
        "# === Timer ===\n",
        "start = time.time()\n",
        "\n",
        "# === Load files ===\n",
        "train = pd.read_csv(\"train.csv\", low_memory=False)\n",
        "test = pd.read_csv(\"test.csv\", low_memory=False)\n",
        "\n",
        "# === Relevant columns ===\n",
        "features = [\n",
        "    'totalPrice',\n",
        "    'companyID',\n",
        "    'legs0_segments0_cabinClass',\n",
        "    'isAccess3D',\n",
        "    'isVip',\n",
        "    'legs0_segments0_seatsAvailable',\n",
        "    'legs0_segments0_flightNumber',\n",
        "    'taxes',\n",
        "    'legs0_segments0_baggageAllowance_quantity',\n",
        "    'legs0_segments0_baggageAllowance_weightMeasurementType',\n",
        "    'pricingInfo_isAccessTP',\n",
        "    'miniRules0_monetaryAmount',\n",
        "    'miniRules1_monetaryAmount',\n",
        "    'miniRules0_statusInfos',\n",
        "    'miniRules1_statusInfos'\n",
        "]\n",
        "target = 'legs1_segments0_marketingCarrier_code'\n",
        "\n",
        "# === Train on complete rows from train ===\n",
        "train_valid = train.dropna(subset=features + [target])\n",
        "X_train = train_valid[features]\n",
        "y_train_raw = train_valid[target]\n",
        "\n",
        "# === Label encode target ===\n",
        "le = LabelEncoder()\n",
        "y_train = le.fit_transform(y_train_raw)\n",
        "\n",
        "# === Model ===\n",
        "model = XGBClassifier(\n",
        "    n_estimators=500,\n",
        "    max_depth=12,\n",
        "    learning_rate=0.1,\n",
        "    tree_method='hist',\n",
        "    n_jobs=24,\n",
        "    random_state=42,\n",
        "    use_label_encoder=False,\n",
        "    eval_metric='logloss'\n",
        ")\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# === Imputation function ===\n",
        "def impute_column(df, name=\"train\"):\n",
        "    missing_mask = df[target].isna()\n",
        "    if missing_mask.sum() == 0:\n",
        "        print(f\"‚úÖ {name}: No missing values in '{target}'\")\n",
        "        return df\n",
        "\n",
        "    imputable = df.loc[missing_mask, features].dropna()\n",
        "    imputable_indices = imputable.index\n",
        "\n",
        "    if len(imputable_indices) == 0:\n",
        "        print(f\"‚ö†Ô∏è {name}: No imputable rows with all required features.\")\n",
        "        return df\n",
        "\n",
        "    preds = model.predict(imputable)\n",
        "    preds_labels = le.inverse_transform(preds)\n",
        "    df.loc[imputable_indices, target] = preds_labels\n",
        "    print(f\"‚úÖ {name}: Imputed {len(imputable_indices)} missing values in '{target}'\")\n",
        "    return df\n",
        "\n",
        "# === Impute ===\n",
        "train = impute_column(train, \"train\")\n",
        "test = impute_column(test, \"test\")\n",
        "\n",
        "# === Overwrite files ===\n",
        "train.to_csv(\"train.csv\", index=False)\n",
        "test.to_csv(\"test.csv\", index=False)\n",
        "\n",
        "# === Post-imputation statistics ===\n",
        "def report(df, name):\n",
        "    total = len(df)\n",
        "    missing = df[target].isna().sum()\n",
        "    value_counts = df[target].value_counts(dropna=False).sort_index()\n",
        "    print(f\"\\nüìä {name} ‚Äî '{target}':\")\n",
        "    print(f\"  Total rows: {total}\")\n",
        "    print(f\"  Missing: {missing} ({100 * missing / total:.2f}%)\")\n",
        "    print(\"  Top 10 value counts (including imputations):\")\n",
        "    print(value_counts.head(10))\n",
        "\n",
        "report(train, \"train\")\n",
        "report(test, \"test\")\n",
        "\n",
        "# === Done ===\n",
        "print(f\"\\n‚è±Ô∏è Total duration: {round(time.time() - start, 2)} seconds\")\n"
      ],
      "metadata": {
        "id": "71sa1T-jaCni"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Parameters: { \"use_label_encoder\" } are not used.\n",
        "\n",
        "  bst.update(dtrain, iteration=i, fobj=obj)\n",
        "‚úÖ train: Imputed 4387201 missing values in 'legs1_segments0_marketingCarrier_code'\n",
        "‚úÖ test: Imputed 1115840 missing values in 'legs1_segments0_marketingCarrier_code'\n",
        "\n",
        "üìä train ‚Äî 'legs1_segments0_marketingCarrier_code':\n",
        "  Total rows: 18145372\n",
        "  Missing: 0 (0.00%)\n",
        "  Top 10 value counts (including imputations):\n",
        "legs1_segments0_marketingCarrier_code\n",
        "3U      8705\n",
        "4G        12\n",
        "5F      2054\n",
        "5G       374\n",
        "5N    186241\n",
        "6H         4\n",
        "6R     69389\n",
        "7R     17384\n",
        "9B     16191\n",
        "A3      1202\n",
        "Name: count, dtype: int64\n",
        "\n",
        "üìä test ‚Äî 'legs1_segments0_marketingCarrier_code':\n",
        "  Total rows: 6897776\n",
        "  Missing: 0 (0.00%)\n",
        "  Top 10 value counts (including imputations):\n",
        "legs1_segments0_marketingCarrier_code\n",
        "3U     7057\n",
        "4G        1\n",
        "5F     1126\n",
        "5G      395\n",
        "5N    36423\n",
        "6H        1\n",
        "6R    27423\n",
        "7R    12391\n",
        "9B     4263\n",
        "A3      351\n",
        "Name: count, dtype: int64\n",
        "\n",
        "‚è±Ô∏è Total duration: 10785.08 seconds"
      ],
      "metadata": {
        "id": "dHsJqTA_aEFy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile impute_legs1_segments0_targets.py\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import time\n",
        "\n",
        "# === Timer ===\n",
        "start = time.time()\n",
        "\n",
        "# === Load the files ===\n",
        "train = pd.read_csv(\"train.csv\", low_memory=False)\n",
        "test = pd.read_csv(\"test.csv\", low_memory=False)\n",
        "\n",
        "# === Relevant columns for prediction ===\n",
        "features = [\n",
        "    'totalPrice',\n",
        "    'companyID',\n",
        "    'legs0_segments0_cabinClass',\n",
        "    'isAccess3D',\n",
        "    'isVip',\n",
        "    'legs0_segments0_seatsAvailable',\n",
        "    'legs0_segments0_flightNumber',\n",
        "    'taxes',\n",
        "    'legs0_segments0_baggageAllowance_quantity',\n",
        "    'legs0_segments0_baggageAllowance_weightMeasurementType',\n",
        "    'pricingInfo_isAccessTP',\n",
        "    'miniRules0_monetaryAmount',\n",
        "    'miniRules1_monetaryAmount',\n",
        "    'miniRules0_statusInfos',\n",
        "    'miniRules1_statusInfos'\n",
        "]\n",
        "\n",
        "# === Target columns to impute ===\n",
        "target_columns = [\n",
        "    'legs1_segments0_arrivalTo_airport_city_iata',\n",
        "    'legs1_segments0_operatingCarrier_code',\n",
        "    'legs1_segments0_departureFrom_airport_iata'\n",
        "]\n",
        "\n",
        "# === Train and impute function for a target column ===\n",
        "def impute_column(target):\n",
        "    print(f\"\\nüîß Processing target: '{target}'\")\n",
        "\n",
        "    train_valid = train.dropna(subset=features + [target])\n",
        "    if train_valid.empty:\n",
        "        print(f\"‚ùå Skipped '{target}': No complete training data.\")\n",
        "        return\n",
        "\n",
        "    X_train = train_valid[features]\n",
        "    y_train_raw = train_valid[target]\n",
        "\n",
        "    # Label Encoding\n",
        "    le = LabelEncoder()\n",
        "    y_train = le.fit_transform(y_train_raw)\n",
        "\n",
        "    # Model\n",
        "    model = XGBClassifier(\n",
        "        n_estimators=500,\n",
        "        max_depth=12,\n",
        "        learning_rate=0.1,\n",
        "        tree_method='hist',\n",
        "        n_jobs=24,\n",
        "        random_state=42,\n",
        "        eval_metric='logloss'\n",
        "    )\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Impute train & test\n",
        "    for df, name in [(train, \"train\"), (test, \"test\")]:\n",
        "        missing_mask = df[target].isna()\n",
        "        if missing_mask.sum() == 0:\n",
        "            print(f\"‚úÖ {name}: No missing values in '{target}'\")\n",
        "            continue\n",
        "\n",
        "        imputable = df.loc[missing_mask, features].dropna()\n",
        "        imputable_indices = imputable.index\n",
        "\n",
        "        if len(imputable_indices) == 0:\n",
        "            print(f\"‚ö†Ô∏è {name}: No imputable rows with all required features for '{target}'.\")\n",
        "            continue\n",
        "\n",
        "        preds = model.predict(imputable)\n",
        "        preds_labels = le.inverse_transform(preds)\n",
        "        df.loc[imputable_indices, target] = preds_labels\n",
        "        print(f\"‚úÖ {name}: Imputed {len(imputable_indices)} missing values in '{target}'\")\n",
        "\n",
        "    # Report\n",
        "    for df, name in [(train, \"train\"), (test, \"test\")]:\n",
        "        total = len(df)\n",
        "        missing = df[target].isna().sum()\n",
        "        value_counts = df[target].value_counts(dropna=False).sort_index()\n",
        "        print(f\"\\nüìä {name} ‚Äî '{target}':\")\n",
        "        print(f\"  Total rows: {total}\")\n",
        "        print(f\"  Missing: {missing} ({100 * missing / total:.2f}%)\")\n",
        "        print(\"  Top 10 value counts (including imputations):\")\n",
        "        print(value_counts.head(10))\n",
        "\n",
        "# === Run for each target column ===\n",
        "for target in target_columns:\n",
        "    impute_column(target)\n",
        "\n",
        "# === Save the final files ===\n",
        "train.to_csv(\"train.csv\", index=False)\n",
        "test.to_csv(\"test.csv\", index=False)\n",
        "\n",
        "# === Done ===\n",
        "print(f\"\\n‚è±Ô∏è Total duration: {round(time.time() - start, 2)} seconds\")\n"
      ],
      "metadata": {
        "id": "-zen6V5Dadog"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "üîß Processing target: 'legs1_segments0_arrivalTo_airport_city_iata'\n",
        "‚úÖ train: Imputed 4387237 missing values in 'legs1_segments0_arrivalTo_airport_city_iata'\n",
        "‚úÖ test: Imputed 1115846 missing values in 'legs1_segments0_arrivalTo_airport_city_iata'\n",
        "\n",
        "üìä train ‚Äî 'legs1_segments0_arrivalTo_airport_city_iata':\n",
        "  Total rows: 18145372\n",
        "  Missing: 0 (0.00%)\n",
        "  Top 10 value counts (including imputations):\n",
        "legs1_segments0_arrivalTo_airport_city_iata\n",
        "ABA      1103\n",
        "ADA        93\n",
        "ADD      1730\n",
        "AER    570004\n",
        "AGP         6\n",
        "AKX        37\n",
        "ALA      5817\n",
        "ALG       377\n",
        "AMD       273\n",
        "AMM       263\n",
        "Name: count, dtype: int64\n",
        "\n",
        "üìä test ‚Äî 'legs1_segments0_arrivalTo_airport_city_iata':\n",
        "  Total rows: 6897776\n",
        "  Missing: 0 (0.00%)\n",
        "  Top 10 value counts (including imputations):\n",
        "legs1_segments0_arrivalTo_airport_city_iata\n",
        "ABA      348\n",
        "ADA        5\n",
        "ADD      185\n",
        "AER    97793\n",
        "AKX       43\n",
        "ALA     4641\n",
        "ALG      290\n",
        "AMD       79\n",
        "AMM       91\n",
        "AMS     1806\n",
        "Name: count, dtype: int64\n",
        "\n",
        "üîß Processing target: 'legs1_segments0_operatingCarrier_code'\n",
        "‚úÖ train: Imputed 4387201 missing values in 'legs1_segments0_operatingCarrier_code'\n",
        "‚úÖ test: Imputed 1115840 missing values in 'legs1_segments0_operatingCarrier_code'\n",
        "\n",
        "üìä train ‚Äî 'legs1_segments0_operatingCarrier_code':\n",
        "  Total rows: 18145372\n",
        "  Missing: 0 (0.00%)\n",
        "  Top 10 value counts (including imputations):\n",
        "legs1_segments0_operatingCarrier_code\n",
        "2C     387\n",
        "2L     339\n",
        "3F    1182\n",
        "3K      55\n",
        "3L     217\n",
        "3U    7824\n",
        "4G      12\n",
        "4Z    1132\n",
        "5F     844\n",
        "5G     373\n",
        "Name: count, dtype: int64\n",
        "\n",
        "üìä test ‚Äî 'legs1_segments0_operatingCarrier_code':\n",
        "  Total rows: 6897776\n",
        "  Missing: 0 (0.00%)\n",
        "  Top 10 value counts (including imputations):\n",
        "legs1_segments0_operatingCarrier_code\n",
        "2C      369\n",
        "2L      207\n",
        "3F      731\n",
        "3K        4\n",
        "3L      126\n",
        "3U     3921\n",
        "4Z        1\n",
        "5F      390\n",
        "5G      389\n",
        "5N    38292\n",
        "Name: count, dtype: int64\n",
        "\n",
        "üîß Processing target: 'legs1_segments0_departureFrom_airport_iata'\n",
        "‚úÖ train: Imputed 4387206 missing values in 'legs1_segments0_departureFrom_airport_iata'\n",
        "‚úÖ test: Imputed 1115840 missing values in 'legs1_segments0_departureFrom_airport_iata'\n",
        "\n",
        "üìä train ‚Äî 'legs1_segments0_departureFrom_airport_iata':\n",
        "  Total rows: 18145372\n",
        "  Missing: 0 (0.00%)\n",
        "  Top 10 value counts (including imputations):\n",
        "legs1_segments0_departureFrom_airport_iata\n",
        "ABA       5126\n",
        "ADB       3781\n",
        "ADD        471\n",
        "AEP        527\n",
        "AER    1092525\n",
        "AKX        366\n",
        "ALA      73262\n",
        "AMS       5853\n",
        "ARH      27852\n",
        "ARN        909\n",
        "Name: count, dtype: int64\n",
        "\n",
        "üìä test ‚Äî 'legs1_segments0_departureFrom_airport_iata':\n",
        "  Total rows: 6897776\n",
        "  Missing: 0 (0.00%)\n",
        "  Top 10 value counts (including imputations):\n",
        "legs1_segments0_departureFrom_airport_iata\n",
        "AAR       256\n",
        "ABA      1954\n",
        "ADB      1302\n",
        "ADD         6\n",
        "AEP        17\n",
        "AER    384921\n",
        "AGP        44\n",
        "AKX         4\n",
        "ALA     32775\n",
        "AMS      2467\n",
        "Name: count, dtype: int64\n",
        "\n",
        "‚è±Ô∏è Total duration: 59858.45 seconds"
      ],
      "metadata": {
        "id": "J61Scm-JagEA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile impute_multiple_targets.py\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import time\n",
        "\n",
        "# === Timer ===\n",
        "start = time.time()\n",
        "\n",
        "# === Load files ===\n",
        "train = pd.read_csv(\"train.csv\", low_memory=False)\n",
        "test = pd.read_csv(\"test.csv\", low_memory=False)\n",
        "\n",
        "# === Relevant columns for prediction ===\n",
        "features = [\n",
        "    'totalPrice',\n",
        "    'companyID',\n",
        "    'legs0_segments0_cabinClass',\n",
        "    'isAccess3D',\n",
        "    'isVip',\n",
        "    'legs0_segments0_seatsAvailable',\n",
        "    'legs0_segments0_flightNumber',\n",
        "    'taxes',\n",
        "    'legs0_segments0_baggageAllowance_quantity',\n",
        "    'legs0_segments0_baggageAllowance_weightMeasurementType',\n",
        "    'pricingInfo_isAccessTP',\n",
        "    'miniRules0_monetaryAmount',\n",
        "    'miniRules1_monetaryAmount',\n",
        "    'miniRules0_statusInfos',\n",
        "    'miniRules1_statusInfos'\n",
        "]\n",
        "\n",
        "# === Target columns to impute ===\n",
        "target_columns = [\n",
        "    'legs1_segments0_arrivalTo_airport_iata',\n",
        "    'frequentFlyer',\n",
        "    'legs1_segments0_seatsAvailable',\n",
        "    'legs1_segments0_cabinClass'\n",
        "]\n",
        "\n",
        "# === Function to train and impute one target column ===\n",
        "def impute_column(target):\n",
        "    print(f\"\\nüîß Processing target: '{target}'\")\n",
        "\n",
        "    train_valid = train.dropna(subset=features + [target])\n",
        "    if train_valid.empty:\n",
        "        print(f\"‚ùå Skipped '{target}': No complete training data.\")\n",
        "        return\n",
        "\n",
        "    X_train = train_valid[features]\n",
        "    y_train_raw = train_valid[target]\n",
        "\n",
        "    # Label Encoding\n",
        "    le = LabelEncoder()\n",
        "    y_train = le.fit_transform(y_train_raw)\n",
        "\n",
        "    # Model\n",
        "    model = XGBClassifier(\n",
        "        n_estimators=500,\n",
        "        max_depth=12,\n",
        "        learning_rate=0.1,\n",
        "        tree_method='hist',\n",
        "        n_jobs=24,\n",
        "        random_state=42,\n",
        "        eval_metric='logloss'\n",
        "    )\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Impute for train & test\n",
        "    for df, name in [(train, \"train\"), (test, \"test\")]:\n",
        "        missing_mask = df[target].isna()\n",
        "        if missing_mask.sum() == 0:\n",
        "            print(f\"‚úÖ {name}: No missing values in '{target}'\")\n",
        "            continue\n",
        "\n",
        "        imputable = df.loc[missing_mask, features].dropna()\n",
        "        imputable_indices = imputable.index\n",
        "\n",
        "        if len(imputable_indices) == 0:\n",
        "            print(f\"‚ö†Ô∏è {name}: No imputable rows with all required features for '{target}'.\")\n",
        "            continue\n",
        "\n",
        "        preds = model.predict(imputable)\n",
        "        preds_labels = le.inverse_transform(preds)\n",
        "        df.loc[imputable_indices, target] = preds_labels\n",
        "        print(f\"‚úÖ {name}: Imputed {len(imputable_indices)} missing values in '{target}'\")\n",
        "\n",
        "    # Report\n",
        "    for df, name in [(train, \"train\"), (test, \"test\")]:\n",
        "        total = len(df)\n",
        "        missing = df[target].isna().sum()\n",
        "        value_counts = df[target].value_counts(dropna=False).sort_index()\n",
        "        print(f\"\\nüìä {name} ‚Äî '{target}':\")\n",
        "        print(f\"  Total rows: {total}\")\n",
        "        print(f\"  Missing: {missing} ({100 * missing / total:.2f}%)\")\n",
        "        print(\"  Top 10 value counts (including imputations):\")\n",
        "        print(value_counts.head(10))\n",
        "\n",
        "# === Run for each target column ===\n",
        "for target in target_columns:\n",
        "    impute_column(target)\n",
        "\n",
        "# === Save final files ===\n",
        "train.to_csv(\"train.csv\", index=False)\n",
        "test.to_csv(\"test.csv\", index=False)\n",
        "\n",
        "# === Done ===\n",
        "print(f\"\\n‚è±Ô∏è Total duration: {round(time.time() - start, 2)} seconds\")\n"
      ],
      "metadata": {
        "id": "T5E138fia3l_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "üîß Processing target: 'legs1_segments0_arrivalTo_airport_iata'\n",
        "‚úÖ train: Imputed 4387203 missing values in 'legs1_segments0_arrivalTo_airport_iata'\n",
        "‚úÖ test: Imputed 1115840 missing values in 'legs1_segments0_arrivalTo_airport_iata'\n",
        "\n",
        "üìä train ‚Äî 'legs1_segments0_arrivalTo_airport_iata':\n",
        "  Total rows: 18145372\n",
        "  Missing: 0 (0.00%)\n",
        "  Top 10 value counts (including imputations):\n",
        "legs1_segments0_arrivalTo_airport_iata\n",
        "ABA      1457\n",
        "ADA        47\n",
        "ADB       311\n",
        "ADD      1803\n",
        "AER    583660\n",
        "AGP         6\n",
        "AKX        44\n",
        "ALA      5901\n",
        "ALG       389\n",
        "AMD       740\n",
        "Name: count, dtype: int64\n",
        "\n",
        "üìä test ‚Äî 'legs1_segments0_arrivalTo_airport_iata':\n",
        "  Total rows: 6897776\n",
        "  Missing: 0 (0.00%)\n",
        "  Top 10 value counts (including imputations):\n",
        "legs1_segments0_arrivalTo_airport_iata\n",
        "ABA       410\n",
        "ADA         1\n",
        "ADB        40\n",
        "ADD       198\n",
        "AER    100424\n",
        "AKX        42\n",
        "ALA      4576\n",
        "ALG       286\n",
        "AMD        46\n",
        "AMM        94\n",
        "Name: count, dtype: int64\n",
        "\n",
        "üîß Processing target: 'frequentFlyer'\n",
        "‚úÖ train: Imputed 12012727 missing values in 'frequentFlyer'\n",
        "‚úÖ test: Imputed 3974920 missing values in 'frequentFlyer'\n",
        "\n",
        "üìä train ‚Äî 'frequentFlyer':\n",
        "  Total rows: 18145372\n",
        "  Missing: 0 (0.00%)\n",
        "  Top 10 value counts (including imputations):\n",
        "frequentFlyer\n",
        "- –Æ–¢—ç–π—Ä –ó–ê–û                3854\n",
        "- –Æ–¢—ç–π—Ä –ó–ê–û/KC/LH/S7/SU    1235\n",
        "- –Æ–¢—ç–π—Ä –ó–ê–û/SU/S7          1948\n",
        "2G                         1670\n",
        "6W/S7/SU                    180\n",
        "AB/LH                      4047\n",
        "AF                          989\n",
        "AF/SU                      1807\n",
        "AF/SU/LH/BA/TK/EK          1314\n",
        "AF/TK                        25\n",
        "Name: count, dtype: int64\n",
        "\n",
        "üìä test ‚Äî 'frequentFlyer':\n",
        "  Total rows: 6897776\n",
        "  Missing: 0 (0.00%)\n",
        "  Top 10 value counts (including imputations):\n",
        "frequentFlyer\n",
        "- –Æ–¢—ç–π—Ä –ó–ê–û                2455\n",
        "- –Æ–¢—ç–π—Ä –ó–ê–û/KC/LH/S7/SU     701\n",
        "- –Æ–¢—ç–π—Ä –ó–ê–û/SU              571\n",
        "- –Æ–¢—ç–π—Ä –ó–ê–û/SU/S7            34\n",
        "2G                          138\n",
        "6W/S7/SU                    126\n",
        "AB/LH                      2092\n",
        "AF                          285\n",
        "AF/SU                       144\n",
        "AF/SU/LH/BA/TK/EK            24\n",
        "Name: count, dtype: int64\n",
        "\n",
        "üîß Processing target: 'legs1_segments0_seatsAvailable'\n",
        "‚úÖ train: Imputed 4580895 missing values in 'legs1_segments0_seatsAvailable'\n",
        "‚úÖ test: Imputed 1124817 missing values in 'legs1_segments0_seatsAvailable'\n",
        "\n",
        "üìä train ‚Äî 'legs1_segments0_seatsAvailable':\n",
        "  Total rows: 18145372\n",
        "  Missing: 0 (0.00%)\n",
        "  Top 10 value counts (including imputations):\n",
        "legs1_segments0_seatsAvailable\n",
        "1.0    2834013\n",
        "2.0    2018940\n",
        "3.0    1531366\n",
        "4.0    1704667\n",
        "5.0    1233873\n",
        "6.0     883865\n",
        "7.0     798732\n",
        "8.0     604838\n",
        "9.0    6535078\n",
        "Name: count, dtype: int64\n",
        "\n",
        "üìä test ‚Äî 'legs1_segments0_seatsAvailable':\n",
        "  Total rows: 6897776\n",
        "  Missing: 0 (0.00%)\n",
        "  Top 10 value counts (including imputations):\n",
        "legs1_segments0_seatsAvailable\n",
        "1.0    1345117\n",
        "2.0     878437\n",
        "3.0     568834\n",
        "4.0     518823\n",
        "5.0     388642\n",
        "6.0     288154\n",
        "7.0     279193\n",
        "8.0     226923\n",
        "9.0    2403653\n",
        "Name: count, dtype: int64\n",
        "\n",
        "üîß Processing target: 'legs1_segments0_cabinClass'\n",
        "‚úÖ train: Imputed 4525013 missing values in 'legs1_segments0_cabinClass'\n",
        "‚úÖ test: Imputed 1124817 missing values in 'legs1_segments0_cabinClass'\n",
        "\n",
        "üìä train ‚Äî 'legs1_segments0_cabinClass':\n",
        "  Total rows: 18145372\n",
        "  Missing: 0 (0.00%)\n",
        "  Top 10 value counts (including imputations):\n",
        "legs1_segments0_cabinClass\n",
        "1.0    14980700\n",
        "2.0     2994301\n",
        "3.0         891\n",
        "4.0      169480\n",
        "Name: count, dtype: int64\n",
        "\n",
        "üìä test ‚Äî 'legs1_segments0_cabinClass':\n",
        "  Total rows: 6897776\n",
        "  Missing: 0 (0.00%)\n",
        "  Top 10 value counts (including imputations):\n",
        "legs1_segments0_cabinClass\n",
        "1.0    6648042\n",
        "2.0     247044\n",
        "3.0        836\n",
        "4.0       1854\n",
        "Name: count, dtype: int64\n",
        "\n",
        "‚è±Ô∏è Total duration: 43699.51 seconds"
      ],
      "metadata": {
        "id": "YQndRtCaa4iH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile impute_multiple_targets.py\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import time\n",
        "\n",
        "# === Timer ===\n",
        "start = time.time()\n",
        "\n",
        "# === Load the files ===\n",
        "train = pd.read_csv(\"train.csv\", low_memory=False)\n",
        "test = pd.read_csv(\"test.csv\", low_memory=False)\n",
        "\n",
        "# === Relevant columns for prediction ===\n",
        "features = [\n",
        "    'totalPrice',\n",
        "    'companyID',\n",
        "    'legs0_segments0_cabinClass',\n",
        "    'isAccess3D',\n",
        "    'isVip',\n",
        "    'legs0_segments0_seatsAvailable',\n",
        "    'legs0_segments0_flightNumber',\n",
        "    'taxes',\n",
        "    'legs0_segments0_baggageAllowance_quantity',\n",
        "    'legs0_segments0_baggageAllowance_weightMeasurementType',\n",
        "    'pricingInfo_isAccessTP',\n",
        "    'miniRules0_monetaryAmount',\n",
        "    'miniRules1_monetaryAmount',\n",
        "    'miniRules0_statusInfos',\n",
        "    'miniRules1_statusInfos'\n",
        "]\n",
        "\n",
        "# === Target columns to impute ===\n",
        "target_columns = [\n",
        "    'corporateTariffCode',\n",
        "    'legs1_segments0_baggageAllowance_quantity'\n",
        "]\n",
        "\n",
        "# === Function to train and impute a target column ===\n",
        "def impute_column(target):\n",
        "    print(f\"\\nüîß Processing target: '{target}'\")\n",
        "\n",
        "    train_valid = train.dropna(subset=features + [target])\n",
        "    if train_valid.empty:\n",
        "        print(f\"‚ùå Skipped '{target}': No complete training data.\")\n",
        "        return\n",
        "\n",
        "    X_train = train_valid[features]\n",
        "    y_train_raw = train_valid[target]\n",
        "\n",
        "    # Label Encoding\n",
        "    le = LabelEncoder()\n",
        "    y_train = le.fit_transform(y_train_raw)\n",
        "\n",
        "    # Model\n",
        "    model = XGBClassifier(\n",
        "        n_estimators=500,\n",
        "        max_depth=12,\n",
        "        learning_rate=0.1,\n",
        "        tree_method='hist',\n",
        "        n_jobs=24,\n",
        "        random_state=42,\n",
        "        eval_metric='logloss'\n",
        "    )\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Impute for train & test\n",
        "    for df, name in [(train, \"train\"), (test, \"test\")]:\n",
        "        missing_mask = df[target].isna()\n",
        "        if missing_mask.sum() == 0:\n",
        "            print(f\"‚úÖ {name}: No missing values in '{target}'\")\n",
        "            continue\n",
        "\n",
        "        imputable = df.loc[missing_mask, features].dropna()\n",
        "        imputable_indices = imputable.index\n",
        "\n",
        "        if len(imputable_indices) == 0:\n",
        "            print(f\"‚ö†Ô∏è {name}: No imputable rows with all required features for '{target}'.\")\n",
        "            continue\n",
        "\n",
        "        preds = model.predict(imputable)\n",
        "        preds_labels = le.inverse_transform(preds)\n",
        "        df.loc[imputable_indices, target] = preds_labels\n",
        "        print(f\"‚úÖ {name}: Imputed {len(imputable_indices)} missing values in '{target}'\")\n",
        "\n",
        "    # Report\n",
        "    for df, name in [(train, \"train\"), (test, \"test\")]:\n",
        "        total = len(df)\n",
        "        missing = df[target].isna().sum()\n",
        "        value_counts = df[target].value_counts(dropna=False).sort_index()\n",
        "        print(f\"\\nüìä {name} ‚Äî '{target}':\")\n",
        "        print(f\"  Total rows: {total}\")\n",
        "        print(f\"  Missing: {missing} ({100 * missing / total:.2f}%)\")\n",
        "        print(\"  Top 10 value counts (including imputations):\")\n",
        "        print(value_counts.head(10))\n",
        "\n",
        "# === Run for each target column ===\n",
        "for target in target_columns:\n",
        "    impute_column(target)\n",
        "\n",
        "# === Save final files ===\n",
        "train.to_csv(\"train.csv\", index=False)\n",
        "test.to_csv(\"test.csv\", index=False)\n",
        "\n",
        "# === Done ===\n",
        "print(f\"\\n‚è±Ô∏è Total duration: {round(time.time() - start, 2)} seconds\")\n"
      ],
      "metadata": {
        "id": "uSApqwMzbHt1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "üîß Processing target: 'corporateTariffCode'\n",
        "‚úÖ train: Imputed 9233925 missing values in 'corporateTariffCode'\n",
        "‚úÖ test: Imputed 3535335 missing values in 'corporateTariffCode'\n",
        "\n",
        "üìä train ‚Äî 'corporateTariffCode':\n",
        "  Total rows: 18145372\n",
        "  Missing: 0 (0.00%)\n",
        "  Top 10 value counts (including imputations):\n",
        "corporateTariffCode\n",
        "0.0    16821\n",
        "1.0     2035\n",
        "2.0       87\n",
        "3.0    24452\n",
        "4.0     1619\n",
        "5.0    43595\n",
        "6.0    16895\n",
        "7.0     1496\n",
        "8.0      724\n",
        "9.0     3963\n",
        "Name: count, dtype: int64\n",
        "\n",
        "üìä test ‚Äî 'corporateTariffCode':\n",
        "  Total rows: 6897776\n",
        "  Missing: 0 (0.00%)\n",
        "  Top 10 value counts (including imputations):\n",
        "corporateTariffCode\n",
        "0.0    1934\n",
        "1.0      21\n",
        "2.0       1\n",
        "3.0    6369\n",
        "4.0     212\n",
        "5.0    6267\n",
        "6.0    1455\n",
        "7.0      19\n",
        "8.0      22\n",
        "9.0     457\n",
        "Name: count, dtype: int64\n",
        "\n",
        "üîß Processing target: 'legs1_segments0_baggageAllowance_quantity'\n",
        "‚úÖ train: Imputed 4527297 missing values in 'legs1_segments0_baggageAllowance_quantity'\n",
        "‚úÖ test: Imputed 1125350 missing values in 'legs1_segments0_baggageAllowance_quantity'\n",
        "\n",
        "üìä train ‚Äî 'legs1_segments0_baggageAllowance_quantity':\n",
        "  Total rows: 18145372\n",
        "  Missing: 0 (0.00%)\n",
        "  Top 10 value counts (including imputations):\n",
        "legs1_segments0_baggageAllowance_quantity\n",
        "0.0     6292151\n",
        "1.0     5893088\n",
        "2.0     4958200\n",
        "3.0        4310\n",
        "10.0       3138\n",
        "15.0       5773\n",
        "20.0      86603\n",
        "23.0      41322\n",
        "25.0      57706\n",
        "30.0     465936\n",
        "Name: count, dtype: int64\n",
        "\n",
        "üìä test ‚Äî 'legs1_segments0_baggageAllowance_quantity':\n",
        "  Total rows: 6897776\n",
        "  Missing: 0 (0.00%)\n",
        "  Top 10 value counts (including imputations):\n",
        "legs1_segments0_baggageAllowance_quantity\n",
        "0.0     2871904\n",
        "1.0     2130799\n",
        "2.0     1544038\n",
        "3.0        1246\n",
        "10.0       1089\n",
        "15.0       1448\n",
        "20.0      40173\n",
        "23.0       7014\n",
        "25.0      41021\n",
        "30.0     139836\n",
        "Name: count, dtype: int64\n",
        "\n",
        "‚è±Ô∏è Total duration: 10105.78 seconds"
      ],
      "metadata": {
        "id": "NV3KIx_-bIvk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile analyze_baggage_quantity_by_type.py\n",
        "import pandas as pd\n",
        "\n",
        "# Load train.csv\n",
        "df = pd.read_csv(\"train.csv\", low_memory=False)\n",
        "\n",
        "# Column names\n",
        "qty_col = \"legs1_segments0_baggageAllowance_quantity\"\n",
        "type_col = \"legs1_segments0_baggageAllowance_weightMeasurementType\"\n",
        "\n",
        "# Filter rows where both values are present\n",
        "df_filtered = df[[qty_col, type_col]].dropna()\n",
        "\n",
        "# Grouped statistics\n",
        "grouped_stats = df_filtered.groupby(type_col)[qty_col].describe()\n",
        "value_counts = df_filtered.groupby(type_col)[qty_col].value_counts().sort_index()\n",
        "\n",
        "# Format output\n",
        "lines = []\n",
        "lines.append(\"üìä Baggage Allowance Quantity Analysis by Measurement Type\\n\")\n",
        "\n",
        "for measurement_type, stats in grouped_stats.iterrows():\n",
        "    type_label = \"PIECE (0.0)\" if measurement_type == 0.0 else \"WEIGHT (1.0)\"\n",
        "    lines.append(f\"\\n‚ñ∂Ô∏è Type: {type_label}\")\n",
        "    lines.append(stats.to_string())\n",
        "\n",
        "    # Extra info: frequency of each quantity value\n",
        "    lines.append(\"\\nüî¢ Frequency of Baggage Quantities:\")\n",
        "    qty_freq = value_counts[measurement_type]\n",
        "    total = qty_freq.sum()\n",
        "\n",
        "    for val, count in qty_freq.items():\n",
        "        percent = 100 * count / total\n",
        "        lines.append(f\"  - {val}: {count} ({percent:.2f}%)\")\n",
        "\n",
        "    # Most frequent quantity (mode)\n",
        "    mode = qty_freq.idxmax()\n",
        "    lines.append(f\"\\nüìå Most frequent quantity: {mode} ({qty_freq[mode]} times)\")\n",
        "\n",
        "    # Count of baggage quantities > 2 (example threshold)\n",
        "    over_two = qty_freq[qty_freq.index > 2].sum()\n",
        "    lines.append(f\"üì¶ Entries with quantity > 2: {over_two} ({100 * over_two / total:.2f}%)\")\n",
        "\n",
        "# Save to TXT\n",
        "output_file = \"baggage_quantity_by_type_stats.txt\"\n",
        "with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(\"\\n\".join(lines))\n",
        "\n",
        "print(f\"‚úÖ Detailed analysis saved to '{output_file}'\")"
      ],
      "metadata": {
        "id": "xocWp2RMbNvd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile rule_based_impute_weight_type.py\n",
        "import pandas as pd\n",
        "\n",
        "# === Load files ===\n",
        "train = pd.read_csv(\"train.csv\", low_memory=False)\n",
        "test = pd.read_csv(\"test.csv\", low_memory=False)\n",
        "\n",
        "# === Rules ===\n",
        "piece_values = [1.0, 2.0, 3.0]\n",
        "weight_values = [10.0, 15.0, 20.0, 23.0, 25.0, 30.0, 32.0, 33.0, 35.0, 40.0, 45.0, 50.0, 60.0]\n",
        "target_col = 'legs1_segments0_baggageAllowance_weightMeasurementType'\n",
        "quantity_col = 'legs1_segments0_baggageAllowance_quantity'\n",
        "\n",
        "# === Imputation function and report ===\n",
        "def rule_based_impute(df, name=\"\"):\n",
        "    log = []\n",
        "    log.append(f\"üìÑ Dataset: {name}\")\n",
        "    initial_missing = df[target_col].isna().sum()\n",
        "    log.append(f\"üîç Missing before imputing: {initial_missing}\")\n",
        "\n",
        "    # Imputation rules\n",
        "    mask_piece = df[target_col].isna() & df[quantity_col].isin(piece_values)\n",
        "    mask_weight = df[target_col].isna() & df[quantity_col].isin(weight_values)\n",
        "\n",
        "    df.loc[mask_piece, target_col] = 0.0\n",
        "    df.loc[mask_weight, target_col] = 1.0\n",
        "\n",
        "    piece_count = mask_piece.sum()\n",
        "    weight_count = mask_weight.sum()\n",
        "\n",
        "    log.append(f\"‚úÖ Imputed PIECE (0.0): {piece_count}\")\n",
        "    log.append(f\"‚úÖ Imputed WEIGHT (1.0): {weight_count}\")\n",
        "\n",
        "    final_missing = df[target_col].isna().sum()\n",
        "    log.append(f\"üßÆ Missing after rule-based imputing: {final_missing}\")\n",
        "\n",
        "    # Post-imputation stats\n",
        "    log.append(\"\\nüìä Value counts after imputing:\")\n",
        "    log.append(df[target_col].value_counts(dropna=False).to_string())\n",
        "\n",
        "    # If NaNs remain, show the distribution of quantity for those\n",
        "    if final_missing > 0:\n",
        "        log.append(\"\\nüîé Distribution of quantity for remaining NaN values:\")\n",
        "        remaining_nan = df[df[target_col].isna()]\n",
        "        qty_counts = remaining_nan[quantity_col].value_counts(dropna=False).sort_index()\n",
        "        log.append(qty_counts.to_string())\n",
        "\n",
        "    return df, \"\\n\".join(log)\n",
        "\n",
        "# === Apply to both datasets and generate logs ===\n",
        "train, train_log = rule_based_impute(train, \"train\")\n",
        "test, test_log = rule_based_impute(test, \"test\")\n",
        "\n",
        "# === Save updated files ===\n",
        "train.to_csv(\"train.csv\", index=False)\n",
        "test.to_csv(\"test.csv\", index=False)\n",
        "\n",
        "# === Write the log to a file ===\n",
        "with open(\"rule_based_weight_type_imputation_log.txt\", \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(train_log)\n",
        "    f.write(\"\\n\\n\" + \"=\"*60 + \"\\n\\n\")\n",
        "    f.write(test_log)\n",
        "\n",
        "print(\"‚úÖ Imputation complete.\")\n",
        "print(\"üìù Log saved to 'rule_based_weight_type_imputation_log.txt'\")\n"
      ],
      "metadata": {
        "id": "n2YOYusIbaLL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile impute_legs1_segments0_baggageAllowance_weightMeasurementType.py\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import time\n",
        "\n",
        "# === Timer ===\n",
        "start = time.time()\n",
        "\n",
        "# === Load files ===\n",
        "train = pd.read_csv(\"train.csv\", low_memory=False)\n",
        "test = pd.read_csv(\"test.csv\", low_memory=False)\n",
        "\n",
        "# === Relevant features for prediction ===\n",
        "features = [\n",
        "    'totalPrice',\n",
        "    'companyID',\n",
        "    'legs0_segments0_cabinClass',\n",
        "    'isAccess3D',\n",
        "    'isVip',\n",
        "    'legs0_segments0_seatsAvailable',\n",
        "    'legs0_segments0_flightNumber',\n",
        "    'taxes',\n",
        "    'legs0_segments0_baggageAllowance_quantity',\n",
        "    'legs0_segments0_baggageAllowance_weightMeasurementType',\n",
        "    'pricingInfo_isAccessTP',\n",
        "    'miniRules0_monetaryAmount',\n",
        "    'miniRules1_monetaryAmount',\n",
        "    'miniRules0_statusInfos',\n",
        "    'miniRules1_statusInfos',\n",
        "    'legs1_segments0_baggageAllowance_quantity'\n",
        "]\n",
        "\n",
        "# === Target columns to impute ===\n",
        "target_columns = [\n",
        "    'legs1_segments0_baggageAllowance_weightMeasurementType'\n",
        "]\n",
        "\n",
        "# === Train and impute for one target column ===\n",
        "def impute_column(target):\n",
        "    print(f\"\\nüîß Processing target: '{target}'\")\n",
        "\n",
        "    # === Special case: only impute when quantity == 0.0 ===\n",
        "    if target == 'legs1_segments0_baggageAllowance_weightMeasurementType':\n",
        "        train_subset = train[\n",
        "            (train[target].notna()) &\n",
        "            (train['legs1_segments0_baggageAllowance_quantity'] == 0.0)\n",
        "        ]\n",
        "    else:\n",
        "        train_subset = train.dropna(subset=features + [target])\n",
        "\n",
        "    if train_subset.empty:\n",
        "        print(f\"‚ùå Skipped '{target}': No complete training data.\")\n",
        "        return\n",
        "\n",
        "    X_train = train_subset[features]\n",
        "    y_train_raw = train_subset[target]\n",
        "\n",
        "    # Label Encoding\n",
        "    le = LabelEncoder()\n",
        "    y_train = le.fit_transform(y_train_raw)\n",
        "\n",
        "    # Model\n",
        "    model = XGBClassifier(\n",
        "        n_estimators=500,\n",
        "        max_depth=12,\n",
        "        learning_rate=0.1,\n",
        "        tree_method='hist',\n",
        "        n_jobs=24,\n",
        "        random_state=42,\n",
        "        eval_metric='logloss'\n",
        "    )\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Impute train & test\n",
        "    for df, name in [(train, \"train\"), (test, \"test\")]:\n",
        "        if target == 'legs1_segments0_baggageAllowance_weightMeasurementType':\n",
        "            missing_mask = df[target].isna() & (df['legs1_segments0_baggageAllowance_quantity'] == 0.0)\n",
        "        else:\n",
        "            missing_mask = df[target].isna()\n",
        "\n",
        "        if missing_mask.sum() == 0:\n",
        "            print(f\"‚úÖ {name}: No missing values in '{target}'\")\n",
        "            continue\n",
        "\n",
        "        imputable = df.loc[missing_mask, features].dropna()\n",
        "        imputable_indices = imputable.index\n",
        "\n",
        "        if len(imputable_indices) == 0:\n",
        "            print(f\"‚ö†Ô∏è {name}: No imputable rows with all required features for '{target}'.\")\n",
        "            continue\n",
        "\n",
        "        preds = model.predict(imputable)\n",
        "        preds_labels = le.inverse_transform(preds)\n",
        "        df.loc[imputable_indices, target] = preds_labels\n",
        "        print(f\"‚úÖ {name}: Imputed {len(imputable_indices)} missing values in '{target}'\")\n",
        "\n",
        "    # Report\n",
        "    for df, name in [(train, \"train\"), (test, \"test\")]:\n",
        "        total = len(df)\n",
        "        missing = df[target].isna().sum()\n",
        "        value_counts = df[target].value_counts(dropna=False).sort_index()\n",
        "        print(f\"\\nüìä {name} ‚Äî '{target}':\")\n",
        "        print(f\"  Total rows: {total}\")\n",
        "        print(f\"  Missing: {missing} ({100 * missing / total:.2f}%)\")\n",
        "        print(\"  Top 10 value counts (including imputations):\")\n",
        "        print(value_counts.head(10))\n",
        "\n",
        "# === Run for each target column ===\n",
        "for target in target_columns:\n",
        "    impute_column(target)\n",
        "\n",
        "# === Save final files ===\n",
        "train.to_csv(\"train.csv\", index=False)\n",
        "test.to_csv(\"test.csv\", index=False)\n",
        "\n",
        "# === End ===\n",
        "print(f\"\\n‚è±Ô∏è Total duration: {round(time.time() - start, 2)} seconds\")"
      ],
      "metadata": {
        "id": "HM4QOaEhboI7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "üîß Processing target: 'legs1_segments0_baggageAllowance_weightMeasurementType'\n",
        "‚úÖ train: Imputed 1314851 missing values in 'legs1_segments0_baggageAllowance_weightMeasurementType'\n",
        "‚úÖ test: Imputed 370664 missing values in 'legs1_segments0_baggageAllowance_weightMeasurementType'\n",
        "\n",
        "üìä train ‚Äî 'legs1_segments0_baggageAllowance_weightMeasurementType':\n",
        "  Total rows: 18145372\n",
        "  Missing: 0 (0.00%)\n",
        "  Top 10 value counts (including imputations):\n",
        "legs1_segments0_baggageAllowance_weightMeasurementType\n",
        "0.0    17089873\n",
        "1.0     1055499\n",
        "Name: count, dtype: int64\n",
        "\n",
        "üìä test ‚Äî 'legs1_segments0_baggageAllowance_weightMeasurementType':\n",
        "  Total rows: 6897776\n",
        "  Missing: 0 (0.00%)\n",
        "  Top 10 value counts (including imputations):\n",
        "legs1_segments0_baggageAllowance_weightMeasurementType\n",
        "0.0    6531933\n",
        "1.0     365843\n",
        "Name: count, dtype: int64\n",
        "\n",
        "‚è±Ô∏è Total duration: 440.47 seconds"
      ],
      "metadata": {
        "id": "OcU_gQ4_bvJi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile convert_duration.py\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# === Load files ===\n",
        "train = pd.read_csv(\"train.csv\", low_memory=False)\n",
        "test = pd.read_csv(\"test.csv\", low_memory=False)\n",
        "\n",
        "# === Columns to convert ===\n",
        "duration_columns = [\"legs1_segments0_duration\", \"legs1_duration\"]\n",
        "\n",
        "# === Conversion function HH:MM:SS ‚Üí minutes ===\n",
        "def duration_to_minutes(duration_str):\n",
        "    if pd.isna(duration_str):\n",
        "        return np.nan\n",
        "    try:\n",
        "        h, m, s = map(int, duration_str.split(\":\"))\n",
        "        return h * 60 + m + s / 60\n",
        "    except:\n",
        "        return np.nan\n",
        "\n",
        "# === Text output for report ===\n",
        "lines = []\n",
        "lines.append(\"üìÑ Duration Conversion Report (HH:MM:SS ‚Üí minutes)\\n\")\n",
        "\n",
        "# === Conversion + statistics ===\n",
        "for col in duration_columns:\n",
        "    for df, name in [(train, \"Train\"), (test, \"Test\")]:\n",
        "        orig_col = df[col].copy()\n",
        "        df[col] = df[col].apply(duration_to_minutes)\n",
        "\n",
        "        nan_before = orig_col.isna().sum()\n",
        "        nan_after = df[col].isna().sum()\n",
        "\n",
        "        lines.append(f\"\\n=== üìä Dataset: {name} ‚Äî Column: {col} ===\")\n",
        "        lines.append(f\"üî¢ Total rows: {len(df)}\")\n",
        "        lines.append(f\"‚ùå Missing before: {nan_before}\")\n",
        "        lines.append(f\"‚ùå Missing after:  {nan_after}\")\n",
        "        lines.append(\"\\nüìà Descriptive stats:\")\n",
        "        lines.append(df[col].describe().to_string())\n",
        "\n",
        "        value_counts = df[col].value_counts().sort_index()\n",
        "        lines.append(\"\\nüîü Top 10 most common durations (minutes):\")\n",
        "        lines.append(value_counts.head(10).to_string())\n",
        "\n",
        "# === Save updated files ===\n",
        "train.to_csv(\"train.csv\", index=False)\n",
        "test.to_csv(\"test.csv\", index=False)\n",
        "\n",
        "# === Write report to .txt file ===\n",
        "with open(\"duration_conversion_report.txt\", \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(\"\\n\".join(lines))\n",
        "\n",
        "print(\"‚úÖ Conversion completed and saved to 'train.csv' and 'test.csv'\")\n",
        "print(\"üìù Report generated: 'duration_conversion_report.txt'\")\n"
      ],
      "metadata": {
        "id": "PtPKPrWeb6Pr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile impute_multiple_targets.py\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from xgboost import XGBRegressor\n",
        "import time\n",
        "\n",
        "# === Timer ===\n",
        "start = time.time()\n",
        "\n",
        "# === Load files ===\n",
        "train = pd.read_csv(\"train.csv\", low_memory=False)\n",
        "test = pd.read_csv(\"test.csv\", low_memory=False)\n",
        "\n",
        "# === Relevant columns for prediction ===\n",
        "features = [\n",
        "    'totalPrice',\n",
        "    'companyID',\n",
        "    'legs0_segments0_cabinClass',\n",
        "    'isAccess3D',\n",
        "    'isVip',\n",
        "    'legs0_segments0_seatsAvailable',\n",
        "    'legs0_segments0_flightNumber',\n",
        "    'taxes',\n",
        "    'legs0_segments0_baggageAllowance_quantity',\n",
        "    'legs0_segments0_baggageAllowance_weightMeasurementType',\n",
        "    'pricingInfo_isAccessTP',\n",
        "    'miniRules0_monetaryAmount',\n",
        "    'miniRules1_monetaryAmount',\n",
        "    'miniRules0_statusInfos',\n",
        "    'miniRules1_statusInfos'\n",
        "]\n",
        "\n",
        "# === Target columns to impute ===\n",
        "target_columns = [\n",
        "    'legs1_segments0_duration',\n",
        "    'legs1_duration'\n",
        "]\n",
        "\n",
        "# === Training and imputing function for one target column ===\n",
        "def impute_column(target):\n",
        "    print(f\"\\nüîß Processing target: '{target}'\")\n",
        "\n",
        "    train_valid = train.dropna(subset=features + [target])\n",
        "    if train_valid.empty:\n",
        "        print(f\"‚ùå Skipped '{target}': No complete training data.\")\n",
        "        return\n",
        "\n",
        "    X_train = train_valid[features]\n",
        "    y_train = train_valid[target].astype(float)\n",
        "\n",
        "    # Model\n",
        "    model = XGBRegressor(\n",
        "        n_estimators=500,\n",
        "        max_depth=12,\n",
        "        learning_rate=0.1,\n",
        "        tree_method='hist',\n",
        "        n_jobs=24,\n",
        "        random_state=42,\n",
        "        eval_metric='rmse'\n",
        "    )\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Impute train & test\n",
        "    for df, name in [(train, \"train\"), (test, \"test\")]:\n",
        "        missing_mask = df[target].isna()\n",
        "        if missing_mask.sum() == 0:\n",
        "            print(f\"‚úÖ {name}: No missing values in '{target}'\")\n",
        "            continue\n",
        "\n",
        "        imputable = df.loc[missing_mask, features].dropna()\n",
        "        imputable_indices = imputable.index\n",
        "\n",
        "        if len(imputable_indices) == 0:\n",
        "            print(f\"‚ö†Ô∏è {name}: No imputable rows with all required features for '{target}'.\")\n",
        "            continue\n",
        "\n",
        "        preds = model.predict(imputable)\n",
        "        preds_rounded = np.round(preds)  # Round to nearest minute\n",
        "        df.loc[imputable_indices, target] = preds_rounded\n",
        "        print(f\"‚úÖ {name}: Imputed {len(imputable_indices)} missing values in '{target}'\")\n",
        "\n",
        "    # Report\n",
        "    for df, name in [(train, \"train\"), (test, \"test\")]:\n",
        "        total = len(df)\n",
        "        missing = df[target].isna().sum()\n",
        "        value_counts = df[target].value_counts(dropna=False).sort_index()\n",
        "        print(f\"\\nüìä {name} ‚Äî '{target}':\")\n",
        "        print(f\"  Total rows: {total}\")\n",
        "        print(f\"  Missing: {missing} ({100 * missing / total:.2f}%)\")\n",
        "        print(\"  Top 10 value counts (including imputations):\")\n",
        "        print(value_counts.head(10))\n",
        "\n",
        "# === Run for each target column ===\n",
        "for target in target_columns:\n",
        "    impute_column(target)\n",
        "\n",
        "# === Save final files ===\n",
        "train.to_csv(\"train.csv\", index=False)\n",
        "test.to_csv(\"test.csv\", index=False)\n",
        "\n",
        "# === End ===\n",
        "print(f\"\\n‚è±Ô∏è Total duration: {round(time.time() - start, 2)} seconds\")\n"
      ],
      "metadata": {
        "id": "DyThkA3BcLpv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "üîß Processing target: 'legs1_segments0_duration'\n",
        "‚úÖ train: Imputed 4387201 missing values in 'legs1_segments0_duration'\n",
        "‚úÖ test: Imputed 1115840 missing values in 'legs1_segments0_duration'\n",
        "\n",
        "üìä train ‚Äî 'legs1_segments0_duration':\n",
        "  Total rows: 18145372\n",
        "  Missing: 0 (0.00%)\n",
        "  Top 10 value counts (including imputations):\n",
        "legs1_segments0_duration\n",
        "-39.0      1\n",
        "-36.0      1\n",
        "-12.0      1\n",
        "-11.0      1\n",
        "-10.0      1\n",
        "-7.0       1\n",
        "-6.0       1\n",
        "-2.0       9\n",
        "-1.0       1\n",
        " 0.0     208\n",
        "Name: count, dtype: int64\n",
        "\n",
        "üìä test ‚Äî 'legs1_segments0_duration':\n",
        "  Total rows: 6897776\n",
        "  Missing: 0 (0.00%)\n",
        "  Top 10 value counts (including imputations):\n",
        "legs1_segments0_duration\n",
        "14.0    1\n",
        "19.0    1\n",
        "21.0    1\n",
        "22.0    4\n",
        "23.0    3\n",
        "25.0    2\n",
        "26.0    4\n",
        "27.0    3\n",
        "28.0    2\n",
        "29.0    4\n",
        "Name: count, dtype: int64\n",
        "\n",
        "üîß Processing target: 'legs1_duration'\n",
        "‚úÖ train: Imputed 5017122 missing values in 'legs1_duration'\n",
        "‚úÖ test: Imputed 1404203 missing values in 'legs1_duration'\n",
        "\n",
        "üìä train ‚Äî 'legs1_duration':\n",
        "  Total rows: 18145372\n",
        "  Missing: 0 (0.00%)\n",
        "  Top 10 value counts (including imputations):\n",
        "legs1_duration\n",
        "-311.0    1\n",
        "-264.0    1\n",
        "-257.0    2\n",
        "-253.0    2\n",
        "-242.0    4\n",
        "-241.0    1\n",
        "-232.0    2\n",
        "-231.0    1\n",
        "-223.0    7\n",
        "-221.0    1\n",
        "Name: count, dtype: int64\n",
        "\n",
        "üìä test ‚Äî 'legs1_duration':\n",
        "  Total rows: 6897776\n",
        "  Missing: 0 (0.00%)\n",
        "  Top 10 value counts (including imputations):\n",
        "legs1_duration\n",
        "-192.0     1\n",
        "-159.0     1\n",
        "-141.0     1\n",
        "-121.0     1\n",
        "-117.0     4\n",
        "-114.0    10\n",
        "-111.0     1\n",
        "-108.0     1\n",
        "-100.0     5\n",
        "-99.0      1\n",
        "Name: count, dtype: int64\n",
        "\n",
        "‚è±Ô∏è Total duration: 696.13 seconds"
      ],
      "metadata": {
        "id": "kKn_MADDcMfN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile check_neg.py\n",
        "import pandas as pd\n",
        "\n",
        "# Load files\n",
        "train = pd.read_csv(\"train.csv\", low_memory=False)\n",
        "test = pd.read_csv(\"test.csv\", low_memory=False)\n",
        "\n",
        "# Columns to check\n",
        "cols = ['legs1_segments0_duration', 'legs1_duration']\n",
        "\n",
        "# Function for checking\n",
        "def check_nulls_and_negatives(df, df_name):\n",
        "    print(f\"\\nüìä Checking {df_name}\")\n",
        "    for col in cols:\n",
        "        if col not in df.columns:\n",
        "            print(f\"‚ö†Ô∏è Column '{col}' does not exist in {df_name}\")\n",
        "            continue\n",
        "        try:\n",
        "            # Convert to numeric (if needed)\n",
        "            series = pd.to_numeric(df[col], errors='coerce')\n",
        "            null_count = series.isna().sum()\n",
        "            negative_count = (series < 0).sum()\n",
        "            print(f\"üîπ {col}:\")\n",
        "            print(f\"   - Null values: {null_count}\")\n",
        "            print(f\"   - Values < 0: {negative_count}\")\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Error processing column '{col}': {e}\")\n",
        "\n",
        "# Run for both datasets\n",
        "check_nulls_and_negatives(train, \"train.csv\")\n",
        "check_nulls_and_negatives(test, \"test.csv\")\n"
      ],
      "metadata": {
        "id": "6fxCtHvmcVoi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "üìä Check for train.csv\n",
        "üîπ legs1_segments0_duration:\n",
        "\n",
        "Missing values: 0\n",
        "\n",
        "Values < 0: 17\n",
        "\n",
        "üîπ legs1_duration:\n",
        "\n",
        "Missing values: 0\n",
        "\n",
        "Values < 0: 2719\n",
        "\n",
        "üìä Check for test.csv\n",
        "üîπ legs1_segments0_duration:\n",
        "\n",
        "Missing values: 0\n",
        "\n",
        "Values < 0: 0\n",
        "\n",
        "üîπ legs1_duration:\n",
        "\n",
        "Missing values: 0\n",
        "\n",
        "Values < 0: 642"
      ],
      "metadata": {
        "id": "sbvo2uaMchsC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile impute_neg_with_median.py\n",
        "import pandas as pd\n",
        "\n",
        "# === Load the data ===\n",
        "train = pd.read_csv(\"train.csv\")\n",
        "test = pd.read_csv(\"test.csv\")\n",
        "\n",
        "# === Columns to process ===\n",
        "columns = [\"legs1_segments0_duration\", \"legs1_duration\"]\n",
        "\n",
        "# === Prepare report ===\n",
        "report_lines = [\"üìÑ Report ‚Äî Replacing values ‚â§ 0 with median\\n\"]\n",
        "\n",
        "# === Process each column and dataset ===\n",
        "for col in columns:\n",
        "    report_lines.append(f\"\\n=== üîß Column: {col} ===\")\n",
        "\n",
        "    for df, name in [(train, \"Train\"), (test, \"Test\")]:\n",
        "        mask = df[col] <= 0\n",
        "        count_replaced = mask.sum()\n",
        "        median = df.loc[df[col] > 0, col].median()\n",
        "\n",
        "        df.loc[mask, col] = median\n",
        "\n",
        "        report_lines.append(f\"üìä {name}:\")\n",
        "        report_lines.append(f\"  - Median used: {median}\")\n",
        "        report_lines.append(f\"  - Values replaced (‚â§ 0): {count_replaced}\")\n",
        "\n",
        "# === Save modified files ===\n",
        "train.to_csv(\"train.csv\", index=False)\n",
        "test.to_csv(\"test.csv\", index=False)\n",
        "\n",
        "# === Save the report ===\n",
        "with open(\"imputation_report.txt\", \"w\") as f:\n",
        "    f.write(\"\\n\".join(report_lines))\n",
        "\n",
        "print(\"‚úÖ Processing complete. Details saved in 'imputation_report.txt'.\")\n"
      ],
      "metadata": {
        "id": "_XLR6Rcwcgy6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "=== üîß Column: legs1_segments0_duration ===\n",
        "üìä Train:\n",
        "  - Median used: 117.0\n",
        "  - Values replaced (‚â§ 0): 225\n",
        "üìä Test:\n",
        "  - Median used: 105.0\n",
        "  - Values replaced (‚â§ 0): 0\n",
        "\n",
        "=== üîß Column: legs1_duration ===\n",
        "üìä Train:\n",
        "  - Median used: 139.0\n",
        "  - Values replaced (‚â§ 0): 2771\n",
        "üìä Test:\n",
        "  - Median used: 105.0\n",
        "  - Values replaced (‚â§ 0): 659"
      ],
      "metadata": {
        "id": "aYcaFfPncwCq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile impute_legs1_segments0_flightNumber.py\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import time\n",
        "\n",
        "# === Timer ===\n",
        "start = time.time()\n",
        "\n",
        "# === Load files ===\n",
        "train = pd.read_csv(\"train.csv\", low_memory=False)\n",
        "test = pd.read_csv(\"test.csv\", low_memory=False)\n",
        "\n",
        "# === Relevant columns for prediction ===\n",
        "features = [\n",
        "    'totalPrice',\n",
        "    'companyID',\n",
        "    'legs0_segments0_cabinClass',\n",
        "    'isAccess3D',\n",
        "    'isVip',\n",
        "    'legs0_segments0_seatsAvailable',\n",
        "    'legs0_segments0_flightNumber',\n",
        "    'taxes',\n",
        "    'legs0_segments0_baggageAllowance_quantity',\n",
        "    'legs0_segments0_baggageAllowance_weightMeasurementType',\n",
        "    'pricingInfo_isAccessTP',\n",
        "    'miniRules0_monetaryAmount',\n",
        "    'miniRules1_monetaryAmount',\n",
        "    'miniRules0_statusInfos',\n",
        "    'miniRules1_statusInfos'\n",
        "]\n",
        "\n",
        "# === Target columns to impute ===\n",
        "target_columns = [\n",
        "    'legs1_segments0_flightNumber'\n",
        "]\n",
        "\n",
        "# === Train and impute function for a target column ===\n",
        "def impute_column(target):\n",
        "    print(f\"\\nüîß Processing target: '{target}'\")\n",
        "\n",
        "    train_valid = train.dropna(subset=features + [target])\n",
        "    if train_valid.empty:\n",
        "        print(f\"‚ùå Skipped '{target}': No complete training data.\")\n",
        "        return\n",
        "\n",
        "    # Sample: 10% of the data\n",
        "    train_valid = train_valid.sample(frac=0.1, random_state=42)\n",
        "\n",
        "    X_train = train_valid[features]\n",
        "    y_train_raw = train_valid[target].astype(str)  # treat as identifier\n",
        "\n",
        "    # Label Encoding\n",
        "    le = LabelEncoder()\n",
        "    y_train = le.fit_transform(y_train_raw)\n",
        "\n",
        "    # Model\n",
        "    model = XGBClassifier(\n",
        "        n_estimators=50,\n",
        "        max_depth=4,\n",
        "        learning_rate=0.1,\n",
        "        tree_method='hist',\n",
        "        n_jobs=8,\n",
        "        random_state=42,\n",
        "        eval_metric='mlogloss'\n",
        "    )\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Impute train & test\n",
        "    for df, name in [(train, \"train\"), (test, \"test\")]:\n",
        "        missing_mask = df[target].isna()\n",
        "        if missing_mask.sum() == 0:\n",
        "            print(f\"‚úÖ {name}: No missing values in '{target}'\")\n",
        "            continue\n",
        "\n",
        "        imputable = df.loc[missing_mask, features].dropna()\n",
        "        imputable_indices = imputable.index\n",
        "\n",
        "        if len(imputable_indices) == 0:\n",
        "            print(f\"‚ö†Ô∏è {name}: No imputable rows with all required features for '{target}'.\")\n",
        "            continue\n",
        "\n",
        "        preds = model.predict(imputable)\n",
        "        preds_labels = le.inverse_transform(preds).astype(float)  # convert back to numeric\n",
        "        df.loc[imputable_indices, target] = preds_labels\n",
        "        print(f\"‚úÖ {name}: Imputed {len(imputable_indices)} missing values in '{target}'\")\n",
        "\n",
        "    # Report\n",
        "    for df, name in [(train, \"train\"), (test, \"test\")]:\n",
        "        total = len(df)\n",
        "        missing = df[target].isna().sum()\n",
        "        value_counts = df[target].value_counts(dropna=False).sort_index()\n",
        "        print(f\"\\nüìä {name} ‚Äî '{target}':\")\n",
        "        print(f\"  Total rows: {total}\")\n",
        "        print(f\"  Missing: {missing} ({100 * missing / total:.2f}%)\")\n",
        "        print(\"  Top 10 value counts (including imputations):\")\n",
        "        print(value_counts.head(10))\n",
        "\n",
        "# === Run for each target column ===\n",
        "for target in target_columns:\n",
        "    impute_column(target)\n",
        "\n",
        "# === Save final files ===\n",
        "train.to_csv(\"train.csv\", index=False)\n",
        "test.to_csv(\"test.csv\", index=False)\n",
        "\n",
        "# === Final ===\n",
        "print(f\"\\n‚è±Ô∏è Total duration: {round(time.time() - start, 2)} seconds\")\n"
      ],
      "metadata": {
        "id": "1YUXIFWncw9K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile convert_leg1_arrival_departure.py\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Read CSV files\n",
        "train_df = pd.read_csv(\"train.csv\")\n",
        "test_df = pd.read_csv(\"test.csv\")\n",
        "\n",
        "def engineer_datetime_features(df, col):\n",
        "    df[col] = pd.to_datetime(df[col], errors='coerce')\n",
        "    prefix = f\"{col}_\"\n",
        "\n",
        "    df[f\"{prefix}dayofweek\"] = df[col].dt.dayofweek\n",
        "    df[f\"{prefix}hour\"] = df[col].dt.hour\n",
        "    df[f\"{prefix}minute\"] = df[col].dt.minute\n",
        "    df[f\"{prefix}is_weekend\"] = df[f\"{prefix}dayofweek\"].isin([5, 6]).astype(int)\n",
        "    df[f\"{prefix}day\"] = df[col].dt.day\n",
        "    df[f\"{prefix}month\"] = df[col].dt.month\n",
        "    df[f\"{prefix}year\"] = df[col].dt.year\n",
        "    df[f\"{prefix}weekofyear\"] = df[col].dt.isocalendar().week\n",
        "\n",
        "    def get_part_of_day(hour):\n",
        "        if pd.isna(hour): return np.nan\n",
        "        if hour < 6: return \"night\"\n",
        "        elif hour < 12: return \"morning\"\n",
        "        elif hour < 18: return \"afternoon\"\n",
        "        else: return \"evening\"\n",
        "\n",
        "    df[f\"{prefix}part_of_day\"] = df[f\"{prefix}hour\"].apply(get_part_of_day).astype(\"category\")\n",
        "    df[f\"{prefix}hour_sin\"] = np.sin(2 * np.pi * df[f\"{prefix}hour\"] / 24)\n",
        "    df[f\"{prefix}hour_cos\"] = np.cos(2 * np.pi * df[f\"{prefix}hour\"] / 24)\n",
        "\n",
        "    return df\n",
        "\n",
        "# Apply the function for both columns\n",
        "for col in [\"legs1_departureAt\", \"legs1_arrivalAt\"]:\n",
        "    train_df = engineer_datetime_features(train_df, col)\n",
        "    test_df = engineer_datetime_features(test_df, col)\n",
        "\n",
        "# Save a .txt file with important info\n",
        "with open(\"leg1_features_info.txt\", \"w\") as f:\n",
        "    for col in [\"legs1_departureAt\", \"legs1_arrivalAt\"]:\n",
        "        prefix = f\"{col}_\"\n",
        "        f.write(f\"\\n==== {col} ====\\n\")\n",
        "        for feature in [\n",
        "            f\"{prefix}dayofweek\", f\"{prefix}hour\", f\"{prefix}minute\",\n",
        "            f\"{prefix}is_weekend\", f\"{prefix}day\", f\"{prefix}month\",\n",
        "            f\"{prefix}year\", f\"{prefix}weekofyear\", f\"{prefix}part_of_day\"\n",
        "        ]:\n",
        "            nulls = train_df[feature].isnull().sum()\n",
        "            unique_vals = train_df[feature].dropna().unique()\n",
        "            unique_count = len(unique_vals)\n",
        "            f.write(f\"{feature}: {unique_count} unique values, {nulls} missing values\\n\")\n",
        "            preview_vals = unique_vals[:20]\n",
        "            f.write(f\"    Sample values: {', '.join(map(str, preview_vals))}\\n\")\n",
        "\n",
        "# üî• Save modified DataFrames to CSV\n",
        "train_df.to_csv(\"train.csv\", index=False)\n",
        "test_df.to_csv(\"test.csv\", index=False)\n"
      ],
      "metadata": {
        "id": "-iP0CWkNdGGK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "==== legs1_departureAt ====\n",
        "legs1_departureAt_dayofweek: 7 unique values, 4387201 missing values\n",
        "    Sample values: 1.0, 5.0, 2.0, 3.0, 4.0, 0.0, 6.0\n",
        "legs1_departureAt_hour: 24 unique values, 4387201 missing values\n",
        "    Sample values: 9.0, 22.0, 19.0, 17.0, 6.0, 14.0, 11.0, 12.0, 8.0, 16.0, 7.0, 4.0, 5.0, 13.0, 18.0, 1.0, 3.0, 15.0, 20.0, 21.0\n",
        "legs1_departureAt_minute: 51 unique values, 4387201 missing values\n",
        "    Sample values: 45.0, 5.0, 35.0, 55.0, 0.0, 25.0, 20.0, 30.0, 15.0, 40.0, 50.0, 10.0, 29.0, 38.0, 4.0, 58.0, 42.0, 57.0, 36.0, 32.0\n",
        "legs1_departureAt_is_weekend: 2 unique values, 0 missing values\n",
        "    Sample values: 0, 1\n",
        "legs1_departureAt_day: 31 unique values, 4387201 missing values\n",
        "    Sample values: 9.0, 25.0, 22.0, 29.0, 15.0, 30.0, 23.0, 24.0, 31.0, 5.0, 16.0, 19.0, 21.0, 7.0, 28.0, 26.0, 1.0, 20.0, 2.0, 4.0\n",
        "legs1_departureAt_month: 11 unique values, 4387201 missing values\n",
        "    Sample values: 7.0, 5.0, 8.0, 6.0, 9.0, 10.0, 11.0, 12.0, 1.0, 2.0, 3.0\n",
        "legs1_departureAt_year: 2 unique values, 4387201 missing values\n",
        "    Sample values: 2024.0, 2025.0\n",
        "legs1_departureAt_weekofyear: 41 unique values, 4387201 missing values\n",
        "    Sample values: 28, 21, 22, 33, 23, 38, 34, 25, 24, 26, 29, 27, 31, 35, 37, 30, 41, 39, 32, 36\n",
        "legs1_departureAt_part_of_day: 4 unique values, 4387201 missing values\n",
        "    Sample values: morning, evening, afternoon, night\n",
        "\n",
        "==== legs1_arrivalAt ====\n",
        "legs1_arrivalAt_dayofweek: 7 unique values, 4387201 missing values\n",
        "    Sample values: 1.0, 2.0, 5.0, 3.0, 4.0, 0.0, 6.0\n",
        "legs1_arrivalAt_hour: 24 unique values, 4387201 missing values\n",
        "    Sample values: 14.0, 8.0, 11.0, 22.0, 18.0, 16.0, 12.0, 5.0, 19.0, 20.0, 0.0, 3.0, 17.0, 23.0, 15.0, 13.0, 21.0, 4.0, 1.0, 6.0\n",
        "legs1_arrivalAt_minute: 24 unique values, 4387201 missing values\n",
        "    Sample values: 20.0, 30.0, 5.0, 40.0, 35.0, 15.0, 55.0, 0.0, 25.0, 50.0, 45.0, 10.0, 59.0, 1.0, 56.0, 28.0, 4.0, 23.0, 12.0, 27.0\n",
        "legs1_arrivalAt_is_weekend: 2 unique values, 0 missing values\n",
        "    Sample values: 0, 1\n",
        "legs1_arrivalAt_day: 31 unique values, 4387201 missing values\n",
        "    Sample values: 9.0, 10.0, 25.0, 22.0, 23.0, 29.0, 30.0, 15.0, 16.0, 31.0, 24.0, 1.0, 5.0, 6.0, 17.0, 19.0, 21.0, 7.0, 8.0, 28.0\n",
        "legs1_arrivalAt_month: 11 unique values, 4387201 missing values\n",
        "    Sample values: 7.0, 5.0, 8.0, 6.0, 9.0, 10.0, 11.0, 12.0, 1.0, 2.0, 3.0\n",
        "legs1_arrivalAt_year: 2 unique values, 4387201 missing values\n",
        "    Sample values: 2024.0, 2025.0\n",
        "legs1_arrivalAt_weekofyear: 43 unique values, 4387201 missing values\n",
        "    Sample values: 28, 21, 22, 33, 23, 38, 34, 25, 24, 26, 29, 27, 31, 35, 37, 30, 41, 39, 32, 36\n",
        "legs1_arrivalAt_part_of_day: 4 unique values, 4387201 missing values\n",
        "    Sample values: afternoon, morning, evening, night"
      ],
      "metadata": {
        "id": "NUgBvM15dHLx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile check_leg1_columns.py\n",
        "import pandas as pd\n",
        "\n",
        "# === Load CSV files ===\n",
        "train = pd.read_csv(\"train.csv\", low_memory=False)\n",
        "test = pd.read_csv(\"test.csv\", low_memory=False)\n",
        "\n",
        "# === Function to extract columns with a given prefix ===\n",
        "def get_prefixed_columns(df, prefix):\n",
        "    return sorted([col for col in df.columns if col.startswith(prefix)])\n",
        "\n",
        "# === Extract relevant columns ===\n",
        "prefixes = [\"legs1_departureAt\", \"legs1_arrivalAt\"]\n",
        "\n",
        "for prefix in prefixes:\n",
        "    train_cols = get_prefixed_columns(train, prefix)\n",
        "    test_cols = get_prefixed_columns(test, prefix)\n",
        "\n",
        "    print(f\"\\nüì¶ Prefix: {prefix}\")\n",
        "    print(f\"‚úÖ train.csv: {len(train_cols)} columns\")\n",
        "    print(train_cols)\n",
        "\n",
        "    print(f\"\\n‚úÖ test.csv: {len(test_cols)} columns\")\n",
        "    print(test_cols)\n",
        "\n",
        "    # === Differences between train and test ===\n",
        "    missing_in_train = set(test_cols) - set(train_cols)\n",
        "    missing_in_test = set(train_cols) - set(test_cols)\n",
        "\n",
        "    if missing_in_train:\n",
        "        print(f\"\\n‚ö†Ô∏è Columns present in test but missing in train: {sorted(missing_in_train)}\")\n",
        "    if missing_in_test:\n",
        "        print(f\"‚ö†Ô∏è Columns present in train but missing in test: {sorted(missing_in_test)}\")\n",
        "    if not missing_in_train and not missing_in_test:\n",
        "        print(\"‚úÖ Columns match between train and test.\")\n",
        "\n",
        "print(\"\\n‚úÖ Final check complete.\")\n"
      ],
      "metadata": {
        "id": "L97qoWqydR5Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "üì¶ Prefix: legs1_departureAt\n",
        "‚úÖ train.csv: 12 columns\n",
        "['legs1_departureAt', 'legs1_departureAt_day', 'legs1_departureAt_dayofweek', 'legs1_departureAt_hour', 'legs1_departureAt_hour_cos', 'legs1_departureAt_hour_sin', 'legs1_departureAt_is_weekend', 'legs1_departureAt_minute', 'legs1_departureAt_month', 'legs1_departureAt_part_of_day', 'legs1_departureAt_weekofyear', 'legs1_departureAt_year']\n",
        "\n",
        "‚úÖ test.csv: 12 columns\n",
        "['legs1_departureAt', 'legs1_departureAt_day', 'legs1_departureAt_dayofweek', 'legs1_departureAt_hour', 'legs1_departureAt_hour_cos', 'legs1_departureAt_hour_sin', 'legs1_departureAt_is_weekend', 'legs1_departureAt_minute', 'legs1_departureAt_month', 'legs1_departureAt_part_of_day', 'legs1_departureAt_weekofyear', 'legs1_departureAt_year']\n",
        "‚úÖ Coloanele se potrivesc √Æntre train »ôi test.\n",
        "\n",
        "üì¶ Prefix: legs1_arrivalAt\n",
        "‚úÖ train.csv: 12 columns\n",
        "['legs1_arrivalAt', 'legs1_arrivalAt_day', 'legs1_arrivalAt_dayofweek', 'legs1_arrivalAt_hour', 'legs1_arrivalAt_hour_cos', 'legs1_arrivalAt_hour_sin', 'legs1_arrivalAt_is_weekend', 'legs1_arrivalAt_minute', 'legs1_arrivalAt_month', 'legs1_arrivalAt_part_of_day', 'legs1_arrivalAt_weekofyear', 'legs1_arrivalAt_year']\n",
        "\n",
        "‚úÖ test.csv: 12 columns\n",
        "['legs1_arrivalAt', 'legs1_arrivalAt_day', 'legs1_arrivalAt_dayofweek', 'legs1_arrivalAt_hour', 'legs1_arrivalAt_hour_cos', 'legs1_arrivalAt_hour_sin', 'legs1_arrivalAt_is_weekend', 'legs1_arrivalAt_minute', 'legs1_arrivalAt_month', 'legs1_arrivalAt_part_of_day', 'legs1_arrivalAt_weekofyear', 'legs1_arrivalAt_year']\n",
        "‚úÖ Coloanele se potrivesc √Æntre train »ôi test.\n",
        "\n",
        "‚úÖ Verificare finalizatƒÉ."
      ],
      "metadata": {
        "id": "BRmeAY3kdTex"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile impute_arrival_departure.py\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import time\n",
        "\n",
        "# === Timer ===\n",
        "start = time.time()\n",
        "\n",
        "# === Load files ===\n",
        "train = pd.read_csv(\"train.csv\", low_memory=False)\n",
        "test = pd.read_csv(\"test.csv\", low_memory=False)\n",
        "\n",
        "# === Relevant columns for prediction ===\n",
        "features = [\n",
        "    'totalPrice',\n",
        "    'companyID',\n",
        "    'legs0_segments0_cabinClass',\n",
        "    'isAccess3D',\n",
        "    'isVip',\n",
        "    'legs0_segments0_seatsAvailable',\n",
        "    'legs0_segments0_flightNumber',\n",
        "    'taxes',\n",
        "    'legs0_segments0_baggageAllowance_quantity',\n",
        "    'legs0_segments0_baggageAllowance_weightMeasurementType',\n",
        "    'pricingInfo_isAccessTP',\n",
        "    'miniRules0_monetaryAmount',\n",
        "    'miniRules1_monetaryAmount',\n",
        "    'miniRules0_statusInfos',\n",
        "    'miniRules1_statusInfos'\n",
        "]\n",
        "\n",
        "# === Target columns to impute ===\n",
        "target_columns = [\n",
        "    'legs1_departureAt_hour',\n",
        "    'legs1_departureAt_day',\n",
        "    'legs1_departureAt_year',\n",
        "    'legs1_arrivalAt_hour',\n",
        "    'legs1_arrivalAt_day',\n",
        "    'legs1_arrivalAt_year',\n",
        "]\n",
        "\n",
        "# === Training and imputation function for a target column ===\n",
        "def impute_column(target):\n",
        "    print(f\"\\nüîß Processing target: '{target}'\")\n",
        "\n",
        "    train_valid = train.dropna(subset=features + [target])\n",
        "    if train_valid.empty:\n",
        "        print(f\"‚ùå Skipped '{target}': No complete training data.\")\n",
        "        return\n",
        "\n",
        "    X_train = train_valid[features]\n",
        "    y_train_raw = train_valid[target]\n",
        "\n",
        "    # Label Encoding\n",
        "    le = LabelEncoder()\n",
        "    y_train = le.fit_transform(y_train_raw)\n",
        "\n",
        "    # Model\n",
        "    model = XGBClassifier(\n",
        "        n_estimators=500,\n",
        "        max_depth=12,\n",
        "        learning_rate=0.1,\n",
        "        tree_method='hist',\n",
        "        n_jobs=24,\n",
        "        random_state=42,\n",
        "        eval_metric='logloss'\n",
        "    )\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Impute train & test\n",
        "    for df, name in [(train, \"train\"), (test, \"test\")]:\n",
        "        missing_mask = df[target].isna()\n",
        "        if missing_mask.sum() == 0:\n",
        "            print(f\"‚úÖ {name}: No missing values in '{target}'\")\n",
        "            continue\n",
        "\n",
        "        imputable = df.loc[missing_mask, features].dropna()\n",
        "        imputable_indices = imputable.index\n",
        "\n",
        "        if len(imputable_indices) == 0:\n",
        "            print(f\"‚ö†Ô∏è {name}: No imputable rows with all required features for '{target}'.\")\n",
        "            continue\n",
        "\n",
        "        preds = model.predict(imputable)\n",
        "        preds_labels = le.inverse_transform(preds)\n",
        "        df.loc[imputable_indices, target] = preds_labels\n",
        "        print(f\"‚úÖ {name}: Imputed {len(imputable_indices)} missing values in '{target}'\")\n",
        "\n",
        "    # Report\n",
        "    for df, name in [(train, \"train\"), (test, \"test\")]:\n",
        "        total = len(df)\n",
        "        missing = df[target].isna().sum()\n",
        "        value_counts = df[target].value_counts(dropna=False).sort_index()\n",
        "        print(f\"\\nüìä {name} ‚Äî '{target}':\")\n",
        "        print(f\"  Total rows: {total}\")\n",
        "        print(f\"  Missing: {missing} ({100 * missing / total:.2f}%)\")\n",
        "        print(\"  Top 10 value counts (including imputations):\")\n",
        "        print(value_counts.head(10))\n",
        "\n",
        "# === Run for each target column ===\n",
        "for target in target_columns:\n",
        "    impute_column(target)\n",
        "\n",
        "# === Save final files ===\n",
        "train.to_csv(\"train.csv\", index=False)\n",
        "test.to_csv(\"test.csv\", index=False)\n",
        "\n",
        "# === Done ===\n",
        "print(f\"\\n‚è±Ô∏è Total duration: {round(time.time() - start, 2)} seconds\")\n"
      ],
      "metadata": {
        "id": "lvVGRpuodgvq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "üîß Processing target: 'legs1_departureAt_hour'\n",
        "‚úÖ train: Imputed 4387201 missing values in 'legs1_departureAt_hour'\n",
        "‚úÖ test: Imputed 1115840 missing values in 'legs1_departureAt_hour'\n",
        "\n",
        "üìä train ‚Äî 'legs1_departureAt_hour':\n",
        "  Total rows: 18145372\n",
        "  Missing: 0 (0.00%)\n",
        "  Top 10 value counts (including imputations):\n",
        "legs1_departureAt_hour\n",
        "0.0    393387\n",
        "1.0    161969\n",
        "2.0    115577\n",
        "3.0     86281\n",
        "4.0    106254\n",
        "5.0    261518\n",
        "6.0    719628\n",
        "7.0    895037\n",
        "8.0    760941\n",
        "9.0    945254\n",
        "Name: count, dtype: int64\n",
        "\n",
        "üìä test ‚Äî 'legs1_departureAt_hour':\n",
        "  Total rows: 6897776\n",
        "  Missing: 0 (0.00%)\n",
        "  Top 10 value counts (including imputations):\n",
        "legs1_departureAt_hour\n",
        "0.0     53296\n",
        "1.0     43638\n",
        "2.0     24363\n",
        "3.0     14219\n",
        "4.0     16397\n",
        "5.0     72157\n",
        "6.0    277442\n",
        "7.0    458236\n",
        "8.0    344471\n",
        "9.0    419305\n",
        "Name: count, dtype: int64\n",
        "\n",
        "üîß Processing target: 'legs1_departureAt_day'\n",
        "‚úÖ train: Imputed 4387201 missing values in 'legs1_departureAt_day'\n",
        "‚úÖ test: Imputed 1115840 missing values in 'legs1_departureAt_day'\n",
        "\n",
        "üìä train ‚Äî 'legs1_departureAt_day':\n",
        "  Total rows: 18145372\n",
        "  Missing: 0 (0.00%)\n",
        "  Top 10 value counts (including imputations):\n",
        "legs1_departureAt_day\n",
        "1.0     511800\n",
        "2.0     508327\n",
        "3.0     536821\n",
        "4.0     685396\n",
        "5.0     678663\n",
        "6.0     689507\n",
        "7.0     418581\n",
        "8.0     524057\n",
        "9.0     594026\n",
        "10.0    499952\n",
        "Name: count, dtype: int64\n",
        "\n",
        "üìä test ‚Äî 'legs1_departureAt_day':\n",
        "  Total rows: 6897776\n",
        "  Missing: 0 (0.00%)\n",
        "  Top 10 value counts (including imputations):\n",
        "legs1_departureAt_day\n",
        "1.0     106524\n",
        "2.0      69987\n",
        "3.0      96969\n",
        "4.0     156785\n",
        "5.0     180100\n",
        "6.0     511520\n",
        "7.0     186139\n",
        "8.0     241671\n",
        "9.0      83000\n",
        "10.0    107924\n",
        "Name: count, dtype: int64\n",
        "\n",
        "üîß Processing target: 'legs1_departureAt_year'\n",
        "‚úÖ train: Imputed 4387201 missing values in 'legs1_departureAt_year'\n",
        "‚úÖ test: Imputed 1115840 missing values in 'legs1_departureAt_year'\n",
        "\n",
        "üìä train ‚Äî 'legs1_departureAt_year':\n",
        "  Total rows: 18145372\n",
        "  Missing: 0 (0.00%)\n",
        "  Top 10 value counts (including imputations):\n",
        "legs1_departureAt_year\n",
        "2024.0    18083540\n",
        "2025.0       61832\n",
        "Name: count, dtype: int64\n",
        "\n",
        "üìä test ‚Äî 'legs1_departureAt_year':\n",
        "  Total rows: 6897776\n",
        "  Missing: 0 (0.00%)\n",
        "  Top 10 value counts (including imputations):\n",
        "legs1_departureAt_year\n",
        "2024.0    6057506\n",
        "2025.0     840270\n",
        "Name: count, dtype: int64\n",
        "\n",
        "üîß Processing target: 'legs1_arrivalAt_hour'\n",
        "‚úÖ train: Imputed 4387201 missing values in 'legs1_arrivalAt_hour'\n",
        "‚úÖ test: Imputed 1115840 missing values in 'legs1_arrivalAt_hour'\n",
        "\n",
        "üìä train ‚Äî 'legs1_arrivalAt_hour':\n",
        "  Total rows: 18145372\n",
        "  Missing: 0 (0.00%)\n",
        "  Top 10 value counts (including imputations):\n",
        "legs1_arrivalAt_hour\n",
        "0.0    683270\n",
        "1.0    836862\n",
        "2.0    274884\n",
        "3.0    103193\n",
        "4.0    280755\n",
        "5.0    337765\n",
        "6.0    472778\n",
        "7.0    568381\n",
        "8.0    762010\n",
        "9.0    708097\n",
        "Name: count, dtype: int64\n",
        "\n",
        "üìä test ‚Äî 'legs1_arrivalAt_hour':\n",
        "  Total rows: 6897776\n",
        "  Missing: 0 (0.00%)\n",
        "  Top 10 value counts (including imputations):\n",
        "legs1_arrivalAt_hour\n",
        "0.0    299374\n",
        "1.0    156804\n",
        "2.0     68247\n",
        "3.0     42509\n",
        "4.0     41576\n",
        "5.0    121890\n",
        "6.0    146090\n",
        "7.0    181799\n",
        "8.0    339903\n",
        "9.0    346955\n",
        "Name: count, dtype: int64\n",
        "\n",
        "üîß Processing target: 'legs1_arrivalAt_day'\n",
        "‚úÖ train: Imputed 4387201 missing values in 'legs1_arrivalAt_day'\n",
        "‚úÖ test: Imputed 1115840 missing values in 'legs1_arrivalAt_day'\n",
        "\n",
        "üìä train ‚Äî 'legs1_arrivalAt_day':\n",
        "  Total rows: 18145372\n",
        "  Missing: 0 (0.00%)\n",
        "  Top 10 value counts (including imputations):\n",
        "legs1_arrivalAt_day\n",
        "1.0     552349\n",
        "2.0     522264\n",
        "3.0     502369\n",
        "4.0     609874\n",
        "5.0     805291\n",
        "6.0     606334\n",
        "7.0     496193\n",
        "8.0     512826\n",
        "9.0     575112\n",
        "10.0    517415\n",
        "Name: count, dtype: int64\n",
        "\n",
        "üìä test ‚Äî 'legs1_arrivalAt_day':\n",
        "  Total rows: 6897776\n",
        "  Missing: 0 (0.00%)\n",
        "  Top 10 value counts (including imputations):\n",
        "legs1_arrivalAt_day\n",
        "1.0     122863\n",
        "2.0      72214\n",
        "3.0      84069\n",
        "4.0     143204\n",
        "5.0     186988\n",
        "6.0     452903\n",
        "7.0     223914\n",
        "8.0     231200\n",
        "9.0     118884\n",
        "10.0    110787\n",
        "Name: count, dtype: int64\n",
        "\n",
        "üîß Processing target: 'legs1_arrivalAt_year'\n",
        "‚úÖ train: Imputed 4387201 missing values in 'legs1_arrivalAt_year'\n",
        "‚úÖ test: Imputed 1115840 missing values in 'legs1_arrivalAt_year'\n",
        "\n",
        "üìä train ‚Äî 'legs1_arrivalAt_year':\n",
        "  Total rows: 18145372\n",
        "  Missing: 0 (0.00%)\n",
        "  Top 10 value counts (including imputations):\n",
        "legs1_arrivalAt_year\n",
        "2024.0    18083978\n",
        "2025.0       61394\n",
        "Name: count, dtype: int64\n",
        "\n",
        "üìä test ‚Äî 'legs1_arrivalAt_year':\n",
        "  Total rows: 6897776\n",
        "  Missing: 0 (0.00%)\n",
        "  Top 10 value counts (including imputations):\n",
        "legs1_arrivalAt_year\n",
        "2024.0    6057960\n",
        "2025.0     839816\n",
        "Name: count, dtype: int64\n",
        "\n",
        "‚è±Ô∏è Total duration: 19245.6 seconds"
      ],
      "metadata": {
        "id": "Xab-FmkgdjBx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile impute_multiple_targets.py\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from xgboost import XGBRegressor\n",
        "import time\n",
        "\n",
        "# === Timer ===\n",
        "start = time.time()\n",
        "\n",
        "# === Load files ===\n",
        "train = pd.read_csv(\"train.csv\", low_memory=False)\n",
        "test = pd.read_csv(\"test.csv\", low_memory=False)\n",
        "\n",
        "# === Relevant columns for prediction ===\n",
        "features = [\n",
        "    'totalPrice',\n",
        "    'companyID',\n",
        "    'legs0_segments0_cabinClass',\n",
        "    'isAccess3D',\n",
        "    'isVip',\n",
        "    'legs0_segments0_seatsAvailable',\n",
        "    'legs0_segments0_flightNumber',\n",
        "    'taxes',\n",
        "    'legs0_segments0_baggageAllowance_quantity',\n",
        "    'legs0_segments0_baggageAllowance_weightMeasurementType',\n",
        "    'pricingInfo_isAccessTP',\n",
        "    'miniRules0_monetaryAmount',\n",
        "    'miniRules1_monetaryAmount',\n",
        "    'miniRules0_statusInfos',\n",
        "    'miniRules1_statusInfos'\n",
        "]\n",
        "\n",
        "# === Target columns to impute ===\n",
        "target_columns = [\n",
        "    'legs1_departureAt_minute',\n",
        "    'legs1_departureAt_month',\n",
        "    'legs1_arrivalAt_minute',\n",
        "    'legs1_arrivalAt_month'\n",
        "]\n",
        "\n",
        "# === Training and imputation function for a target column ===\n",
        "def impute_column(target):\n",
        "    print(f\"\\nüîß Processing target: '{target}'\")\n",
        "\n",
        "    train_valid = train.dropna(subset=features + [target])\n",
        "    if train_valid.empty:\n",
        "        print(f\"‚ùå Skipped '{target}': No complete training data.\")\n",
        "        return\n",
        "\n",
        "    X_train = train_valid[features]\n",
        "    y_train = train_valid[target].astype(float)\n",
        "\n",
        "    # Model\n",
        "    model = XGBRegressor(\n",
        "        n_estimators=500,\n",
        "        max_depth=12,\n",
        "        learning_rate=0.1,\n",
        "        tree_method='hist',\n",
        "        n_jobs=24,\n",
        "        random_state=42,\n",
        "        eval_metric='rmse'\n",
        "    )\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Impute train & test\n",
        "    for df, name in [(train, \"train\"), (test, \"test\")]:\n",
        "        missing_mask = df[target].isna()\n",
        "        if missing_mask.sum() == 0:\n",
        "            print(f\"‚úÖ {name}: No missing values in '{target}'\")\n",
        "            continue\n",
        "\n",
        "        imputable = df.loc[missing_mask, features].dropna()\n",
        "        imputable_indices = imputable.index\n",
        "\n",
        "        if len(imputable_indices) == 0:\n",
        "            print(f\"‚ö†Ô∏è {name}: No imputable rows with all required features for '{target}'.\")\n",
        "            continue\n",
        "\n",
        "        preds = model.predict(imputable)\n",
        "\n",
        "        # Round and clip to valid ranges\n",
        "        if 'minute' in target:\n",
        "            preds_rounded = np.clip(np.round(preds), 0.0, 59.0)\n",
        "        elif 'month' in target:\n",
        "            preds_rounded = np.clip(np.round(preds), 1.0, 12.0)\n",
        "        else:\n",
        "            preds_rounded = np.round(preds)\n",
        "\n",
        "        # Assign as float\n",
        "        df.loc[imputable_indices, target] = preds_rounded\n",
        "        print(f\"‚úÖ {name}: Imputed {len(imputable_indices)} missing values in '{target}'\")\n",
        "\n",
        "    # Report\n",
        "    for df, name in [(train, \"train\"), (test, \"test\")]:\n",
        "        total = len(df)\n",
        "        missing = df[target].isna().sum()\n",
        "        value_counts = df[target].value_counts(dropna=False).sort_index()\n",
        "        print(f\"\\nüìä {name} ‚Äî '{target}':\")\n",
        "        print(f\"  Total rows: {total}\")\n",
        "        print(f\"  Missing: {missing} ({100 * missing / total:.2f}%)\")\n",
        "        print(\"  Top 10 value counts (including imputations):\")\n",
        "        print(value_counts.head(10))\n",
        "\n",
        "# === Run for each target column ===\n",
        "for target in target_columns:\n",
        "    impute_column(target)\n",
        "\n",
        "# === Save final files ===\n",
        "train.to_csv(\"train.csv\", index=False)\n",
        "test.to_csv(\"test.csv\", index=False)\n",
        "\n",
        "# === Done ===\n",
        "print(f\"\\n‚è±Ô∏è Total duration: {round(time.time() - start, 2)} seconds\")\n"
      ],
      "metadata": {
        "id": "uOal65aRdw6r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "üîß Processing target: 'legs1_departureAt_minute'\n",
        "‚úÖ train: Imputed 4387201 missing values in 'legs1_departureAt_minute'\n",
        "‚úÖ test: Imputed 1115840 missing values in 'legs1_departureAt_minute'\n",
        "\n",
        "üìä train ‚Äî 'legs1_departureAt_minute':\n",
        "  Total rows: 18145372\n",
        "  Missing: 0 (0.00%)\n",
        "  Top 10 value counts (including imputations):\n",
        "legs1_departureAt_minute\n",
        "0.0    2858573\n",
        "1.0        900\n",
        "2.0       1381\n",
        "3.0       1482\n",
        "4.0       3034\n",
        "5.0     670899\n",
        "6.0       4307\n",
        "7.0       6378\n",
        "8.0       8066\n",
        "9.0      10667\n",
        "Name: count, dtype: int64\n",
        "\n",
        "üìä test ‚Äî 'legs1_departureAt_minute':\n",
        "  Total rows: 6897776\n",
        "  Missing: 0 (0.00%)\n",
        "  Top 10 value counts (including imputations):\n",
        "legs1_departureAt_minute\n",
        "0.0    1903999\n",
        "1.0        461\n",
        "2.0        295\n",
        "3.0        532\n",
        "4.0        708\n",
        "5.0     239564\n",
        "6.0       1379\n",
        "7.0       3264\n",
        "8.0       2601\n",
        "9.0       3696\n",
        "Name: count, dtype: int64\n",
        "\n",
        "üîß Processing target: 'legs1_departureAt_month'\n",
        "‚úÖ train: Imputed 4387201 missing values in 'legs1_departureAt_month'\n",
        "‚úÖ test: Imputed 1115840 missing values in 'legs1_departureAt_month'\n",
        "\n",
        "üìä train ‚Äî 'legs1_departureAt_month':\n",
        "  Total rows: 18145372\n",
        "  Missing: 0 (0.00%)\n",
        "  Top 10 value counts (including imputations):\n",
        "legs1_departureAt_month\n",
        "1.0       56630\n",
        "2.0        2155\n",
        "3.0         881\n",
        "4.0        1770\n",
        "5.0      197529\n",
        "6.0     1150305\n",
        "7.0     2119744\n",
        "8.0     3810257\n",
        "9.0     5018265\n",
        "10.0    4268105\n",
        "Name: count, dtype: int64\n",
        "\n",
        "üìä test ‚Äî 'legs1_departureAt_month':\n",
        "  Total rows: 6897776\n",
        "  Missing: 0 (0.00%)\n",
        "  Top 10 value counts (including imputations):\n",
        "legs1_departureAt_month\n",
        "1.0     516885\n",
        "2.0     281334\n",
        "3.0      26488\n",
        "4.0       9676\n",
        "5.0       4808\n",
        "6.0       8236\n",
        "7.0      53889\n",
        "8.0     242772\n",
        "9.0     464477\n",
        "10.0    301265\n",
        "Name: count, dtype: int64\n",
        "\n",
        "üîß Processing target: 'legs1_arrivalAt_minute'\n",
        "‚úÖ train: Imputed 4387201 missing values in 'legs1_arrivalAt_minute'\n",
        "‚úÖ test: Imputed 1115840 missing values in 'legs1_arrivalAt_minute'\n",
        "\n",
        "üìä train ‚Äî 'legs1_arrivalAt_minute':\n",
        "  Total rows: 18145372\n",
        "  Missing: 0 (0.00%)\n",
        "  Top 10 value counts (including imputations):\n",
        "legs1_arrivalAt_minute\n",
        "0.0    1935102\n",
        "1.0       1456\n",
        "2.0        983\n",
        "3.0       1482\n",
        "4.0       2212\n",
        "5.0    1025889\n",
        "6.0       4425\n",
        "7.0       5654\n",
        "8.0       8146\n",
        "9.0      10985\n",
        "Name: count, dtype: int64\n",
        "\n",
        "üìä test ‚Äî 'legs1_arrivalAt_minute':\n",
        "  Total rows: 6897776\n",
        "  Missing: 0 (0.00%)\n",
        "  Top 10 value counts (including imputations):\n",
        "legs1_arrivalAt_minute\n",
        "0.0    381944\n",
        "1.0       132\n",
        "2.0       208\n",
        "3.0       317\n",
        "4.0       392\n",
        "5.0    530740\n",
        "6.0       955\n",
        "7.0      1225\n",
        "8.0      1760\n",
        "9.0      2303\n",
        "Name: count, dtype: int64\n",
        "\n",
        "üîß Processing target: 'legs1_arrivalAt_month'\n",
        "‚úÖ train: Imputed 4387201 missing values in 'legs1_arrivalAt_month'\n",
        "‚úÖ test: Imputed 1115840 missing values in 'legs1_arrivalAt_month'\n",
        "\n",
        "üìä train ‚Äî 'legs1_arrivalAt_month':\n",
        "  Total rows: 18145372\n",
        "  Missing: 0 (0.00%)\n",
        "  Top 10 value counts (including imputations):\n",
        "legs1_arrivalAt_month\n",
        "1.0       56672\n",
        "2.0        2188\n",
        "3.0         901\n",
        "4.0        1974\n",
        "5.0      188626\n",
        "6.0     1147816\n",
        "7.0     2096783\n",
        "8.0     3889195\n",
        "9.0     5038136\n",
        "10.0    4162021\n",
        "Name: count, dtype: int64\n",
        "\n",
        "üìä test ‚Äî 'legs1_arrivalAt_month':\n",
        "  Total rows: 6897776\n",
        "  Missing: 0 (0.00%)\n",
        "  Top 10 value counts (including imputations):\n",
        "legs1_arrivalAt_month\n",
        "1.0     499721\n",
        "2.0     296704\n",
        "3.0      28547\n",
        "4.0       9830\n",
        "5.0       5620\n",
        "6.0      12366\n",
        "7.0      60138\n",
        "8.0     254093\n",
        "9.0     454942\n",
        "10.0    287553\n",
        "Name: count, dtype: int64\n",
        "\n",
        "‚è±Ô∏è Total duration: 1180.55 seconds"
      ],
      "metadata": {
        "id": "jPHAUlcYdx2x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile check_unique_values.py\n",
        "import pandas as pd\n",
        "\n",
        "# Load CSV files\n",
        "train = pd.read_csv(\"train.csv\", low_memory=False)\n",
        "test = pd.read_csv(\"test.csv\", low_memory=False)\n",
        "\n",
        "# Columns of interest\n",
        "columns = [\n",
        "    'legs1_departureAt_minute',\n",
        "    'legs1_departureAt_month',\n",
        "    'legs1_arrivalAt_minute',\n",
        "    'legs1_arrivalAt_month'\n",
        "]\n",
        "\n",
        "# Display unique values for each column in train and test\n",
        "for col in columns:\n",
        "    print(f\"\\nüîç {col} ‚Äî train.csv:\")\n",
        "    print(sorted(train[col].dropna().unique()))\n",
        "\n",
        "    print(f\"üîç {col} ‚Äî test.csv:\")\n",
        "    print(sorted(test[col].dropna().unique()))\n"
      ],
      "metadata": {
        "id": "ai_CxqJnd4WZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "üîç legs1_departureAt_minute ‚Äî train.csv:\n",
        "[np.float64(0.0), np.float64(1.0), np.float64(2.0), np.float64(3.0), np.float64(4.0), np.float64(5.0), np.float64(6.0), np.float64(7.0), np.float64(8.0), np.float64(9.0), np.float64(10.0), np.float64(11.0), np.float64(12.0), np.float64(13.0), np.float64(14.0), np.float64(15.0), np.float64(16.0), np.float64(17.0), np.float64(18.0), np.float64(19.0), np.float64(20.0), np.float64(21.0), np.float64(22.0), np.float64(23.0), np.float64(24.0), np.float64(25.0), np.float64(26.0), np.float64(27.0), np.float64(28.0), np.float64(29.0), np.float64(30.0), np.float64(31.0), np.float64(32.0), np.float64(33.0), np.float64(34.0), np.float64(35.0), np.float64(36.0), np.float64(37.0), np.float64(38.0), np.float64(39.0), np.float64(40.0), np.float64(41.0), np.float64(42.0), np.float64(43.0), np.float64(44.0), np.float64(45.0), np.float64(46.0), np.float64(47.0), np.float64(48.0), np.float64(49.0), np.float64(50.0), np.float64(51.0), np.float64(52.0), np.float64(53.0), np.float64(54.0), np.float64(55.0), np.float64(56.0), np.float64(57.0), np.float64(58.0), np.float64(59.0)]\n",
        "üîç legs1_departureAt_minute ‚Äî test.csv:\n",
        "[np.float64(0.0), np.float64(1.0), np.float64(2.0), np.float64(3.0), np.float64(4.0), np.float64(5.0), np.float64(6.0), np.float64(7.0), np.float64(8.0), np.float64(9.0), np.float64(10.0), np.float64(11.0), np.float64(12.0), np.float64(13.0), np.float64(14.0), np.float64(15.0), np.float64(16.0), np.float64(17.0), np.float64(18.0), np.float64(19.0), np.float64(20.0), np.float64(21.0), np.float64(22.0), np.float64(23.0), np.float64(24.0), np.float64(25.0), np.float64(26.0), np.float64(27.0), np.float64(28.0), np.float64(29.0), np.float64(30.0), np.float64(31.0), np.float64(32.0), np.float64(33.0), np.float64(34.0), np.float64(35.0), np.float64(36.0), np.float64(37.0), np.float64(38.0), np.float64(39.0), np.float64(40.0), np.float64(41.0), np.float64(42.0), np.float64(43.0), np.float64(44.0), np.float64(45.0), np.float64(46.0), np.float64(47.0), np.float64(48.0), np.float64(49.0), np.float64(50.0), np.float64(51.0), np.float64(52.0), np.float64(53.0), np.float64(54.0), np.float64(55.0), np.float64(56.0), np.float64(57.0), np.float64(58.0), np.float64(59.0)]\n",
        "\n",
        "üîç legs1_departureAt_month ‚Äî train.csv:\n",
        "[np.float64(1.0), np.float64(2.0), np.float64(3.0), np.float64(4.0), np.float64(5.0), np.float64(6.0), np.float64(7.0), np.float64(8.0), np.float64(9.0), np.float64(10.0), np.float64(11.0), np.float64(12.0)]\n",
        "üîç legs1_departureAt_month ‚Äî test.csv:\n",
        "[np.float64(1.0), np.float64(2.0), np.float64(3.0), np.float64(4.0), np.float64(5.0), np.float64(6.0), np.float64(7.0), np.float64(8.0), np.float64(9.0), np.float64(10.0), np.float64(11.0), np.float64(12.0)]\n",
        "\n",
        "üîç legs1_arrivalAt_minute ‚Äî train.csv:\n",
        "[np.float64(0.0), np.float64(1.0), np.float64(2.0), np.float64(3.0), np.float64(4.0), np.float64(5.0), np.float64(6.0), np.float64(7.0), np.float64(8.0), np.float64(9.0), np.float64(10.0), np.float64(11.0), np.float64(12.0), np.float64(13.0), np.float64(14.0), np.float64(15.0), np.float64(16.0), np.float64(17.0), np.float64(18.0), np.float64(19.0), np.float64(20.0), np.float64(21.0), np.float64(22.0), np.float64(23.0), np.float64(24.0), np.float64(25.0), np.float64(26.0), np.float64(27.0), np.float64(28.0), np.float64(29.0), np.float64(30.0), np.float64(31.0), np.float64(32.0), np.float64(33.0), np.float64(34.0), np.float64(35.0), np.float64(36.0), np.float64(37.0), np.float64(38.0), np.float64(39.0), np.float64(40.0), np.float64(41.0), np.float64(42.0), np.float64(43.0), np.float64(44.0), np.float64(45.0), np.float64(46.0), np.float64(47.0), np.float64(48.0), np.float64(49.0), np.float64(50.0), np.float64(51.0), np.float64(52.0), np.float64(53.0), np.float64(54.0), np.float64(55.0), np.float64(56.0), np.float64(57.0), np.float64(58.0), np.float64(59.0)]\n",
        "üîç legs1_arrivalAt_minute ‚Äî test.csv:\n",
        "[np.float64(0.0), np.float64(1.0), np.float64(2.0), np.float64(3.0), np.float64(4.0), np.float64(5.0), np.float64(6.0), np.float64(7.0), np.float64(8.0), np.float64(9.0), np.float64(10.0), np.float64(11.0), np.float64(12.0), np.float64(13.0), np.float64(14.0), np.float64(15.0), np.float64(16.0), np.float64(17.0), np.float64(18.0), np.float64(19.0), np.float64(20.0), np.float64(21.0), np.float64(22.0), np.float64(23.0), np.float64(24.0), np.float64(25.0), np.float64(26.0), np.float64(27.0), np.float64(28.0), np.float64(29.0), np.float64(30.0), np.float64(31.0), np.float64(32.0), np.float64(33.0), np.float64(34.0), np.float64(35.0), np.float64(36.0), np.float64(37.0), np.float64(38.0), np.float64(39.0), np.float64(40.0), np.float64(41.0), np.float64(42.0), np.float64(43.0), np.float64(44.0), np.float64(45.0), np.float64(46.0), np.float64(47.0), np.float64(48.0), np.float64(49.0), np.float64(50.0), np.float64(51.0), np.float64(52.0), np.float64(53.0), np.float64(54.0), np.float64(55.0), np.float64(56.0), np.float64(57.0), np.float64(58.0), np.float64(59.0)]\n",
        "\n",
        "üîç legs1_arrivalAt_month ‚Äî train.csv:\n",
        "[np.float64(1.0), np.float64(2.0), np.float64(3.0), np.float64(4.0), np.float64(5.0), np.float64(6.0), np.float64(7.0), np.float64(8.0), np.float64(9.0), np.float64(10.0), np.float64(11.0), np.float64(12.0)]\n",
        "üîç legs1_arrivalAt_month ‚Äî test.csv:\n",
        "[np.float64(1.0), np.float64(2.0), np.float64(3.0), np.float64(4.0), np.float64(5.0), np.float64(6.0), np.float64(7.0), np.float64(8.0), np.float64(9.0), np.float64(10.0), np.float64(11.0), np.float64(12.0)]"
      ],
      "metadata": {
        "id": "P_-8Zo6Gd_KJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile complete_columns.py\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Load files\n",
        "train = pd.read_csv(\"train.csv\", low_memory=False)\n",
        "test = pd.read_csv(\"test.csv\", low_memory=False)\n",
        "\n",
        "def fill_missing_time_features(df, prefix):\n",
        "    # 1. Create mask for missing values\n",
        "    missing_mask = df[f\"{prefix}_dayofweek\"].isna() | df[f\"{prefix}_weekofyear\"].isna() | \\\n",
        "                   df[f\"{prefix}_is_weekend\"].isna() | df[f\"{prefix}_part_of_day\"].isna() | \\\n",
        "                   df[f\"{prefix}_hour_sin\"].isna() | df[f\"{prefix}_hour_cos\"].isna()\n",
        "\n",
        "    # 2. Ensure all required components are available\n",
        "    required_cols = [f\"{prefix}_{comp}\" for comp in [\"year\", \"month\", \"day\", \"hour\", \"minute\"]]\n",
        "    if not all(col in df.columns for col in required_cols):\n",
        "        print(f\"‚ö†Ô∏è Missing components for {prefix}, skipping.\")\n",
        "        return df\n",
        "\n",
        "    complete_mask = df[required_cols].notnull().all(axis=1)\n",
        "    final_mask = missing_mask & complete_mask\n",
        "\n",
        "    if final_mask.sum() == 0:\n",
        "        print(f\"‚úÖ {prefix}: nothing to complete.\")\n",
        "        return df\n",
        "\n",
        "    print(f\"üîß Filling {final_mask.sum()} rows for {prefix}\")\n",
        "\n",
        "    # 3. Create datetime only for missing rows\n",
        "    temp_dt = pd.to_datetime(dict(\n",
        "        year=df.loc[final_mask, f\"{prefix}_year\"].astype(int),\n",
        "        month=df.loc[final_mask, f\"{prefix}_month\"].astype(int),\n",
        "        day=df.loc[final_mask, f\"{prefix}_day\"].astype(int),\n",
        "        hour=df.loc[final_mask, f\"{prefix}_hour\"].astype(int),\n",
        "        minute=df.loc[final_mask, f\"{prefix}_minute\"].astype(int)\n",
        "    ), errors='coerce')\n",
        "\n",
        "    # 4. Fill in missing values\n",
        "    df.loc[final_mask, f\"{prefix}_dayofweek\"] = temp_dt.dt.dayofweek\n",
        "    df.loc[final_mask, f\"{prefix}_weekofyear\"] = temp_dt.dt.isocalendar().week\n",
        "    df.loc[final_mask, f\"{prefix}_is_weekend\"] = temp_dt.dt.dayofweek.isin([5, 6]).astype(int)\n",
        "\n",
        "    def get_part_of_day(hour):\n",
        "        if pd.isna(hour): return np.nan\n",
        "        if hour < 6: return \"night\"\n",
        "        elif hour < 12: return \"morning\"\n",
        "        elif hour < 18: return \"afternoon\"\n",
        "        else: return \"evening\"\n",
        "\n",
        "    df.loc[final_mask, f\"{prefix}_part_of_day\"] = df.loc[final_mask, f\"{prefix}_hour\"].apply(get_part_of_day)\n",
        "\n",
        "    hour = df.loc[final_mask, f\"{prefix}_hour\"]\n",
        "    df.loc[final_mask, f\"{prefix}_hour_sin\"] = np.sin(2 * np.pi * hour / 24)\n",
        "    df.loc[final_mask, f\"{prefix}_hour_cos\"] = np.cos(2 * np.pi * hour / 24)\n",
        "\n",
        "    return df\n",
        "\n",
        "# Apply for both train and test, for departure and arrival\n",
        "for df in [train, test]:\n",
        "    df = fill_missing_time_features(df, \"legs1_departureAt\")\n",
        "    df = fill_missing_time_features(df, \"legs1_arrivalAt\")\n",
        "\n",
        "# Save the files\n",
        "train.to_csv(\"train.csv\", index=False)\n",
        "test.to_csv(\"test.csv\", index=False)\n"
      ],
      "metadata": {
        "id": "UW9GF9cDeJ2J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile check_columns.py\n",
        "import pandas as pd\n",
        "\n",
        "# Load the files\n",
        "train = pd.read_csv(\"train.csv\", low_memory=False)\n",
        "test = pd.read_csv(\"test.csv\", low_memory=False)\n",
        "\n",
        "def check_leg_columns(df, name):\n",
        "    print(f\"\\nüîç Checks for: {name}\")\n",
        "    # Select only relevant columns\n",
        "    relevant_cols = [col for col in df.columns if \"departureAt\" in col or \"arrivalAt\" in col]\n",
        "\n",
        "    for col in sorted(relevant_cols):\n",
        "        nan_count = df[col].isna().sum()\n",
        "        unique_vals = df[col].dropna().unique()\n",
        "        sample_vals = sorted(unique_vals[:20])\n",
        "        total_unique = len(unique_vals)\n",
        "\n",
        "        print(f\"\\nüìå Column: {col}\")\n",
        "        print(f\"   - Missing values: {nan_count}\")\n",
        "        print(f\"   - Number of unique values: {total_unique}\")\n",
        "        print(f\"   - Sample unique values: {sample_vals}\")\n",
        "\n",
        "# Apply to both DataFrames\n",
        "check_leg_columns(train, \"train.csv\")\n",
        "check_leg_columns(test, \"test.csv\")\n"
      ],
      "metadata": {
        "id": "EXK5O4BzeR6Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "üîç VerificƒÉri pentru: train.csv\n",
        "\n",
        "üìå Coloana: legs0_arrivalAt\n",
        "   - Valori lipsƒÉ: 0\n",
        "   - Nr. valori unice: 60143\n",
        "   - Valori unice (e»ôantion): ['2024-05-20T10:30:00', '2024-05-20T12:30:00', '2024-05-20T15:40:00', '2024-05-20T22:15:00', '2024-05-21T08:35:00', '2024-05-29T11:10:00', '2024-05-30T07:35:00', '2024-05-30T12:55:00', '2024-05-30T18:30:00', '2024-06-04T10:55:00', '2024-06-04T11:30:00', '2024-06-04T12:25:00', '2024-06-04T15:50:00', '2024-06-04T17:15:00', '2024-06-15T09:15:00', '2024-06-15T14:50:00', '2024-06-15T16:20:00', '2024-06-15T17:20:00', '2024-06-15T21:35:00', '2024-06-16T06:50:00']\n",
        "\n",
        "üìå Coloana: legs0_departureAt\n",
        "   - Valori lipsƒÉ: 0\n",
        "   - Nr. valori unice: 56619\n",
        "   - Valori unice (e»ôantion): ['2024-05-20T08:05:00', '2024-05-20T08:10:00', '2024-05-20T10:10:00', '2024-05-20T13:20:00', '2024-05-20T19:40:00', '2024-05-29T08:05:00', '2024-05-29T10:50:00', '2024-05-30T10:40:00', '2024-05-30T16:00:00', '2024-06-04T06:50:00', '2024-06-04T09:20:00', '2024-06-04T09:35:00', '2024-06-04T11:05:00', '2024-06-04T11:25:00', '2024-06-15T09:25:00', '2024-06-15T09:50:00', '2024-06-15T11:25:00', '2024-06-15T15:40:00', '2024-06-28T10:10:00', '2024-06-28T16:20:00']\n",
        "\n",
        "üìå Coloana: legs1_arrivalAt\n",
        "   - Valori lipsƒÉ: 4387201\n",
        "   - Nr. valori unice: 50352\n",
        "   - Valori unice (e»ôantion): ['2024-05-22 05:55:00', '2024-05-22 08:25:00', '2024-05-22 08:55:00', '2024-05-22 12:55:00', '2024-05-22 19:35:00', '2024-05-22 20:20:00', '2024-05-22 20:55:00', '2024-05-23 00:50:00', '2024-05-23 05:20:00', '2024-05-23 05:35:00', '2024-05-25 11:05:00', '2024-05-25 12:55:00', '2024-05-25 14:35:00', '2024-05-25 16:35:00', '2024-05-25 18:15:00', '2024-05-25 22:00:00', '2024-05-25 22:40:00', '2024-05-29 03:05:00', '2024-07-09 14:20:00', '2024-07-10 08:30:00']\n",
        "\n",
        "üìå Coloana: legs1_arrivalAt_day\n",
        "   - Valori lipsƒÉ: 0\n",
        "   - Nr. valori unice: 31\n",
        "   - Valori unice (e»ôantion): [np.float64(4.0), np.float64(5.0), np.float64(6.0), np.float64(9.0), np.float64(10.0), np.float64(11.0), np.float64(13.0), np.float64(16.0), np.float64(17.0), np.float64(18.0), np.float64(19.0), np.float64(21.0), np.float64(22.0), np.float64(23.0), np.float64(24.0), np.float64(26.0), np.float64(27.0), np.float64(28.0), np.float64(29.0), np.float64(30.0)]\n",
        "\n",
        "üìå Coloana: legs1_arrivalAt_dayofweek\n",
        "   - Valori lipsƒÉ: 23376\n",
        "   - Nr. valori unice: 7\n",
        "   - Valori unice (e»ôantion): [np.float64(0.0), np.float64(1.0), np.float64(2.0), np.float64(3.0), np.float64(4.0), np.float64(5.0), np.float64(6.0)]\n",
        "\n",
        "üìå Coloana: legs1_arrivalAt_hour\n",
        "   - Valori lipsƒÉ: 0\n",
        "   - Nr. valori unice: 24\n",
        "   - Valori unice (e»ôantion): [np.float64(2.0), np.float64(3.0), np.float64(5.0), np.float64(6.0), np.float64(7.0), np.float64(8.0), np.float64(9.0), np.float64(10.0), np.float64(11.0), np.float64(12.0), np.float64(13.0), np.float64(14.0), np.float64(15.0), np.float64(16.0), np.float64(17.0), np.float64(18.0), np.float64(19.0), np.float64(20.0), np.float64(21.0), np.float64(23.0)]\n",
        "\n",
        "üìå Coloana: legs1_arrivalAt_hour_cos\n",
        "   - Valori lipsƒÉ: 0\n",
        "   - Nr. valori unice: 23\n",
        "   - Valori unice (e»ôantion): [np.float64(-1.0), np.float64(-0.9659258262890684), np.float64(-0.9659258262890682), np.float64(-0.8660254037844388), np.float64(-0.8660254037844387), np.float64(-0.7071067811865479), np.float64(-0.7071067811865475), np.float64(-0.5000000000000004), np.float64(-0.4999999999999998), np.float64(-0.2588190451025206), np.float64(-1.8369701987210294e-16), np.float64(6.123233995736766e-17), np.float64(0.2588190451025203), np.float64(0.2588190451025207), np.float64(0.5000000000000001), np.float64(0.7071067811865474), np.float64(0.7071067811865476), np.float64(0.8660254037844384), np.float64(0.8660254037844387), np.float64(0.965925826289068)]\n",
        "\n",
        "üìå Coloana: legs1_arrivalAt_hour_sin\n",
        "   - Valori lipsƒÉ: 0\n",
        "   - Nr. valori unice: 21\n",
        "   - Valori unice (e»ôantion): [np.float64(-1.0), np.float64(-0.9659258262890684), np.float64(-0.8660254037844386), np.float64(-0.8660254037844384), np.float64(-0.7071067811865477), np.float64(-0.7071067811865471), np.float64(-0.5000000000000004), np.float64(-0.4999999999999997), np.float64(-0.2588190451025215), np.float64(-0.2588190451025208), np.float64(1.2246467991473532e-16), np.float64(0.2588190451025207), np.float64(0.258819045102521), np.float64(0.4999999999999999), np.float64(0.7071067811865475), np.float64(0.7071067811865476), np.float64(0.8660254037844386), np.float64(0.8660254037844387), np.float64(0.9659258262890684), np.float64(1.0)]\n",
        "\n",
        "üìå Coloana: legs1_arrivalAt_is_weekend\n",
        "   - Valori lipsƒÉ: 0\n",
        "   - Nr. valori unice: 2\n",
        "   - Valori unice (e»ôantion): [np.int64(0), np.int64(1)]\n",
        "\n",
        "üìå Coloana: legs1_arrivalAt_minute\n",
        "   - Valori lipsƒÉ: 0\n",
        "   - Nr. valori unice: 60\n",
        "   - Valori unice (e»ôantion): [np.float64(18.0), np.float64(20.0), np.float64(21.0), np.float64(22.0), np.float64(24.0), np.float64(25.0), np.float64(26.0), np.float64(27.0), np.float64(28.0), np.float64(29.0), np.float64(30.0), np.float64(31.0), np.float64(32.0), np.float64(33.0), np.float64(34.0), np.float64(35.0), np.float64(37.0), np.float64(38.0), np.float64(39.0), np.float64(41.0)]\n",
        "\n",
        "üìå Coloana: legs1_arrivalAt_month\n",
        "   - Valori lipsƒÉ: 0\n",
        "   - Nr. valori unice: 12\n",
        "   - Valori unice (e»ôantion): [np.float64(1.0), np.float64(2.0), np.float64(3.0), np.float64(4.0), np.float64(5.0), np.float64(6.0), np.float64(7.0), np.float64(8.0), np.float64(9.0), np.float64(10.0), np.float64(11.0), np.float64(12.0)]\n",
        "\n",
        "üìå Coloana: legs1_arrivalAt_part_of_day\n",
        "   - Valori lipsƒÉ: 0\n",
        "   - Nr. valori unice: 4\n",
        "   - Valori unice (e»ôantion): ['afternoon', 'evening', 'morning', 'night']\n",
        "\n",
        "üìå Coloana: legs1_arrivalAt_weekofyear\n",
        "   - Valori lipsƒÉ: 23376\n",
        "   - Nr. valori unice: 52\n",
        "   - Valori unice (e»ôantion): [np.float64(19.0), np.float64(20.0), np.float64(22.0), np.float64(23.0), np.float64(25.0), np.float64(26.0), np.float64(28.0), np.float64(29.0), np.float64(30.0), np.float64(31.0), np.float64(32.0), np.float64(33.0), np.float64(34.0), np.float64(35.0), np.float64(37.0), np.float64(38.0), np.float64(39.0), np.float64(40.0), np.float64(41.0), np.float64(42.0)]\n",
        "\n",
        "üìå Coloana: legs1_arrivalAt_year\n",
        "   - Valori lipsƒÉ: 0\n",
        "   - Nr. valori unice: 2\n",
        "   - Valori unice (e»ôantion): [np.float64(2024.0), np.float64(2025.0)]\n",
        "\n",
        "üìå Coloana: legs1_departureAt\n",
        "   - Valori lipsƒÉ: 4387201\n",
        "   - Nr. valori unice: 48606\n",
        "   - Valori unice (e»ôantion): ['2024-05-22 04:45:00', '2024-05-22 05:15:00', '2024-05-22 07:45:00', '2024-05-22 08:25:00', '2024-05-22 11:10:00', '2024-05-22 11:45:00', '2024-05-22 13:40:00', '2024-05-22 18:50:00', '2024-05-25 06:00:00', '2024-05-25 08:25:00', '2024-05-25 08:30:00', '2024-05-25 11:30:00', '2024-05-25 12:05:00', '2024-05-25 14:20:00', '2024-05-25 16:30:00', '2024-05-25 22:25:00', '2024-07-09 09:45:00', '2024-07-09 17:55:00', '2024-07-09 19:35:00', '2024-07-09 22:05:00']\n",
        "\n",
        "üìå Coloana: legs1_departureAt_day\n",
        "   - Valori lipsƒÉ: 0\n",
        "   - Nr. valori unice: 31\n",
        "   - Valori unice (e»ôantion): [np.float64(1.0), np.float64(3.0), np.float64(5.0), np.float64(6.0), np.float64(9.0), np.float64(11.0), np.float64(13.0), np.float64(16.0), np.float64(17.0), np.float64(18.0), np.float64(19.0), np.float64(20.0), np.float64(21.0), np.float64(22.0), np.float64(24.0), np.float64(25.0), np.float64(27.0), np.float64(28.0), np.float64(29.0), np.float64(30.0)]\n",
        "\n",
        "üìå Coloana: legs1_departureAt_dayofweek\n",
        "   - Valori lipsƒÉ: 33113\n",
        "   - Nr. valori unice: 7\n",
        "   - Valori unice (e»ôantion): [np.float64(0.0), np.float64(1.0), np.float64(2.0), np.float64(3.0), np.float64(4.0), np.float64(5.0), np.float64(6.0)]\n",
        "\n",
        "üìå Coloana: legs1_departureAt_hour\n",
        "   - Valori lipsƒÉ: 0\n",
        "   - Nr. valori unice: 24\n",
        "   - Valori unice (e»ôantion): [np.float64(2.0), np.float64(3.0), np.float64(4.0), np.float64(5.0), np.float64(6.0), np.float64(7.0), np.float64(8.0), np.float64(9.0), np.float64(10.0), np.float64(12.0), np.float64(13.0), np.float64(14.0), np.float64(15.0), np.float64(17.0), np.float64(18.0), np.float64(19.0), np.float64(20.0), np.float64(21.0), np.float64(22.0), np.float64(23.0)]\n",
        "\n",
        "üìå Coloana: legs1_departureAt_hour_cos\n",
        "   - Valori lipsƒÉ: 0\n",
        "   - Nr. valori unice: 23\n",
        "   - Valori unice (e»ôantion): [np.float64(-1.0), np.float64(-0.9659258262890684), np.float64(-0.9659258262890682), np.float64(-0.8660254037844388), np.float64(-0.8660254037844387), np.float64(-0.7071067811865479), np.float64(-0.7071067811865475), np.float64(-0.5000000000000004), np.float64(-0.4999999999999998), np.float64(-0.2588190451025206), np.float64(-1.8369701987210294e-16), np.float64(6.123233995736766e-17), np.float64(0.2588190451025203), np.float64(0.2588190451025207), np.float64(0.5000000000000001), np.float64(0.7071067811865474), np.float64(0.7071067811865476), np.float64(0.8660254037844384), np.float64(0.8660254037844387), np.float64(0.965925826289068)]\n",
        "\n",
        "üìå Coloana: legs1_departureAt_hour_sin\n",
        "   - Valori lipsƒÉ: 0\n",
        "   - Nr. valori unice: 21\n",
        "   - Valori unice (e»ôantion): [np.float64(-1.0), np.float64(-0.9659258262890684), np.float64(-0.8660254037844386), np.float64(-0.8660254037844384), np.float64(-0.7071067811865477), np.float64(-0.7071067811865471), np.float64(-0.5000000000000004), np.float64(-0.4999999999999997), np.float64(-0.2588190451025215), np.float64(-0.2588190451025208), np.float64(1.2246467991473532e-16), np.float64(0.2588190451025207), np.float64(0.258819045102521), np.float64(0.4999999999999999), np.float64(0.7071067811865475), np.float64(0.7071067811865476), np.float64(0.8660254037844386), np.float64(0.8660254037844387), np.float64(0.9659258262890684), np.float64(1.0)]\n",
        "\n",
        "üìå Coloana: legs1_departureAt_is_weekend\n",
        "   - Valori lipsƒÉ: 0\n",
        "   - Nr. valori unice: 2\n",
        "   - Valori unice (e»ôantion): [np.int64(0), np.int64(1)]\n",
        "\n",
        "üìå Coloana: legs1_departureAt_minute\n",
        "   - Valori lipsƒÉ: 0\n",
        "   - Nr. valori unice: 60\n",
        "   - Valori unice (e»ôantion): [np.float64(5.0), np.float64(19.0), np.float64(20.0), np.float64(21.0), np.float64(22.0), np.float64(23.0), np.float64(24.0), np.float64(25.0), np.float64(27.0), np.float64(28.0), np.float64(29.0), np.float64(30.0), np.float64(31.0), np.float64(32.0), np.float64(33.0), np.float64(35.0), np.float64(38.0), np.float64(39.0), np.float64(45.0), np.float64(55.0)]\n",
        "\n",
        "üìå Coloana: legs1_departureAt_month\n",
        "   - Valori lipsƒÉ: 0\n",
        "   - Nr. valori unice: 12\n",
        "   - Valori unice (e»ôantion): [np.float64(1.0), np.float64(2.0), np.float64(3.0), np.float64(4.0), np.float64(5.0), np.float64(6.0), np.float64(7.0), np.float64(8.0), np.float64(9.0), np.float64(10.0), np.float64(11.0), np.float64(12.0)]\n",
        "\n",
        "üìå Coloana: legs1_departureAt_part_of_day\n",
        "   - Valori lipsƒÉ: 0\n",
        "   - Nr. valori unice: 4\n",
        "   - Valori unice (e»ôantion): ['afternoon', 'evening', 'morning', 'night']\n",
        "\n",
        "üìå Coloana: legs1_departureAt_weekofyear\n",
        "   - Valori lipsƒÉ: 33113\n",
        "   - Nr. valori unice: 52\n",
        "   - Valori unice (e»ôantion): [np.float64(21.0), np.float64(22.0), np.float64(23.0), np.float64(24.0), np.float64(25.0), np.float64(26.0), np.float64(27.0), np.float64(28.0), np.float64(29.0), np.float64(30.0), np.float64(31.0), np.float64(32.0), np.float64(33.0), np.float64(34.0), np.float64(35.0), np.float64(36.0), np.float64(37.0), np.float64(38.0), np.float64(39.0), np.float64(42.0)]\n",
        "\n",
        "üìå Coloana: legs1_departureAt_year\n",
        "   - Valori lipsƒÉ: 0\n",
        "   - Nr. valori unice: 2\n",
        "   - Valori unice (e»ôantion): [np.float64(2024.0), np.float64(2025.0)]\n",
        "\n",
        "üîç VerificƒÉri pentru: test.csv\n",
        "\n",
        "üìå Coloana: legs0_arrivalAt\n",
        "   - Valori lipsƒÉ: 0\n",
        "   - Nr. valori unice: 29117\n",
        "   - Valori unice (e»ôantion): ['2024-11-13T07:45:00', '2024-11-13T21:00:00', '2024-11-14T04:30:00', '2024-12-19T11:20:00', '2024-12-19T12:30:00', '2024-12-19T12:45:00', '2024-12-19T14:20:00', '2024-12-19T17:25:00', '2024-12-19T18:00:00', '2024-12-19T20:10:00', '2024-12-19T22:05:00', '2024-12-19T22:10:00', '2024-12-20T00:55:00', '2024-12-20T02:00:00', '2024-12-20T02:20:00', '2024-12-20T03:45:00', '2024-12-20T03:50:00', '2024-12-20T04:05:00', '2024-12-20T04:20:00', '2024-12-20T06:45:00']\n",
        "\n",
        "üìå Coloana: legs0_departureAt\n",
        "   - Valori lipsƒÉ: 0\n",
        "   - Nr. valori unice: 27294\n",
        "   - Valori unice (e»ôantion): ['2024-11-13T01:10:00', '2024-12-19T06:50:00', '2024-12-19T07:50:00', '2024-12-19T08:25:00', '2024-12-19T09:40:00', '2024-12-19T10:00:00', '2024-12-19T12:50:00', '2024-12-19T13:35:00', '2024-12-19T15:40:00', '2024-12-19T16:45:00', '2024-12-19T17:40:00', '2024-12-19T17:45:00', '2024-12-19T20:35:00', '2024-12-19T21:15:00', '2024-12-19T21:30:00', '2024-12-19T22:00:00', '2024-12-19T23:10:00', '2024-12-19T23:25:00', '2024-12-19T23:45:00', '2024-12-19T23:55:00']\n",
        "\n",
        "üìå Coloana: legs1_arrivalAt\n",
        "   - Valori lipsƒÉ: 1115840\n",
        "   - Nr. valori unice: 22232\n",
        "   - Valori unice (e»ôantion): ['2024-11-14 20:45:00', '2024-11-15 01:20:00', '2024-12-21 06:15:00', '2024-12-21 07:30:00', '2024-12-21 07:35:00', '2024-12-21 07:45:00', '2024-12-21 08:55:00', '2024-12-21 09:20:00', '2024-12-21 10:10:00', '2024-12-21 12:35:00', '2024-12-21 13:00:00', '2024-12-21 13:20:00', '2024-12-21 14:35:00', '2024-12-21 16:00:00', '2024-12-21 16:40:00', '2024-12-21 19:05:00', '2024-12-21 19:40:00', '2024-12-21 21:10:00', '2024-12-21 21:55:00', '2024-12-21 23:50:00']\n",
        "\n",
        "üìå Coloana: legs1_arrivalAt_day\n",
        "   - Valori lipsƒÉ: 0\n",
        "   - Nr. valori unice: 31\n",
        "   - Valori unice (e»ôantion): [np.float64(2.0), np.float64(3.0), np.float64(5.0), np.float64(8.0), np.float64(9.0), np.float64(10.0), np.float64(11.0), np.float64(13.0), np.float64(14.0), np.float64(15.0), np.float64(16.0), np.float64(17.0), np.float64(18.0), np.float64(19.0), np.float64(21.0), np.float64(22.0), np.float64(23.0), np.float64(25.0), np.float64(26.0), np.float64(28.0)]\n",
        "\n",
        "üìå Coloana: legs1_arrivalAt_dayofweek\n",
        "   - Valori lipsƒÉ: 7022\n",
        "   - Nr. valori unice: 7\n",
        "   - Valori unice (e»ôantion): [np.float64(0.0), np.float64(1.0), np.float64(2.0), np.float64(3.0), np.float64(4.0), np.float64(5.0), np.float64(6.0)]\n",
        "\n",
        "üìå Coloana: legs1_arrivalAt_hour\n",
        "   - Valori lipsƒÉ: 0\n",
        "   - Nr. valori unice: 24\n",
        "   - Valori unice (e»ôantion): [np.float64(0.0), np.float64(1.0), np.float64(2.0), np.float64(5.0), np.float64(6.0), np.float64(7.0), np.float64(8.0), np.float64(9.0), np.float64(10.0), np.float64(11.0), np.float64(12.0), np.float64(13.0), np.float64(14.0), np.float64(16.0), np.float64(17.0), np.float64(19.0), np.float64(20.0), np.float64(21.0), np.float64(22.0), np.float64(23.0)]\n",
        "\n",
        "üìå Coloana: legs1_arrivalAt_hour_cos\n",
        "   - Valori lipsƒÉ: 0\n",
        "   - Nr. valori unice: 23\n",
        "   - Valori unice (e»ôantion): [np.float64(-1.0), np.float64(-0.9659258262890684), np.float64(-0.9659258262890682), np.float64(-0.8660254037844388), np.float64(-0.8660254037844387), np.float64(-0.7071067811865475), np.float64(-0.5000000000000004), np.float64(-0.4999999999999998), np.float64(-0.2588190451025206), np.float64(6.123233995736766e-17), np.float64(0.2588190451025203), np.float64(0.2588190451025207), np.float64(0.5000000000000001), np.float64(0.7071067811865474), np.float64(0.7071067811865476), np.float64(0.8660254037844384), np.float64(0.8660254037844387), np.float64(0.965925826289068), np.float64(0.9659258262890684), np.float64(1.0)]\n",
        "\n",
        "üìå Coloana: legs1_arrivalAt_hour_sin\n",
        "   - Valori lipsƒÉ: 0\n",
        "   - Nr. valori unice: 21\n",
        "   - Valori unice (e»ôantion): [np.float64(-1.0), np.float64(-0.9659258262890684), np.float64(-0.8660254037844386), np.float64(-0.8660254037844384), np.float64(-0.7071067811865477), np.float64(-0.7071067811865471), np.float64(-0.5000000000000004), np.float64(-0.4999999999999997), np.float64(-0.2588190451025215), np.float64(-0.2588190451025208), np.float64(0.0), np.float64(1.2246467991473532e-16), np.float64(0.2588190451025207), np.float64(0.258819045102521), np.float64(0.4999999999999999), np.float64(0.7071067811865475), np.float64(0.7071067811865476), np.float64(0.8660254037844387), np.float64(0.9659258262890684), np.float64(1.0)]\n",
        "\n",
        "üìå Coloana: legs1_arrivalAt_is_weekend\n",
        "   - Valori lipsƒÉ: 0\n",
        "   - Nr. valori unice: 2\n",
        "   - Valori unice (e»ôantion): [np.int64(0), np.int64(1)]\n",
        "\n",
        "üìå Coloana: legs1_arrivalAt_minute\n",
        "   - Valori lipsƒÉ: 0\n",
        "   - Nr. valori unice: 60\n",
        "   - Valori unice (e»ôantion): [np.float64(0.0), np.float64(5.0), np.float64(10.0), np.float64(15.0), np.float64(20.0), np.float64(23.0), np.float64(24.0), np.float64(25.0), np.float64(26.0), np.float64(29.0), np.float64(30.0), np.float64(31.0), np.float64(32.0), np.float64(33.0), np.float64(34.0), np.float64(35.0), np.float64(40.0), np.float64(45.0), np.float64(50.0), np.float64(55.0)]\n",
        "\n",
        "üìå Coloana: legs1_arrivalAt_month\n",
        "   - Valori lipsƒÉ: 0\n",
        "   - Nr. valori unice: 12\n",
        "   - Valori unice (e»ôantion): [np.float64(1.0), np.float64(2.0), np.float64(3.0), np.float64(4.0), np.float64(5.0), np.float64(6.0), np.float64(7.0), np.float64(8.0), np.float64(9.0), np.float64(10.0), np.float64(11.0), np.float64(12.0)]\n",
        "\n",
        "üìå Coloana: legs1_arrivalAt_part_of_day\n",
        "   - Valori lipsƒÉ: 0\n",
        "   - Nr. valori unice: 4\n",
        "   - Valori unice (e»ôantion): ['afternoon', 'evening', 'morning', 'night']\n",
        "\n",
        "üìå Coloana: legs1_arrivalAt_weekofyear\n",
        "   - Valori lipsƒÉ: 7022\n",
        "   - Nr. valori unice: 52\n",
        "   - Valori unice (e»ôantion): [np.float64(27.0), np.float64(28.0), np.float64(31.0), np.float64(32.0), np.float64(33.0), np.float64(34.0), np.float64(35.0), np.float64(36.0), np.float64(37.0), np.float64(38.0), np.float64(39.0), np.float64(41.0), np.float64(42.0), np.float64(43.0), np.float64(44.0), np.float64(45.0), np.float64(46.0), np.float64(47.0), np.float64(48.0), np.float64(51.0)]\n",
        "\n",
        "üìå Coloana: legs1_arrivalAt_year\n",
        "   - Valori lipsƒÉ: 0\n",
        "   - Nr. valori unice: 2\n",
        "   - Valori unice (e»ôantion): [np.float64(2024.0), np.float64(2025.0)]\n",
        "\n",
        "üìå Coloana: legs1_departureAt\n",
        "   - Valori lipsƒÉ: 1115840\n",
        "   - Nr. valori unice: 21221\n",
        "   - Valori unice (e»ôantion): ['2024-11-14 08:50:00', '2024-11-14 18:05:00', '2024-11-14 22:20:00', '2024-12-21 05:30:00', '2024-12-21 06:50:00', '2024-12-21 07:00:00', '2024-12-21 07:20:00', '2024-12-21 08:15:00', '2024-12-21 08:30:00', '2024-12-21 09:30:00', '2024-12-21 12:00:00', '2024-12-21 12:15:00', '2024-12-21 13:55:00', '2024-12-21 15:20:00', '2024-12-21 16:00:00', '2024-12-21 18:25:00', '2024-12-21 19:00:00', '2024-12-21 20:30:00', '2024-12-21 21:10:00', '2024-12-21 23:10:00']\n",
        "\n",
        "üìå Coloana: legs1_departureAt_day\n",
        "   - Valori lipsƒÉ: 0\n",
        "   - Nr. valori unice: 31\n",
        "   - Valori unice (e»ôantion): [np.float64(2.0), np.float64(5.0), np.float64(6.0), np.float64(7.0), np.float64(8.0), np.float64(10.0), np.float64(11.0), np.float64(13.0), np.float64(14.0), np.float64(15.0), np.float64(16.0), np.float64(17.0), np.float64(18.0), np.float64(20.0), np.float64(21.0), np.float64(22.0), np.float64(24.0), np.float64(26.0), np.float64(29.0), np.float64(31.0)]\n",
        "\n",
        "üìå Coloana: legs1_departureAt_dayofweek\n",
        "   - Valori lipsƒÉ: 7492\n",
        "   - Nr. valori unice: 7\n",
        "   - Valori unice (e»ôantion): [np.float64(0.0), np.float64(1.0), np.float64(2.0), np.float64(3.0), np.float64(4.0), np.float64(5.0), np.float64(6.0)]\n",
        "\n",
        "üìå Coloana: legs1_departureAt_hour\n",
        "   - Valori lipsƒÉ: 0\n",
        "   - Nr. valori unice: 24\n",
        "   - Valori unice (e»ôantion): [np.float64(2.0), np.float64(5.0), np.float64(6.0), np.float64(7.0), np.float64(8.0), np.float64(9.0), np.float64(10.0), np.float64(11.0), np.float64(12.0), np.float64(13.0), np.float64(14.0), np.float64(15.0), np.float64(16.0), np.float64(17.0), np.float64(18.0), np.float64(19.0), np.float64(20.0), np.float64(21.0), np.float64(22.0), np.float64(23.0)]\n",
        "\n",
        "üìå Coloana: legs1_departureAt_hour_cos\n",
        "   - Valori lipsƒÉ: 0\n",
        "   - Nr. valori unice: 23\n",
        "   - Valori unice (e»ôantion): [np.float64(-1.0), np.float64(-0.9659258262890684), np.float64(-0.9659258262890682), np.float64(-0.8660254037844388), np.float64(-0.8660254037844387), np.float64(-0.7071067811865479), np.float64(-0.7071067811865475), np.float64(-0.5000000000000004), np.float64(-0.4999999999999998), np.float64(-0.2588190451025206), np.float64(-1.8369701987210294e-16), np.float64(-1.8369701987210287e-16), np.float64(6.123233995736766e-17), np.float64(0.2588190451025203), np.float64(0.2588190451025207), np.float64(0.5000000000000001), np.float64(0.7071067811865474), np.float64(0.8660254037844384), np.float64(0.8660254037844387), np.float64(0.965925826289068)]\n",
        "\n",
        "üìå Coloana: legs1_departureAt_hour_sin\n",
        "   - Valori lipsƒÉ: 0\n",
        "   - Nr. valori unice: 21\n",
        "   - Valori unice (e»ôantion): [np.float64(-1.0), np.float64(-0.9659258262890684), np.float64(-0.8660254037844386), np.float64(-0.8660254037844384), np.float64(-0.7071067811865477), np.float64(-0.7071067811865471), np.float64(-0.5000000000000004), np.float64(-0.4999999999999997), np.float64(-0.2588190451025215), np.float64(-0.2588190451025208), np.float64(0.0), np.float64(1.2246467991473532e-16), np.float64(0.2588190451025207), np.float64(0.258819045102521), np.float64(0.4999999999999999), np.float64(0.7071067811865476), np.float64(0.8660254037844386), np.float64(0.8660254037844387), np.float64(0.9659258262890684), np.float64(1.0)]\n",
        "\n",
        "üìå Coloana: legs1_departureAt_is_weekend\n",
        "   - Valori lipsƒÉ: 0\n",
        "   - Nr. valori unice: 2\n",
        "   - Valori unice (e»ôantion): [np.int64(0), np.int64(1)]\n",
        "\n",
        "üìå Coloana: legs1_departureAt_minute\n",
        "   - Valori lipsƒÉ: 0\n",
        "   - Nr. valori unice: 60\n",
        "   - Valori unice (e»ôantion): [np.float64(0.0), np.float64(5.0), np.float64(10.0), np.float64(15.0), np.float64(19.0), np.float64(20.0), np.float64(21.0), np.float64(22.0), np.float64(24.0), np.float64(25.0), np.float64(26.0), np.float64(27.0), np.float64(29.0), np.float64(30.0), np.float64(31.0), np.float64(35.0), np.float64(40.0), np.float64(45.0), np.float64(50.0), np.float64(55.0)]\n",
        "\n",
        "üìå Coloana: legs1_departureAt_month\n",
        "   - Valori lipsƒÉ: 0\n",
        "   - Nr. valori unice: 12\n",
        "   - Valori unice (e»ôantion): [np.float64(1.0), np.float64(2.0), np.float64(3.0), np.float64(4.0), np.float64(5.0), np.float64(6.0), np.float64(7.0), np.float64(8.0), np.float64(9.0), np.float64(10.0), np.float64(11.0), np.float64(12.0)]\n",
        "\n",
        "üìå Coloana: legs1_departureAt_part_of_day\n",
        "   - Valori lipsƒÉ: 0\n",
        "   - Nr. valori unice: 4\n",
        "   - Valori unice (e»ôantion): ['afternoon', 'evening', 'morning', 'night']\n",
        "\n",
        "üìå Coloana: legs1_departureAt_weekofyear\n",
        "   - Valori lipsƒÉ: 7492\n",
        "   - Nr. valori unice: 52\n",
        "   - Valori unice (e»ôantion): [np.float64(29.0), np.float64(30.0), np.float64(31.0), np.float64(32.0), np.float64(33.0), np.float64(34.0), np.float64(35.0), np.float64(36.0), np.float64(37.0), np.float64(38.0), np.float64(39.0), np.float64(40.0), np.float64(41.0), np.float64(42.0), np.float64(43.0), np.float64(44.0), np.float64(45.0), np.float64(46.0), np.float64(47.0), np.float64(51.0)]\n",
        "\n",
        "üìå Coloana: legs1_departureAt_year\n",
        "   - Valori lipsƒÉ: 0\n",
        "   - Nr. valori unice: 2\n",
        "   - Valori unice (e»ôantion): [np.float64(2024.0), np.float64(2025.0)]"
      ],
      "metadata": {
        "id": "iXScEJc8efV5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile impute_missing_dayofweek_and_weekofyear.py\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# === Load CSV files ===\n",
        "train = pd.read_csv(\"train.csv\", low_memory=False)\n",
        "test = pd.read_csv(\"test.csv\", low_memory=False)\n",
        "\n",
        "# === Function to selectively fill dayofweek and weekofyear ===\n",
        "def fill_missing_dayofweek_and_weekofyear(df, prefix):\n",
        "    # Check if all components are present\n",
        "    components = [f\"{prefix}_{p}\" for p in [\"year\", \"month\", \"day\", \"hour\", \"minute\"]]\n",
        "    if not all(c in df.columns for c in components):\n",
        "        print(f\"‚ö†Ô∏è Required components missing for {prefix}.\")\n",
        "        return df\n",
        "\n",
        "    # Create a mask for rows where all components are available\n",
        "    complete_mask = df[components].notnull().all(axis=1)\n",
        "\n",
        "    # Rows where either dayofweek or weekofyear is missing\n",
        "    needs_impute = df[f\"{prefix}_dayofweek\"].isna() | df[f\"{prefix}_weekofyear\"].isna()\n",
        "\n",
        "    # Final mask: components available, but target values missing\n",
        "    mask = complete_mask & needs_impute\n",
        "\n",
        "    if mask.sum() == 0:\n",
        "        print(f\"‚úÖ {prefix}: nothing to impute.\")\n",
        "        return df\n",
        "\n",
        "    print(f\"üîß {prefix}: imputing {mask.sum()} missing rows\")\n",
        "\n",
        "    # Build temporary datetime for selected rows\n",
        "    temp_dt = pd.to_datetime(dict(\n",
        "        year=df.loc[mask, f\"{prefix}_year\"].astype(int),\n",
        "        month=df.loc[mask, f\"{prefix}_month\"].astype(int),\n",
        "        day=df.loc[mask, f\"{prefix}_day\"].astype(int),\n",
        "        hour=df.loc[mask, f\"{prefix}_hour\"].astype(int),\n",
        "        minute=df.loc[mask, f\"{prefix}_minute\"].astype(int)\n",
        "    ), errors='coerce')\n",
        "\n",
        "    # Assign computed values\n",
        "    df.loc[mask, f\"{prefix}_dayofweek\"] = temp_dt.dt.dayofweek\n",
        "    df.loc[mask, f\"{prefix}_weekofyear\"] = temp_dt.dt.isocalendar().week.astype(float)\n",
        "\n",
        "    return df\n",
        "\n",
        "# === Apply to both datasets and both columns ===\n",
        "for df_name, df in [(\"train\", train), (\"test\", test)]:\n",
        "    print(f\"\\nüìÇ Processing: {df_name}.csv\")\n",
        "    df = fill_missing_dayofweek_and_weekofyear(df, \"legs1_departureAt\")\n",
        "    df = fill_missing_dayofweek_and_weekofyear(df, \"legs1_arrivalAt\")\n",
        "\n",
        "    # Save result\n",
        "    df.to_csv(f\"{df_name}.csv\", index=False)\n"
      ],
      "metadata": {
        "id": "pLl9YuZzfrzK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Summary of Imputation:\n",
        "For train.csv:\n",
        "\n",
        "legs1_departureAt_dayofweek & legs1_departureAt_weekofyear: 33,113 rows filled\n",
        "\n",
        "legs1_arrivalAt_dayofweek & legs1_arrivalAt_weekofyear: 23,376 rows filled\n",
        "\n",
        "For test.csv:\n",
        "\n",
        "legs1_departureAt_dayofweek & legs1_departureAt_weekofyear: 7,492 rows filled\n",
        "\n",
        "legs1_arrivalAt_dayofweek & legs1_arrivalAt_weekofyear: 7,022 rows filled"
      ],
      "metadata": {
        "id": "Pf79INuCf4IK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile remove_columns.py\n",
        "import pandas as pd\n",
        "\n",
        "# List of column names to be removed\n",
        "columns_to_drop = [\n",
        "    'legs1_segments0_flightNumber',\n",
        "    'legs1_departureAt',\n",
        "    'legs1_arrivalAt',\n",
        "    'legs1_departureAt_dayofweek',\n",
        "    'legs1_departureAt_weekofyear',\n",
        "    'legs1_arrivalAt_dayofweek',\n",
        "    'legs1_arrivalAt_weekofyear'\n",
        "]\n",
        "\n",
        "# Load and modify train.csv\n",
        "train_df = pd.read_csv('train.csv')\n",
        "train_df = train_df.drop(columns=[col for col in columns_to_drop if col in train_df.columns])\n",
        "train_df.to_csv('train.csv', index=False)  # overwrite the original file\n",
        "\n",
        "# Load and modify test.csv\n",
        "test_df = pd.read_csv('test.csv')\n",
        "test_df = test_df.drop(columns=[col for col in columns_to_drop if col in test_df.columns])\n",
        "test_df.to_csv('test.csv', index=False)  # overwrite the original file\n"
      ],
      "metadata": {
        "id": "SO2W2k65f1Ui"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile remove_columns_2.py\n",
        "import pandas as pd\n",
        "\n",
        "# List of column names to be removed (copied from your output)\n",
        "columns_to_drop = [\n",
        "    'legs1_segments3_cabinClass',\n",
        "    'legs1_segments3_baggageAllowance_weightMeasurementType',\n",
        "    'legs1_segments3_arrivalTo_airport_iata',\n",
        "    'legs1_segments3_baggageAllowance_quantity',\n",
        "    'legs1_segments3_aircraft_code',\n",
        "    'legs1_segments3_arrivalTo_airport_city_iata',\n",
        "    'legs1_segments3_marketingCarrier_code',\n",
        "    'legs1_segments3_flightNumber',\n",
        "    'legs1_segments3_seatsAvailable',\n",
        "    'legs1_segments3_operatingCarrier_code',\n",
        "    'legs1_segments3_duration',\n",
        "    'legs1_segments3_departureFrom_airport_iata',\n",
        "    'legs0_segments3_aircraft_code',\n",
        "    'legs0_segments3_cabinClass',\n",
        "    'legs0_segments3_seatsAvailable',\n",
        "    'legs0_segments3_baggageAllowance_quantity',\n",
        "    'legs0_segments3_baggageAllowance_weightMeasurementType',\n",
        "    'legs0_segments3_flightNumber',\n",
        "    'legs0_segments3_arrivalTo_airport_iata',\n",
        "    'legs0_segments3_arrivalTo_airport_city_iata',\n",
        "    'legs0_segments3_operatingCarrier_code',\n",
        "    'legs0_segments3_marketingCarrier_code',\n",
        "    'legs0_segments3_duration',\n",
        "    'legs0_segments3_departureFrom_airport_iata',\n",
        "    'legs1_segments2_baggageAllowance_quantity',\n",
        "    'legs1_segments2_baggageAllowance_weightMeasurementType',\n",
        "    'legs1_segments2_seatsAvailable',\n",
        "    'legs1_segments2_cabinClass',\n",
        "    'legs1_segments2_aircraft_code',\n",
        "    'legs1_segments2_operatingCarrier_code',\n",
        "    'legs1_segments2_arrivalTo_airport_iata',\n",
        "    'legs1_segments2_arrivalTo_airport_city_iata',\n",
        "    'legs1_segments2_duration',\n",
        "    'legs1_segments2_departureFrom_airport_iata',\n",
        "    'legs1_segments2_marketingCarrier_code',\n",
        "    'legs1_segments2_flightNumber',\n",
        "    'legs0_segments2_baggageAllowance_quantity',\n",
        "    'legs0_segments2_baggageAllowance_weightMeasurementType',\n",
        "    'legs0_segments2_seatsAvailable',\n",
        "    'legs0_segments2_cabinClass',\n",
        "    'legs0_segments2_aircraft_code',\n",
        "    'legs0_segments2_marketingCarrier_code',\n",
        "    'legs0_segments2_duration',\n",
        "    'legs0_segments2_operatingCarrier_code',\n",
        "    'legs0_segments2_arrivalTo_airport_iata',\n",
        "    'legs0_segments2_flightNumber',\n",
        "    'legs0_segments2_arrivalTo_airport_city_iata',\n",
        "    'legs0_segments2_departureFrom_airport_iata',\n",
        "    'miniRules1_percentage',\n",
        "    'miniRules0_percentage',\n",
        "    'legs1_segments1_seatsAvailable',\n",
        "    'legs1_segments1_baggageAllowance_weightMeasurementType',\n",
        "    'legs1_segments1_baggageAllowance_quantity',\n",
        "    'legs1_segments1_cabinClass',\n",
        "    'legs1_segments1_departureFrom_airport_iata',\n",
        "    'legs1_segments1_flightNumber',\n",
        "    'legs1_segments1_marketingCarrier_code',\n",
        "    'legs1_segments1_aircraft_code',\n",
        "    'legs1_segments1_duration',\n",
        "    'legs1_segments1_operatingCarrier_code',\n",
        "    'legs1_segments1_arrivalTo_airport_iata',\n",
        "    'legs1_segments1_arrivalTo_airport_city_iata',\n",
        "    'legs0_segments1_seatsAvailable',\n",
        "    'legs0_segments1_baggageAllowance_weightMeasurementType',\n",
        "    'legs0_segments1_baggageAllowance_quantity',\n",
        "    'legs0_segments1_cabinClass',\n",
        "    'legs0_segments1_aircraft_code',\n",
        "    'legs0_segments1_arrivalTo_airport_city_iata',\n",
        "    'legs0_segments1_departureFrom_airport_iata',\n",
        "    'legs0_segments1_arrivalTo_airport_iata',\n",
        "    'legs0_segments1_marketingCarrier_code',\n",
        "    'legs0_segments1_flightNumber',\n",
        "    'legs0_segments1_duration',\n",
        "    'legs0_segments1_operatingCarrier_code'\n",
        "]\n",
        "\n",
        "# Load and modify train.csv\n",
        "train_df = pd.read_csv('train.csv')\n",
        "train_df = train_df.drop(columns=[col for col in columns_to_drop if col in train_df.columns])\n",
        "train_df.to_csv('train.csv', index=False)\n",
        "\n",
        "# Load and modify test.csv\n",
        "test_df = pd.read_csv('test.csv')\n",
        "test_df = test_df.drop(columns=[col for col in columns_to_drop if col in test_df.columns])\n",
        "test_df.to_csv('test.csv', index=False)\n"
      ],
      "metadata": {
        "id": "LwWUYm6VgNpb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile analyze_data.py\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Load files\n",
        "train = pd.read_csv(\"train.csv\")\n",
        "test = pd.read_csv(\"test.csv\")\n",
        "\n",
        "# Function to analyze a DataFrame\n",
        "def analyze_dataframe(df, name=\"DataFrame\"):\n",
        "    print(f\"\\n===== {name.upper()} INFO =====\")\n",
        "    print(f\"Number of rows: {df.shape[0]}\")\n",
        "    print(f\"Number of columns: {df.shape[1]}\")\n",
        "    print(\"\\n--- Data types and missing values ---\")\n",
        "    print(df.info())\n",
        "\n",
        "    print(\"\\n--- Descriptive Statistics (Numerical) ---\")\n",
        "    print(df.describe().T)\n",
        "\n",
        "    print(\"\\n--- Descriptive Statistics (Categorical) ---\")\n",
        "    cat_cols = df.select_dtypes(include=['object', 'category']).columns\n",
        "    if len(cat_cols) > 0:\n",
        "        for col in cat_cols:\n",
        "            print(f\"\\nColumn: {col}\")\n",
        "            print(f\"Unique values ({df[col].nunique()}): {df[col].unique()[:10]}\")\n",
        "            print(f\"Frequency:\\n{df[col].value_counts(dropna=False).head(5)}\")\n",
        "    else:\n",
        "        print(\"No categorical columns.\")\n",
        "\n",
        "    print(\"\\n--- Distributions, Min, Max, and Unique values for all columns ---\")\n",
        "    for col in df.columns:\n",
        "        print(f\"\\nColumn: {col}\")\n",
        "        print(f\"  Type: {df[col].dtype}\")\n",
        "        print(f\"  Missing values: {df[col].isnull().sum()} ({(df[col].isnull().mean()*100):.2f}%)\")\n",
        "        print(f\"  Unique values: {df[col].nunique()}\")\n",
        "        if df[col].nunique() < 20:\n",
        "            print(f\"  Examples: {df[col].unique()}\")\n",
        "        else:\n",
        "            print(f\"  Examples: {df[col].dropna().unique()[:5]}\")\n",
        "        if np.issubdtype(df[col].dtype, np.number):\n",
        "            print(f\"  Min: {df[col].min()}, Max: {df[col].max()}, Mean: {df[col].mean():.2f}, Std: {df[col].std():.2f}\")\n",
        "\n",
        "# Analysis for train.csv\n",
        "analyze_dataframe(train, name=\"train.csv\")\n",
        "\n",
        "# Analysis for test.csv\n",
        "analyze_dataframe(test, name=\"test.csv\")\n"
      ],
      "metadata": {
        "id": "Gsod0rTYg3vr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "===== TRAIN.CSV INFO =====\n",
        "NumƒÉr de r√¢nduri: 18145372\n",
        "NumƒÉr de coloane: 73\n",
        "\n",
        "--- Tipuri de date »ôi valori lipsƒÉ ---\n",
        "<class 'pandas.core.frame.DataFrame'>\n",
        "RangeIndex: 18145372 entries, 0 to 18145371\n",
        "Data columns (total 73 columns):\n",
        " #   Column                                                  Dtype\n",
        "---  ------                                                  -----\n",
        " 0   Id                                                      int64\n",
        " 1   bySelf                                                  bool\n",
        " 2   companyID                                               int64\n",
        " 3   corporateTariffCode                                     float64\n",
        " 4   frequentFlyer                                           object\n",
        " 5   nationality                                             int64\n",
        " 6   isAccess3D                                              bool\n",
        " 7   isVip                                                   bool\n",
        " 8   legs0_arrivalAt                                         object\n",
        " 9   legs0_departureAt                                       object\n",
        " 10  legs0_duration                                          object\n",
        " 11  legs0_segments0_aircraft_code                           object\n",
        " 12  legs0_segments0_arrivalTo_airport_city_iata             object\n",
        " 13  legs0_segments0_arrivalTo_airport_iata                  object\n",
        " 14  legs0_segments0_baggageAllowance_quantity               float64\n",
        " 15  legs0_segments0_baggageAllowance_weightMeasurementType  float64\n",
        " 16  legs0_segments0_cabinClass                              float64\n",
        " 17  legs0_segments0_departureFrom_airport_iata              object\n",
        " 18  legs0_segments0_duration                                object\n",
        " 19  legs0_segments0_flightNumber                            int64\n",
        " 20  legs0_segments0_marketingCarrier_code                   object\n",
        " 21  legs0_segments0_operatingCarrier_code                   object\n",
        " 22  legs0_segments0_seatsAvailable                          float64\n",
        " 23  legs1_duration                                          float64\n",
        " 24  legs1_segments0_aircraft_code                           object\n",
        " 25  legs1_segments0_arrivalTo_airport_city_iata             object\n",
        " 26  legs1_segments0_arrivalTo_airport_iata                  object\n",
        " 27  legs1_segments0_baggageAllowance_quantity               float64\n",
        " 28  legs1_segments0_baggageAllowance_weightMeasurementType  float64\n",
        " 29  legs1_segments0_cabinClass                              float64\n",
        " 30  legs1_segments0_departureFrom_airport_iata              object\n",
        " 31  legs1_segments0_duration                                float64\n",
        " 32  legs1_segments0_marketingCarrier_code                   object\n",
        " 33  legs1_segments0_operatingCarrier_code                   object\n",
        " 34  legs1_segments0_seatsAvailable                          float64\n",
        " 35  miniRules0_monetaryAmount                               float64\n",
        " 36  miniRules0_statusInfos                                  float64\n",
        " 37  miniRules1_monetaryAmount                               float64\n",
        " 38  miniRules1_statusInfos                                  float64\n",
        " 39  pricingInfo_isAccessTP                                  float64\n",
        " 40  pricingInfo_passengerCount                              int64\n",
        " 41  profileId                                               int64\n",
        " 42  ranker_id                                               object\n",
        " 43  requestDate                                             object\n",
        " 44  searchRoute                                             object\n",
        " 45  sex                                                     bool\n",
        " 46  taxes                                                   float64\n",
        " 47  totalPrice                                              float64\n",
        " 48  selected                                                int64\n",
        " 49  __index_level_0__                                       int64\n",
        " 50  legs0_segments0_baggageAllowance_missing_initially      int64\n",
        " 51  legs0_segments0_seatsAvailable_missing_initially        int64\n",
        " 52  miniRules0_statusInfos_was_missing                      int64\n",
        " 53  miniRules1_statusInfos_was_missing                      int64\n",
        " 54  legs1_segments0_aircraft_code_was_missing               int64\n",
        " 55  legs1_departureAt_hour                                  float64\n",
        " 56  legs1_departureAt_minute                                float64\n",
        " 57  legs1_departureAt_is_weekend                            int64\n",
        " 58  legs1_departureAt_day                                   float64\n",
        " 59  legs1_departureAt_month                                 float64\n",
        " 60  legs1_departureAt_year                                  float64\n",
        " 61  legs1_departureAt_part_of_day                           object\n",
        " 62  legs1_departureAt_hour_sin                              float64\n",
        " 63  legs1_departureAt_hour_cos                              float64\n",
        " 64  legs1_arrivalAt_hour                                    float64\n",
        " 65  legs1_arrivalAt_minute                                  float64\n",
        " 66  legs1_arrivalAt_is_weekend                              int64\n",
        " 67  legs1_arrivalAt_day                                     float64\n",
        " 68  legs1_arrivalAt_month                                   float64\n",
        " 69  legs1_arrivalAt_year                                    float64\n",
        " 70  legs1_arrivalAt_part_of_day                             object\n",
        " 71  legs1_arrivalAt_hour_sin                                float64\n",
        " 72  legs1_arrivalAt_hour_cos                                float64\n",
        "dtypes: bool(4), float64(32), int64(15), object(22)\n",
        "memory usage: 9.4+ GB\n",
        "None\n",
        "\n",
        "--- Descriptive Statistics (Numerice) ---\n",
        "                                                         count  ...         max\n",
        "Id                                                  18145372.0  ...  18146431.0\n",
        "companyID                                           18145372.0  ...     63482.0\n",
        "corporateTariffCode                                 18145372.0  ...       181.0\n",
        "nationality                                         18145372.0  ...        48.0\n",
        "legs0_segments0_baggageAllowance_quantity           18145372.0  ...        60.0\n",
        "legs0_segments0_baggageAllowance_weightMeasurem...  18145372.0  ...         1.0\n",
        "legs0_segments0_cabinClass                          18145372.0  ...         4.0\n",
        "legs0_segments0_flightNumber                        18145372.0  ...      9996.0\n",
        "legs0_segments0_seatsAvailable                      18145372.0  ...        10.0\n",
        "legs1_duration                                      18145372.0  ...      1646.0\n",
        "legs1_segments0_baggageAllowance_quantity           18145372.0  ...        60.0\n",
        "legs1_segments0_baggageAllowance_weightMeasurem...  18145372.0  ...         1.0\n",
        "legs1_segments0_cabinClass                          18145372.0  ...         4.0\n",
        "legs1_segments0_duration                            18145372.0  ...      1175.0\n",
        "legs1_segments0_seatsAvailable                      18145372.0  ...         9.0\n",
        "miniRules0_monetaryAmount                           18145372.0  ...    502237.0\n",
        "miniRules0_statusInfos                              18145372.0  ...         1.0\n",
        "miniRules1_monetaryAmount                           18145372.0  ...   7161273.0\n",
        "miniRules1_statusInfos                              18145372.0  ...         1.0\n",
        "pricingInfo_isAccessTP                              18145372.0  ...         1.0\n",
        "pricingInfo_passengerCount                          18145372.0  ...         1.0\n",
        "profileId                                           18145372.0  ...   3604410.0\n",
        "taxes                                               18145372.0  ...    897921.0\n",
        "totalPrice                                          18145372.0  ...   9944355.0\n",
        "selected                                            18145372.0  ...         1.0\n",
        "__index_level_0__                                   18145372.0  ...  18146431.0\n",
        "legs0_segments0_baggageAllowance_missing_initially  18145372.0  ...         1.0\n",
        "legs0_segments0_seatsAvailable_missing_initially    18145372.0  ...         1.0\n",
        "miniRules0_statusInfos_was_missing                  18145372.0  ...         1.0\n",
        "miniRules1_statusInfos_was_missing                  18145372.0  ...         1.0\n",
        "legs1_segments0_aircraft_code_was_missing           18145372.0  ...         1.0\n",
        "legs1_departureAt_hour                              18145372.0  ...        23.0\n",
        "legs1_departureAt_minute                            18145372.0  ...        59.0\n",
        "legs1_departureAt_is_weekend                        18145372.0  ...         1.0\n",
        "legs1_departureAt_day                               18145372.0  ...        31.0\n",
        "legs1_departureAt_month                             18145372.0  ...        12.0\n",
        "legs1_departureAt_year                              18145372.0  ...      2025.0\n",
        "legs1_departureAt_hour_sin                          18145372.0  ...         1.0\n",
        "legs1_departureAt_hour_cos                          18145372.0  ...         1.0\n",
        "legs1_arrivalAt_hour                                18145372.0  ...        23.0\n",
        "legs1_arrivalAt_minute                              18145372.0  ...        59.0\n",
        "legs1_arrivalAt_is_weekend                          18145372.0  ...         1.0\n",
        "legs1_arrivalAt_day                                 18145372.0  ...        31.0\n",
        "legs1_arrivalAt_month                               18145372.0  ...        12.0\n",
        "legs1_arrivalAt_year                                18145372.0  ...      2025.0\n",
        "legs1_arrivalAt_hour_sin                            18145372.0  ...         1.0\n",
        "legs1_arrivalAt_hour_cos                            18145372.0  ...         1.0\n",
        "\n",
        "[47 rows x 8 columns]\n",
        "\n",
        "--- Descriptive Statistics (Categorice) ---\n",
        "\n",
        "Coloana: frequentFlyer\n",
        "Valori unice (371): ['S7/SU/UT' 'S7/SU/I8' 'SU/S7/UT/N4' 'S7/UT/SU' 'SU/UT/S7' 'SU' 'S7'\n",
        " 'UT/SU/S7' 'SU/S7' 'S7/SU']\n",
        "Frecven»õƒÉ:\n",
        "frequentFlyer\n",
        "SU       11203125\n",
        "SU/S7     2317383\n",
        "S7/SU      951785\n",
        "S7         721072\n",
        "SU/TK      335349\n",
        "Name: count, dtype: int64\n",
        "\n",
        "Coloana: legs0_arrivalAt\n",
        "Valori unice (60143): ['2024-06-15T16:20:00' '2024-06-15T14:50:00' '2024-06-15T17:20:00'\n",
        " '2024-06-15T21:35:00' '2024-06-15T09:15:00' '2024-06-16T06:50:00'\n",
        " '2024-05-30T18:30:00' '2024-05-30T12:55:00' '2024-06-04T15:50:00'\n",
        " '2024-06-04T11:30:00']\n",
        "Frecven»õƒÉ:\n",
        "legs0_arrivalAt\n",
        "2024-11-06T17:10:00    9708\n",
        "2024-11-06T15:45:00    9605\n",
        "2024-08-21T02:00:00    7346\n",
        "2024-09-18T09:30:00    7128\n",
        "2024-08-14T02:00:00    6969\n",
        "Name: count, dtype: int64\n",
        "\n",
        "Coloana: legs0_departureAt\n",
        "Valori unice (56619): ['2024-06-15T15:40:00' '2024-06-15T09:25:00' '2024-06-15T11:25:00'\n",
        " '2024-06-15T09:50:00' '2024-05-30T16:00:00' '2024-05-30T10:40:00'\n",
        " '2024-06-04T11:25:00' '2024-06-04T09:20:00' '2024-06-04T06:50:00'\n",
        " '2024-06-04T11:05:00']\n",
        "Frecven»õƒÉ:\n",
        "legs0_departureAt\n",
        "2024-11-05T08:05:00    11663\n",
        "2024-11-05T08:55:00     9022\n",
        "2024-10-28T07:00:00     8081\n",
        "2024-08-21T00:30:00     7461\n",
        "2024-10-01T06:20:00     7196\n",
        "Name: count, dtype: int64\n",
        "\n",
        "Coloana: legs0_duration\n",
        "Valori unice (1542): ['02:40:00' '07:25:00' '09:55:00' '12:10:00' '01:25:00' '21:25:00'\n",
        " '02:30:00' '02:15:00' '09:25:00' '07:10:00']\n",
        "Frecven»õƒÉ:\n",
        "legs0_duration\n",
        "01:30:00    5286759\n",
        "01:40:00    1002231\n",
        "01:25:00     892348\n",
        "01:35:00     816454\n",
        "01:45:00     443707\n",
        "Name: count, dtype: int64\n",
        "\n",
        "Coloana: legs0_segments0_aircraft_code\n",
        "Valori unice (108): ['YK2' 'E70' 'CRJ' 'AN4' '32N' '32A' '319' 'DH4' '321' '73H']\n",
        "Frecven»õƒÉ:\n",
        "legs0_segments0_aircraft_code\n",
        "SU9    7514233\n",
        "32A    2093755\n",
        "32B    1666842\n",
        "73H    1596430\n",
        "320    1280482\n",
        "Name: count, dtype: int64\n",
        "\n",
        "Coloana: legs0_segments0_arrivalTo_airport_city_iata\n",
        "Valori unice (499): ['KJA' 'OVB' 'NJC' 'IKT' 'AER' 'MOW' 'UUS' 'BQS' 'KHV' 'ODO']\n",
        "Frecven»õƒÉ:\n",
        "legs0_segments0_arrivalTo_airport_city_iata\n",
        "MOW    6521261\n",
        "LED    4767952\n",
        "AER    1128843\n",
        "SVX     893210\n",
        "IST     686558\n",
        "Name: count, dtype: int64\n",
        "\n",
        "Coloana: legs0_segments0_arrivalTo_airport_iata\n",
        "Valori unice (533): ['KJA' 'OVB' 'NJC' 'IKT' 'AER' 'DME' 'UUS' 'BQS' 'KHV' 'SVO']\n",
        "Frecven»õƒÉ:\n",
        "legs0_segments0_arrivalTo_airport_iata\n",
        "LED    4767952\n",
        "SVO    4321862\n",
        "VKO    1398528\n",
        "AER    1128843\n",
        "SVX     893210\n",
        "Name: count, dtype: int64\n",
        "\n",
        "Coloana: legs0_segments0_departureFrom_airport_iata\n",
        "Valori unice (393): ['TLK' 'TOF' 'ODO' 'IKT' 'KHV' 'GDX' 'KJA' 'OVB' 'CEK' 'HTA']\n",
        "Frecven»õƒÉ:\n",
        "legs0_segments0_departureFrom_airport_iata\n",
        "SVO    5468076\n",
        "LED    3803234\n",
        "VKO    2750619\n",
        "DME    1256576\n",
        "AER     653059\n",
        "Name: count, dtype: int64\n",
        "\n",
        "Coloana: legs0_segments0_duration\n",
        "Valori unice (296): ['02:40:00' '02:50:00' '00:50:00' '01:25:00' '02:30:00' '02:15:00'\n",
        " '07:10:00' '02:35:00' '06:10:00' '06:15:00']\n",
        "Frecven»õƒÉ:\n",
        "legs0_segments0_duration\n",
        "01:30:00    5483181\n",
        "01:40:00    1091580\n",
        "01:25:00     981998\n",
        "01:35:00     894720\n",
        "01:45:00     499612\n",
        "Name: count, dtype: int64\n",
        "\n",
        "Coloana: legs0_segments0_marketingCarrier_code\n",
        "Valori unice (164): ['KV' 'S7' '7R' 'IO' '–ò–ö' 'SU' 'HZ' 'UT' 'DP' '5N']\n",
        "Frecven»õƒÉ:\n",
        "legs0_segments0_marketingCarrier_code\n",
        "SU    12465824\n",
        "S7     1286981\n",
        "U6     1160466\n",
        "TK      734996\n",
        "DP      637209\n",
        "Name: count, dtype: int64\n",
        "\n",
        "Coloana: legs0_segments0_operatingCarrier_code\n",
        "Valori unice (220): ['KV' 'S7' '7R' 'IO' '–ò–ö' 'HZ' 'FV' 'UT' 'SU' 'DP']\n",
        "Frecven»õƒÉ:\n",
        "legs0_segments0_operatingCarrier_code\n",
        "FV    7768836\n",
        "SU    4660441\n",
        "S7    1285536\n",
        "U6    1160464\n",
        "TK     731413\n",
        "Name: count, dtype: int64\n",
        "\n",
        "Coloana: legs1_segments0_aircraft_code\n",
        "Valori unice (93): ['YK2' 'E70' '73H' 'SU9' '321' '32A' '32N' '319' '738' '773']\n",
        "Frecven»õƒÉ:\n",
        "legs1_segments0_aircraft_code\n",
        "SU9    7274698\n",
        "32A    2138416\n",
        "73H    1965832\n",
        "32B    1551218\n",
        "320    1373672\n",
        "Name: count, dtype: int64\n",
        "\n",
        "Coloana: legs1_segments0_arrivalTo_airport_city_iata\n",
        "Valori unice (312): ['TLK' 'OVB' 'ABA' 'NJC' 'KZN' 'MOW' 'DEL' 'IKT' 'FRU' 'VVO']\n",
        "Frecven»õƒÉ:\n",
        "legs1_segments0_arrivalTo_airport_city_iata\n",
        "MOW    9133651\n",
        "LED    3541867\n",
        "SVX     820109\n",
        "OVB     669045\n",
        "AER     570004\n",
        "Name: count, dtype: int64\n",
        "\n",
        "Coloana: legs1_segments0_arrivalTo_airport_iata\n",
        "Valori unice (338): ['TLK' 'OVB' 'ABA' 'NJC' 'KZN' 'LED' 'AMD' 'IKT' 'DME' 'KHV']\n",
        "Frecven»õƒÉ:\n",
        "legs1_segments0_arrivalTo_airport_iata\n",
        "SVO    5856081\n",
        "LED    3425824\n",
        "VKO    1949143\n",
        "DME    1104426\n",
        "SVX     846886\n",
        "Name: count, dtype: int64\n",
        "\n",
        "Coloana: legs1_segments0_departureFrom_airport_iata\n",
        "Valori unice (343): ['KJA' 'OVB' 'SVO' 'LED' 'HTA' 'SVX' 'IKT' 'UUD' 'DME' 'AER']\n",
        "Frecven»õƒÉ:\n",
        "legs1_segments0_departureFrom_airport_iata\n",
        "LED    4828009\n",
        "SVO    3652051\n",
        "VKO    1332010\n",
        "AER    1092525\n",
        "DME     816334\n",
        "Name: count, dtype: int64\n",
        "\n",
        "Coloana: legs1_segments0_marketingCarrier_code\n",
        "Valori unice (144): ['KV' 'S7' 'DP' 'SU' 'N4' '5N' 'R3' 'UT' '6R' 'U6']\n",
        "Frecven»õƒÉ:\n",
        "legs1_segments0_marketingCarrier_code\n",
        "SU    11971226\n",
        "S7     1288880\n",
        "U6     1130770\n",
        "DP      845103\n",
        "TK      718166\n",
        "Name: count, dtype: int64\n",
        "\n",
        "Coloana: legs1_segments0_operatingCarrier_code\n",
        "Valori unice (186): ['KV' 'S7' 'EO' 'N4' 'U6' 'FV' 'HZ' 'DP' 'SU' 'UT']\n",
        "Frecven»õƒÉ:\n",
        "legs1_segments0_operatingCarrier_code\n",
        "FV    6642739\n",
        "SU    5384702\n",
        "S7    1281893\n",
        "U6    1131912\n",
        "DP     833079\n",
        "Name: count, dtype: int64\n",
        "\n",
        "Coloana: ranker_id\n",
        "Valori unice (105539): ['98ce0dabf6964640b63079fbafd42cbe' '905909166d934c618ad55ab7f5cea598'\n",
        " '7ec8ce3fdebd4c9699b03582ebd60d5d' 'd2906d4d6a4a4b8ea7406a96080c7a44'\n",
        " 'e04b757602824a4dbe227f1e67dbdbd3' '6dabbda422034b089089b2b719004191'\n",
        " 'e0f9319a8b3048cdb1c974395e599e8d' 'e109b50aca4a43908dd146c55733e354'\n",
        " '7fe752f09aad420b8dfe753dfb713aba' 'a2343d6f691a42a68316eb7b7d08bec2']\n",
        "Frecven»õƒÉ:\n",
        "ranker_id\n",
        "f9833fe7d58441c8a8feed74fec32a2c    8236\n",
        "796854b386874b40b4a8843f70a2b0f7    7841\n",
        "4d0bee7eede2454187405709ea187702    7793\n",
        "db85d3d24c164a798b518be8fbce1f1c    7678\n",
        "92e54e4a04f94eec9c30a59cb729ed5a    7676\n",
        "Name: count, dtype: int64\n",
        "\n",
        "Coloana: requestDate\n",
        "Valori unice (104428): ['2024-05-17T03:03:08.000000000' '2024-05-17T03:09:59.000000000'\n",
        " '2024-05-17T03:10:04.000000000' '2024-05-17T03:31:00.000000000'\n",
        " '2024-05-17T03:40:53.000000000' '2024-05-17T03:51:28.000000000'\n",
        " '2024-05-17T04:02:26.000000000' '2024-05-17T04:06:51.000000000'\n",
        " '2024-05-17T04:08:12.000000000' '2024-05-17T04:10:23.000000000']\n",
        "Frecven»õƒÉ:\n",
        "requestDate\n",
        "2024-07-17T15:29:28.000000000    11673\n",
        "2024-09-08T09:26:02.000000000     8236\n",
        "2024-09-03T17:40:10.000000000     7841\n",
        "2024-09-03T18:10:14.000000000     7793\n",
        "2024-09-12T12:53:40.000000000     7678\n",
        "Name: count, dtype: int64\n",
        "\n",
        "Coloana: searchRoute\n",
        "Valori unice (5769): ['TLKKJA/KJATLK' 'TOFNJC' 'ODOIKT' 'IKTAER' 'KHVUUS' 'KHVBQS' 'GDXOVB'\n",
        " 'KJAIKT' 'IKTODO' 'OVBGDX']\n",
        "Frecven»õƒÉ:\n",
        "searchRoute\n",
        "MOWLED/LEDMOW    3250607\n",
        "LEDMOW/MOWLED    2031821\n",
        "MOWLED           1161009\n",
        "LEDMOW           1126614\n",
        "MOWAER/AERMOW     811476\n",
        "Name: count, dtype: int64\n",
        "\n",
        "Coloana: legs1_departureAt_part_of_day\n",
        "Valori unice (4): ['morning' 'evening' 'afternoon' 'night']\n",
        "Frecven»õƒÉ:\n",
        "legs1_departureAt_part_of_day\n",
        "evening      6657728\n",
        "afternoon    5421663\n",
        "morning      4940995\n",
        "night        1124986\n",
        "Name: count, dtype: int64\n",
        "\n",
        "Coloana: legs1_arrivalAt_part_of_day\n",
        "Valori unice (4): ['afternoon' 'morning' 'night' 'evening']\n",
        "Frecven»õƒÉ:\n",
        "legs1_arrivalAt_part_of_day\n",
        "evening      6503826\n",
        "afternoon    5188524\n",
        "morning      3936293\n",
        "night        2516729\n",
        "Name: count, dtype: int64\n",
        "\n",
        "--- Distribu»õii, Min, Max »ôi Valori unice pentru toate coloanele ---\n",
        "\n",
        "Coloana: Id\n",
        "  Tip: int64\n",
        "  Valori lipsƒÉ: 0 (0.00%)\n",
        "  Valori unice: 18145372\n",
        "  Exemple: [0 1 2 3 4]\n",
        "  Min: 0, Max: 18146431, Mean: 9072685.54, Std: 5238117.92\n",
        "\n",
        "Coloana: bySelf\n",
        "  Tip: bool\n",
        "  Valori lipsƒÉ: 0 (0.00%)\n",
        "  Valori unice: 1\n",
        "  Exemple: [ True]\n",
        "\n",
        "Coloana: companyID\n",
        "  Tip: int64\n",
        "  Valori lipsƒÉ: 0 (0.00%)\n",
        "  Valori unice: 641\n",
        "  Exemple: [57323 53407 59096 62836 25312]\n",
        "  Min: 16636, Max: 63482, Mean: 47293.87, Std: 12119.86\n",
        "\n",
        "Coloana: corporateTariffCode\n",
        "  Tip: float64\n",
        "  Valori lipsƒÉ: 0 (0.00%)\n",
        "  Valori unice: 170\n",
        "  Exemple: [ 42. 123. 161. 101. 130.]\n",
        "  Min: 0.0, Max: 181.0, Mean: 107.23, Std: 47.04\n",
        "\n",
        "Coloana: frequentFlyer\n",
        "  Tip: object\n",
        "  Valori lipsƒÉ: 0 (0.00%)\n",
        "  Valori unice: 371\n",
        "  Exemple: ['S7/SU/UT' 'S7/SU/I8' 'SU/S7/UT/N4' 'S7/UT/SU' 'SU/UT/S7']\n",
        "\n",
        "Coloana: nationality\n",
        "  Tip: int64\n",
        "  Valori lipsƒÉ: 0 (0.00%)\n",
        "  Valori unice: 48\n",
        "  Exemple: [36  6 21 46  8]\n",
        "  Min: 0, Max: 48, Mean: 35.70, Std: 2.92\n",
        "\n",
        "Coloana: isAccess3D\n",
        "  Tip: bool\n",
        "  Valori lipsƒÉ: 0 (0.00%)\n",
        "  Valori unice: 2\n",
        "  Exemple: [False  True]\n",
        "\n",
        "Coloana: isVip\n",
        "  Tip: bool\n",
        "  Valori lipsƒÉ: 0 (0.00%)\n",
        "  Valori unice: 2\n",
        "  Exemple: [False  True]\n",
        "\n",
        "Coloana: legs0_arrivalAt\n",
        "  Tip: object\n",
        "  Valori lipsƒÉ: 0 (0.00%)\n",
        "  Valori unice: 60143\n",
        "  Exemple: ['2024-06-15T16:20:00' '2024-06-15T14:50:00' '2024-06-15T17:20:00'\n",
        " '2024-06-15T21:35:00' '2024-06-15T09:15:00']\n",
        "\n",
        "Coloana: legs0_departureAt\n",
        "  Tip: object\n",
        "  Valori lipsƒÉ: 0 (0.00%)\n",
        "  Valori unice: 56619\n",
        "  Exemple: ['2024-06-15T15:40:00' '2024-06-15T09:25:00' '2024-06-15T11:25:00'\n",
        " '2024-06-15T09:50:00' '2024-05-30T16:00:00']\n",
        "\n",
        "Coloana: legs0_duration\n",
        "  Tip: object\n",
        "  Valori lipsƒÉ: 0 (0.00%)\n",
        "  Valori unice: 1542\n",
        "  Exemple: ['02:40:00' '07:25:00' '09:55:00' '12:10:00' '01:25:00']\n",
        "\n",
        "Coloana: legs0_segments0_aircraft_code\n",
        "  Tip: object\n",
        "  Valori lipsƒÉ: 0 (0.00%)\n",
        "  Valori unice: 108\n",
        "  Exemple: ['YK2' 'E70' 'CRJ' 'AN4' '32N']\n",
        "\n",
        "Coloana: legs0_segments0_arrivalTo_airport_city_iata\n",
        "  Tip: object\n",
        "  Valori lipsƒÉ: 0 (0.00%)\n",
        "  Valori unice: 499\n",
        "  Exemple: ['KJA' 'OVB' 'NJC' 'IKT' 'AER']\n",
        "\n",
        "Coloana: legs0_segments0_arrivalTo_airport_iata\n",
        "  Tip: object\n",
        "  Valori lipsƒÉ: 0 (0.00%)\n",
        "  Valori unice: 533\n",
        "  Exemple: ['KJA' 'OVB' 'NJC' 'IKT' 'AER']\n",
        "\n",
        "Coloana: legs0_segments0_baggageAllowance_quantity\n",
        "  Tip: float64\n",
        "  Valori lipsƒÉ: 0 (0.00%)\n",
        "  Valori unice: 18\n",
        "  Exemple: [ 1.  0. 20.  2. 25. 23. 30. 40. 35. 50. 10. 60. 15.  3. 33. 45. 46. 32.]\n",
        "  Min: 0.0, Max: 60.0, Mean: 2.63, Std: 7.25\n",
        "\n",
        "Coloana: legs0_segments0_baggageAllowance_weightMeasurementType\n",
        "  Tip: float64\n",
        "  Valori lipsƒÉ: 0 (0.00%)\n",
        "  Valori unice: 2\n",
        "  Exemple: [0. 1.]\n",
        "  Min: 0.0, Max: 1.0, Mean: 0.06, Std: 0.24\n",
        "\n",
        "Coloana: legs0_segments0_cabinClass\n",
        "  Tip: float64\n",
        "  Valori lipsƒÉ: 0 (0.00%)\n",
        "  Valori unice: 4\n",
        "  Exemple: [1. 2. 4. 3.]\n",
        "  Min: 1.0, Max: 4.0, Mean: 1.21, Std: 0.49\n",
        "\n",
        "Coloana: legs0_segments0_departureFrom_airport_iata\n",
        "  Tip: object\n",
        "  Valori lipsƒÉ: 0 (0.00%)\n",
        "  Valori unice: 393\n",
        "  Exemple: ['TLK' 'TOF' 'ODO' 'IKT' 'KHV']\n",
        "\n",
        "Coloana: legs0_segments0_duration\n",
        "  Tip: object\n",
        "  Valori lipsƒÉ: 0 (0.00%)\n",
        "  Valori unice: 296\n",
        "  Exemple: ['02:40:00' '02:50:00' '00:50:00' '01:25:00' '02:30:00']\n",
        "\n",
        "Coloana: legs0_segments0_flightNumber\n",
        "  Tip: int64\n",
        "  Valori lipsƒÉ: 0 (0.00%)\n",
        "  Valori unice: 7531\n",
        "  Exemple: [ 216 5358 5322  816  142]\n",
        "  Min: 1, Max: 9996, Mean: 3627.11, Std: 2724.58\n",
        "\n",
        "Coloana: legs0_segments0_marketingCarrier_code\n",
        "  Tip: object\n",
        "  Valori lipsƒÉ: 0 (0.00%)\n",
        "  Valori unice: 164\n",
        "  Exemple: ['KV' 'S7' '7R' 'IO' '–ò–ö']\n",
        "\n",
        "Coloana: legs0_segments0_operatingCarrier_code\n",
        "  Tip: object\n",
        "  Valori lipsƒÉ: 0 (0.00%)\n",
        "  Valori unice: 220\n",
        "  Exemple: ['KV' 'S7' '7R' 'IO' '–ò–ö']\n",
        "\n",
        "Coloana: legs0_segments0_seatsAvailable\n",
        "  Tip: float64\n",
        "  Valori lipsƒÉ: 0 (0.00%)\n",
        "  Valori unice: 10\n",
        "  Exemple: [ 9.  4.  7.  6.  2.  3.  1.  5.  8. 10.]\n",
        "  Min: 1.0, Max: 10.0, Mean: 5.15, Std: 3.11\n",
        "\n",
        "Coloana: legs1_duration\n",
        "  Tip: float64\n",
        "  Valori lipsƒÉ: 0 (0.00%)\n",
        "  Valori unice: 1478\n",
        "  Exemple: [155. 505. 655. 755.  72.]\n",
        "  Min: 1.0, Max: 1646.0, Mean: 255.47, Std: 283.73\n",
        "\n",
        "Coloana: legs1_segments0_aircraft_code\n",
        "  Tip: object\n",
        "  Valori lipsƒÉ: 0 (0.00%)\n",
        "  Valori unice: 93\n",
        "  Exemple: ['YK2' 'E70' '73H' 'SU9' '321']\n",
        "\n",
        "Coloana: legs1_segments0_arrivalTo_airport_city_iata\n",
        "  Tip: object\n",
        "  Valori lipsƒÉ: 0 (0.00%)\n",
        "  Valori unice: 312\n",
        "  Exemple: ['TLK' 'OVB' 'ABA' 'NJC' 'KZN']\n",
        "\n",
        "Coloana: legs1_segments0_arrivalTo_airport_iata\n",
        "  Tip: object\n",
        "  Valori lipsƒÉ: 0 (0.00%)\n",
        "  Valori unice: 338\n",
        "  Exemple: ['TLK' 'OVB' 'ABA' 'NJC' 'KZN']\n",
        "\n",
        "Coloana: legs1_segments0_baggageAllowance_quantity\n",
        "  Tip: float64\n",
        "  Valori lipsƒÉ: 0 (0.00%)\n",
        "  Valori unice: 17\n",
        "  Exemple: [ 1.  0. 20.  2. 10. 23. 30. 40. 35. 50. 25. 45. 15.  3. 60. 33. 32.]\n",
        "  Min: 0.0, Max: 60.0, Mean: 2.60, Std: 7.19\n",
        "\n",
        "Coloana: legs1_segments0_baggageAllowance_weightMeasurementType\n",
        "  Tip: float64\n",
        "  Valori lipsƒÉ: 0 (0.00%)\n",
        "  Valori unice: 2\n",
        "  Exemple: [0. 1.]\n",
        "  Min: 0.0, Max: 1.0, Mean: 0.06, Std: 0.23\n",
        "\n",
        "Coloana: legs1_segments0_cabinClass\n",
        "  Tip: float64\n",
        "  Valori lipsƒÉ: 0 (0.00%)\n",
        "  Valori unice: 4\n",
        "  Exemple: [1. 2. 4. 3.]\n",
        "  Min: 1.0, Max: 4.0, Mean: 1.19, Std: 0.46\n",
        "\n",
        "Coloana: legs1_segments0_departureFrom_airport_iata\n",
        "  Tip: object\n",
        "  Valori lipsƒÉ: 0 (0.00%)\n",
        "  Valori unice: 343\n",
        "  Exemple: ['KJA' 'OVB' 'SVO' 'LED' 'HTA']\n",
        "\n",
        "Coloana: legs1_segments0_duration\n",
        "  Tip: float64\n",
        "  Valori lipsƒÉ: 0 (0.00%)\n",
        "  Valori unice: 754\n",
        "  Exemple: [155.  85.  69.  96. 117.]\n",
        "  Min: 3.0, Max: 1175.0, Mean: 148.23, Std: 82.29\n",
        "\n",
        "Coloana: legs1_segments0_marketingCarrier_code\n",
        "  Tip: object\n",
        "  Valori lipsƒÉ: 0 (0.00%)\n",
        "  Valori unice: 144\n",
        "  Exemple: ['KV' 'S7' 'DP' 'SU' 'N4']\n",
        "\n",
        "Coloana: legs1_segments0_operatingCarrier_code\n",
        "  Tip: object\n",
        "  Valori lipsƒÉ: 0 (0.00%)\n",
        "  Valori unice: 186\n",
        "  Exemple: ['KV' 'S7' 'EO' 'N4' 'U6']\n",
        "\n",
        "Coloana: legs1_segments0_seatsAvailable\n",
        "  Tip: float64\n",
        "  Valori lipsƒÉ: 0 (0.00%)\n",
        "  Valori unice: 9\n",
        "  Exemple: [9. 2. 1. 4. 5. 3. 8. 6. 7.]\n",
        "  Min: 1.0, Max: 9.0, Mean: 5.46, Std: 3.16\n",
        "\n",
        "Coloana: miniRules0_monetaryAmount\n",
        "  Tip: float64\n",
        "  Valori lipsƒÉ: 0 (0.00%)\n",
        "  Valori unice: 640652\n",
        "  Exemple: [3944.20117188 2300.            0.         4000.         2122.98583984]\n",
        "  Min: 0.0, Max: 502237.0, Mean: 2535.51, Std: 3340.50\n",
        "\n",
        "Coloana: miniRules0_statusInfos\n",
        "  Tip: float64\n",
        "  Valori lipsƒÉ: 0 (0.00%)\n",
        "  Valori unice: 2\n",
        "  Exemple: [1. 0.]\n",
        "  Min: 0.0, Max: 1.0, Mean: 0.98, Std: 0.15\n",
        "\n",
        "Coloana: miniRules1_monetaryAmount\n",
        "  Tip: float64\n",
        "  Valori lipsƒÉ: 0 (0.00%)\n",
        "  Valori unice: 527962\n",
        "  Exemple: [ 686.99304199 3500.            0.         1377.74414062 1215.37109375]\n",
        "  Min: 0.0, Max: 7161273.0, Mean: 1344.94, Std: 5733.92\n",
        "\n",
        "Coloana: miniRules1_statusInfos\n",
        "  Tip: float64\n",
        "  Valori lipsƒÉ: 0 (0.00%)\n",
        "  Valori unice: 2\n",
        "  Exemple: [0. 1.]\n",
        "  Min: 0.0, Max: 1.0, Mean: 0.57, Std: 0.50\n",
        "\n",
        "Coloana: pricingInfo_isAccessTP\n",
        "  Tip: float64\n",
        "  Valori lipsƒÉ: 0 (0.00%)\n",
        "  Valori unice: 2\n",
        "  Exemple: [1. 0.]\n",
        "  Min: 0.0, Max: 1.0, Mean: 0.51, Std: 0.50\n",
        "\n",
        "Coloana: pricingInfo_passengerCount\n",
        "  Tip: int64\n",
        "  Valori lipsƒÉ: 0 (0.00%)\n",
        "  Valori unice: 1\n",
        "  Exemple: [1]\n",
        "  Min: 1, Max: 1, Mean: 1.00, Std: 0.00\n",
        "\n",
        "Coloana: profileId\n",
        "  Tip: int64\n",
        "  Valori lipsƒÉ: 0 (0.00%)\n",
        "  Valori unice: 32922\n",
        "  Exemple: [2087645 2087904 2447853 2384252 3382768]\n",
        "  Min: 813, Max: 3604410, Mean: 2494203.03, Std: 950391.40\n",
        "\n",
        "Coloana: ranker_id\n",
        "  Tip: object\n",
        "  Valori lipsƒÉ: 0 (0.00%)\n",
        "  Valori unice: 105539\n",
        "  Exemple: ['98ce0dabf6964640b63079fbafd42cbe' '905909166d934c618ad55ab7f5cea598'\n",
        " '7ec8ce3fdebd4c9699b03582ebd60d5d' 'd2906d4d6a4a4b8ea7406a96080c7a44'\n",
        " 'e04b757602824a4dbe227f1e67dbdbd3']\n",
        "\n",
        "Coloana: requestDate\n",
        "  Tip: object\n",
        "  Valori lipsƒÉ: 0 (0.00%)\n",
        "  Valori unice: 104428\n",
        "  Exemple: ['2024-05-17T03:03:08.000000000' '2024-05-17T03:09:59.000000000'\n",
        " '2024-05-17T03:10:04.000000000' '2024-05-17T03:31:00.000000000'\n",
        " '2024-05-17T03:40:53.000000000']\n",
        "\n",
        "Coloana: searchRoute\n",
        "  Tip: object\n",
        "  Valori lipsƒÉ: 0 (0.00%)\n",
        "  Valori unice: 5769\n",
        "  Exemple: ['TLKKJA/KJATLK' 'TOFNJC' 'ODOIKT' 'IKTAER' 'KHVUUS']\n",
        "\n",
        "Coloana: sex\n",
        "  Tip: bool\n",
        "  Valori lipsƒÉ: 0 (0.00%)\n",
        "  Valori unice: 2\n",
        "  Exemple: [ True False]\n",
        "\n",
        "Coloana: taxes\n",
        "  Tip: float64\n",
        "  Valori lipsƒÉ: 0 (0.00%)\n",
        "  Valori unice: 44448\n",
        "  Exemple: [ 370. 2240.  444.  870. 1185.]\n",
        "  Min: 0.0, Max: 897921.0, Mean: 4284.70, Std: 11839.75\n",
        "\n",
        "Coloana: totalPrice\n",
        "  Tip: float64\n",
        "  Valori lipsƒÉ: 0 (0.00%)\n",
        "  Valori unice: 230704\n",
        "  Exemple: [16884. 51125. 53695. 81880. 86070.]\n",
        "  Min: 770.0, Max: 9944355.0, Mean: 46314.44, Std: 75068.08\n",
        "\n",
        "Coloana: selected\n",
        "  Tip: int64\n",
        "  Valori lipsƒÉ: 0 (0.00%)\n",
        "  Valori unice: 2\n",
        "  Exemple: [1 0]\n",
        "  Min: 0, Max: 1, Mean: 0.01, Std: 0.08\n",
        "\n",
        "Coloana: __index_level_0__\n",
        "  Tip: int64\n",
        "  Valori lipsƒÉ: 0 (0.00%)\n",
        "  Valori unice: 18145372\n",
        "  Exemple: [0 1 2 3 4]\n",
        "  Min: 0, Max: 18146431, Mean: 9072685.54, Std: 5238117.92\n",
        "\n",
        "Coloana: legs0_segments0_baggageAllowance_missing_initially\n",
        "  Tip: int64\n",
        "  Valori lipsƒÉ: 0 (0.00%)\n",
        "  Valori unice: 2\n",
        "  Exemple: [1 0]\n",
        "  Min: 0, Max: 1, Mean: 1.00, Std: 0.01\n",
        "\n",
        "Coloana: legs0_segments0_seatsAvailable_missing_initially\n",
        "  Tip: int64\n",
        "  Valori lipsƒÉ: 0 (0.00%)\n",
        "  Valori unice: 2\n",
        "  Exemple: [1 0]\n",
        "  Min: 0, Max: 1, Mean: 1.00, Std: 0.07\n",
        "\n",
        "Coloana: miniRules0_statusInfos_was_missing\n",
        "  Tip: int64\n",
        "  Valori lipsƒÉ: 0 (0.00%)\n",
        "  Valori unice: 2\n",
        "  Exemple: [0 1]\n",
        "  Min: 0, Max: 1, Mean: 0.92, Std: 0.27\n",
        "\n",
        "Coloana: miniRules1_statusInfos_was_missing\n",
        "  Tip: int64\n",
        "  Valori lipsƒÉ: 0 (0.00%)\n",
        "  Valori unice: 2\n",
        "  Exemple: [0 1]\n",
        "  Min: 0, Max: 1, Mean: 0.92, Std: 0.28\n",
        "\n",
        "Coloana: legs1_segments0_aircraft_code_was_missing\n",
        "  Tip: int64\n",
        "  Valori lipsƒÉ: 0 (0.00%)\n",
        "  Valori unice: 2\n",
        "  Exemple: [1 0]\n",
        "  Min: 0, Max: 1, Mean: 0.76, Std: 0.43\n",
        "\n",
        "Coloana: legs1_departureAt_hour\n",
        "  Tip: float64\n",
        "  Valori lipsƒÉ: 0 (0.00%)\n",
        "  Valori unice: 24\n",
        "  Exemple: [ 9. 22. 19. 17. 14.]\n",
        "  Min: 0.0, Max: 23.0, Mean: 14.43, Std: 6.02\n",
        "\n",
        "Coloana: legs1_departureAt_minute\n",
        "  Tip: float64\n",
        "  Valori lipsƒÉ: 0 (0.00%)\n",
        "  Valori unice: 60\n",
        "  Exemple: [45.  5. 35. 55. 29.]\n",
        "  Min: 0.0, Max: 59.0, Mean: 25.00, Std: 15.74\n",
        "\n",
        "Coloana: legs1_departureAt_is_weekend\n",
        "  Tip: int64\n",
        "  Valori lipsƒÉ: 0 (0.00%)\n",
        "  Valori unice: 2\n",
        "  Exemple: [0 1]\n",
        "  Min: 0, Max: 1, Mean: 0.22, Std: 0.41\n",
        "\n",
        "Coloana: legs1_departureAt_day\n",
        "  Tip: float64\n",
        "  Valori lipsƒÉ: 0 (0.00%)\n",
        "  Valori unice: 31\n",
        "  Exemple: [ 9.  3. 11. 13. 24.]\n",
        "  Min: 1.0, Max: 31.0, Mean: 16.02, Std: 8.83\n",
        "\n",
        "Coloana: legs1_departureAt_month\n",
        "  Tip: float64\n",
        "  Valori lipsƒÉ: 0 (0.00%)\n",
        "  Valori unice: 12\n",
        "  Exemple: [ 7.  9. 10.  8.  5.  6.  4. 11.  3. 12.  2.  1.]\n",
        "  Min: 1.0, Max: 12.0, Mean: 8.71, Std: 1.47\n",
        "\n",
        "Coloana: legs1_departureAt_year\n",
        "  Tip: float64\n",
        "  Valori lipsƒÉ: 0 (0.00%)\n",
        "  Valori unice: 2\n",
        "  Exemple: [2024. 2025.]\n",
        "  Min: 2024.0, Max: 2025.0, Mean: 2024.00, Std: 0.06\n",
        "\n",
        "Coloana: legs1_departureAt_part_of_day\n",
        "  Tip: object\n",
        "  Valori lipsƒÉ: 0 (0.00%)\n",
        "  Valori unice: 4\n",
        "  Exemple: ['morning' 'evening' 'afternoon' 'night']\n",
        "\n",
        "Coloana: legs1_departureAt_hour_sin\n",
        "  Tip: float64\n",
        "  Valori lipsƒÉ: 0 (0.00%)\n",
        "  Valori unice: 21\n",
        "  Exemple: [ 0.70710678 -0.5        -0.96592583 -0.5         0.96592583]\n",
        "  Min: -1.0, Max: 1.0, Mean: -0.20, Std: 0.68\n",
        "\n",
        "Coloana: legs1_departureAt_hour_cos\n",
        "  Tip: float64\n",
        "  Valori lipsƒÉ: 0 (0.00%)\n",
        "  Valori unice: 22\n",
        "  Exemple: [-0.70710678  0.8660254   0.25881905 -0.25881905 -0.8660254 ]\n",
        "  Min: -1.0, Max: 1.0, Mean: -0.10, Std: 0.69\n",
        "\n",
        "Coloana: legs1_arrivalAt_hour\n",
        "  Tip: float64\n",
        "  Valori lipsƒÉ: 0 (0.00%)\n",
        "  Valori unice: 24\n",
        "  Exemple: [14.  8. 15. 12.  7.]\n",
        "  Min: 0.0, Max: 23.0, Mean: 13.75, Std: 6.79\n",
        "\n",
        "Coloana: legs1_arrivalAt_minute\n",
        "  Tip: float64\n",
        "  Valori lipsƒÉ: 0 (0.00%)\n",
        "  Valori unice: 60\n",
        "  Exemple: [20. 30. 37. 31. 35.]\n",
        "  Min: 0.0, Max: 59.0, Mean: 26.61, Std: 16.12\n",
        "\n",
        "Coloana: legs1_arrivalAt_is_weekend\n",
        "  Tip: int64\n",
        "  Valori lipsƒÉ: 0 (0.00%)\n",
        "  Valori unice: 2\n",
        "  Exemple: [0 1]\n",
        "  Min: 0, Max: 1, Mean: 0.25, Std: 0.44\n",
        "\n",
        "Coloana: legs1_arrivalAt_day\n",
        "  Tip: float64\n",
        "  Valori lipsƒÉ: 0 (0.00%)\n",
        "  Valori unice: 31\n",
        "  Exemple: [ 9. 10. 18. 16. 11.]\n",
        "  Min: 1.0, Max: 31.0, Mean: 15.95, Std: 8.81\n",
        "\n",
        "Coloana: legs1_arrivalAt_month\n",
        "  Tip: float64\n",
        "  Valori lipsƒÉ: 0 (0.00%)\n",
        "  Valori unice: 12\n",
        "  Exemple: [ 7. 10.  8.  9.  5.  6.  4. 11.  3.  2. 12.  1.]\n",
        "  Min: 1.0, Max: 12.0, Mean: 8.71, Std: 1.47\n",
        "\n",
        "Coloana: legs1_arrivalAt_year\n",
        "  Tip: float64\n",
        "  Valori lipsƒÉ: 0 (0.00%)\n",
        "  Valori unice: 2\n",
        "  Exemple: [2024. 2025.]\n",
        "  Min: 2024.0, Max: 2025.0, Mean: 2024.00, Std: 0.06\n",
        "\n",
        "Coloana: legs1_arrivalAt_part_of_day\n",
        "  Tip: object\n",
        "  Valori lipsƒÉ: 0 (0.00%)\n",
        "  Valori unice: 4\n",
        "  Exemple: ['afternoon' 'morning' 'night' 'evening']\n",
        "\n",
        "Coloana: legs1_arrivalAt_hour_sin\n",
        "  Tip: float64\n",
        "  Valori lipsƒÉ: 0 (0.00%)\n",
        "  Valori unice: 21\n",
        "  Exemple: [-5.00000000e-01  8.66025404e-01 -7.07106781e-01  1.22464680e-16\n",
        "  9.65925826e-01]\n",
        "  Min: -1.0, Max: 1.0, Mean: -0.20, Std: 0.66\n",
        "\n",
        "Coloana: legs1_arrivalAt_hour_cos\n",
        "  Tip: float64\n",
        "  Valori lipsƒÉ: 0 (0.00%)\n",
        "  Valori unice: 22\n",
        "  Exemple: [-0.8660254  -0.5        -0.70710678 -1.         -0.25881905]\n",
        "  Min: -1.0, Max: 1.0, Mean: -0.01, Std: 0.73\n",
        "\n",
        "===== TEST.CSV INFO =====\n",
        "NumƒÉr de r√¢nduri: 6897776\n",
        "NumƒÉr de coloane: 71\n",
        "\n",
        "--- Tipuri de date »ôi valori lipsƒÉ ---\n",
        "<class 'pandas.core.frame.DataFrame'>\n",
        "RangeIndex: 6897776 entries, 0 to 6897775\n",
        "Data columns (total 71 columns):\n",
        " #   Column                                                  Dtype\n",
        "---  ------                                                  -----\n",
        " 0   Id                                                      int64\n",
        " 1   bySelf                                                  bool\n",
        " 2   companyID                                               int64\n",
        " 3   corporateTariffCode                                     float64\n",
        " 4   frequentFlyer                                           object\n",
        " 5   nationality                                             int64\n",
        " 6   isAccess3D                                              bool\n",
        " 7   isVip                                                   bool\n",
        " 8   legs0_arrivalAt                                         object\n",
        " 9   legs0_departureAt                                       object\n",
        " 10  legs0_duration                                          object\n",
        " 11  legs0_segments0_aircraft_code                           object\n",
        " 12  legs0_segments0_arrivalTo_airport_city_iata             object\n",
        " 13  legs0_segments0_arrivalTo_airport_iata                  object\n",
        " 14  legs0_segments0_baggageAllowance_quantity               float64\n",
        " 15  legs0_segments0_baggageAllowance_weightMeasurementType  float64\n",
        " 16  legs0_segments0_cabinClass                              float64\n",
        " 17  legs0_segments0_departureFrom_airport_iata              object\n",
        " 18  legs0_segments0_duration                                object\n",
        " 19  legs0_segments0_flightNumber                            int64\n",
        " 20  legs0_segments0_marketingCarrier_code                   object\n",
        " 21  legs0_segments0_operatingCarrier_code                   object\n",
        " 22  legs0_segments0_seatsAvailable                          float64\n",
        " 23  legs1_duration                                          float64\n",
        " 24  legs1_segments0_aircraft_code                           object\n",
        " 25  legs1_segments0_arrivalTo_airport_city_iata             object\n",
        " 26  legs1_segments0_arrivalTo_airport_iata                  object\n",
        " 27  legs1_segments0_baggageAllowance_quantity               float64\n",
        " 28  legs1_segments0_baggageAllowance_weightMeasurementType  float64\n",
        " 29  legs1_segments0_cabinClass                              float64\n",
        " 30  legs1_segments0_departureFrom_airport_iata              object\n",
        " 31  legs1_segments0_duration                                float64\n",
        " 32  legs1_segments0_marketingCarrier_code                   object\n",
        " 33  legs1_segments0_operatingCarrier_code                   object\n",
        " 34  legs1_segments0_seatsAvailable                          float64\n",
        " 35  miniRules0_monetaryAmount                               float64\n",
        " 36  miniRules0_statusInfos                                  float64\n",
        " 37  miniRules1_monetaryAmount                               float64\n",
        " 38  miniRules1_statusInfos                                  float64\n",
        " 39  pricingInfo_isAccessTP                                  float64\n",
        " 40  pricingInfo_passengerCount                              int64\n",
        " 41  profileId                                               int64\n",
        " 42  ranker_id                                               object\n",
        " 43  requestDate                                             object\n",
        " 44  searchRoute                                             object\n",
        " 45  sex                                                     bool\n",
        " 46  taxes                                                   float64\n",
        " 47  totalPrice                                              float64\n",
        " 48  __index_level_0__                                       int64\n",
        " 49  legs0_segments0_baggageAllowance_missing_initially      int64\n",
        " 50  miniRules0_statusInfos_was_missing                      int64\n",
        " 51  miniRules1_statusInfos_was_missing                      int64\n",
        " 52  legs1_segments0_aircraft_code_was_missing               int64\n",
        " 53  legs1_departureAt_hour                                  float64\n",
        " 54  legs1_departureAt_minute                                float64\n",
        " 55  legs1_departureAt_is_weekend                            int64\n",
        " 56  legs1_departureAt_day                                   float64\n",
        " 57  legs1_departureAt_month                                 float64\n",
        " 58  legs1_departureAt_year                                  float64\n",
        " 59  legs1_departureAt_part_of_day                           object\n",
        " 60  legs1_departureAt_hour_sin                              float64\n",
        " 61  legs1_departureAt_hour_cos                              float64\n",
        " 62  legs1_arrivalAt_hour                                    float64\n",
        " 63  legs1_arrivalAt_minute                                  float64\n",
        " 64  legs1_arrivalAt_is_weekend                              int64\n",
        " 65  legs1_arrivalAt_day                                     float64\n",
        " 66  legs1_arrivalAt_month                                   float64\n",
        " 67  legs1_arrivalAt_year                                    float64\n",
        " 68  legs1_arrivalAt_part_of_day                             object\n",
        " 69  legs1_arrivalAt_hour_sin                                float64\n",
        " 70  legs1_arrivalAt_hour_cos                                float64\n",
        "dtypes: bool(4), float64(32), int64(13), object(22)\n",
        "memory usage: 3.5+ GB\n",
        "None\n",
        "\n",
        "--- Descriptive Statistics (Numerice) ---\n",
        "                                                        count  ...         max\n",
        "Id                                                  6897776.0  ...  25043147.0\n",
        "companyID                                           6897776.0  ...     63482.0\n",
        "corporateTariffCode                                 6897776.0  ...       181.0\n",
        "nationality                                         6897776.0  ...        47.0\n",
        "legs0_segments0_baggageAllowance_quantity           6897776.0  ...        60.0\n",
        "legs0_segments0_baggageAllowance_weightMeasurem...  6897776.0  ...         1.0\n",
        "legs0_segments0_cabinClass                          6897776.0  ...         4.0\n",
        "legs0_segments0_flightNumber                        6897776.0  ...      9980.0\n",
        "legs0_segments0_seatsAvailable                      6897776.0  ...         9.0\n",
        "legs1_duration                                      6897776.0  ...      1523.0\n",
        "legs1_segments0_baggageAllowance_quantity           6897776.0  ...        60.0\n",
        "legs1_segments0_baggageAllowance_weightMeasurem...  6897776.0  ...         1.0\n",
        "legs1_segments0_cabinClass                          6897776.0  ...         4.0\n",
        "legs1_segments0_duration                            6897776.0  ...      1130.0\n",
        "legs1_segments0_seatsAvailable                      6897776.0  ...         9.0\n",
        "miniRules0_monetaryAmount                           6897776.0  ...    243187.0\n",
        "miniRules0_statusInfos                              6897776.0  ...         1.0\n",
        "miniRules1_monetaryAmount                           6897776.0  ...    473635.0\n",
        "miniRules1_statusInfos                              6897776.0  ...         1.0\n",
        "pricingInfo_isAccessTP                              6897776.0  ...         1.0\n",
        "pricingInfo_passengerCount                          6897776.0  ...         1.0\n",
        "profileId                                           6897776.0  ...   3667551.0\n",
        "taxes                                               6897776.0  ...    840097.0\n",
        "totalPrice                                          6897776.0  ...   9934573.0\n",
        "__index_level_0__                                   6897776.0  ...  25043147.0\n",
        "legs0_segments0_baggageAllowance_missing_initially  6897776.0  ...         1.0\n",
        "miniRules0_statusInfos_was_missing                  6897776.0  ...         1.0\n",
        "miniRules1_statusInfos_was_missing                  6897776.0  ...         1.0\n",
        "legs1_segments0_aircraft_code_was_missing           6897776.0  ...         1.0\n",
        "legs1_departureAt_hour                              6897776.0  ...        23.0\n",
        "legs1_departureAt_minute                            6897776.0  ...        59.0\n",
        "legs1_departureAt_is_weekend                        6897776.0  ...         1.0\n",
        "legs1_departureAt_day                               6897776.0  ...        31.0\n",
        "legs1_departureAt_month                             6897776.0  ...        12.0\n",
        "legs1_departureAt_year                              6897776.0  ...      2025.0\n",
        "legs1_departureAt_hour_sin                          6897776.0  ...         1.0\n",
        "legs1_departureAt_hour_cos                          6897776.0  ...         1.0\n",
        "legs1_arrivalAt_hour                                6897776.0  ...        23.0\n",
        "legs1_arrivalAt_minute                              6897776.0  ...        59.0\n",
        "legs1_arrivalAt_is_weekend                          6897776.0  ...         1.0\n",
        "legs1_arrivalAt_day                                 6897776.0  ...        31.0\n",
        "legs1_arrivalAt_month                               6897776.0  ...        12.0\n",
        "legs1_arrivalAt_year                                6897776.0  ...      2025.0\n",
        "legs1_arrivalAt_hour_sin                            6897776.0  ...         1.0\n",
        "legs1_arrivalAt_hour_cos                            6897776.0  ...         1.0\n",
        "\n",
        "[45 rows x 8 columns]\n",
        "\n",
        "--- Descriptive Statistics (Categorice) ---\n",
        "\n",
        "Coloana: frequentFlyer\n",
        "Valori unice (417): ['SU' 'S7/SU' 'SU/S7' 'SU/B2' 'SU/B2/KC' 'SU/S7/KC/UT' 'SU/EK' 'TK'\n",
        " 'S7/SU/UT' 'S7']\n",
        "Frecven»õƒÉ:\n",
        "frequentFlyer\n",
        "SU          3981260\n",
        "SU/S7        932857\n",
        "S7/SU        514990\n",
        "S7           235467\n",
        "SU/S7/UT      99182\n",
        "Name: count, dtype: int64\n",
        "\n",
        "Coloana: legs0_arrivalAt\n",
        "Valori unice (29117): ['2024-12-19T11:20:00' '2024-12-19T12:45:00' '2024-12-20T03:50:00'\n",
        " '2024-12-20T04:20:00' '2024-12-19T14:20:00' '2024-12-19T22:05:00'\n",
        " '2024-12-20T00:55:00' '2024-12-20T02:20:00' '2024-12-20T04:05:00'\n",
        " '2024-12-19T18:00:00']\n",
        "Frecven»õƒÉ:\n",
        "legs0_arrivalAt\n",
        "2025-02-03T20:15:00    10347\n",
        "2025-02-03T23:05:00     6606\n",
        "2025-02-03T15:05:00     6095\n",
        "2025-02-04T00:05:00     5920\n",
        "2025-02-03T12:20:00     5577\n",
        "Name: count, dtype: int64\n",
        "\n",
        "Coloana: legs0_departureAt\n",
        "Valori unice (27294): ['2024-12-19T06:50:00' '2024-12-19T08:25:00' '2024-12-19T23:25:00'\n",
        " '2024-12-19T23:55:00' '2024-12-19T10:00:00' '2024-12-19T17:45:00'\n",
        " '2024-12-19T20:35:00' '2024-12-19T22:00:00' '2024-12-19T23:45:00'\n",
        " '2024-12-19T13:35:00']\n",
        "Frecven»õƒÉ:\n",
        "legs0_departureAt\n",
        "2025-02-03T16:30:00    8756\n",
        "2025-02-03T09:15:00    8101\n",
        "2024-12-04T11:00:00    7630\n",
        "2024-11-20T11:30:00    7372\n",
        "2024-11-20T11:00:00    7362\n",
        "Name: count, dtype: int64\n",
        "\n",
        "Coloana: legs0_duration\n",
        "Valori unice (1024): ['02:30:00' '02:20:00' '02:25:00' '02:35:00' '02:40:00' '07:30:00'\n",
        " '12:00:00' '04:35:00' '04:40:00' '04:45:00']\n",
        "Frecven»õƒÉ:\n",
        "legs0_duration\n",
        "01:40:00    2213466\n",
        "01:35:00     807684\n",
        "01:45:00     553931\n",
        "01:30:00     160680\n",
        "02:40:00     117778\n",
        "Name: count, dtype: int64\n",
        "\n",
        "Coloana: legs0_segments0_aircraft_code\n",
        "Valori unice (93): ['32A' '320' '73H' '32N' '333' '32B' '7M8' '738' 'SU9' '789']\n",
        "Frecven»õƒÉ:\n",
        "legs0_segments0_aircraft_code\n",
        "SU9    3304389\n",
        "32A     577763\n",
        "73H     549876\n",
        "32B     542038\n",
        "320     541774\n",
        "Name: count, dtype: int64\n",
        "\n",
        "Coloana: legs0_segments0_arrivalTo_airport_city_iata\n",
        "Valori unice (386): ['SVX' 'OVB' 'ALA' 'NQZ' 'CIT' 'LED' 'TAS' 'BAK' 'IST' 'BJS']\n",
        "Frecven»õƒÉ:\n",
        "legs0_segments0_arrivalTo_airport_city_iata\n",
        "LED    2342858\n",
        "MOW    2331945\n",
        "AER     357402\n",
        "SVX     296480\n",
        "OVB     196742\n",
        "Name: count, dtype: int64\n",
        "\n",
        "Coloana: legs0_segments0_arrivalTo_airport_iata\n",
        "Valori unice (413): ['SVX' 'OVB' 'ALA' 'NQZ' 'CIT' 'LED' 'TAS' 'GYD' 'IST' 'PKX']\n",
        "Frecven»õƒÉ:\n",
        "legs0_segments0_arrivalTo_airport_iata\n",
        "LED    2342858\n",
        "SVO    1484397\n",
        "VKO     604228\n",
        "AER     357402\n",
        "SVX     296480\n",
        "Name: count, dtype: int64\n",
        "\n",
        "Coloana: legs0_segments0_departureFrom_airport_iata\n",
        "Valori unice (290): ['SVO' 'DME' 'VKO' 'KZN' 'OVB' 'LED' 'DXB' 'KUF' 'IST' 'ZIA']\n",
        "Frecven»õƒÉ:\n",
        "legs0_segments0_departureFrom_airport_iata\n",
        "SVO    2394433\n",
        "LED    1529889\n",
        "VKO    1069548\n",
        "DME     417614\n",
        "SVX     170454\n",
        "Name: count, dtype: int64\n",
        "\n",
        "Coloana: legs0_segments0_duration\n",
        "Valori unice (214): ['02:30:00' '02:20:00' '02:25:00' '02:35:00' '02:40:00' '04:05:00'\n",
        " '04:35:00' '04:40:00' '04:45:00' '03:00:00']\n",
        "Frecven»õƒÉ:\n",
        "legs0_segments0_duration\n",
        "01:40:00    2266050\n",
        "01:35:00     843241\n",
        "01:45:00     587908\n",
        "02:20:00     187274\n",
        "01:30:00     173301\n",
        "Name: count, dtype: int64\n",
        "\n",
        "Coloana: legs0_segments0_marketingCarrier_code\n",
        "Valori unice (136): ['SU' 'U6' 'DP' 'S7' 'DV' 'HY' 'J2' 'TK' 'CZ' 'N4']\n",
        "Frecven»õƒÉ:\n",
        "legs0_segments0_marketingCarrier_code\n",
        "SU    4808781\n",
        "U6     404319\n",
        "S7     382823\n",
        "DP     251517\n",
        "TK     158722\n",
        "Name: count, dtype: int64\n",
        "\n",
        "Coloana: legs0_segments0_operatingCarrier_code\n",
        "Valori unice (170): ['SU' 'U6' 'DP' 'S7' 'DV' 'FV' 'HY' 'J2' 'TK' 'CZ']\n",
        "Frecven»õƒÉ:\n",
        "legs0_segments0_operatingCarrier_code\n",
        "FV    3377167\n",
        "SU    1422753\n",
        "U6     404319\n",
        "S7     382222\n",
        "DP     251517\n",
        "Name: count, dtype: int64\n",
        "\n",
        "Coloana: legs1_segments0_aircraft_code\n",
        "Valori unice (94): ['32B' '32N' '320' '73H' '32A' 'E70' '7M8' '319' '737' '32Q']\n",
        "Frecven»õƒÉ:\n",
        "legs1_segments0_aircraft_code\n",
        "SU9    3284661\n",
        "73H     605434\n",
        "32B     565255\n",
        "32A     558852\n",
        "320     542247\n",
        "Name: count, dtype: int64\n",
        "\n",
        "Coloana: legs1_segments0_arrivalTo_airport_city_iata\n",
        "Valori unice (282): ['MOW' 'OVB' 'LED' 'NQZ' 'TAS' 'BAK' 'IST' 'BJS' 'KZN' 'KUF']\n",
        "Frecven»õƒÉ:\n",
        "legs1_segments0_arrivalTo_airport_city_iata\n",
        "MOW    3644054\n",
        "LED    1478167\n",
        "SVX     259467\n",
        "OVB     205681\n",
        "KZN     158139\n",
        "Name: count, dtype: int64\n",
        "\n",
        "Coloana: legs1_segments0_arrivalTo_airport_iata\n",
        "Valori unice (304): ['SVO' 'DME' 'VKO' 'OVB' 'LED' 'NQZ' 'TAS' 'GYD' 'IST' 'PKX']\n",
        "Frecven»õƒÉ:\n",
        "legs1_segments0_arrivalTo_airport_iata\n",
        "SVO    2291377\n",
        "LED    1442148\n",
        "VKO     936221\n",
        "DME     337668\n",
        "SVX     269303\n",
        "Name: count, dtype: int64\n",
        "\n",
        "Coloana: legs1_segments0_departureFrom_airport_iata\n",
        "Valori unice (338): ['SVX' 'ALA' 'SVO' 'DME' 'ZIA' 'VKO' 'OVB' 'LED' 'KJA' 'AER']\n",
        "Frecven»õƒÉ:\n",
        "legs1_segments0_departureFrom_airport_iata\n",
        "LED    2339509\n",
        "SVO    1220733\n",
        "VKO     670632\n",
        "AER     384921\n",
        "DME     249666\n",
        "Name: count, dtype: int64\n",
        "\n",
        "Coloana: legs1_segments0_marketingCarrier_code\n",
        "Valori unice (137): ['SU' 'U6' 'DP' 'S7' 'DV' 'HY' 'J2' 'TK' 'CZ' '5N']\n",
        "Frecven»õƒÉ:\n",
        "legs1_segments0_marketingCarrier_code\n",
        "SU    4755435\n",
        "U6     380017\n",
        "S7     378223\n",
        "DP     226756\n",
        "TK     163455\n",
        "Name: count, dtype: int64\n",
        "\n",
        "Coloana: legs1_segments0_operatingCarrier_code\n",
        "Valori unice (169): ['SU' 'U6' 'DP' 'S7' 'DV' 'FV' 'HY' 'J2' 'TK' 'KC']\n",
        "Frecven»õƒÉ:\n",
        "legs1_segments0_operatingCarrier_code\n",
        "FV    3199314\n",
        "SU    1573985\n",
        "U6     379187\n",
        "S7     378974\n",
        "DP     231062\n",
        "Name: count, dtype: int64\n",
        "\n",
        "Coloana: ranker_id\n",
        "Valori unice (45231): ['c9373e5f772e43d593dd6ad2fa90f67a' '2e6b0b51f761433cb28fae7c439db04c'\n",
        " '726ad47c29bb4196b54bbe283a7267bb' '458c1e8431814da99092580f45eed7e8'\n",
        " '8c387f33dc824a89ba7a6f2cb5908e36' 'c20984555e9c45e2a351943dd8616caa'\n",
        " '47131784f2dc47a2b34369443052a197' 'bb4cc7c6993b4883a626c39d1f817e03'\n",
        " 'a08c023735464fa7b8f2d5c13850ee6a' '72f9c70ad8e04feabf9d38dd1dd7f140']\n",
        "Frecven»õƒÉ:\n",
        "ranker_id\n",
        "ccedcdeb3bf646d7abaa9ac6ba1ca9f7    7022\n",
        "53f9b3c0949f459bb8e4cf15044a43c3    6840\n",
        "e9f3de07c353417bb937cfe35342bd43    6360\n",
        "674d9cad04ac4880bf28b61c88b58120    6352\n",
        "61eac0f0364d472cbe71551924439653    6335\n",
        "Name: count, dtype: int64\n",
        "\n",
        "Coloana: requestDate\n",
        "Valori unice (44738): ['2024-10-29T12:50:42.000000000' '2024-10-29T12:52:12.000000000'\n",
        " '2024-10-29T12:49:43.000000000' '2024-10-29T12:50:13.000000000'\n",
        " '2024-10-29T12:53:16.000000000' '2024-10-29T12:53:04.000000000'\n",
        " '2024-10-29T12:56:49.000000000' '2024-10-29T12:55:32.000000000'\n",
        " '2024-10-29T12:56:25.000000000' '2024-10-29T12:58:03.000000000']\n",
        "Frecven»õƒÉ:\n",
        "requestDate\n",
        "2024-12-18T10:47:41.000000000    7022\n",
        "2024-12-04T17:50:47.000000000    6840\n",
        "2024-12-03T11:43:59.000000000    6360\n",
        "2024-12-04T08:47:07.000000000    6352\n",
        "2024-12-16T19:21:01.000000000    6335\n",
        "Name: count, dtype: int64\n",
        "\n",
        "Coloana: searchRoute\n",
        "Valori unice (3646): ['MOWSVX/SVXMOW' 'MOWALA/ALAMOW' 'KZNMOW/MOWKZN' 'OVBMOW' 'LEDMOW/MOWLED'\n",
        " 'DXBLON' 'KUFAER/AERKUF' 'MOWSZX/SZXMOW' 'ISTMOW' 'KUFGOJ/GOJKUF']\n",
        "Frecven»õƒÉ:\n",
        "searchRoute\n",
        "MOWLED/LEDMOW    1997387\n",
        "LEDMOW/MOWLED    1145816\n",
        "MOWAER/AERMOW     293821\n",
        "LEDMOW            229396\n",
        "MOWLED            223257\n",
        "Name: count, dtype: int64\n",
        "\n",
        "Coloana: legs1_departureAt_part_of_day\n",
        "Valori unice (4): ['evening' 'afternoon' 'morning' 'night']\n",
        "Frecven»õƒÉ:\n",
        "legs1_departureAt_part_of_day\n",
        "evening      2384321\n",
        "morning      2209612\n",
        "afternoon    2079773\n",
        "night         224070\n",
        "Name: count, dtype: int64\n",
        "\n",
        "Coloana: legs1_arrivalAt_part_of_day\n",
        "Valori unice (4): ['evening' 'afternoon' 'morning' 'night']\n",
        "Frecven»õƒÉ:\n",
        "legs1_arrivalAt_part_of_day\n",
        "evening      2414900\n",
        "afternoon    2053985\n",
        "morning      1698491\n",
        "night         730400\n",
        "Name: count, dtype: int64\n",
        "\n",
        "--- Distribu»õii, Min, Max »ôi Valori unice pentru toate coloanele ---\n",
        "\n",
        "Coloana: Id\n",
        "  Tip: int64\n",
        "  Valori lipsƒÉ: 0 (0.00%)\n",
        "  Valori unice: 6897776\n",
        "  Exemple: [18144679 18144680 18144681 18144682 18144683]\n",
        "  Min: 18144679, Max: 25043147, Mean: 21594259.40, Std: 1991216.74\n",
        "\n",
        "Coloana: bySelf\n",
        "  Tip: bool\n",
        "  Valori lipsƒÉ: 0 (0.00%)\n",
        "  Valori unice: 2\n",
        "  Exemple: [ True False]\n",
        "\n",
        "Coloana: companyID\n",
        "  Tip: int64\n",
        "  Valori lipsƒÉ: 0 (0.00%)\n",
        "  Valori unice: 495\n",
        "  Exemple: [62840 59766 42620 28626 36948]\n",
        "  Min: 16636, Max: 63482, Mean: 44505.69, Std: 13024.60\n",
        "\n",
        "Coloana: corporateTariffCode\n",
        "  Tip: float64\n",
        "  Valori lipsƒÉ: 0 (0.00%)\n",
        "  Valori unice: 179\n",
        "  Exemple: [ 81. 179.  50. 139.  62.]\n",
        "  Min: 0.0, Max: 181.0, Mean: 105.83, Std: 46.53\n",
        "\n",
        "Coloana: frequentFlyer\n",
        "  Tip: object\n",
        "  Valori lipsƒÉ: 0 (0.00%)\n",
        "  Valori unice: 417\n",
        "  Exemple: ['SU' 'S7/SU' 'SU/S7' 'SU/B2' 'SU/B2/KC']\n",
        "\n",
        "Coloana: nationality\n",
        "  Tip: int64\n",
        "  Valori lipsƒÉ: 0 (0.00%)\n",
        "  Valori unice: 34\n",
        "  Exemple: [36 47 21 23  0]\n",
        "  Min: 0, Max: 47, Mean: 35.77, Std: 2.43\n",
        "\n",
        "Coloana: isAccess3D\n",
        "  Tip: bool\n",
        "  Valori lipsƒÉ: 0 (0.00%)\n",
        "  Valori unice: 2\n",
        "  Exemple: [False  True]\n",
        "\n",
        "Coloana: isVip\n",
        "  Tip: bool\n",
        "  Valori lipsƒÉ: 0 (0.00%)\n",
        "  Valori unice: 2\n",
        "  Exemple: [False  True]\n",
        "\n",
        "Coloana: legs0_arrivalAt\n",
        "  Tip: object\n",
        "  Valori lipsƒÉ: 0 (0.00%)\n",
        "  Valori unice: 29117\n",
        "  Exemple: ['2024-12-19T11:20:00' '2024-12-19T12:45:00' '2024-12-20T03:50:00'\n",
        " '2024-12-20T04:20:00' '2024-12-19T14:20:00']\n",
        "\n",
        "Coloana: legs0_departureAt\n",
        "  Tip: object\n",
        "  Valori lipsƒÉ: 0 (0.00%)\n",
        "  Valori unice: 27294\n",
        "  Exemple: ['2024-12-19T06:50:00' '2024-12-19T08:25:00' '2024-12-19T23:25:00'\n",
        " '2024-12-19T23:55:00' '2024-12-19T10:00:00']\n",
        "\n",
        "Coloana: legs0_duration\n",
        "  Tip: object\n",
        "  Valori lipsƒÉ: 0 (0.00%)\n",
        "  Valori unice: 1024\n",
        "  Exemple: ['02:30:00' '02:20:00' '02:25:00' '02:35:00' '02:40:00']\n",
        "\n",
        "Coloana: legs0_segments0_aircraft_code\n",
        "  Tip: object\n",
        "  Valori lipsƒÉ: 0 (0.00%)\n",
        "  Valori unice: 93\n",
        "  Exemple: ['32A' '320' '73H' '32N' '333']\n",
        "\n",
        "Coloana: legs0_segments0_arrivalTo_airport_city_iata\n",
        "  Tip: object\n",
        "  Valori lipsƒÉ: 0 (0.00%)\n",
        "  Valori unice: 386\n",
        "  Exemple: ['SVX' 'OVB' 'ALA' 'NQZ' 'CIT']\n",
        "\n",
        "Coloana: legs0_segments0_arrivalTo_airport_iata\n",
        "  Tip: object\n",
        "  Valori lipsƒÉ: 0 (0.00%)\n",
        "  Valori unice: 413\n",
        "  Exemple: ['SVX' 'OVB' 'ALA' 'NQZ' 'CIT']\n",
        "\n",
        "Coloana: legs0_segments0_baggageAllowance_quantity\n",
        "  Tip: float64\n",
        "  Valori lipsƒÉ: 0 (0.00%)\n",
        "  Valori unice: 17\n",
        "  Exemple: [ 0.  1.  2. 40. 30. 35. 25. 20. 10. 50. 23. 33.  3. 60. 15. 45. 46.]\n",
        "  Min: 0.0, Max: 60.0, Mean: 2.34, Std: 6.89\n",
        "\n",
        "Coloana: legs0_segments0_baggageAllowance_weightMeasurementType\n",
        "  Tip: float64\n",
        "  Valori lipsƒÉ: 0 (0.00%)\n",
        "  Valori unice: 2\n",
        "  Exemple: [0. 1.]\n",
        "  Min: 0.0, Max: 1.0, Mean: 0.05, Std: 0.23\n",
        "\n",
        "Coloana: legs0_segments0_cabinClass\n",
        "  Tip: float64\n",
        "  Valori lipsƒÉ: 0 (0.00%)\n",
        "  Valori unice: 4\n",
        "  Exemple: [1. 2. 4. 3.]\n",
        "  Min: 1.0, Max: 4.0, Mean: 1.04, Std: 0.20\n",
        "\n",
        "Coloana: legs0_segments0_departureFrom_airport_iata\n",
        "  Tip: object\n",
        "  Valori lipsƒÉ: 0 (0.00%)\n",
        "  Valori unice: 290\n",
        "  Exemple: ['SVO' 'DME' 'VKO' 'KZN' 'OVB']\n",
        "\n",
        "Coloana: legs0_segments0_duration\n",
        "  Tip: object\n",
        "  Valori lipsƒÉ: 0 (0.00%)\n",
        "  Valori unice: 214\n",
        "  Exemple: ['02:30:00' '02:20:00' '02:25:00' '02:35:00' '02:40:00']\n",
        "\n",
        "Coloana: legs0_segments0_flightNumber\n",
        "  Tip: int64\n",
        "  Valori lipsƒÉ: 0 (0.00%)\n",
        "  Valori unice: 5714\n",
        "  Exemple: [1410  273 6541  403  261]\n",
        "  Min: 1, Max: 9980, Mean: 3856.57, Std: 2749.47\n",
        "\n",
        "Coloana: legs0_segments0_marketingCarrier_code\n",
        "  Tip: object\n",
        "  Valori lipsƒÉ: 0 (0.00%)\n",
        "  Valori unice: 136\n",
        "  Exemple: ['SU' 'U6' 'DP' 'S7' 'DV']\n",
        "\n",
        "Coloana: legs0_segments0_operatingCarrier_code\n",
        "  Tip: object\n",
        "  Valori lipsƒÉ: 0 (0.00%)\n",
        "  Valori unice: 170\n",
        "  Exemple: ['SU' 'U6' 'DP' 'S7' 'DV']\n",
        "\n",
        "Coloana: legs0_segments0_seatsAvailable\n",
        "  Tip: float64\n",
        "  Valori lipsƒÉ: 0 (0.00%)\n",
        "  Valori unice: 9\n",
        "  Exemple: [4. 7. 2. 9. 6. 8. 3. 5. 1.]\n",
        "  Min: 1.0, Max: 9.0, Mean: 4.93, Std: 3.23\n",
        "\n",
        "Coloana: legs1_duration\n",
        "  Tip: float64\n",
        "  Valori lipsƒÉ: 0 (0.00%)\n",
        "  Valori unice: 1403\n",
        "  Exemple: [165. 155. 160. 170. 470.]\n",
        "  Min: 1.0, Max: 1523.0, Mean: 252.47, Std: 295.19\n",
        "\n",
        "Coloana: legs1_segments0_aircraft_code\n",
        "  Tip: object\n",
        "  Valori lipsƒÉ: 0 (0.00%)\n",
        "  Valori unice: 94\n",
        "  Exemple: ['32B' '32N' '320' '73H' '32A']\n",
        "\n",
        "Coloana: legs1_segments0_arrivalTo_airport_city_iata\n",
        "  Tip: object\n",
        "  Valori lipsƒÉ: 0 (0.00%)\n",
        "  Valori unice: 282\n",
        "  Exemple: ['MOW' 'OVB' 'LED' 'NQZ' 'TAS']\n",
        "\n",
        "Coloana: legs1_segments0_arrivalTo_airport_iata\n",
        "  Tip: object\n",
        "  Valori lipsƒÉ: 0 (0.00%)\n",
        "  Valori unice: 304\n",
        "  Exemple: ['SVO' 'DME' 'VKO' 'OVB' 'LED']\n",
        "\n",
        "Coloana: legs1_segments0_baggageAllowance_quantity\n",
        "  Tip: float64\n",
        "  Valori lipsƒÉ: 0 (0.00%)\n",
        "  Valori unice: 16\n",
        "  Exemple: [ 0.  1.  2. 40. 30. 35. 25. 20. 10. 50. 23. 15.  3. 33. 60. 45.]\n",
        "  Min: 0.0, Max: 60.0, Mean: 2.33, Std: 6.87\n",
        "\n",
        "Coloana: legs1_segments0_baggageAllowance_weightMeasurementType\n",
        "  Tip: float64\n",
        "  Valori lipsƒÉ: 0 (0.00%)\n",
        "  Valori unice: 2\n",
        "  Exemple: [0. 1.]\n",
        "  Min: 0.0, Max: 1.0, Mean: 0.05, Std: 0.22\n",
        "\n",
        "Coloana: legs1_segments0_cabinClass\n",
        "  Tip: float64\n",
        "  Valori lipsƒÉ: 0 (0.00%)\n",
        "  Valori unice: 4\n",
        "  Exemple: [1. 2. 4. 3.]\n",
        "  Min: 1.0, Max: 4.0, Mean: 1.04, Std: 0.19\n",
        "\n",
        "Coloana: legs1_segments0_departureFrom_airport_iata\n",
        "  Tip: object\n",
        "  Valori lipsƒÉ: 0 (0.00%)\n",
        "  Valori unice: 338\n",
        "  Exemple: ['SVX' 'ALA' 'SVO' 'DME' 'ZIA']\n",
        "\n",
        "Coloana: legs1_segments0_duration\n",
        "  Tip: float64\n",
        "  Valori lipsƒÉ: 0 (0.00%)\n",
        "  Valori unice: 698\n",
        "  Exemple: [165. 155. 160. 170. 135.]\n",
        "  Min: 14.0, Max: 1130.0, Mean: 147.37, Std: 92.84\n",
        "\n",
        "Coloana: legs1_segments0_marketingCarrier_code\n",
        "  Tip: object\n",
        "  Valori lipsƒÉ: 0 (0.00%)\n",
        "  Valori unice: 137\n",
        "  Exemple: ['SU' 'U6' 'DP' 'S7' 'DV']\n",
        "\n",
        "Coloana: legs1_segments0_operatingCarrier_code\n",
        "  Tip: object\n",
        "  Valori lipsƒÉ: 0 (0.00%)\n",
        "  Valori unice: 169\n",
        "  Exemple: ['SU' 'U6' 'DP' 'S7' 'DV']\n",
        "\n",
        "Coloana: legs1_segments0_seatsAvailable\n",
        "  Tip: float64\n",
        "  Valori lipsƒÉ: 0 (0.00%)\n",
        "  Valori unice: 9\n",
        "  Exemple: [4. 3. 2. 7. 9. 6. 8. 1. 5.]\n",
        "  Min: 1.0, Max: 9.0, Mean: 5.21, Std: 3.27\n",
        "\n",
        "Coloana: miniRules0_monetaryAmount\n",
        "  Tip: float64\n",
        "  Valori lipsƒÉ: 0 (0.00%)\n",
        "  Valori unice: 237129\n",
        "  Exemple: [2800.            0.         2838.95288086 2858.6003418  2817.37475586]\n",
        "  Min: 0.0, Max: 243187.0, Mean: 2719.36, Std: 4006.76\n",
        "\n",
        "Coloana: miniRules0_statusInfos\n",
        "  Tip: float64\n",
        "  Valori lipsƒÉ: 0 (0.00%)\n",
        "  Valori unice: 2\n",
        "  Exemple: [1. 0.]\n",
        "  Min: 0.0, Max: 1.0, Mean: 0.98, Std: 0.15\n",
        "\n",
        "Coloana: miniRules1_monetaryAmount\n",
        "  Tip: float64\n",
        "  Valori lipsƒÉ: 0 (0.00%)\n",
        "  Valori unice: 187477\n",
        "  Exemple: [   0.         2800.         1500.         2838.27294922 2837.67724609]\n",
        "  Min: 0.0, Max: 473635.0, Mean: 1416.30, Std: 4016.97\n",
        "\n",
        "Coloana: miniRules1_statusInfos\n",
        "  Tip: float64\n",
        "  Valori lipsƒÉ: 0 (0.00%)\n",
        "  Valori unice: 2\n",
        "  Exemple: [0. 1.]\n",
        "  Min: 0.0, Max: 1.0, Mean: 0.54, Std: 0.50\n",
        "\n",
        "Coloana: pricingInfo_isAccessTP\n",
        "  Tip: float64\n",
        "  Valori lipsƒÉ: 0 (0.00%)\n",
        "  Valori unice: 2\n",
        "  Exemple: [1. 0.]\n",
        "  Min: 0.0, Max: 1.0, Mean: 0.63, Std: 0.48\n",
        "\n",
        "Coloana: pricingInfo_passengerCount\n",
        "  Tip: int64\n",
        "  Valori lipsƒÉ: 0 (0.00%)\n",
        "  Valori unice: 1\n",
        "  Exemple: [1]\n",
        "  Min: 1, Max: 1, Mean: 1.00, Std: 0.00\n",
        "\n",
        "Coloana: profileId\n",
        "  Tip: int64\n",
        "  Valori lipsƒÉ: 0 (0.00%)\n",
        "  Valori unice: 18981\n",
        "  Exemple: [3604015 3344069  639964  638530 3292775]\n",
        "  Min: 5065, Max: 3667551, Mean: 2479011.18, Std: 1029325.77\n",
        "\n",
        "Coloana: ranker_id\n",
        "  Tip: object\n",
        "  Valori lipsƒÉ: 0 (0.00%)\n",
        "  Valori unice: 45231\n",
        "  Exemple: ['c9373e5f772e43d593dd6ad2fa90f67a' '2e6b0b51f761433cb28fae7c439db04c'\n",
        " '726ad47c29bb4196b54bbe283a7267bb' '458c1e8431814da99092580f45eed7e8'\n",
        " '8c387f33dc824a89ba7a6f2cb5908e36']\n",
        "\n",
        "Coloana: requestDate\n",
        "  Tip: object\n",
        "  Valori lipsƒÉ: 0 (0.00%)\n",
        "  Valori unice: 44738\n",
        "  Exemple: ['2024-10-29T12:50:42.000000000' '2024-10-29T12:52:12.000000000'\n",
        " '2024-10-29T12:49:43.000000000' '2024-10-29T12:50:13.000000000'\n",
        " '2024-10-29T12:53:16.000000000']\n",
        "\n",
        "Coloana: searchRoute\n",
        "  Tip: object\n",
        "  Valori lipsƒÉ: 0 (0.00%)\n",
        "  Valori unice: 3646\n",
        "  Exemple: ['MOWSVX/SVXMOW' 'MOWALA/ALAMOW' 'KZNMOW/MOWKZN' 'OVBMOW' 'LEDMOW/MOWLED']\n",
        "\n",
        "Coloana: sex\n",
        "  Tip: bool\n",
        "  Valori lipsƒÉ: 0 (0.00%)\n",
        "  Valori unice: 2\n",
        "  Exemple: [False  True]\n",
        "\n",
        "Coloana: taxes\n",
        "  Tip: float64\n",
        "  Valori lipsƒÉ: 0 (0.00%)\n",
        "  Valori unice: 23672\n",
        "  Exemple: [1018. 3284.  570. 2192. 3357.]\n",
        "  Min: 0.0, Max: 840097.0, Mean: 4675.95, Std: 13980.20\n",
        "\n",
        "Coloana: totalPrice\n",
        "  Tip: float64\n",
        "  Valori lipsƒÉ: 0 (0.00%)\n",
        "  Valori unice: 150082\n",
        "  Exemple: [ 9818. 14018. 22418. 12974. 16974.]\n",
        "  Min: 800.0, Max: 9934573.0, Mean: 36164.77, Std: 67193.55\n",
        "\n",
        "Coloana: __index_level_0__\n",
        "  Tip: int64\n",
        "  Valori lipsƒÉ: 0 (0.00%)\n",
        "  Valori unice: 6897776\n",
        "  Exemple: [18144679 18144680 18144681 18144682 18144683]\n",
        "  Min: 18144679, Max: 25043147, Mean: 21594259.40, Std: 1991216.74\n",
        "\n",
        "Coloana: legs0_segments0_baggageAllowance_missing_initially\n",
        "  Tip: int64\n",
        "  Valori lipsƒÉ: 0 (0.00%)\n",
        "  Valori unice: 2\n",
        "  Exemple: [1 0]\n",
        "  Min: 0, Max: 1, Mean: 1.00, Std: 0.00\n",
        "\n",
        "Coloana: miniRules0_statusInfos_was_missing\n",
        "  Tip: int64\n",
        "  Valori lipsƒÉ: 0 (0.00%)\n",
        "  Valori unice: 2\n",
        "  Exemple: [1 0]\n",
        "  Min: 0, Max: 1, Mean: 0.92, Std: 0.27\n",
        "\n",
        "Coloana: miniRules1_statusInfos_was_missing\n",
        "  Tip: int64\n",
        "  Valori lipsƒÉ: 0 (0.00%)\n",
        "  Valori unice: 2\n",
        "  Exemple: [1 0]\n",
        "  Min: 0, Max: 1, Mean: 0.92, Std: 0.28\n",
        "\n",
        "Coloana: legs1_segments0_aircraft_code_was_missing\n",
        "  Tip: int64\n",
        "  Valori lipsƒÉ: 0 (0.00%)\n",
        "  Valori unice: 2\n",
        "  Exemple: [1 0]\n",
        "  Min: 0, Max: 1, Mean: 0.84, Std: 0.37\n",
        "\n",
        "Coloana: legs1_departureAt_hour\n",
        "  Tip: float64\n",
        "  Valori lipsƒÉ: 0 (0.00%)\n",
        "  Valori unice: 24\n",
        "  Exemple: [21. 12. 23.  6. 20.]\n",
        "  Min: 0.0, Max: 23.0, Mean: 14.28, Std: 5.59\n",
        "\n",
        "Coloana: legs1_departureAt_minute\n",
        "  Tip: float64\n",
        "  Valori lipsƒÉ: 0 (0.00%)\n",
        "  Valori unice: 60\n",
        "  Exemple: [10.  0. 50. 30. 25.]\n",
        "  Min: 0.0, Max: 59.0, Mean: 21.11, Std: 16.57\n",
        "\n",
        "Coloana: legs1_departureAt_is_weekend\n",
        "  Tip: int64\n",
        "  Valori lipsƒÉ: 0 (0.00%)\n",
        "  Valori unice: 2\n",
        "  Exemple: [1 0]\n",
        "  Min: 0, Max: 1, Mean: 0.21, Std: 0.41\n",
        "\n",
        "Coloana: legs1_departureAt_day\n",
        "  Tip: float64\n",
        "  Valori lipsƒÉ: 0 (0.00%)\n",
        "  Valori unice: 31\n",
        "  Exemple: [21. 14. 15.  5. 16.]\n",
        "  Min: 1.0, Max: 31.0, Mean: 16.42, Std: 7.97\n",
        "\n",
        "Coloana: legs1_departureAt_month\n",
        "  Tip: float64\n",
        "  Valori lipsƒÉ: 0 (0.00%)\n",
        "  Valori unice: 12\n",
        "  Exemple: [12. 11.  9. 10.  8.  7.  6.  4.  5.  1.  2.  3.]\n",
        "  Min: 1.0, Max: 12.0, Mean: 9.95, Std: 3.35\n",
        "\n",
        "Coloana: legs1_departureAt_year\n",
        "  Tip: float64\n",
        "  Valori lipsƒÉ: 0 (0.00%)\n",
        "  Valori unice: 2\n",
        "  Exemple: [2024. 2025.]\n",
        "  Min: 2024.0, Max: 2025.0, Mean: 2024.12, Std: 0.33\n",
        "\n",
        "Coloana: legs1_departureAt_part_of_day\n",
        "  Tip: object\n",
        "  Valori lipsƒÉ: 0 (0.00%)\n",
        "  Valori unice: 4\n",
        "  Exemple: ['evening' 'afternoon' 'morning' 'night']\n",
        "\n",
        "Coloana: legs1_departureAt_hour_sin\n",
        "  Tip: float64\n",
        "  Valori lipsƒÉ: 0 (0.00%)\n",
        "  Valori unice: 21\n",
        "  Exemple: [-7.07106781e-01  1.22464680e-16 -2.58819045e-01  1.00000000e+00\n",
        " -8.66025404e-01]\n",
        "  Min: -1.0, Max: 1.0, Mean: -0.17, Std: 0.71\n",
        "\n",
        "Coloana: legs1_departureAt_hour_cos\n",
        "  Tip: float64\n",
        "  Valori lipsƒÉ: 0 (0.00%)\n",
        "  Valori unice: 22\n",
        "  Exemple: [ 7.07106781e-01 -1.00000000e+00  9.65925826e-01  6.12323400e-17\n",
        "  5.00000000e-01]\n",
        "  Min: -1.0, Max: 1.0, Mean: -0.18, Std: 0.66\n",
        "\n",
        "Coloana: legs1_arrivalAt_hour\n",
        "  Tip: float64\n",
        "  Valori lipsƒÉ: 0 (0.00%)\n",
        "  Valori unice: 24\n",
        "  Exemple: [21. 12. 23.  7. 19.]\n",
        "  Min: 0.0, Max: 23.0, Mean: 13.90, Std: 6.38\n",
        "\n",
        "Coloana: legs1_arrivalAt_minute\n",
        "  Tip: float64\n",
        "  Valori lipsƒÉ: 0 (0.00%)\n",
        "  Valori unice: 60\n",
        "  Exemple: [55. 35. 50. 30. 10.]\n",
        "  Min: 0.0, Max: 59.0, Mean: 26.53, Std: 15.79\n",
        "\n",
        "Coloana: legs1_arrivalAt_is_weekend\n",
        "  Tip: int64\n",
        "  Valori lipsƒÉ: 0 (0.00%)\n",
        "  Valori unice: 2\n",
        "  Exemple: [1 0]\n",
        "  Min: 0, Max: 1, Mean: 0.26, Std: 0.44\n",
        "\n",
        "Coloana: legs1_arrivalAt_day\n",
        "  Tip: float64\n",
        "  Valori lipsƒÉ: 0 (0.00%)\n",
        "  Valori unice: 31\n",
        "  Exemple: [21. 15. 14. 17. 18.]\n",
        "  Min: 1.0, Max: 31.0, Mean: 16.47, Std: 7.95\n",
        "\n",
        "Coloana: legs1_arrivalAt_month\n",
        "  Tip: float64\n",
        "  Valori lipsƒÉ: 0 (0.00%)\n",
        "  Valori unice: 12\n",
        "  Exemple: [12. 11.  9. 10.  8.  7.  4.  6.  5.  3.  1.  2.]\n",
        "  Min: 1.0, Max: 12.0, Mean: 9.95, Std: 3.35\n",
        "\n",
        "Coloana: legs1_arrivalAt_year\n",
        "  Tip: float64\n",
        "  Valori lipsƒÉ: 0 (0.00%)\n",
        "  Valori unice: 2\n",
        "  Exemple: [2024. 2025.]\n",
        "  Min: 2024.0, Max: 2025.0, Mean: 2024.12, Std: 0.33\n",
        "\n",
        "Coloana: legs1_arrivalAt_part_of_day\n",
        "  Tip: object\n",
        "  Valori lipsƒÉ: 0 (0.00%)\n",
        "  Valori unice: 4\n",
        "  Exemple: ['evening' 'afternoon' 'morning' 'night']\n",
        "\n",
        "Coloana: legs1_arrivalAt_hour_sin\n",
        "  Tip: float64\n",
        "  Valori lipsƒÉ: 0 (0.00%)\n",
        "  Valori unice: 21\n",
        "  Exemple: [-7.07106781e-01  1.22464680e-16 -2.58819045e-01  9.65925826e-01\n",
        " -9.65925826e-01]\n",
        "  Min: -1.0, Max: 1.0, Mean: -0.21, Std: 0.65\n",
        "\n",
        "Coloana: legs1_arrivalAt_hour_cos\n",
        "  Tip: float64\n",
        "  Valori lipsƒÉ: 0 (0.00%)\n",
        "  Valori unice: 22\n",
        "  Exemple: [ 0.70710678 -1.          0.96592583 -0.25881905  0.25881905]\n",
        "  Min: -1.0, Max: 1.0, Mean: -0.09, Std: 0.72"
      ],
      "metadata": {
        "id": "zEvrzHZ3g9Oz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Preprocessing & Imputation 2**"
      ],
      "metadata": {
        "id": "DjjP98zIPc5h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile convert_parquet.py\n",
        "import polars as pl\n",
        "\n",
        "# Load the Parquet files\n",
        "train_df = pl.read_parquet(\"train.parquet\")\n",
        "test_df = pl.read_parquet(\"test.parquet\")\n",
        "\n",
        "# Optional: check shape or preview\n",
        "print(\"Train shape:\", train_df.shape)\n",
        "print(\"Test shape:\", test_df.shape)\n",
        "\n",
        "# Save to CSV (or another format if needed)\n",
        "train_df.write_csv(\"train.csv\")\n",
        "test_df.write_csv(\"test.csv\")\n",
        "\n",
        "print(\"Parquet files successfully converted to CSV.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ySLYH6APfx5",
        "outputId": "f515ca21-40d2-421f-fee3-7a8c0b4fc53e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing convert_parquet.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile summary.py\n",
        "import pandas as pd\n",
        "\n",
        "# List of columns to analyze\n",
        "features = [\n",
        "    \"legs0_segments0_arrivalTo_airport_iata\",\n",
        "    \"legs0_segments0_aircraft_code\",\n",
        "    \"legs0_segments0_departureFrom_airport_iata\",\n",
        "    \"legs0_segments0_arrivalTo_airport_city_iata\",\n",
        "    \"legs0_segments0_baggageAllowance_weightMeasurementType\",\n",
        "    \"legs0_segments0_baggageAllowance_quantity\",\n",
        "    \"legs0_segments0_seatsAvailable\"\n",
        "]\n",
        "\n",
        "# Load datasets\n",
        "train = pd.read_csv(\"train.csv\", low_memory=False)\n",
        "test = pd.read_csv(\"test.csv\", low_memory=False)\n",
        "\n",
        "report = []\n",
        "\n",
        "def get_feature_report(df, dataset_name, feature_name):\n",
        "    if feature_name not in df.columns:\n",
        "        return f\"{dataset_name}: Column '{feature_name}' not found.\\n\"\n",
        "\n",
        "    col = df[feature_name]\n",
        "    total = len(col)\n",
        "    missing = col.isna().sum()\n",
        "    pct_missing = missing / total * 100\n",
        "    nunique = col.nunique(dropna=True)\n",
        "    dtype = col.dtype\n",
        "    most_freq_val = col.value_counts(dropna=True).idxmax()\n",
        "    most_freq_count = col.value_counts(dropna=True).max()\n",
        "    pct_most_freq = most_freq_count / (total - missing) * 100\n",
        "    n_uniq_once = (col.value_counts(dropna=True) == 1).sum()\n",
        "    n_duplicates = total - nunique - missing\n",
        "\n",
        "    section = [\n",
        "        f\"üìä Dataset: {dataset_name}\",\n",
        "        f\"Column: {feature_name}\",\n",
        "        f\"Data type: {dtype}\",\n",
        "        f\"Total rows: {total:,}\",\n",
        "        f\"Missing values: {missing:,} ({pct_missing:.6f}%)\",\n",
        "        f\"Unique values (non-null): {nunique:,}\",\n",
        "        f\"Values appearing only once: {n_uniq_once:,}\",\n",
        "        f\"Duplicate values (excluding nulls): {n_duplicates:,}\",\n",
        "        f\"Most frequent value: {most_freq_val} ({most_freq_count:,} times, {pct_most_freq:.2f}%)\",\n",
        "    ]\n",
        "\n",
        "    if pd.api.types.is_numeric_dtype(col):\n",
        "        section.append(\"\\nüîπ Descriptive statistics:\")\n",
        "        section.append(str(col.describe()))\n",
        "    else:\n",
        "        top_values = col.value_counts(dropna=True).head(5)\n",
        "        section.append(\"\\nüîπ Top 5 most frequent values:\")\n",
        "        for val, count in top_values.items():\n",
        "            section.append(f\"  {val}: {count:,} ({(count / (total - missing)) * 100:.2f}%)\")\n",
        "\n",
        "    sample_values = col.dropna().unique()\n",
        "    if len(sample_values) > 0:\n",
        "        section.append(\"\\nüîπ Example distinct values:\")\n",
        "        section.append(\", \".join(map(str, sample_values[:10])) + (\" ...\" if len(sample_values) > 10 else \"\"))\n",
        "\n",
        "    return \"\\n\".join(section)\n",
        "\n",
        "# Build report for all features\n",
        "for feature in features:\n",
        "    report.append(get_feature_report(train, \"Train\", feature))\n",
        "    report.append(\"\\n\" + \"-\" * 40 + \"\\n\")\n",
        "    report.append(get_feature_report(test, \"Test\", feature))\n",
        "    report.append(\"\\n\" + \"=\" * 60 + \"\\n\")\n",
        "\n",
        "# Save to file\n",
        "output = \"\\n\".join(report)\n",
        "filename = \"feature_summary.txt\"\n",
        "\n",
        "with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(output)\n",
        "\n",
        "print(f\"‚úÖ Summary for all features saved to '{filename}'\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j5dJZ6PtShr9",
        "outputId": "e41b08ec-99c1-4986-b4b9-cf5a34ade095"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing summary.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "list1 = ['bySelf', 'companyID', 'corporateTariffCode', 'nationality', 'isAccess3D', 'isVip', 'legs0_duration', 'legs0_segments0_aircraft_code', 'legs0_segments0_arrivalTo_airport_city_iata', 'legs0_segments0_arrivalTo_airport_iata', 'legs0_segments0_baggageAllowance_quantity', 'legs0_segments0_baggageAllowance_weightMeasurementType', 'legs0_segments0_departureFrom_airport_iata', 'legs0_segments0_duration', 'legs0_segments0_marketingCarrier_code', 'legs0_segments0_operatingCarrier_code', 'legs0_segments0_seatsAvailable', 'legs0_segments1_duration', 'legs1_duration', 'legs1_segments0_duration', 'legs1_segments1_duration', 'miniRules0_monetaryAmount', 'miniRules0_statusInfos', 'miniRules1_monetaryAmount', 'miniRules1_statusInfos', 'sex', 'taxes', 'totalPrice', 'price_per_tax', 'tax_rate', 'log_price', 'total_duration', 'duration_ratio', 'is_one_way', 'l0_seg', 'n_ff_programs', 'has_corporate_tariff', 'has_access_tp', 'corporate_policy_compliant', 'corporate_vip_flag', 'baggage_min', 'rules_missing', 'total_fees', 'is_popular_route', 'is_round_trip', 'n_segments_leg0', 'n_segments_leg1', 'total_segments', 'is_direct_leg0', 'is_direct_leg1', 'is_direct_shortest', 'both_direct', 'is_vip_freq', 'has_baggage', 'has_fees', 'fee_rate', 'group_size', 'group_size_log', 'stay_duration_hours', 'legs0_departureAt_hour', 'legs0_departureAt_weekday', 'legs0_departureAt_business_time', 'legs0_departureAt_time_bin', 'legs0_arrivalAt_hour', 'legs0_arrivalAt_weekday', 'legs0_arrivalAt_business_time', 'legs0_arrivalAt_time_bin', 'legs1_departureAt_hour', 'legs1_departureAt_weekday', 'legs1_departureAt_business_time', 'legs1_departureAt_time_bin', 'legs1_arrivalAt_hour', 'legs1_arrivalAt_weekday', 'legs1_arrivalAt_business_time', 'legs1_arrivalAt_time_bin', 'stay_duration_hours_log', 'is_short_trip', 'stay_duration_bin', 'hours_to_departure', 'days_to_departure', 'is_last_minute_booking', 'price_quantile_rank', 'duration_quantile_rank', 'rank_interaction_mul', 'rank_interaction_ratio', 'rank_interaction_sum', 'rank_interaction_sub', 'price_pct_rank', 'is_cheapest', 'price_from_median', 'is_min_segments', 'price_gap_ratio_from_min', 'is_direct_cheapest', 'legs0_segments0_cabinClass_is_1', 'legs0_segments0_cabinClass_is_2', 'legs0_segments0_cabinClass_is_3', 'legs0_segments0_cabinClass_is_4', 'legs1_segments0_cabinClass_is_1', 'legs1_segments0_cabinClass_is_2', 'legs1_segments0_cabinClass_is_3', 'legs1_segments0_cabinClass_is_4', 'cabin_class_level_sum_3', 'has_business_class', 'cabin_class_highest', 'cabin_class_lowest', 'cabin_class_diversity', 'all_cabin_level_1', 'company_select_count', 'avg_selected_price', 'std_selected_price', 'avg_selected_cabin', 'selected_direct_ratio', 'selected_night_ratio', 'log_company_select_count', 'is_very_popular_company', 'is_popular_company', 'is_top_selected_company', 'z_price_vs_company_selected', 'legs0_segments0_marketingCarrier_code_selection_rate', 'legs0_segments0_marketingCarrier_code_log_total_count', 'legs0_segments0_marketingCarrier_code_selected_rank_bin', 'legs1_segments0_marketingCarrier_code_selection_rate', 'legs1_segments0_marketingCarrier_code_log_total_count', 'legs1_segments0_marketingCarrier_code_selected_rank_bin', 'legs0_segments0_marketingCarrier_code_in_frequentFlyer', 'is_major_carrier_0_0', 'legs0_segments0_marketingCarrier_code_ff_and_business']\n",
        "list2 = [\n",
        "    \"legs1_segments3_marketingCarrier_code\",\n",
        "    \"legs1_segments3_flightNumber\",\n",
        "    \"legs1_segments3_baggageAllowance_quantity\",\n",
        "    \"legs1_segments3_departureFrom_airport_iata\",\n",
        "    \"legs1_segments3_cabinClass\",\n",
        "    \"legs1_segments3_baggageAllowance_weightMeasurementType\",\n",
        "    \"legs1_segments3_seatsAvailable\",\n",
        "    \"legs1_segments3_operatingCarrier_code\",\n",
        "    \"legs1_segments3_aircraft_code\",\n",
        "    \"legs1_segments3_arrivalTo_airport_city_iata\",\n",
        "    \"legs1_segments3_duration\",\n",
        "    \"legs1_segments3_arrivalTo_airport_iata\",\n",
        "    \"legs0_segments3_aircraft_code\",\n",
        "    \"legs0_segments3_baggageAllowance_weightMeasurementType\",\n",
        "    \"legs0_segments3_seatsAvailable\",\n",
        "    \"legs0_segments3_cabinClass\",\n",
        "    \"legs0_segments3_baggageAllowance_quantity\",\n",
        "    \"legs0_segments3_departureFrom_airport_iata\",\n",
        "    \"legs0_segments3_flightNumber\",\n",
        "    \"legs0_segments3_duration\",\n",
        "    \"legs0_segments3_arrivalTo_airport_city_iata\",\n",
        "    \"legs0_segments3_operatingCarrier_code\",\n",
        "    \"legs0_segments3_marketingCarrier_code\",\n",
        "    \"legs0_segments3_arrivalTo_airport_iata\",\n",
        "    \"legs1_segments2_baggageAllowance_weightMeasurementType\",\n",
        "    \"legs1_segments2_baggageAllowance_quantity\",\n",
        "    \"legs1_segments2_seatsAvailable\",\n",
        "    \"legs1_segments2_cabinClass\",\n",
        "    \"legs1_segments2_duration\",\n",
        "    \"legs1_segments2_aircraft_code\",\n",
        "    \"legs1_segments2_operatingCarrier_code\",\n",
        "    \"legs1_segments2_arrivalTo_airport_city_iata\",\n",
        "    \"legs1_segments2_arrivalTo_airport_iata\",\n",
        "    \"legs1_segments2_marketingCarrier_code\",\n",
        "    \"legs1_segments2_flightNumber\",\n",
        "    \"legs1_segments2_departureFrom_airport_iata\",\n",
        "    \"legs0_segments2_baggageAllowance_weightMeasurementType\",\n",
        "    \"legs0_segments2_baggageAllowance_quantity\",\n",
        "    \"legs0_segments2_cabinClass\",\n",
        "    \"legs0_segments2_seatsAvailable\",\n",
        "    \"legs0_segments2_aircraft_code\",\n",
        "    \"legs0_segments2_marketingCarrier_code\",\n",
        "    \"legs0_segments2_departureFrom_airport_iata\",\n",
        "    \"legs0_segments2_arrivalTo_airport_city_iata\",\n",
        "    \"legs0_segments2_flightNumber\",\n",
        "    \"legs0_segments2_operatingCarrier_code\",\n",
        "    \"legs0_segments2_duration\",\n",
        "    \"legs0_segments2_arrivalTo_airport_iata\",\n",
        "    \"miniRules1_percentage\",\n",
        "    \"miniRules0_percentage\",\n",
        "    \"legs1_segments1_seatsAvailable\",\n",
        "    \"legs1_segments1_baggageAllowance_weightMeasurementType\",\n",
        "    \"legs1_segments1_baggageAllowance_quantity\",\n",
        "    \"legs1_segments1_cabinClass\",\n",
        "    \"legs1_segments1_departureFrom_airport_iata\",\n",
        "    \"legs1_segments1_marketingCarrier_code\",\n",
        "    \"legs1_segments1_flightNumber\",\n",
        "    \"legs1_segments1_aircraft_code\",\n",
        "    \"legs1_segments1_operatingCarrier_code\",\n",
        "    \"legs1_segments1_arrivalTo_airport_city_iata\",\n",
        "    \"legs1_segments1_arrivalTo_airport_iata\",\n",
        "    \"legs1_segments1_duration\",\n",
        "    \"legs0_segments1_seatsAvailable\",\n",
        "    \"legs0_segments1_baggageAllowance_weightMeasurementType\",\n",
        "    \"legs0_segments1_baggageAllowance_quantity\",\n",
        "    \"legs0_segments1_cabinClass\",\n",
        "    \"legs0_segments1_aircraft_code\",\n",
        "    \"legs0_segments1_arrivalTo_airport_city_iata\",\n",
        "    \"legs0_segments1_departureFrom_airport_iata\",\n",
        "    \"legs0_segments1_flightNumber\",\n",
        "    \"legs0_segments1_operatingCarrier_code\",\n",
        "    \"legs0_segments1_duration\",\n",
        "    \"legs0_segments1_arrivalTo_airport_iata\",\n",
        "    \"legs0_segments1_marketingCarrier_code\",\n",
        "    \"frequentFlyer\",\n",
        "    \"corporateTariffCode\",\n",
        "    \"legs1_segments0_seatsAvailable\",\n",
        "    \"legs1_segments0_baggageAllowance_quantity\",\n",
        "    \"legs1_segments0_baggageAllowance_weightMeasurementType\",\n",
        "    \"legs1_segments0_cabinClass\",\n",
        "    \"legs1_segments0_arrivalTo_airport_city_iata\",\n",
        "    \"legs1_segments0_departureFrom_airport_iata\",\n",
        "    \"legs1_segments0_arrivalTo_airport_iata\",\n",
        "    \"legs1_departureAt\",\n",
        "    \"legs1_arrivalAt\",\n",
        "    \"legs1_duration\",\n",
        "    \"legs1_segments0_duration\",\n",
        "    \"legs1_segments0_operatingCarrier_code\",\n",
        "    \"legs1_segments0_marketingCarrier_code\",\n",
        "    \"legs1_segments0_flightNumber\",\n",
        "    \"legs1_segments0_aircraft_code\",\n",
        "    \"miniRules1_statusInfos\",\n",
        "    \"miniRules0_statusInfos\",\n",
        "    \"miniRules1_monetaryAmount\",\n",
        "    \"miniRules0_monetaryAmount\",\n",
        "    \"pricingInfo_isAccessTP\",\n",
        "    \"legs0_segments0_seatsAvailable\",\n",
        "    \"legs0_segments0_baggageAllowance_quantity\",\n",
        "    \"legs0_segments0_baggageAllowance_weightMeasurementType\",\n",
        "    \"legs0_segments0_arrivalTo_airport_city_iata\",\n",
        "    \"legs0_segments0_departureFrom_airport_iata\",\n",
        "    \"legs0_segments0_aircraft_code\",\n",
        "    \"legs0_segments0_arrivalTo_airport_iata\"\n",
        "]\n",
        "\n",
        "common_elements = sorted(set(list1) & set(list2))\n",
        "\n",
        "print(f\"‚úÖ Found {len(common_elements)} common elements:\\n\")\n",
        "for i, col in enumerate(common_elements, 1):\n",
        "    print(f\"{i:>2}. {col}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cdeatSz1YeuG",
        "outputId": "21b28f1f-5324-499c-e37b-49039d751c14"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Found 16 common elements:\n",
            "\n",
            " 1. corporateTariffCode\n",
            " 2. legs0_segments0_aircraft_code\n",
            " 3. legs0_segments0_arrivalTo_airport_city_iata\n",
            " 4. legs0_segments0_arrivalTo_airport_iata\n",
            " 5. legs0_segments0_baggageAllowance_quantity\n",
            " 6. legs0_segments0_baggageAllowance_weightMeasurementType\n",
            " 7. legs0_segments0_departureFrom_airport_iata\n",
            " 8. legs0_segments0_seatsAvailable\n",
            " 9. legs0_segments1_duration\n",
            "10. legs1_duration\n",
            "11. legs1_segments0_duration\n",
            "12. legs1_segments1_duration\n",
            "13. miniRules0_monetaryAmount\n",
            "14. miniRules0_statusInfos\n",
            "15. miniRules1_monetaryAmount\n",
            "16. miniRules1_statusInfos\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile test_imputation.py\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import time\n",
        "\n",
        "# === Start the timer ===\n",
        "start = time.time()\n",
        "\n",
        "# === Load the data ===\n",
        "train_original = pd.read_csv(\"train.csv\", low_memory=False)\n",
        "train_copy = train_original.copy(deep=True)\n",
        "\n",
        "# === Select relevant columns ===\n",
        "selected_features = [\n",
        "    'totalPrice',\n",
        "    'companyID',\n",
        "    'legs0_segments0_cabinClass',\n",
        "    'isAccess3D',\n",
        "    'isVip',\n",
        "    'legs0_segments0_seatsAvailable',\n",
        "    'legs0_segments0_flightNumber',\n",
        "    'taxes',\n",
        "    'legs0_segments0_baggageAllowance_quantity',\n",
        "    'legs0_segments0_baggageAllowance_weightMeasurementType',\n",
        "    'pricingInfo_isAccessTP',\n",
        "    'miniRules0_monetaryAmount',\n",
        "    'miniRules1_monetaryAmount'\n",
        "]\n",
        "\n",
        "target_col = 'corporateTariffCode'\n",
        "cols_needed = selected_features + [target_col]\n",
        "\n",
        "# === Filter complete rows for training ===\n",
        "df_full = train_copy[cols_needed].dropna(subset=cols_needed)\n",
        "\n",
        "# === Encode the target column ===\n",
        "le = LabelEncoder()\n",
        "df_full[target_col] = le.fit_transform(df_full[target_col])\n",
        "\n",
        "# === Randomly select 1,000,000 rows for validation ===\n",
        "sample = df_full.sample(n=1000000, random_state=42)\n",
        "X_valid = sample[selected_features]\n",
        "y_valid = sample[target_col]\n",
        "\n",
        "# === Remove these rows from training data ===\n",
        "df_train = df_full.drop(sample.index, errors='ignore')\n",
        "X_train = df_train[selected_features]\n",
        "y_train = df_train[target_col]\n",
        "\n",
        "# === Train a classification model ===\n",
        "model = XGBClassifier(\n",
        "    n_estimators=500,\n",
        "    max_depth=12,\n",
        "    learning_rate=0.1,\n",
        "    tree_method='hist',\n",
        "    n_jobs=24,\n",
        "    random_state=42,\n",
        "    use_label_encoder=False,\n",
        "    eval_metric='logloss'\n",
        ")\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# === Predict missing values from the sample ===\n",
        "predicted = model.predict(X_valid)\n",
        "\n",
        "# === Compute metrics ===\n",
        "acc = accuracy_score(y_valid, predicted)\n",
        "f1 = f1_score(y_valid, predicted, average='weighted')\n",
        "cm = confusion_matrix(y_valid, predicted)\n",
        "duration = round(time.time() - start, 2)\n",
        "\n",
        "# === Save results to file ===\n",
        "with open(\"imputation_results.txt\", \"w\") as f:\n",
        "    f.write(\"‚úÖ Direct prediction results (XGBClassifier with LabelEncoder):\\n\")\n",
        "    f.write(f\"Accuracy: {acc:.4f}\\n\")\n",
        "    f.write(f\"F1 Score (weighted): {f1:.4f}\\n\")\n",
        "    f.write(\"Confusion Matrix:\\n\")\n",
        "    f.write(np.array2string(cm))\n",
        "    f.write(f\"\\n‚è±Ô∏è Duration: {duration} seconds\\n\")\n",
        "\n",
        "# === Also print to console ===\n",
        "print(\"‚úÖ Results saved to imputation_results.txt\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NU_oYmDMamcz",
        "outputId": "8236f7a6-db2a-4374-ab6c-1e51ed8f44ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing test_imputation.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "‚úÖ Direct prediction results (XGBClassifier with LabelEncoder):\n",
        "Accuracy: 0.9939\n",
        "F1 Score (weighted): 0.9937\n",
        "Confusion Matrix:\n",
        "[[  788     0     0 ...     0     0     0]\n",
        " [    0   131     0 ...     0     0     0]\n",
        " [    0     0     4 ...     0     0     0]\n",
        " ...\n",
        " [    0     0     0 ... 13902     5     4]\n",
        " [    0     0     0 ...    23   976     0]\n",
        " [    0     0     0 ...     4     0 32641]]\n",
        "‚è±Ô∏è Duration: 6587.36 seconds"
      ],
      "metadata": {
        "id": "hcpX9XQyHv9Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile impute_corporateTariffCode.py\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import time\n",
        "\n",
        "# === Timer ===\n",
        "start = time.time()\n",
        "\n",
        "# === Load the files ===\n",
        "train = pd.read_csv(\"train.csv\", low_memory=False)\n",
        "test = pd.read_csv(\"test.csv\", low_memory=False)\n",
        "\n",
        "# === Relevant columns for prediction ===\n",
        "features = [\n",
        "    'totalPrice',\n",
        "    'companyID',\n",
        "    'legs0_segments0_cabinClass',\n",
        "    'isAccess3D',\n",
        "    'isVip',\n",
        "    'legs0_segments0_seatsAvailable',\n",
        "    'legs0_segments0_flightNumber',\n",
        "    'taxes',\n",
        "    'legs0_segments0_baggageAllowance_quantity',\n",
        "    'legs0_segments0_baggageAllowance_weightMeasurementType',\n",
        "    'pricingInfo_isAccessTP',\n",
        "    'miniRules0_monetaryAmount',\n",
        "    'miniRules1_monetaryAmount',\n",
        "    'miniRules0_statusInfos',\n",
        "    'miniRules1_statusInfos'\n",
        "]\n",
        "\n",
        "# === Target columns to impute ===\n",
        "target_columns = [\n",
        "    'corporateTariffCode'\n",
        "]\n",
        "\n",
        "# === Function to train and impute a target column ===\n",
        "def impute_column(target):\n",
        "    print(f\"\\nüîß Processing target: '{target}'\")\n",
        "\n",
        "    train_valid = train.dropna(subset=features + [target])\n",
        "    if train_valid.empty:\n",
        "        print(f\"‚ùå Skipped '{target}': No complete training data.\")\n",
        "        return\n",
        "\n",
        "    X_train = train_valid[features]\n",
        "    y_train_raw = train_valid[target]\n",
        "\n",
        "    # Label Encoding\n",
        "    le = LabelEncoder()\n",
        "    y_train = le.fit_transform(y_train_raw)\n",
        "\n",
        "    # Model\n",
        "    model = XGBClassifier(\n",
        "        n_estimators=500,\n",
        "        max_depth=12,\n",
        "        learning_rate=0.1,\n",
        "        tree_method='hist',\n",
        "        n_jobs=24,\n",
        "        random_state=42,\n",
        "        eval_metric='logloss'\n",
        "    )\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Impute for train & test\n",
        "    for df, name in [(train, \"train\"), (test, \"test\")]:\n",
        "        missing_mask = df[target].isna()\n",
        "        if missing_mask.sum() == 0:\n",
        "            print(f\"‚úÖ {name}: No missing values in '{target}'\")\n",
        "            continue\n",
        "\n",
        "        imputable = df.loc[missing_mask, features].dropna()\n",
        "        imputable_indices = imputable.index\n",
        "\n",
        "        if len(imputable_indices) == 0:\n",
        "            print(f\"‚ö†Ô∏è {name}: No imputable rows with all required features for '{target}'.\")\n",
        "            continue\n",
        "\n",
        "        preds = model.predict(imputable)\n",
        "        preds_labels = le.inverse_transform(preds)\n",
        "        df.loc[imputable_indices, target] = preds_labels\n",
        "        print(f\"‚úÖ {name}: Imputed {len(imputable_indices)} missing values in '{target}'\")\n",
        "\n",
        "    # Report\n",
        "    for df, name in [(train, \"train\"), (test, \"test\")]:\n",
        "        total = len(df)\n",
        "        missing = df[target].isna().sum()\n",
        "        value_counts = df[target].value_counts(dropna=False).sort_index()\n",
        "        print(f\"\\nüìä {name} ‚Äî '{target}':\")\n",
        "        print(f\"  Total rows: {total}\")\n",
        "        print(f\"  Missing: {missing} ({100 * missing / total:.2f}%)\")\n",
        "        print(\"  Top 10 value counts (including imputations):\")\n",
        "        print(value_counts.head(10))\n",
        "\n",
        "    # === Save only the imputed target column ===\n",
        "    train[[target]].to_csv(f\"train_{target}.csv\", index=False)\n",
        "    test[[target]].to_csv(f\"test_{target}.csv\", index=False)\n",
        "    print(f\"üíæ Saved: train_{target}.csv and test_{target}.csv\")\n",
        "\n",
        "# === Run for each target column ===\n",
        "for target in target_columns:\n",
        "    impute_column(target)\n",
        "\n",
        "# === Done ===\n",
        "print(f\"\\n‚è±Ô∏è Total duration: {round(time.time() - start, 2)} seconds\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "76pGy6l8JRfY",
        "outputId": "193aaf4f-1d12-4d1b-bd54-9ff041466816"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing impute_corporateTariffCode.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "  bst.update(dtrain, iteration=i, fobj=obj)\n",
        "‚úÖ Results saved to imputation_results.txt\n",
        "\n",
        "üîß Processing target: 'corporateTariffCode'\n",
        "‚úÖ train: Imputed 6903139 missing values in 'corporateTariffCode'\n",
        "‚úÖ test: Imputed 2725874 missing values in 'corporateTariffCode'\n",
        "\n",
        "üìä train ‚Äî 'corporateTariffCode':\n",
        "  Total rows: 18145372\n",
        "  Missing: 2330786 (12.85%)\n",
        "  Top 10 value counts (including imputations):\n",
        "corporateTariffCode\n",
        "0.0    11695\n",
        "1.0     2045\n",
        "2.0       77\n",
        "3.0    25928\n",
        "4.0     1555\n",
        "5.0    35289\n",
        "6.0    20952\n",
        "7.0     1354\n",
        "8.0       98\n",
        "9.0     4283\n",
        "Name: count, dtype: int64\n",
        "\n",
        "üìä test ‚Äî 'corporateTariffCode':\n",
        "  Total rows: 6897776\n",
        "  Missing: 809461 (11.74%)\n",
        "  Top 10 value counts (including imputations):\n",
        "corporateTariffCode\n",
        "0.0      1480\n",
        "3.0      5145\n",
        "4.0        26\n",
        "5.0      3406\n",
        "6.0      1905\n",
        "7.0        11\n",
        "9.0       763\n",
        "10.0    21867\n",
        "11.0      156\n",
        "13.0     2232\n",
        "Name: count, dtype: int64\n",
        "üíæ Saved: train_corporateTariffCode.csv and test_corporateTariffCode.csv\n",
        "\n",
        "‚è±Ô∏è Total duration: 7697.46 seconds"
      ],
      "metadata": {
        "id": "ngjqJzSNCd5P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile summary.py\n",
        "import pandas as pd\n",
        "\n",
        "# List of columns to analyze\n",
        "features = [\n",
        "    \"corporateTariffCode\"\n",
        "]\n",
        "\n",
        "# Load datasets\n",
        "train = pd.read_csv(\"train_corporateTariffCode.csv\", low_memory=False)\n",
        "test = pd.read_csv(\"test_corporateTariffCode.csv\", low_memory=False)\n",
        "\n",
        "report = []\n",
        "\n",
        "def get_feature_report(df, dataset_name, feature_name):\n",
        "    if feature_name not in df.columns:\n",
        "        return f\"{dataset_name}: Column '{feature_name}' not found.\\n\"\n",
        "\n",
        "    col = df[feature_name]\n",
        "    total = len(col)\n",
        "    missing = col.isna().sum()\n",
        "    pct_missing = missing / total * 100\n",
        "    nunique = col.nunique(dropna=True)\n",
        "    dtype = col.dtype\n",
        "    most_freq_val = col.value_counts(dropna=True).idxmax()\n",
        "    most_freq_count = col.value_counts(dropna=True).max()\n",
        "    pct_most_freq = most_freq_count / (total - missing) * 100\n",
        "    n_uniq_once = (col.value_counts(dropna=True) == 1).sum()\n",
        "    n_duplicates = total - nunique - missing\n",
        "\n",
        "    section = [\n",
        "        f\"üìä Dataset: {dataset_name}\",\n",
        "        f\"Column: {feature_name}\",\n",
        "        f\"Data type: {dtype}\",\n",
        "        f\"Total rows: {total:,}\",\n",
        "        f\"Missing values: {missing:,} ({pct_missing:.6f}%)\",\n",
        "        f\"Unique values (non-null): {nunique:,}\",\n",
        "        f\"Values appearing only once: {n_uniq_once:,}\",\n",
        "        f\"Duplicate values (excluding nulls): {n_duplicates:,}\",\n",
        "        f\"Most frequent value: {most_freq_val} ({most_freq_count:,} times, {pct_most_freq:.2f}%)\",\n",
        "    ]\n",
        "\n",
        "    if pd.api.types.is_numeric_dtype(col):\n",
        "        section.append(\"\\nüîπ Descriptive statistics:\")\n",
        "        section.append(str(col.describe()))\n",
        "    else:\n",
        "        top_values = col.value_counts(dropna=True).head(5)\n",
        "        section.append(\"\\nüîπ Top 5 most frequent values:\")\n",
        "        for val, count in top_values.items():\n",
        "            section.append(f\"  {val}: {count:,} ({(count / (total - missing)) * 100:.2f}%)\")\n",
        "\n",
        "    sample_values = col.dropna().unique()\n",
        "    if len(sample_values) > 0:\n",
        "        section.append(\"\\nüîπ Example distinct values:\")\n",
        "        section.append(\", \".join(map(str, sample_values[:10])) + (\" ...\" if len(sample_values) > 10 else \"\"))\n",
        "\n",
        "    return \"\\n\".join(section)\n",
        "\n",
        "# Build report for all features\n",
        "for feature in features:\n",
        "    report.append(get_feature_report(train, \"Train\", feature))\n",
        "    report.append(\"\\n\" + \"-\" * 40 + \"\\n\")\n",
        "    report.append(get_feature_report(test, \"Test\", feature))\n",
        "    report.append(\"\\n\" + \"=\" * 60 + \"\\n\")\n",
        "\n",
        "# Save to file\n",
        "output = \"\\n\".join(report)\n",
        "filename = \"feature_summary.txt\"\n",
        "\n",
        "with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(output)\n",
        "\n",
        "print(f\"‚úÖ Summary for all features saved to '{filename}'\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PDzNMQX-CyB4",
        "outputId": "a2bf3c67-3447-4527-bbe0-1b47cc36f8cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing summary.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile impute_corporateTariffCode.py\n",
        "import pandas as pd\n",
        "\n",
        "# === Load the datasets ===\n",
        "train = pd.read_csv(\"train_corporateTariffCode.csv\", low_memory=False)\n",
        "test = pd.read_csv(\"test_corporateTariffCode.csv\", low_memory=False)\n",
        "\n",
        "# === Find the most frequent value in 'corporateTariffCode' from TRAIN ===\n",
        "most_frequent_value = train['corporateTariffCode'].mode(dropna=True)[0]\n",
        "print(f\"üîç Most frequent value to impute: {most_frequent_value}\")\n",
        "\n",
        "# === Fill missing values in both datasets ===\n",
        "train['corporateTariffCode'].fillna(most_frequent_value, inplace=True)\n",
        "test['corporateTariffCode'].fillna(most_frequent_value, inplace=True)\n",
        "\n",
        "# === Save the updated files ===\n",
        "train.to_csv(\"train_corporateTariffCode.csv\", index=False)\n",
        "test.to_csv(\"test_corporateTariffCode.csv\", index=False)\n",
        "print(\"‚úÖ Missing values imputed and files saved.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RoKVUfH4EHSA",
        "outputId": "0ad8c84d-3df0-4094-ed17-f70bddaa374d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing impute_corporateTariffCode.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile test_imputation.py\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tqdm import tqdm\n",
        "import time\n",
        "\n",
        "# === Start the timer ===\n",
        "start = time.time()\n",
        "\n",
        "# === Load the data ===\n",
        "df_original = pd.read_parquet(\"train.parquet\")\n",
        "df = df_original.copy(deep=True)  # Work on a deep copy\n",
        "\n",
        "# === Define features and target ===\n",
        "features = [\n",
        "    'totalPrice',\n",
        "    'companyID',\n",
        "    'legs0_segments0_cabinClass',\n",
        "    'isAccess3D',\n",
        "    'isVip',\n",
        "    'legs0_segments0_flightNumber',\n",
        "    'taxes'\n",
        "]\n",
        "target = 'corporateTariffCode'\n",
        "cols_needed = features + [target]\n",
        "\n",
        "# === Drop rows with missing values in features or target ===\n",
        "df = df.dropna(subset=cols_needed)\n",
        "\n",
        "# === Encode categorical features ===\n",
        "cat_features = ['companyID', 'legs0_segments0_cabinClass', 'legs0_segments0_flightNumber']\n",
        "feature_encoders = {}\n",
        "\n",
        "print(\"\\nüî§ Encoding categorical features:\")\n",
        "for col in tqdm(cat_features, desc=\"Encoding features\"):\n",
        "    le = LabelEncoder()\n",
        "    df[col] = le.fit_transform(df[col].astype(str))\n",
        "    feature_encoders[col] = le\n",
        "\n",
        "# === Encode target ===\n",
        "target_encoder = LabelEncoder()\n",
        "df[target] = target_encoder.fit_transform(df[target].astype(str))\n",
        "\n",
        "# === Sample 1,000,000 rows for validation (or fewer if needed) ===\n",
        "sample_size = min(1_000_000, len(df))\n",
        "sample = df.sample(n=sample_size, random_state=42)\n",
        "X_valid = sample[features]\n",
        "y_valid = sample[target]\n",
        "\n",
        "# === Use remaining data for training ===\n",
        "train_df = df.drop(sample.index)\n",
        "X_train = train_df[features]\n",
        "y_train = train_df[target]\n",
        "\n",
        "# === Train the classifier ===\n",
        "model = XGBClassifier(\n",
        "    n_estimators=500,\n",
        "    max_depth=12,\n",
        "    learning_rate=0.1,\n",
        "    tree_method='hist',\n",
        "    device='cuda',\n",
        "    n_jobs=24,\n",
        "    random_state=42,\n",
        "    eval_metric='logloss'\n",
        ")\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# === Predict and evaluate ===\n",
        "preds = model.predict(X_valid)\n",
        "acc = accuracy_score(y_valid, preds)\n",
        "f1 = f1_score(y_valid, preds, average='weighted')\n",
        "cm = confusion_matrix(y_valid, preds)\n",
        "duration = round(time.time() - start, 2)\n",
        "\n",
        "# === Save results ===\n",
        "with open(\"imputation_results.txt\", \"w\") as f:\n",
        "    f.write(\"‚úÖ Imputation Evaluation Results:\\n\")\n",
        "    f.write(f\"Accuracy: {acc:.4f}\\n\")\n",
        "    f.write(f\"F1 Score (weighted): {f1:.4f}\\n\")\n",
        "    f.write(\"Confusion Matrix:\\n\")\n",
        "    f.write(np.array2string(cm))\n",
        "    f.write(f\"\\n‚è±Ô∏è Duration: {duration} seconds\\n\")\n",
        "\n",
        "# === Also print to console ===\n",
        "print(\"‚úÖ Results saved to imputation_results.txt\")"
      ],
      "metadata": {
        "id": "42g72h3sJppU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a46e3d3-3b43-4592-c751-47a69f7861e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing test_imputation.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "‚úÖ Imputation Evaluation Results:\n",
        "Accuracy: 0.9897\n",
        "F1 Score (weighted): 0.9895\n",
        "Confusion Matrix:\n",
        "[[ 871    0    0 ...    0    0    0]\n",
        " [   0  117    0 ...    0    0    0]\n",
        " [   0    0  440 ...    0    0    0]\n",
        " ...\n",
        " [   0    0    0 ... 2617    0    0]\n",
        " [   0    0    0 ...    0  118    0]\n",
        " [   0    0    0 ...    0    0  647]]\n",
        "‚è±Ô∏è Duration: 2114.58 seconds"
      ],
      "metadata": {
        "id": "Du8dS6O0l_F7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile impute_corporateTariffCode.py\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tqdm import tqdm\n",
        "import time\n",
        "\n",
        "# === Start the timer ===\n",
        "start = time.time()\n",
        "\n",
        "# === Load and copy data ===\n",
        "train_original = pd.read_parquet(\"train.parquet\")\n",
        "test = pd.read_parquet(\"test.parquet\")\n",
        "train = train_original.copy(deep=True)\n",
        "\n",
        "# === Keep ID columns for final merge ===\n",
        "id_columns = ['Id', 'ranker_id']\n",
        "if not all(col in train.columns for col in id_columns) or not all(col in test.columns for col in id_columns):\n",
        "    raise ValueError(\"‚ùå Both train and test files must contain 'Id' and 'ranker_id' columns.\")\n",
        "\n",
        "# === Features used for prediction ===\n",
        "features = [\n",
        "    'totalPrice',\n",
        "    'companyID',\n",
        "    'legs0_segments0_cabinClass',\n",
        "    'isAccess3D',\n",
        "    'isVip',\n",
        "    'legs0_segments0_flightNumber',\n",
        "    'taxes'\n",
        "]\n",
        "\n",
        "# === Targets to impute ===\n",
        "target_columns = ['corporateTariffCode']\n",
        "\n",
        "# === Encode categorical features ===\n",
        "cat_features = [col for col in features if train[col].dtype == 'object' or test[col].dtype == 'object']\n",
        "encoders = {}\n",
        "\n",
        "print(\"\\nüî§ Encoding categorical features:\")\n",
        "for col in tqdm(cat_features, desc=\"Encoding features\"):\n",
        "    le = LabelEncoder()\n",
        "    combined = pd.concat([train[col], test[col]], axis=0).astype(str)\n",
        "    le.fit(combined)\n",
        "    train[col] = le.transform(train[col].astype(str))\n",
        "    test[col] = le.transform(test[col].astype(str))\n",
        "    encoders[col] = le\n",
        "\n",
        "# === Function to impute one target column ===\n",
        "def impute_column(target):\n",
        "    print(f\"\\nüîß Processing target: '{target}'\")\n",
        "\n",
        "    # Only use complete rows for training\n",
        "    train_valid = train.dropna(subset=features + [target])\n",
        "    if train_valid.empty:\n",
        "        print(f\"‚ùå Skipped '{target}': No complete training data.\")\n",
        "        return\n",
        "\n",
        "    X_train = train_valid[features]\n",
        "    y_raw = train_valid[target].astype(str)\n",
        "\n",
        "    # Encode target\n",
        "    le_target = LabelEncoder()\n",
        "    y_train = le_target.fit_transform(y_raw)\n",
        "\n",
        "    # === Train model ===\n",
        "    model = XGBClassifier(\n",
        "        n_estimators=500,\n",
        "        max_depth=12,\n",
        "        learning_rate=0.1,\n",
        "        tree_method='hist',\n",
        "        device='cuda',\n",
        "        n_jobs=24,\n",
        "        random_state=42,\n",
        "        eval_metric='logloss'\n",
        "    )\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # === Predict and impute missing values ===\n",
        "    for df, name in [(train, \"train\"), (test, \"test\")]:\n",
        "        missing_mask = df[target].isna()\n",
        "        if missing_mask.sum() == 0:\n",
        "            print(f\"‚úÖ {name}: No missing values in '{target}'\")\n",
        "            continue\n",
        "\n",
        "        imputable = df.loc[missing_mask, features].dropna()\n",
        "        if imputable.empty:\n",
        "            print(f\"‚ö†Ô∏è {name}: No imputable rows with all required features for '{target}'.\")\n",
        "            continue\n",
        "\n",
        "        # Predict\n",
        "        probs = model.predict_proba(imputable)\n",
        "        preds = np.argmax(probs, axis=1)\n",
        "        preds_labels = le_target.inverse_transform(preds)\n",
        "        confidences = np.max(probs, axis=1)\n",
        "\n",
        "        # Assign predictions and confidence scores\n",
        "        df.loc[imputable.index, target] = preds_labels\n",
        "        df.loc[imputable.index, f\"{target}_confidence\"] = confidences\n",
        "        print(f\"‚úÖ {name}: Imputed {len(imputable)} rows for '{target}'\")\n",
        "\n",
        "    # === Summary report ===\n",
        "    for df, name in [(train, \"train\"), (test, \"test\")]:\n",
        "        total = len(df)\n",
        "        missing = df[target].isna().sum()\n",
        "        print(f\"\\nüìä {name} ‚Äî '{target}':\")\n",
        "        print(f\"  Total: {total} rows | Missing: {missing} ({100 * missing / total:.2f}%)\")\n",
        "        print(\"  Top values:\")\n",
        "        print(df[target].value_counts(dropna=False).head(10))\n",
        "\n",
        "    # === Save imputed results with ID columns ===\n",
        "    for df, name in [(train, \"train\"), (test, \"test\")]:\n",
        "        output = df[id_columns + [target, f\"{target}_confidence\"]]\n",
        "        output.to_parquet(f\"{name}_{target}.parquet\", index=False)\n",
        "        print(f\"üíæ Saved: {name}_{target}.parquet\")\n",
        "\n",
        "# === Run for each target column ===\n",
        "for target in target_columns:\n",
        "    impute_column(target)\n",
        "\n",
        "# === Done ===\n",
        "print(f\"\\n‚è±Ô∏è Total duration: {round(time.time() - start, 2)} seconds\")"
      ],
      "metadata": {
        "id": "PlMPMCRLoEQ_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "39a73bbc-d8d7-4109-e641-bf97881b7798"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing impute_corporateTariffCode.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "üîß Processing target: 'corporateTariffCode'\n",
        "‚úÖ train: Imputed 9233925 rows for 'corporateTariffCode'\n",
        "‚úÖ test: Imputed 3535335 rows for 'corporateTariffCode'\n",
        "\n",
        "üìä train ‚Äî 'corporateTariffCode':\n",
        "  Total: 18145372 rows | Missing: 0 (0.00%)\n",
        "  Top values:\n",
        "corporateTariffCode\n",
        "108    2681238\n",
        "161    1702303\n",
        "153    1152302\n",
        "112     692479\n",
        "181     670689\n",
        "29      666098\n",
        "39      525542\n",
        "91      518967\n",
        "101     518550\n",
        "57      499939\n",
        "Name: count, dtype: Int64\n",
        "\n",
        "üìä test ‚Äî 'corporateTariffCode':\n",
        "  Total: 6897776 rows | Missing: 0 (0.00%)\n",
        "  Top values:\n",
        "corporateTariffCode\n",
        "161    954166\n",
        "108    824755\n",
        "153    454217\n",
        "57     346277\n",
        "112    322052\n",
        "29     236172\n",
        "181    207049\n",
        "54     196706\n",
        "66     188822\n",
        "91     179587\n",
        "Name: count, dtype: Int64\n",
        "üíæ Saved: train_corporateTariffCode.parquet\n",
        "üíæ Saved: test_corporateTariffCode.parquet\n",
        "\n",
        "‚è±Ô∏è Total duration: 2378.83 seconds"
      ],
      "metadata": {
        "id": "SGPHKSamGMIA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile threshold_to_use.py\n",
        "import polars as pl\n",
        "\n",
        "# Thresholds to analyze\n",
        "thresholds = [0.998, 0.996, 0.994, 0.992, 0.99, 0.98, 0.97, 0.96, 0.95, 0.90, 0.85, 0.80, 0.75, 0.70, 0.65, 0.60, 0.55, 0.50]\n",
        "\n",
        "# Files and labels\n",
        "files = {\n",
        "    \"train\": \"train_corporateTariffCode.parquet\",\n",
        "    \"test\": \"test_corporateTariffCode.parquet\"\n",
        "}\n",
        "\n",
        "# Column to analyze\n",
        "confidence_col = \"corporateTariffCode_confidence\"\n",
        "\n",
        "# Store output lines\n",
        "output_lines = []\n",
        "\n",
        "for name, path in files.items():\n",
        "    df = pl.read_parquet(path)\n",
        "    total_rows = df.height\n",
        "\n",
        "    header = f\"\\nüìÇ {name.upper()} ({path}) ‚Äî Total rows: {total_rows}\"\n",
        "    print(header)\n",
        "    output_lines.append(header)\n",
        "\n",
        "    for t in thresholds:\n",
        "        count = df.filter(pl.col(confidence_col) < t).height\n",
        "        line = f\"  < {t:.2f}: {count} rows ({count / total_rows:.2%})\"\n",
        "        print(line)\n",
        "        output_lines.append(line)\n",
        "\n",
        "# Save results to text file\n",
        "with open(\"confidence_summary.txt\", \"w\") as f:\n",
        "    f.write(\"\\n\".join(output_lines))\n",
        "\n",
        "print(\"\\n‚úÖ Results saved to 'confidence_summary.txt'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tgtcOvWIJMzJ",
        "outputId": "a2738e48-b7e4-448e-868b-8ddb4ead8fee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing threshold_to_use.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "üìÇ TRAIN (train_corporateTariffCode.parquet) ‚Äî Total rows: 18145372\n",
        "  < 0.95: 2330633 rows (12.84%)\n",
        "  < 0.90: 1855031 rows (10.22%)\n",
        "  < 0.85: 1543493 rows (8.51%)\n",
        "  < 0.80: 1302455 rows (7.18%)\n",
        "  < 0.75: 1089950 rows (6.01%)\n",
        "  < 0.70: 901057 rows (4.97%)\n",
        "  < 0.65: 730767 rows (4.03%)\n",
        "  < 0.60: 561450 rows (3.09%)\n",
        "  < 0.55: 394565 rows (2.17%)\n",
        "  < 0.50: 228448 rows (1.26%)\n",
        "\n",
        "üìÇ TEST (test_corporateTariffCode.parquet) ‚Äî Total rows: 6897776\n",
        "  < 0.95: 913306 rows (13.24%)\n",
        "  < 0.90: 721933 rows (10.47%)\n",
        "  < 0.85: 595711 rows (8.64%)\n",
        "  < 0.80: 497986 rows (7.22%)\n",
        "  < 0.75: 415604 rows (6.03%)\n",
        "  < 0.70: 341673 rows (4.95%)\n",
        "  < 0.65: 273161 rows (3.96%)\n",
        "  < 0.60: 206979 rows (3.00%)\n",
        "  < 0.55: 143036 rows (2.07%)\n",
        "  < 0.50: 80523 rows (1.17%)\n",
        "\n",
        "‚úÖ Results saved to 'confidence_summary.txt'"
      ],
      "metadata": {
        "id": "WtFmU7FAKAtc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile remove_based_thr.py\n",
        "import polars as pl\n",
        "\n",
        "# === Files to process ===\n",
        "files = {\n",
        "    \"train_corporateTariffCode.parquet\": \"train_corporateTariffCode_filtered.parquet\",\n",
        "    \"test_corporateTariffCode.parquet\": \"test_corporateTariffCode_filtered.parquet\"\n",
        "}\n",
        "\n",
        "# === Threshold and columns ===\n",
        "confidence_col = \"corporateTariffCode_confidence\"\n",
        "target_col = \"corporateTariffCode\"\n",
        "threshold = 0.995\n",
        "\n",
        "for input_path, output_path in files.items():\n",
        "    # Load the data\n",
        "    df = pl.read_parquet(input_path)\n",
        "\n",
        "    # Replace low-confidence values with null\n",
        "    df_cleaned = df.with_columns([\n",
        "        pl.when(df[confidence_col] < threshold)\n",
        "        .then(None)\n",
        "        .otherwise(df[target_col])\n",
        "        .alias(target_col)\n",
        "    ])\n",
        "\n",
        "    # Save the cleaned dataframe\n",
        "    df_cleaned.write_parquet(output_path)\n",
        "    print(f\"‚úÖ Saved: '{output_path}' with low-confidence values removed.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VlBVg2gNZm-C",
        "outputId": "8f12c148-41e6-41e1-af3c-20c741b54044"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing remove_based_thr.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile change_corporateTariffCode_values.py\n",
        "import polars as pl\n",
        "\n",
        "# === Define file pairs (input, filtered) ===\n",
        "file_pairs = [\n",
        "    (\"train.parquet\", \"train_corporateTariffCode_filtered.parquet\", \"train_filled.parquet\"),\n",
        "    (\"test.parquet\", \"test_corporateTariffCode_filtered.parquet\", \"test_filled.parquet\")\n",
        "]\n",
        "\n",
        "# === Column to update ===\n",
        "column_name = \"corporateTariffCode\"\n",
        "\n",
        "for original_path, filtered_path, output_path in file_pairs:\n",
        "    # Load data\n",
        "    df_orig = pl.read_parquet(original_path)\n",
        "    df_filtered = pl.read_parquet(filtered_path)\n",
        "\n",
        "    # Validate IDs match\n",
        "    if df_orig.shape[0] != df_filtered.shape[0] or not (df_orig[\"Id\"] == df_filtered[\"Id\"]).all():\n",
        "        raise ValueError(f\"‚ùå '{original_path}' and '{filtered_path}' must have same number of rows and identical 'Id' order.\")\n",
        "\n",
        "    # Replace nulls in original with non-null values from filtered\n",
        "    updated_column = (\n",
        "        pl.when(df_orig[column_name].is_null() & df_filtered[column_name].is_not_null())\n",
        "        .then(df_filtered[column_name])\n",
        "        .otherwise(df_orig[column_name])\n",
        "    )\n",
        "\n",
        "    # Update DataFrame\n",
        "    df_updated = df_orig.with_columns([\n",
        "        updated_column.alias(column_name)\n",
        "    ])\n",
        "\n",
        "    # Save result\n",
        "    df_updated.write_parquet(output_path)\n",
        "    print(f\"‚úÖ File saved as '{output_path}'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B6BYJZXBZIOc",
        "outputId": "4e2ba960-860a-45bf-a9de-082d8e5c4616"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing change_corporateTariffCode_values.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile test_imputation.py\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import shutil\n",
        "import time\n",
        "from tqdm import tqdm\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
        "\n",
        "# === Timer start ===\n",
        "start = time.time()\n",
        "\n",
        "# === Copy original file to avoid modifying it ===\n",
        "original_path = \"train.parquet\"\n",
        "copy_path = \"train_copy.parquet\"\n",
        "shutil.copy(original_path, copy_path)\n",
        "\n",
        "# === Load copied data ===\n",
        "df = pd.read_parquet(copy_path)\n",
        "\n",
        "# === Feature and target setup ===\n",
        "selected_features = [\n",
        "    'totalPrice',\n",
        "    'companyID',\n",
        "    'legs0_segments0_cabinClass',\n",
        "    'isAccess3D',\n",
        "    'isVip',\n",
        "    'legs0_segments0_flightNumber',\n",
        "    'taxes'\n",
        "]\n",
        "target_col = 'frequentFlyer'\n",
        "cols_needed = selected_features + [target_col]\n",
        "\n",
        "# === Drop missing values ===\n",
        "df_clean = df[cols_needed].dropna()\n",
        "\n",
        "# === Separate features and raw target ===\n",
        "X = df_clean[selected_features].copy()\n",
        "y_raw = df_clean[target_col]\n",
        "\n",
        "# === Filter out rare classes (frequency < 2) BEFORE encoding ===\n",
        "value_counts = y_raw.value_counts()\n",
        "valid_classes = value_counts[value_counts >= 2].index\n",
        "mask = y_raw.isin(valid_classes)\n",
        "\n",
        "X = X.loc[mask]\n",
        "y_raw_filtered = y_raw.loc[mask]\n",
        "\n",
        "# === Train-validation split (stratified), still using raw labels ===\n",
        "X_train, X_valid, y_train_raw, y_valid_raw = train_test_split(\n",
        "    X, y_raw_filtered, test_size=1_000_000, stratify=y_raw_filtered, random_state=42\n",
        ")\n",
        "\n",
        "# === Keep only common classes between train and valid ===\n",
        "common_classes = set(y_train_raw.unique()) & set(y_valid_raw.unique())\n",
        "train_mask = y_train_raw.isin(common_classes)\n",
        "valid_mask = y_valid_raw.isin(common_classes)\n",
        "\n",
        "X_train = X_train.loc[train_mask]\n",
        "X_valid = X_valid.loc[valid_mask]\n",
        "y_train_raw = y_train_raw.loc[train_mask]\n",
        "y_valid_raw = y_valid_raw.loc[valid_mask]\n",
        "\n",
        "# === Encode labels AFTER filtering ===\n",
        "le = LabelEncoder()\n",
        "le.fit(y_train_raw)\n",
        "y_train = le.transform(y_train_raw)\n",
        "y_valid = le.transform(y_valid_raw)\n",
        "\n",
        "# === Encode categorical features ===\n",
        "cat_columns = ['companyID', 'legs0_segments0_cabinClass', 'legs0_segments0_flightNumber']\n",
        "label_encoders = {}\n",
        "\n",
        "print(\"\\nüî§ Encoding categorical features:\")\n",
        "for col in tqdm(cat_columns, desc=\"Encoding\"):\n",
        "    le_col = LabelEncoder()\n",
        "    combined = pd.concat([X_train[col], X_valid[col]], axis=0).astype(str)\n",
        "    le_col.fit(combined)\n",
        "    X_train[col] = le_col.transform(X_train[col].astype(str))\n",
        "    X_valid[col] = le_col.transform(X_valid[col].astype(str))\n",
        "    label_encoders[col] = le_col\n",
        "\n",
        "# === Train XGBoost model (GPU-compatible setup) ===\n",
        "model = XGBClassifier(\n",
        "    n_estimators=500,\n",
        "    max_depth=12,\n",
        "    learning_rate=0.1,\n",
        "    tree_method='hist',\n",
        "    device='cuda',\n",
        "    n_jobs=24,\n",
        "    random_state=42,\n",
        "    eval_metric='logloss'\n",
        ")\n",
        "\n",
        "print(\"\\nüöÄ Training model on GPU...\")\n",
        "for _ in tqdm(range(1), desc=\"Fitting model\"):\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "# === Predict in batches ===\n",
        "print(\"üîç Predicting on validation set...\")\n",
        "predicted = []\n",
        "batch_size = 500_000\n",
        "for i in tqdm(range(0, len(X_valid), batch_size), desc=\"Predicting\"):\n",
        "    batch = X_valid.iloc[i:i+batch_size]\n",
        "    predicted.extend(model.predict(batch))\n",
        "predicted = np.array(predicted)\n",
        "\n",
        "# === Evaluation ===\n",
        "acc = accuracy_score(y_valid, predicted)\n",
        "f1 = f1_score(y_valid, predicted, average='weighted')\n",
        "cm = confusion_matrix(y_valid, predicted)\n",
        "duration = round(time.time() - start, 2)\n",
        "\n",
        "# === Save results ===\n",
        "with open(\"imputation_results.txt\", \"w\") as f:\n",
        "    f.write(\"‚úÖ Direct prediction results (XGBClassifier + GPU):\\n\")\n",
        "    f.write(f\"Accuracy: {acc:.4f}\\n\")\n",
        "    f.write(f\"F1 Score (weighted): {f1:.4f}\\n\")\n",
        "    f.write(\"Confusion Matrix:\\n\")\n",
        "    f.write(np.array2string(cm))\n",
        "    f.write(f\"\\n‚è±Ô∏è Duration: {duration} seconds\\n\")\n",
        "\n",
        "print(\"‚úÖ Results saved to imputation_results.txt\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cBNE5vLpaIbN",
        "outputId": "b8c7489c-d9be-49f4-a1d6-507ea5f52edd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting test_imputation.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "‚úÖ Direct prediction results (XGBClassifier + GPU):\n",
        "Accuracy: 0.7664\n",
        "F1 Score (weighted): 0.7618\n",
        "Confusion Matrix:\n",
        "[[203   0   0 ...   0   0   0]\n",
        " [  0  25   0 ...   0   0   0]\n",
        " [  0   0 281 ...   0   0   0]\n",
        " ...\n",
        " [  0   0   0 ...  37   0   0]\n",
        " [  0   0   0 ...   0  27   2]\n",
        " [  0   0   0 ...   0   2  25]]\n",
        "‚è±Ô∏è Duration: 3699.16 seconds"
      ],
      "metadata": {
        "id": "SRzr46hYyGMw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile impute_frequentFlyer.py\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tqdm import tqdm\n",
        "import time\n",
        "\n",
        "# === Start the timer ===\n",
        "start = time.time()\n",
        "\n",
        "# === Load and copy data ===\n",
        "train_original = pd.read_parquet(\"train.parquet\")\n",
        "test = pd.read_parquet(\"test.parquet\")\n",
        "train = train_original.copy(deep=True)\n",
        "\n",
        "# === Keep ID columns for final merge ===\n",
        "id_columns = ['Id', 'ranker_id']\n",
        "if not all(col in train.columns for col in id_columns) or not all(col in test.columns for col in id_columns):\n",
        "    raise ValueError(\"‚ùå Both train and test files must contain 'Id' and 'ranker_id' columns.\")\n",
        "\n",
        "# === Features used for prediction ===\n",
        "features = [\n",
        "    'totalPrice',\n",
        "    'companyID',\n",
        "    'legs0_segments0_cabinClass',\n",
        "    'isAccess3D',\n",
        "    'isVip',\n",
        "    'legs0_segments0_flightNumber',\n",
        "    'taxes'\n",
        "]\n",
        "\n",
        "# === Targets to impute ===\n",
        "target_columns = ['frequentFlyer']\n",
        "\n",
        "# === Encode categorical features ===\n",
        "cat_features = [col for col in features if train[col].dtype == 'object' or test[col].dtype == 'object']\n",
        "encoders = {}\n",
        "\n",
        "print(\"\\nüî§ Encoding categorical features:\")\n",
        "for col in tqdm(cat_features, desc=\"Encoding features\"):\n",
        "    le = LabelEncoder()\n",
        "    combined = pd.concat([train[col], test[col]], axis=0).astype(str)\n",
        "    le.fit(combined)\n",
        "    train[col] = le.transform(train[col].astype(str))\n",
        "    test[col] = le.transform(test[col].astype(str))\n",
        "    encoders[col] = le\n",
        "\n",
        "# === Function to impute one target column ===\n",
        "def impute_column(target):\n",
        "    print(f\"\\nüîß Processing target: '{target}'\")\n",
        "\n",
        "    # Only use complete rows for training\n",
        "    train_valid = train.dropna(subset=features + [target])\n",
        "    if train_valid.empty:\n",
        "        print(f\"‚ùå Skipped '{target}': No complete training data.\")\n",
        "        return\n",
        "\n",
        "    X_train = train_valid[features]\n",
        "    y_raw = train_valid[target].astype(str)\n",
        "\n",
        "    # Encode target\n",
        "    le_target = LabelEncoder()\n",
        "    y_train = le_target.fit_transform(y_raw)\n",
        "\n",
        "    # === Train model ===\n",
        "    model = XGBClassifier(\n",
        "        n_estimators=500,\n",
        "        max_depth=12,\n",
        "        learning_rate=0.1,\n",
        "        tree_method='hist',\n",
        "        device='cpu',\n",
        "        n_jobs=24,\n",
        "        random_state=42,\n",
        "        eval_metric='logloss'\n",
        "    )\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # === Predict and impute missing values ===\n",
        "    for df, name in [(train, \"train\"), (test, \"test\")]:\n",
        "        missing_mask = df[target].isna()\n",
        "        if missing_mask.sum() == 0:\n",
        "            print(f\"‚úÖ {name}: No missing values in '{target}'\")\n",
        "            continue\n",
        "\n",
        "        imputable = df.loc[missing_mask, features].dropna()\n",
        "        if imputable.empty:\n",
        "            print(f\"‚ö†Ô∏è {name}: No imputable rows with all required features for '{target}'.\")\n",
        "            continue\n",
        "\n",
        "        # Predict\n",
        "        probs = model.predict_proba(imputable)\n",
        "        preds = np.argmax(probs, axis=1)\n",
        "        preds_labels = le_target.inverse_transform(preds)\n",
        "        confidences = np.max(probs, axis=1)\n",
        "\n",
        "        # Assign predictions and confidence scores\n",
        "        df.loc[imputable.index, target] = preds_labels\n",
        "        df.loc[imputable.index, f\"{target}_confidence\"] = confidences\n",
        "        print(f\"‚úÖ {name}: Imputed {len(imputable)} rows for '{target}'\")\n",
        "\n",
        "    # === Summary report ===\n",
        "    for df, name in [(train, \"train\"), (test, \"test\")]:\n",
        "        total = len(df)\n",
        "        missing = df[target].isna().sum()\n",
        "        print(f\"\\nüìä {name} ‚Äî '{target}':\")\n",
        "        print(f\"  Total: {total} rows | Missing: {missing} ({100 * missing / total:.2f}%)\")\n",
        "        print(\"  Top values:\")\n",
        "        print(df[target].value_counts(dropna=False).head(10))\n",
        "\n",
        "    # === Save imputed results with ID columns ===\n",
        "    for df, name in [(train, \"train\"), (test, \"test\")]:\n",
        "        output = df[id_columns + [target, f\"{target}_confidence\"]]\n",
        "        output.to_parquet(f\"{name}_{target}.parquet\", index=False)\n",
        "        print(f\"üíæ Saved: {name}_{target}.parquet\")\n",
        "\n",
        "# === Run for each target column ===\n",
        "for target in target_columns:\n",
        "    impute_column(target)\n",
        "\n",
        "# === Done ===\n",
        "print(f\"\\n‚è±Ô∏è Total duration: {round(time.time() - start, 2)} seconds\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jTyXHHzqhDO_",
        "outputId": "2dccc897-2e98-4e0a-b5ac-bb3078122ebb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting impute_frequentFlyer.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "üîß Processing target: 'frequentFlyer'\n",
        "‚úÖ train: Imputed 12012727 rows for 'frequentFlyer'\n",
        "‚úÖ test: Imputed 3974920 rows for 'frequentFlyer'\n",
        "\n",
        "üìä train ‚Äî 'frequentFlyer':\n",
        "  Total: 18145372 rows | Missing: 0 (0.00%)\n",
        "  Top values:\n",
        "frequentFlyer\n",
        "SU          11255819\n",
        "SU/S7        2316269\n",
        "S7/SU         913382\n",
        "S7            727887\n",
        "SU/TK         374475\n",
        "SU/S7/UT      201526\n",
        "S7/SU/U6      187879\n",
        "SU/UT         154466\n",
        "SU/S7/U6      151065\n",
        "SU/U6         139020\n",
        "Name: count, dtype: int64\n",
        "\n",
        "üìä test ‚Äî 'frequentFlyer':\n",
        "  Total: 6897776 rows | Missing: 0 (0.00%)\n",
        "  Top values:\n",
        "frequentFlyer\n",
        "SU          3871364\n",
        "SU/S7        978840\n",
        "S7/SU        535440\n",
        "S7           274501\n",
        "SU/S7/UT      99802\n",
        "SU/S7/U6      94280\n",
        "SU/UT         90012\n",
        "SU/TK         78246\n",
        "SU/U6         64699\n",
        "S7/SU/UT      49531\n",
        "Name: count, dtype: int64\n",
        "üíæ Saved: train_frequentFlyer.parquet\n",
        "üíæ Saved: test_frequentFlyer.parquet\n",
        "\n",
        "‚è±Ô∏è Total duration: 15440.66 seconds"
      ],
      "metadata": {
        "id": "h5d9z6YhK_-t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile threshold_to_use.py\n",
        "import polars as pl\n",
        "\n",
        "# Thresholds to analyze\n",
        "thresholds = [0.998, 0.996, 0.994, 0.992, 0.99, 0.98, 0.97, 0.96, 0.95, 0.90, 0.85, 0.80, 0.75, 0.70, 0.65, 0.60, 0.55, 0.50]\n",
        "\n",
        "# Files and labels\n",
        "files = {\n",
        "    \"train\": \"train_frequentFlyer.parquet\",\n",
        "    \"test\": \"test_frequentFlyer.parquet\"\n",
        "}\n",
        "\n",
        "# Column to analyze\n",
        "confidence_col = \"frequentFlyer_confidence\"\n",
        "\n",
        "# Store output lines\n",
        "output_lines = []\n",
        "\n",
        "for name, path in files.items():\n",
        "    df = pl.read_parquet(path)\n",
        "    total_rows = df.height\n",
        "\n",
        "    header = f\"\\nüìÇ {name.upper()} ({path}) ‚Äî Total rows: {total_rows}\"\n",
        "    print(header)\n",
        "    output_lines.append(header)\n",
        "\n",
        "    for t in thresholds:\n",
        "        count = df.filter(pl.col(confidence_col) < t).height\n",
        "        line = f\"  < {t:.2f}: {count} rows ({count / total_rows:.2%})\"\n",
        "        print(line)\n",
        "        output_lines.append(line)\n",
        "\n",
        "# Save results to text file\n",
        "with open(\"confidence_summary.txt\", \"w\") as f:\n",
        "    f.write(\"\\n\".join(output_lines))\n",
        "\n",
        "print(\"\\n‚úÖ Results saved to 'confidence_summary.txt'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ABsYVEheLpcM",
        "outputId": "6edd37d4-0fec-488d-c16d-ff92aeaf412e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing threshold_to_use.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile remove_based_thr.py\n",
        "import polars as pl\n",
        "\n",
        "# === Files to process ===\n",
        "files = {\n",
        "    \"train_frequentFlyer.parquet\": \"train_frequentFlyer_filtered.parquet\",\n",
        "    \"test_frequentFlyer.parquet\": \"test_frequentFlyer_filtered.parquet\"\n",
        "}\n",
        "\n",
        "# === Threshold and columns ===\n",
        "confidence_col = \"frequentFlyer_confidence\"\n",
        "target_col = \"frequentFlyer\"\n",
        "threshold = 0.99\n",
        "\n",
        "for input_path, output_path in files.items():\n",
        "    # Load the data\n",
        "    df = pl.read_parquet(input_path)\n",
        "\n",
        "    # Replace low-confidence values with null\n",
        "    df_cleaned = df.with_columns([\n",
        "        pl.when(df[confidence_col] < threshold)\n",
        "        .then(None)\n",
        "        .otherwise(df[target_col])\n",
        "        .alias(target_col)\n",
        "    ])\n",
        "\n",
        "    # Save the cleaned dataframe\n",
        "    df_cleaned.write_parquet(output_path)\n",
        "    print(f\"‚úÖ Saved: '{output_path}' with low-confidence values removed.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HolhOWVcNEIt",
        "outputId": "65aff3f3-1632-45d3-fc43-ee89cccdc5c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing remove_based_thr.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile change_frequentFlyer_values.py\n",
        "import polars as pl\n",
        "\n",
        "# === Define file pairs (input, filtered) ===\n",
        "file_pairs = [\n",
        "    (\"train.parquet\", \"train_frequentFlyer_filtered.parquet\", \"train_filled.parquet\"),\n",
        "    (\"test.parquet\", \"test_frequentFlyer_filtered.parquet\", \"test_filled.parquet\")\n",
        "]\n",
        "\n",
        "# === Column to update ===\n",
        "column_name = \"frequentFlyer\"\n",
        "\n",
        "for original_path, filtered_path, output_path in file_pairs:\n",
        "    # Load data\n",
        "    df_orig = pl.read_parquet(original_path)\n",
        "    df_filtered = pl.read_parquet(filtered_path)\n",
        "\n",
        "    # Validate IDs match\n",
        "    if df_orig.shape[0] != df_filtered.shape[0] or not (df_orig[\"Id\"] == df_filtered[\"Id\"]).all():\n",
        "        raise ValueError(f\"‚ùå '{original_path}' and '{filtered_path}' must have same number of rows and identical 'Id' order.\")\n",
        "\n",
        "    # Replace nulls in original with non-null values from filtered\n",
        "    updated_column = (\n",
        "        pl.when(df_orig[column_name].is_null() & df_filtered[column_name].is_not_null())\n",
        "        .then(df_filtered[column_name])\n",
        "        .otherwise(df_orig[column_name])\n",
        "    )\n",
        "\n",
        "    # Update DataFrame\n",
        "    df_updated = df_orig.with_columns([\n",
        "        updated_column.alias(column_name)\n",
        "    ])\n",
        "\n",
        "    # Save result\n",
        "    df_updated.write_parquet(output_path)\n",
        "    print(f\"‚úÖ File saved as '{output_path}'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B1_wQaDENG3P",
        "outputId": "50a2ebf2-b476-4f50-bffc-8d94357757e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing change_frequentFlyer_values.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile test_imputation.py\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import shutil\n",
        "import time\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "\n",
        "# === Start the timer ===\n",
        "start = time.time()\n",
        "\n",
        "# === Create a safe copy of the original file ===\n",
        "original_path = \"train.parquet\"\n",
        "copy_path = \"train_copy.parquet\"\n",
        "shutil.copy(original_path, copy_path)\n",
        "\n",
        "# === Load the copied data (.parquet) ===\n",
        "df = pd.read_parquet(copy_path)\n",
        "\n",
        "# === Select relevant columns ===\n",
        "selected_features = [\n",
        "    'totalPrice',\n",
        "    'companyID',\n",
        "    'legs0_segments0_cabinClass',\n",
        "    'isAccess3D',\n",
        "    'isVip',\n",
        "    'legs0_segments0_flightNumber',\n",
        "    'taxes'\n",
        "]\n",
        "target_col = 'miniRules0_monetaryAmount'\n",
        "cols_needed = selected_features + [target_col]\n",
        "\n",
        "# === Filter complete rows for training ===\n",
        "df_full = df[cols_needed].dropna(subset=cols_needed)\n",
        "\n",
        "# === Randomly select 1,000,000 rows for validation ===\n",
        "sample = df_full.sample(n=1_000_000, random_state=42)\n",
        "X_valid = sample[selected_features].copy()\n",
        "y_valid = sample[target_col].copy()\n",
        "\n",
        "# === Remove validation rows from training set ===\n",
        "df_train = df_full.drop(sample.index, errors='ignore')\n",
        "X_train = df_train[selected_features].copy()\n",
        "y_train = df_train[target_col].copy()\n",
        "\n",
        "# === Encode categorical features ===\n",
        "cat_cols = ['companyID', 'legs0_segments0_cabinClass', 'legs0_segments0_flightNumber']\n",
        "print(\"\\nüî§ Encoding categorical features...\")\n",
        "category_maps = {}\n",
        "\n",
        "for col in cat_cols:\n",
        "    X_train[col], uniques = pd.factorize(X_train[col])\n",
        "    X_valid[col] = uniques.get_indexer(X_valid[col])\n",
        "    category_maps[col] = list(uniques)\n",
        "\n",
        "# === Train the model ===\n",
        "model = XGBRegressor(\n",
        "    n_estimators=2000,\n",
        "    max_depth=16,\n",
        "    learning_rate=0.1,\n",
        "    tree_method='hist',\n",
        "    device='cuda',\n",
        "    n_jobs=24,\n",
        "    random_state=42,\n",
        "    eval_metric='rmse'\n",
        ")\n",
        "print(\"\\nüöÄ Training model...\")\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# === Predict on the validation set ===\n",
        "y_pred = model.predict(X_valid)\n",
        "\n",
        "# === Compute evaluation metrics ===\n",
        "mae = mean_absolute_error(y_valid, y_pred)\n",
        "rmse = np.sqrt(mean_squared_error(y_valid, y_pred))\n",
        "r2 = r2_score(y_valid, y_pred)\n",
        "duration = round(time.time() - start, 2)\n",
        "\n",
        "# === Save results ===\n",
        "with open(\"imputation_results.txt\", \"w\") as f:\n",
        "    f.write(\"‚úÖ Imputation evaluation (XGBRegressor on train_copy.parquet):\\n\")\n",
        "    f.write(f\"MAE: {mae:.2f}\\n\")\n",
        "    f.write(f\"RMSE: {rmse:.2f}\\n\")\n",
        "    f.write(f\"R¬≤ Score: {r2:.4f}\\n\")\n",
        "    f.write(f\"‚è±Ô∏è Duration: {duration} seconds\\n\")\n",
        "\n",
        "print(\"‚úÖ Results saved to imputation_results.txt\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9U8ETHSgyzv6",
        "outputId": "c480fd05-9c18-438a-9e4b-3fb701f676ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting test_imputation.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "‚úÖ Imputation evaluation (XGBRegressor on train_copy.parquet):\n",
        "MAE: 253.16\n",
        "RMSE: 1268.10\n",
        "R¬≤ Score: 0.8554\n",
        "‚è±Ô∏è Duration: 279.34 seconds"
      ],
      "metadata": {
        "id": "CGFiGGx80j14"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile test_imputation.py\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import shutil\n",
        "import time\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "\n",
        "# === Start the timer ===\n",
        "start = time.time()\n",
        "\n",
        "# === Create a safe copy of the original file ===\n",
        "original_path = \"train.parquet\"\n",
        "copy_path = \"train_copy.parquet\"\n",
        "shutil.copy(original_path, copy_path)\n",
        "\n",
        "# === Load the copied data (.parquet) ===\n",
        "df = pd.read_parquet(copy_path)\n",
        "\n",
        "# === Select relevant columns ===\n",
        "selected_features = [\n",
        "    'totalPrice',\n",
        "    'companyID',\n",
        "    'legs0_segments0_cabinClass',\n",
        "    'isAccess3D',\n",
        "    'isVip',\n",
        "    'legs0_segments0_flightNumber',\n",
        "    'taxes'\n",
        "]\n",
        "target_col = 'miniRules0_monetaryAmount'\n",
        "cols_needed = selected_features + [target_col]\n",
        "\n",
        "# === Filter complete rows for training ===\n",
        "df_full = df[cols_needed].dropna(subset=cols_needed)\n",
        "\n",
        "# === Randomly select 1,000,000 rows for validation ===\n",
        "sample = df_full.sample(n=1_000_000, random_state=42)\n",
        "X_valid = sample[selected_features].copy()\n",
        "y_valid = sample[target_col].copy()\n",
        "\n",
        "# === Remove validation rows from training set ===\n",
        "df_train = df_full.drop(sample.index, errors='ignore')\n",
        "X_train = df_train[selected_features].copy()\n",
        "y_train = df_train[target_col].copy()\n",
        "\n",
        "# === Encode categorical features ===\n",
        "cat_cols = ['companyID', 'legs0_segments0_cabinClass', 'legs0_segments0_flightNumber']\n",
        "print(\"\\nüî§ Encoding categorical features...\")\n",
        "category_maps = {}\n",
        "\n",
        "for col in cat_cols:\n",
        "    X_train[col], uniques = pd.factorize(X_train[col])\n",
        "    X_valid[col] = uniques.get_indexer(X_valid[col])\n",
        "    category_maps[col] = list(uniques)\n",
        "\n",
        "# === Train the model ===\n",
        "model = XGBRegressor(\n",
        "    n_estimators=2000,\n",
        "    max_depth=16,\n",
        "    learning_rate=0.1,\n",
        "    tree_method='hist',\n",
        "    device='cuda',\n",
        "    n_jobs=24,\n",
        "    random_state=42,\n",
        "    eval_metric='rmse'\n",
        ")\n",
        "print(\"\\nüöÄ Training model...\")\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# === Predict on the validation set ===\n",
        "y_pred = model.predict(X_valid)\n",
        "\n",
        "# === Round predictions and clip negative values to 0 ===\n",
        "y_pred = np.round(np.clip(y_pred, 0, None))\n",
        "\n",
        "# === Compute evaluation metrics ===\n",
        "mae = mean_absolute_error(y_valid, y_pred)\n",
        "rmse = np.sqrt(mean_squared_error(y_valid, y_pred))\n",
        "r2 = r2_score(y_valid, y_pred)\n",
        "duration = round(time.time() - start, 2)\n",
        "\n",
        "# === Save results ===\n",
        "with open(\"imputation_results.txt\", \"w\") as f:\n",
        "    f.write(\"‚úÖ Imputation evaluation (XGBRegressor on train_copy.parquet):\\n\")\n",
        "    f.write(f\"MAE: {mae:.2f}\\n\")\n",
        "    f.write(f\"RMSE: {rmse:.2f}\\n\")\n",
        "    f.write(f\"R¬≤ Score: {r2:.4f}\\n\")\n",
        "    f.write(f\"‚è±Ô∏è Duration: {duration} seconds\\n\")\n",
        "\n",
        "print(\"‚úÖ Results saved to imputation_results.txt\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m_xnid3M3lxh",
        "outputId": "4b855562-accb-4f8b-ac24-b5ed06518398"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting test_imputation.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MAE: 249.32\n",
        "RMSE: 1267.43\n",
        "R¬≤ Score: 0.8555\n",
        "‚è±Ô∏è Duration: 263.22 seconds"
      ],
      "metadata": {
        "id": "yLVtZ_JY5VFx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile test_imputation.py\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import shutil\n",
        "import time\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "\n",
        "# === Start the timer ===\n",
        "start = time.time()\n",
        "\n",
        "# === Create a safe copy of the original file ===\n",
        "original_path = \"train.parquet\"\n",
        "copy_path = \"train_copy.parquet\"\n",
        "shutil.copy(original_path, copy_path)\n",
        "\n",
        "# === Load the copied data (.parquet) ===\n",
        "df = pd.read_parquet(copy_path)\n",
        "\n",
        "# === Select relevant columns ===\n",
        "selected_features = [\n",
        "    'totalPrice',\n",
        "    'companyID',\n",
        "    'legs0_segments0_cabinClass',\n",
        "    'isAccess3D',\n",
        "    'isVip',\n",
        "    'legs0_segments0_flightNumber',\n",
        "    'taxes'\n",
        "]\n",
        "target_col = 'miniRules1_monetaryAmount'\n",
        "cols_needed = selected_features + [target_col]\n",
        "\n",
        "# === Filter complete rows for training ===\n",
        "df_full = df[cols_needed].dropna(subset=cols_needed)\n",
        "\n",
        "# === Randomly select 1,000,000 rows for validation ===\n",
        "sample = df_full.sample(n=1_000_000, random_state=42)\n",
        "X_valid = sample[selected_features].copy()\n",
        "y_valid = sample[target_col].copy()\n",
        "\n",
        "# === Remove validation rows from training set ===\n",
        "df_train = df_full.drop(sample.index, errors='ignore')\n",
        "X_train = df_train[selected_features].copy()\n",
        "y_train = df_train[target_col].copy()\n",
        "\n",
        "# === Encode categorical features ===\n",
        "cat_cols = ['companyID', 'legs0_segments0_cabinClass', 'legs0_segments0_flightNumber']\n",
        "print(\"\\nüî§ Encoding categorical features...\")\n",
        "category_maps = {}\n",
        "\n",
        "for col in cat_cols:\n",
        "    X_train[col], uniques = pd.factorize(X_train[col])\n",
        "    X_valid[col] = uniques.get_indexer(X_valid[col])\n",
        "    category_maps[col] = list(uniques)\n",
        "\n",
        "# === Train the model ===\n",
        "model = XGBRegressor(\n",
        "    n_estimators=2000,\n",
        "    max_depth=16,\n",
        "    learning_rate=0.1,\n",
        "    tree_method='hist',\n",
        "    device='cuda',\n",
        "    n_jobs=24,\n",
        "    random_state=42,\n",
        "    eval_metric='rmse'\n",
        ")\n",
        "print(\"\\nüöÄ Training model...\")\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# === Predict on the validation set ===\n",
        "y_pred = model.predict(X_valid)\n",
        "\n",
        "# === Round predictions and clip negative values to 0 ===\n",
        "y_pred = np.round(np.clip(y_pred, 0, None))\n",
        "\n",
        "# === Compute evaluation metrics ===\n",
        "mae = mean_absolute_error(y_valid, y_pred)\n",
        "rmse = np.sqrt(mean_squared_error(y_valid, y_pred))\n",
        "r2 = r2_score(y_valid, y_pred)\n",
        "duration = round(time.time() - start, 2)\n",
        "\n",
        "# === Save results ===\n",
        "with open(\"imputation_results.txt\", \"w\") as f:\n",
        "    f.write(\"‚úÖ Imputation evaluation (XGBRegressor on train_copy.parquet):\\n\")\n",
        "    f.write(f\"MAE: {mae:.2f}\\n\")\n",
        "    f.write(f\"RMSE: {rmse:.2f}\\n\")\n",
        "    f.write(f\"R¬≤ Score: {r2:.4f}\\n\")\n",
        "    f.write(f\"‚è±Ô∏è Duration: {duration} seconds\\n\")\n",
        "\n",
        "print(\"‚úÖ Results saved to imputation_results.txt\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5g14QZSj3QU-",
        "outputId": "a53c78f6-e5a7-4a12-809b-d9eff2725185"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting test_imputation.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "‚úÖ Imputation evaluation (XGBRegressor on train_copy.parquet):\n",
        "MAE: 385.78\n",
        "RMSE: 4847.35\n",
        "R¬≤ Score: 0.4761\n",
        "‚è±Ô∏è Duration: 339.3 seconds"
      ],
      "metadata": {
        "id": "BglJIaHu5QwR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile impute_monetary.py\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tqdm import tqdm\n",
        "import time\n",
        "\n",
        "# === Start the timer ===\n",
        "start = time.time()\n",
        "\n",
        "# === Load data ===\n",
        "train = pd.read_parquet(\"train.parquet\")\n",
        "test = pd.read_parquet(\"test.parquet\")\n",
        "\n",
        "# === Keep ID columns for final merge ===\n",
        "id_columns = ['Id', 'ranker_id']\n",
        "if not all(col in train.columns for col in id_columns) or not all(col in test.columns for col in id_columns):\n",
        "    raise ValueError(\"‚ùå Both train and test files must contain 'Id' and 'ranker_id' columns.\")\n",
        "\n",
        "# === Features and targets ===\n",
        "features = [\n",
        "    'totalPrice',\n",
        "    'companyID',\n",
        "    'legs0_segments0_cabinClass',\n",
        "    'isAccess3D',\n",
        "    'isVip',\n",
        "    'legs0_segments0_flightNumber',\n",
        "    'taxes'\n",
        "]\n",
        "target_columns = ['miniRules0_monetaryAmount', 'miniRules1_monetaryAmount']\n",
        "\n",
        "# === Encode categorical features ===\n",
        "cat_features = [col for col in features if train[col].dtype == 'object' or test[col].dtype == 'object']\n",
        "encoders = {}\n",
        "\n",
        "print(\"\\nüî§ Encoding categorical features:\")\n",
        "for col in tqdm(cat_features, desc=\"Encoding features\"):\n",
        "    le = LabelEncoder()\n",
        "    combined = pd.concat([train[col], test[col]], axis=0).astype(str)\n",
        "    le.fit(combined)\n",
        "    train[col] = le.transform(train[col].astype(str))\n",
        "    test[col] = le.transform(test[col].astype(str))\n",
        "    encoders[col] = le\n",
        "\n",
        "# === Impute numeric target columns ===\n",
        "def impute_column(target):\n",
        "    print(f\"\\nüîß Imputing: '{target}'\")\n",
        "\n",
        "    train_valid = train.dropna(subset=features + [target])\n",
        "    if train_valid.empty:\n",
        "        print(f\"‚ùå Skipped '{target}': No valid training data.\")\n",
        "        return\n",
        "\n",
        "    X_train = train_valid[features]\n",
        "    y_train = train_valid[target].astype(float)\n",
        "\n",
        "    # === Train model ===\n",
        "    model = XGBRegressor(\n",
        "        n_estimators=2000,\n",
        "        max_depth=16,\n",
        "        learning_rate=0.1,\n",
        "        tree_method='hist',\n",
        "        device='cuda',\n",
        "        n_jobs=24,\n",
        "        random_state=42,\n",
        "        eval_metric='rmse'\n",
        "    )\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # === Predict & impute ===\n",
        "    for df, name in [(train, \"train\"), (test, \"test\")]:\n",
        "        imputable_idx = df[df[target].isna()].index\n",
        "        imputable = df.loc[imputable_idx, features].dropna()\n",
        "\n",
        "        if imputable.empty:\n",
        "            print(f\"‚úÖ {name}: No imputable rows for '{target}'\")\n",
        "            continue\n",
        "\n",
        "        preds = model.predict(imputable)\n",
        "        preds = np.clip(preds, 0, None)\n",
        "        preds = np.floor(preds + 0.5).astype(float)\n",
        "\n",
        "        # Confidence\n",
        "        y_mean = y_train.mean()\n",
        "        confidence = 1 - np.abs(preds - y_mean) / (y_mean + 1e-8)\n",
        "        confidence = np.clip(confidence, 0, 1)\n",
        "\n",
        "        # Fill in imputations\n",
        "        df[target] = df[target].copy()\n",
        "        df.loc[imputable.index, target] = preds\n",
        "\n",
        "        df[target + \"_confidence\"] = np.nan\n",
        "        df.loc[imputable.index, target + \"_confidence\"] = confidence\n",
        "\n",
        "        # Save\n",
        "        output = df[id_columns + [target, target + \"_confidence\"]].copy()\n",
        "        output.to_parquet(f\"{name}_{target}.parquet\", index=False)\n",
        "        print(f\"üíæ Saved: {name}_{target}.parquet ‚Äî {len(imputable)} values imputed\")\n",
        "\n",
        "# === Run for all targets ===\n",
        "for target in target_columns:\n",
        "    impute_column(target)\n",
        "\n",
        "# === Done ===\n",
        "print(f\"\\n‚è±Ô∏è Total duration: {round(time.time() - start, 2)} seconds\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u8MCJ0FvzC5U",
        "outputId": "f98714b0-8904-43f6-d2af-c6533876138d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing impute_monetary.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "üî§ Encoding categorical features:\n",
        "Encoding features: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:01<00:00,  1.40s/it]\n",
        "/home/ionut/anaconda3/envs/test_env/lib/python3.10/site-packages/xgboost/core.py:729: UserWarning: [17:09:27] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
        "Potential solutions:\n",
        "- Use a data structure that matches the device ordinal in the booster.\n",
        "- Set the device for booster before call to inplace_predict.\n",
        "\n",
        "This warning will only be shown once.\n",
        "\n",
        "  return func(**kwargs)\n",
        "\n",
        "üîß Imputing: 'miniRules0_monetaryAmount'\n",
        "üíæ Saved: train_miniRules0_monetaryAmount.parquet ‚Äî 1395743 values imputed\n",
        "üíæ Saved: test_miniRules0_monetaryAmount.parquet ‚Äî 504405 values imputed\n",
        "\n",
        "üîß Imputing: 'miniRules1_monetaryAmount'\n",
        "üíæ Saved: train_miniRules1_monetaryAmount.parquet ‚Äî 1395743 values imputed\n",
        "üíæ Saved: test_miniRules1_monetaryAmount.parquet ‚Äî 504405 values imputed\n",
        "\n",
        "‚è±Ô∏è Total duration: 584.12 seconds"
      ],
      "metadata": {
        "id": "Z0LKsrHoZ7rh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile impute_monetary.py\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tqdm import tqdm\n",
        "import time\n",
        "\n",
        "# === Start timer ===\n",
        "start = time.time()\n",
        "\n",
        "# === Load input files ===\n",
        "train = pd.read_parquet(\"train_filled.parquet\")\n",
        "test = pd.read_parquet(\"test_filled.parquet\")\n",
        "\n",
        "# === Features and targets ===\n",
        "features = [\n",
        "    'totalPrice',\n",
        "    'companyID',\n",
        "    'legs0_segments0_cabinClass',\n",
        "    'isAccess3D',\n",
        "    'isVip',\n",
        "    'legs0_segments0_flightNumber',\n",
        "    'taxes'\n",
        "]\n",
        "target_columns = ['miniRules0_monetaryAmount', 'miniRules1_monetaryAmount']\n",
        "\n",
        "# === Encode categorical features ===\n",
        "cat_features = [col for col in features if train[col].dtype == 'object' or test[col].dtype == 'object']\n",
        "print(\"\\nüî§ Encoding categorical features:\")\n",
        "for col in tqdm(cat_features, desc=\"Encoding\"):\n",
        "    le = LabelEncoder()\n",
        "    full = pd.concat([train[col], test[col]], axis=0).astype(str)\n",
        "    le.fit(full)\n",
        "    train[col] = le.transform(train[col].astype(str))\n",
        "    test[col] = le.transform(test[col].astype(str))\n",
        "\n",
        "# === Logging results ===\n",
        "log_lines = []\n",
        "\n",
        "def impute_column(target):\n",
        "    print(f\"\\nüîß Imputing: {target}\")\n",
        "    log_lines.append(f\"\\nüìå {target}\")\n",
        "\n",
        "    train_valid = train.dropna(subset=features + [target])\n",
        "    if train_valid.empty:\n",
        "        print(f\"‚ùå Skipped: No training data for '{target}'\")\n",
        "        log_lines.append(\"‚ùå No valid training data\")\n",
        "        return\n",
        "\n",
        "    X_train = train_valid[features]\n",
        "    y_train = train_valid[target].astype(float)\n",
        "\n",
        "    model = XGBRegressor(\n",
        "        n_estimators=2000,\n",
        "        max_depth=16,\n",
        "        learning_rate=0.1,\n",
        "        tree_method='hist',\n",
        "        device='cuda',\n",
        "        n_jobs=24,\n",
        "        random_state=42,\n",
        "        eval_metric='rmse'\n",
        "    )\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    for df, name in [(train, \"train\"), (test, \"test\")]:\n",
        "        imputable_idx = df[df[target].isna()].index\n",
        "        imputable = df.loc[imputable_idx, features].dropna()\n",
        "\n",
        "        if imputable.empty:\n",
        "            print(f\"‚úÖ {name}: No imputable values for '{target}'\")\n",
        "            continue\n",
        "\n",
        "        preds = model.predict(imputable)\n",
        "        preds = np.clip(preds, 0, None)\n",
        "        preds = np.floor(preds + 0.5).astype(float)\n",
        "\n",
        "        df.loc[imputable.index, target] = preds\n",
        "\n",
        "        # Logging\n",
        "        imputed_count = len(imputable)\n",
        "        total = len(df)\n",
        "        stats = df[target].describe().to_string()\n",
        "        top_vals = df[target].value_counts().head(5).to_string()\n",
        "\n",
        "        print(f\"‚úÖ {name}: Imputed {imputed_count} rows\")\n",
        "        log_lines.append(f\"\\nüìÇ {name}: {imputed_count} values imputed\")\n",
        "        log_lines.append(\"üìä Stats:\\n\" + stats)\n",
        "        log_lines.append(\"üèÜ Top values:\\n\" + top_vals)\n",
        "\n",
        "# === Run for each target ===\n",
        "for target in target_columns:\n",
        "    impute_column(target)\n",
        "\n",
        "# === Save datasets ===\n",
        "train.to_parquet(\"train_filled.parquet\", index=False)\n",
        "test.to_parquet(\"test_filled.parquet\", index=False)\n",
        "\n",
        "# === Save log ===\n",
        "with open(\"monetary_imputation_log.txt\", \"w\") as f:\n",
        "    f.write(\"\\n\".join(log_lines))\n",
        "\n",
        "print(\"\\nüìù Saved log to 'monetary_imputation_log.txt'\")\n",
        "print(f\"‚è±Ô∏è Done in {round(time.time() - start, 2)} seconds\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MILxgPjruhXK",
        "outputId": "8821719e-2c2d-48f0-e5e5-7d764374fe4b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting impute_monetary.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "üìå miniRules0_monetaryAmount\n",
        "\n",
        "üìÇ train: 1395743 values imputed\n",
        "üìä Stats:\n",
        "count    1.814537e+07\n",
        "mean     2.489853e+03\n",
        "std      3.278354e+03\n",
        "min      0.000000e+00\n",
        "25%      0.000000e+00\n",
        "50%      2.800000e+03\n",
        "75%      2.800000e+03\n",
        "max      5.022370e+05\n",
        "üèÜ Top values:\n",
        "miniRules0_monetaryAmount\n",
        "2800.0    8796221\n",
        "0.0       5619739\n",
        "4000.0     494350\n",
        "2300.0     433760\n",
        "4600.0     268734\n",
        "\n",
        "üìÇ test: 504405 values imputed\n",
        "üìä Stats:\n",
        "count    6.897776e+06\n",
        "mean     2.693489e+03\n",
        "std      3.984846e+03\n",
        "min      0.000000e+00\n",
        "25%      0.000000e+00\n",
        "50%      2.800000e+03\n",
        "75%      2.800000e+03\n",
        "max      2.431870e+05\n",
        "üèÜ Top values:\n",
        "miniRules0_monetaryAmount\n",
        "2800.0    3520728\n",
        "0.0       2038554\n",
        "4000.0     166146\n",
        "2300.0     131509\n",
        "4600.0      41998\n",
        "\n",
        "üìå miniRules1_monetaryAmount\n",
        "\n",
        "üìÇ train: 1395743 values imputed\n",
        "üìä Stats:\n",
        "count    1.814537e+07\n",
        "mean     1.362107e+03\n",
        "std      5.742862e+03\n",
        "min      0.000000e+00\n",
        "25%      0.000000e+00\n",
        "50%      0.000000e+00\n",
        "75%      2.800000e+03\n",
        "max      7.161273e+06\n",
        "üèÜ Top values:\n",
        "miniRules1_monetaryAmount\n",
        "0.0       11578738\n",
        "2800.0     3347198\n",
        "1500.0      677747\n",
        "3500.0      433574\n",
        "4600.0      127484\n",
        "\n",
        "üìÇ test: 504405 values imputed\n",
        "üìä Stats:\n",
        "count    6.897776e+06\n",
        "mean     1.450065e+03\n",
        "std      4.028909e+03\n",
        "min      0.000000e+00\n",
        "25%      0.000000e+00\n",
        "50%      0.000000e+00\n",
        "75%      2.800000e+03\n",
        "max      4.736350e+05\n",
        "üèÜ Top values:\n",
        "miniRules1_monetaryAmount\n",
        "0.0       4501675\n",
        "2800.0    1236787\n",
        "1500.0     227284\n",
        "3500.0     131388\n",
        "4000.0      21480"
      ],
      "metadata": {
        "id": "1i9DW5wFFfNl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile test_imputation.py\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tqdm import tqdm\n",
        "import time\n",
        "\n",
        "# === Start the timer ===\n",
        "start = time.time()\n",
        "\n",
        "# === Load the data ===\n",
        "df_original = pd.read_parquet(\"train.parquet\")\n",
        "df = df_original.copy(deep=True)  # Work on a deep copy\n",
        "\n",
        "# === Define features and target ===\n",
        "features = [\n",
        "    'totalPrice',\n",
        "    'companyID',\n",
        "    'legs0_segments0_cabinClass',\n",
        "    'isAccess3D',\n",
        "    'isVip',\n",
        "    'legs0_segments0_flightNumber',\n",
        "    'taxes'\n",
        "]\n",
        "target = 'miniRules0_statusInfos'\n",
        "cols_needed = features + [target]\n",
        "\n",
        "# === Drop rows with missing values in features or target ===\n",
        "df = df.dropna(subset=cols_needed)\n",
        "\n",
        "# === Encode categorical features ===\n",
        "cat_features = ['companyID', 'legs0_segments0_cabinClass', 'legs0_segments0_flightNumber']\n",
        "feature_encoders = {}\n",
        "\n",
        "print(\"\\nüî§ Encoding categorical features:\")\n",
        "for col in tqdm(cat_features, desc=\"Encoding features\"):\n",
        "    le = LabelEncoder()\n",
        "    df[col] = le.fit_transform(df[col].astype(str))\n",
        "    feature_encoders[col] = le\n",
        "\n",
        "# === Encode target ===\n",
        "target_encoder = LabelEncoder()\n",
        "df[target] = target_encoder.fit_transform(df[target].astype(str))\n",
        "\n",
        "# === Sample 1,000,000 rows for validation (or fewer if needed) ===\n",
        "sample_size = min(1_000_000, len(df))\n",
        "sample = df.sample(n=sample_size, random_state=42)\n",
        "X_valid = sample[features]\n",
        "y_valid = sample[target]\n",
        "\n",
        "# === Use remaining data for training ===\n",
        "train_df = df.drop(sample.index)\n",
        "X_train = train_df[features]\n",
        "y_train = train_df[target]\n",
        "\n",
        "# === Train the classifier ===\n",
        "model = XGBClassifier(\n",
        "    n_estimators=2000,\n",
        "    max_depth=14,\n",
        "    learning_rate=0.1,\n",
        "    tree_method='hist',\n",
        "    device='cuda',\n",
        "    n_jobs=24,\n",
        "    random_state=42,\n",
        "    eval_metric='logloss'\n",
        ")\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# === Predict and evaluate ===\n",
        "preds = model.predict(X_valid)\n",
        "acc = accuracy_score(y_valid, preds)\n",
        "f1 = f1_score(y_valid, preds, average='weighted')\n",
        "cm = confusion_matrix(y_valid, preds)\n",
        "duration = round(time.time() - start, 2)\n",
        "\n",
        "# === Save results ===\n",
        "with open(\"imputation_results.txt\", \"w\") as f:\n",
        "    f.write(\"‚úÖ Imputation Evaluation Results:\\n\")\n",
        "    f.write(f\"Accuracy: {acc:.4f}\\n\")\n",
        "    f.write(f\"F1 Score (weighted): {f1:.4f}\\n\")\n",
        "    f.write(\"Confusion Matrix:\\n\")\n",
        "    f.write(np.array2string(cm))\n",
        "    f.write(f\"\\n‚è±Ô∏è Duration: {duration} seconds\\n\")\n",
        "\n",
        "# === Also print to console ===\n",
        "print(\"‚úÖ Results saved to imputation_results.txt\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RJNrrSe_9xhp",
        "outputId": "343a6dbb-2c84-4b6f-f7c0-a7a5181ffe30"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting test_imputation.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "‚úÖ Imputation Evaluation Results:\n",
        "Accuracy: 0.9936\n",
        "F1 Score (weighted): 0.9934\n",
        "Confusion Matrix:\n",
        "[[ 21279   4158]\n",
        " [  2288 972275]]\n",
        "‚è±Ô∏è Duration: 107.54 seconds"
      ],
      "metadata": {
        "id": "5ZfPOB34SlLJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile impute_statusInfos.py\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from xgboost import XGBClassifier\n",
        "from tqdm import tqdm\n",
        "import time\n",
        "\n",
        "# === Start the timer ===\n",
        "start = time.time()\n",
        "\n",
        "# === Load and copy data ===\n",
        "train_original = pd.read_parquet(\"train.parquet\")\n",
        "test = pd.read_parquet(\"test.parquet\")\n",
        "train = train_original.copy(deep=True)\n",
        "\n",
        "# === Keep ID columns for final merge ===\n",
        "id_columns = ['Id', 'ranker_id']\n",
        "if not all(col in train.columns for col in id_columns) or not all(col in test.columns for col in id_columns):\n",
        "    raise ValueError(\"‚ùå Both train and test files must contain 'Id' and 'ranker_id' columns.\")\n",
        "\n",
        "# === Features used for prediction ===\n",
        "features = [\n",
        "    'totalPrice',\n",
        "    'companyID',\n",
        "    'legs0_segments0_cabinClass',\n",
        "    'isAccess3D',\n",
        "    'isVip',\n",
        "    'legs0_segments0_flightNumber',\n",
        "    'taxes'\n",
        "]\n",
        "\n",
        "# === Targets to impute ===\n",
        "target_columns = ['miniRules0_statusInfos', 'miniRules1_statusInfos']\n",
        "\n",
        "# === Encode categorical features ===\n",
        "cat_features = [col for col in features if train[col].dtype == 'object' or test[col].dtype == 'object']\n",
        "encoders = {}\n",
        "\n",
        "print(\"\\nüî§ Encoding categorical features:\")\n",
        "for col in tqdm(cat_features, desc=\"Encoding features\"):\n",
        "    train[col], uniques = pd.factorize(train[col])\n",
        "    test[col] = uniques.get_indexer(test[col])\n",
        "    encoders[col] = uniques\n",
        "\n",
        "# === Function to impute one target column ===\n",
        "def impute_column(target):\n",
        "    print(f\"\\nüîß Processing target: '{target}'\")\n",
        "\n",
        "    train_valid = train.dropna(subset=features + [target])\n",
        "    if train_valid.empty:\n",
        "        print(f\"‚ùå Skipped '{target}': No complete training data.\")\n",
        "        return\n",
        "\n",
        "    X_train = train_valid[features]\n",
        "    y_train = train_valid[target].astype(float)\n",
        "\n",
        "    # === Train model ===\n",
        "    model = XGBClassifier(\n",
        "        n_estimators=2000,\n",
        "        max_depth=14,\n",
        "        learning_rate=0.1,\n",
        "        tree_method='hist',\n",
        "        device='cpu',\n",
        "        n_jobs=24,\n",
        "        random_state=42,\n",
        "        eval_metric='logloss'\n",
        "    )\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # === Predict and impute for both datasets ===\n",
        "    for df, name in [(train, \"train\"), (test, \"test\")]:\n",
        "        missing_mask = df[target].isna()\n",
        "        if missing_mask.sum() == 0:\n",
        "            print(f\"‚úÖ {name}: No missing values in '{target}'\")\n",
        "            continue\n",
        "\n",
        "        imputable = df.loc[missing_mask, features].dropna()\n",
        "        if imputable.empty:\n",
        "            print(f\"‚ö†Ô∏è {name}: No imputable rows with all required features for '{target}'.\")\n",
        "            continue\n",
        "\n",
        "        # Predict\n",
        "        probs = model.predict_proba(imputable)\n",
        "        preds = np.argmax(probs, axis=1).astype(float)\n",
        "        confidences = np.max(probs, axis=1)\n",
        "\n",
        "        # Assign predictions and confidence scores\n",
        "        df.loc[imputable.index, target] = preds\n",
        "        df.loc[imputable.index, f\"{target}_confidence\"] = confidences\n",
        "        print(f\"‚úÖ {name}: Imputed {len(imputable)} rows for '{target}'\")\n",
        "\n",
        "    # === Summary report ===\n",
        "    for df, name in [(train, \"train\"), (test, \"test\")]:\n",
        "        total = len(df)\n",
        "        missing = df[target].isna().sum()\n",
        "        print(f\"\\nüìä {name} ‚Äî '{target}':\")\n",
        "        print(f\"  Total: {total} rows | Missing: {missing} ({100 * missing / total:.2f}%)\")\n",
        "        print(\"  Top values:\")\n",
        "        print(df[target].value_counts(dropna=False).head(10))\n",
        "\n",
        "    # === Save imputed results ===\n",
        "    for df, name in [(train, \"train\"), (test, \"test\")]:\n",
        "        output = df[id_columns + [target, f\"{target}_confidence\"]]\n",
        "        output.to_parquet(f\"{name}_{target}.parquet\", index=False)\n",
        "        print(f\"üíæ Saved: {name}_{target}.parquet\")\n",
        "\n",
        "# === Run for each target column ===\n",
        "for target in target_columns:\n",
        "    impute_column(target)\n",
        "\n",
        "# === Done ===\n",
        "print(f\"\\n‚è±Ô∏è Total duration: {round(time.time() - start, 2)} seconds\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pUMhRFLASy_Y",
        "outputId": "cbb58933-4fbf-450d-d514-663a3e519604"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing impute_statusInfos.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile impute_statusInfos.py\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from xgboost import XGBClassifier\n",
        "from tqdm import tqdm\n",
        "import time\n",
        "\n",
        "# === Start the timer ===\n",
        "start = time.time()\n",
        "\n",
        "# === Load data ===\n",
        "train = pd.read_parquet(\"train_filled.parquet\")\n",
        "test = pd.read_parquet(\"test_filled.parquet\")\n",
        "\n",
        "# === Features used for prediction ===\n",
        "features = [\n",
        "    'totalPrice',\n",
        "    'companyID',\n",
        "    'legs0_segments0_cabinClass',\n",
        "    'isAccess3D',\n",
        "    'isVip',\n",
        "    'legs0_segments0_flightNumber',\n",
        "    'taxes'\n",
        "]\n",
        "\n",
        "# === Targets to impute ===\n",
        "target_columns = ['miniRules0_statusInfos', 'miniRules1_statusInfos']\n",
        "\n",
        "# === Encode categorical features ===\n",
        "cat_features = [col for col in features if train[col].dtype == 'object' or test[col].dtype == 'object']\n",
        "\n",
        "print(\"\\nüî§ Encoding categorical features:\")\n",
        "for col in tqdm(cat_features, desc=\"Encoding features\"):\n",
        "    train[col], uniques = pd.factorize(train[col])\n",
        "    test[col] = uniques.get_indexer(test[col])\n",
        "\n",
        "# === Prepare report file ===\n",
        "report_lines = []\n",
        "report_lines.append(f\"üìù Imputation Report ‚Äî {time.strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
        "report_lines.append(\"=\" * 60 + \"\\n\")\n",
        "\n",
        "# === Function to impute one target column ===\n",
        "def impute_column(target):\n",
        "    report_lines.append(f\"\\nüîß Target: {target}\\n\")\n",
        "\n",
        "    train_valid = train.dropna(subset=features + [target])\n",
        "    if train_valid.empty:\n",
        "        report_lines.append(f\"‚ùå Skipped: No valid training data for {target}\\n\")\n",
        "        return\n",
        "\n",
        "    X_train = train_valid[features]\n",
        "    y_train = train_valid[target].astype(float)\n",
        "\n",
        "    model = XGBClassifier(\n",
        "        n_estimators=2000,\n",
        "        max_depth=14,\n",
        "        learning_rate=0.1,\n",
        "        tree_method='hist',\n",
        "        device='cpu',\n",
        "        n_jobs=24,\n",
        "        random_state=42,\n",
        "        eval_metric='logloss'\n",
        "    )\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    for df, name in [(train, \"train\"), (test, \"test\")]:\n",
        "        missing_mask = df[target].isna()\n",
        "        total_missing_before = missing_mask.sum()\n",
        "\n",
        "        imputable = df.loc[missing_mask, features].dropna()\n",
        "        imputable_indices = imputable.index\n",
        "        if imputable.empty:\n",
        "            report_lines.append(f\"‚ö†Ô∏è {name}: No imputable rows with all features for {target}\\n\")\n",
        "            continue\n",
        "\n",
        "        preds = model.predict(imputable).astype(float)\n",
        "        df.loc[imputable_indices, target] = preds\n",
        "        total_imputed = len(imputable_indices)\n",
        "\n",
        "        # Summary stats\n",
        "        total_rows = len(df)\n",
        "        total_missing_after = df[target].isna().sum()\n",
        "        top_values = df[target].value_counts(dropna=False).head(10)\n",
        "\n",
        "        report_lines.append(f\"‚úÖ {name}:\\n\")\n",
        "        report_lines.append(f\"  Imputed rows: {total_imputed}\\n\")\n",
        "        report_lines.append(f\"  Total rows: {total_rows}\\n\")\n",
        "        report_lines.append(f\"  Remaining missing: {total_missing_after} ({100 * total_missing_after / total_rows:.2f}%)\\n\")\n",
        "        report_lines.append(\"  Top 10 values after imputation:\\n\")\n",
        "        for val, count in top_values.items():\n",
        "            report_lines.append(f\"    {val}: {count}\\n\")\n",
        "\n",
        "# === Run imputation ===\n",
        "for target in target_columns:\n",
        "    impute_column(target)\n",
        "\n",
        "# === Overwrite the modified DataFrames ===\n",
        "train.to_parquet(\"train_filled.parquet\", index=False)\n",
        "test.to_parquet(\"test_filled.parquet\", index=False)\n",
        "\n",
        "# === Write report to file ===\n",
        "with open(\"imputation_report.txt\", \"w\", encoding=\"utf-8\") as f:\n",
        "    f.writelines([line if line.endswith('\\n') else line + '\\n' for line in report_lines])\n",
        "\n",
        "# === Done ===\n",
        "print(f\"\\nüíæ Overwritten 'train_filled.parquet' and 'test_filled.parquet'\")\n",
        "print(f\"üìù Saved imputation report to 'imputation_report.txt'\")\n",
        "print(f\"‚è±Ô∏è Total duration: {round(time.time() - start, 2)} seconds\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KM6fxOgPjfFL",
        "outputId": "80d53804-f7e4-4e5f-c4ac-42edcd56e144"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing impute_statusInfos.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "üìù Imputation Report ‚Äî 2025-07-19 19:16:42\n",
        "============================================================\n",
        "\n",
        "üîß Target: miniRules0_statusInfos\n",
        "‚úÖ train:\n",
        "  Imputed rows: 1469953\n",
        "  Total rows: 18145372\n",
        "  Remaining missing: 0 (0.00%)\n",
        "  Top 10 values after imputation:\n",
        "    1.0: 17694481\n",
        "    0.0: 450891\n",
        "‚úÖ test:\n",
        "  Imputed rows: 550192\n",
        "  Total rows: 6897776\n",
        "  Remaining missing: 0 (0.00%)\n",
        "  Top 10 values after imputation:\n",
        "    1.0: 6729060\n",
        "    0.0: 168716\n",
        "\n",
        "üîß Target: miniRules1_statusInfos\n",
        "‚úÖ train:\n",
        "  Imputed rows: 1518169\n",
        "  Total rows: 18145372\n",
        "  Remaining missing: 0 (0.00%)\n",
        "  Top 10 values after imputation:\n",
        "    1.0: 10528023\n",
        "    0.0: 7617349\n",
        "‚úÖ test:\n",
        "  Imputed rows: 574432\n",
        "  Total rows: 6897776\n",
        "  Remaining missing: 0 (0.00%)\n",
        "  Top 10 values after imputation:\n",
        "    1.0: 3859158\n",
        "    0.0: 3038618"
      ],
      "metadata": {
        "id": "gDeJXMi4IeuF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile check.py\n",
        "import pandas as pd\n",
        "\n",
        "# === Columns to check ===\n",
        "cols_to_check = [\n",
        "    \"corporateTariffCode\",\n",
        "    \"miniRules0_monetaryAmount\",\n",
        "    \"miniRules1_monetaryAmount\",\n",
        "    \"miniRules0_statusInfos\",\n",
        "    \"miniRules1_statusInfos\"\n",
        "]\n",
        "\n",
        "# === Load parquet files ===\n",
        "train = pd.read_parquet(\"train_filled.parquet\")\n",
        "test = pd.read_parquet(\"test_filled.parquet\")\n",
        "\n",
        "# === Missing value reporting function ===\n",
        "def report_missing(df, name):\n",
        "    print(f\"\\nüìä Missing value report for: {name}\")\n",
        "    total = len(df)\n",
        "    for col in cols_to_check:\n",
        "        missing = df[col].isna().sum()\n",
        "        percent = 100 * missing / total\n",
        "        print(f\"  {col:30s} - Missing: {missing:6d} / {total} ({percent:5.2f}%)\")\n",
        "\n",
        "# === Run the reports ===\n",
        "report_missing(train, \"train_filled.parquet\")\n",
        "report_missing(test, \"test_filled.parquet\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dwa3OjmRItON",
        "outputId": "2ec39eaa-1e6c-4011-dfac-635d74606a1c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing check.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "üìä Missing value report for: train_filled.parquet\n",
        "  corporateTariffCode            - Missing: 3789156 / 18145372 (20.88%)\n",
        "  miniRules0_monetaryAmount      - Missing:      0 / 18145372 ( 0.00%)\n",
        "  miniRules1_monetaryAmount      - Missing:      0 / 18145372 ( 0.00%)\n",
        "  miniRules0_statusInfos         - Missing:      0 / 18145372 ( 0.00%)\n",
        "  miniRules1_statusInfos         - Missing:      0 / 18145372 ( 0.00%)\n",
        "\n",
        "üìä Missing value report for: test_filled.parquet\n",
        "  corporateTariffCode            - Missing: 1480358 / 6897776 (21.46%)\n",
        "  miniRules0_monetaryAmount      - Missing:      0 / 6897776 ( 0.00%)\n",
        "  miniRules1_monetaryAmount      - Missing:      0 / 6897776 ( 0.00%)\n",
        "  miniRules0_statusInfos         - Missing:      0 / 6897776 ( 0.00%)\n",
        "  miniRules1_statusInfos         - Missing:      0 / 6897776 ( 0.00%)"
      ],
      "metadata": {
        "id": "F45gEmd9JBku"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Feature Engineering**"
      ],
      "metadata": {
        "id": "cVFXqC6lhA4S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile column_differencies.py\n",
        "import pandas as pd\n",
        "\n",
        "# Read the CSV files\n",
        "train_df = pd.read_csv('train.csv')\n",
        "test_df = pd.read_csv('test.csv')\n",
        "\n",
        "# Get the sets of column names\n",
        "train_columns = set(train_df.columns)\n",
        "test_columns = set(test_df.columns)\n",
        "\n",
        "# Columns that are in train but not in test\n",
        "only_in_train = train_columns - test_columns\n",
        "\n",
        "# Columns that are in test but not in train\n",
        "only_in_test = test_columns - train_columns\n",
        "\n",
        "# Print the results\n",
        "print(\"Columns only in train.csv:\", only_in_train)\n",
        "print(\"Columns only in test.csv:\", only_in_test)"
      ],
      "metadata": {
        "id": "kgrk_0UNhDcq",
        "outputId": "171fe296-dd7b-458e-b408-bb17e09648b4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing column_differencies.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Columns only in train.csv: {'selected', 'legs0_segments0_seatsAvailable_missing_initially'}\n",
        "\n",
        "Columns only in test.csv: set()"
      ],
      "metadata": {
        "id": "Ea4IwUZIzDMf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile remove_legs0_segments0_seatsAvailable_missing_initially.py\n",
        "import pandas as pd\n",
        "\n",
        "# Load the CSV file\n",
        "train_df = pd.read_csv('train.csv')\n",
        "\n",
        "# Drop the specified column if it exists\n",
        "column_to_remove = 'legs0_segments0_seatsAvailable_missing_initially'\n",
        "if column_to_remove in train_df.columns:\n",
        "    train_df = train_df.drop(columns=[column_to_remove])\n",
        "    train_df.to_csv('train.csv', index=False)\n",
        "    print(f\"Column '{column_to_remove}' has been removed and train.csv has been updated.\")\n",
        "else:\n",
        "    print(f\"Column '{column_to_remove}' not found in train.csv.\")"
      ],
      "metadata": {
        "id": "_9q8AqXLzhkt",
        "outputId": "a323f8f0-6eb9-4460-d508-8b18d00e1244",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing remove_legs0_segments0_seatsAvailable_missing_initially.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile check_columns.py\n",
        "import pandas as pd\n",
        "\n",
        "# Load the CSV files\n",
        "train_df = pd.read_csv('train.csv')\n",
        "test_df = pd.read_csv('test.csv')\n",
        "\n",
        "# Print column names\n",
        "print(\"Columns in train.csv:\")\n",
        "print(train_df.columns.tolist())\n",
        "\n",
        "print(\"\\nColumns in test.csv:\")\n",
        "print(test_df.columns.tolist())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t0roAwNu6fDk",
        "outputId": "648fbde2-d625-4598-e9e1-afe0700f82ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing check_columns.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Columns in train.csv:\n",
        "['Id', 'bySelf', 'companyID', 'corporateTariffCode', 'frequentFlyer', 'nationality', 'isAccess3D', 'isVip', 'legs0_arrivalAt', 'legs0_departureAt', 'legs0_duration', 'legs0_segments0_aircraft_code', 'legs0_segments0_arrivalTo_airport_city_iata', 'legs0_segments0_arrivalTo_airport_iata', 'legs0_segments0_baggageAllowance_quantity', 'legs0_segments0_baggageAllowance_weightMeasurementType', 'legs0_segments0_cabinClass', 'legs0_segments0_departureFrom_airport_iata', 'legs0_segments0_duration', 'legs0_segments0_flightNumber', 'legs0_segments0_marketingCarrier_code', 'legs0_segments0_operatingCarrier_code', 'legs0_segments0_seatsAvailable', 'legs1_duration', 'legs1_segments0_aircraft_code', 'legs1_segments0_arrivalTo_airport_city_iata', 'legs1_segments0_arrivalTo_airport_iata', 'legs1_segments0_baggageAllowance_quantity', 'legs1_segments0_baggageAllowance_weightMeasurementType', 'legs1_segments0_cabinClass', 'legs1_segments0_departureFrom_airport_iata', 'legs1_segments0_duration', 'legs1_segments0_marketingCarrier_code', 'legs1_segments0_operatingCarrier_code', 'legs1_segments0_seatsAvailable', 'miniRules0_monetaryAmount', 'miniRules0_statusInfos', 'miniRules1_monetaryAmount', 'miniRules1_statusInfos', 'pricingInfo_isAccessTP', 'pricingInfo_passengerCount', 'profileId', 'ranker_id', 'requestDate', 'searchRoute', 'sex', 'taxes', 'totalPrice', 'selected', '__index_level_0__', 'legs0_segments0_baggageAllowance_missing_initially', 'miniRules0_statusInfos_was_missing', 'miniRules1_statusInfos_was_missing', 'legs1_segments0_aircraft_code_was_missing', 'legs1_departureAt_hour', 'legs1_departureAt_minute', 'legs1_departureAt_is_weekend', 'legs1_departureAt_day', 'legs1_departureAt_month', 'legs1_departureAt_year', 'legs1_departureAt_part_of_day', 'legs1_departureAt_hour_sin', 'legs1_departureAt_hour_cos', 'legs1_arrivalAt_hour', 'legs1_arrivalAt_minute', 'legs1_arrivalAt_is_weekend', 'legs1_arrivalAt_day', 'legs1_arrivalAt_month', 'legs1_arrivalAt_year', 'legs1_arrivalAt_part_of_day', 'legs1_arrivalAt_hour_sin', 'legs1_arrivalAt_hour_cos']\n",
        "\n",
        "\n",
        "Columns in test.csv:\n",
        "['Id', 'bySelf', 'companyID', 'corporateTariffCode', 'frequentFlyer', 'nationality', 'isAccess3D', 'isVip', 'legs0_arrivalAt', 'legs0_departureAt', 'legs0_duration', 'legs0_segments0_aircraft_code', 'legs0_segments0_arrivalTo_airport_city_iata', 'legs0_segments0_arrivalTo_airport_iata', 'legs0_segments0_baggageAllowance_quantity', 'legs0_segments0_baggageAllowance_weightMeasurementType', 'legs0_segments0_cabinClass', 'legs0_segments0_departureFrom_airport_iata', 'legs0_segments0_duration', 'legs0_segments0_flightNumber', 'legs0_segments0_marketingCarrier_code', 'legs0_segments0_operatingCarrier_code', 'legs0_segments0_seatsAvailable', 'legs1_duration', 'legs1_segments0_aircraft_code', 'legs1_segments0_arrivalTo_airport_city_iata', 'legs1_segments0_arrivalTo_airport_iata', 'legs1_segments0_baggageAllowance_quantity', 'legs1_segments0_baggageAllowance_weightMeasurementType', 'legs1_segments0_cabinClass', 'legs1_segments0_departureFrom_airport_iata', 'legs1_segments0_duration', 'legs1_segments0_marketingCarrier_code', 'legs1_segments0_operatingCarrier_code', 'legs1_segments0_seatsAvailable', 'miniRules0_monetaryAmount', 'miniRules0_statusInfos', 'miniRules1_monetaryAmount', 'miniRules1_statusInfos', 'pricingInfo_isAccessTP', 'pricingInfo_passengerCount', 'profileId', 'ranker_id', 'requestDate', 'searchRoute', 'sex', 'taxes', 'totalPrice', '__index_level_0__', 'legs0_segments0_baggageAllowance_missing_initially', 'miniRules0_statusInfos_was_missing', 'miniRules1_statusInfos_was_missing', 'legs1_segments0_aircraft_code_was_missing', 'legs1_departureAt_hour', 'legs1_departureAt_minute', 'legs1_departureAt_is_weekend', 'legs1_departureAt_day', 'legs1_departureAt_month', 'legs1_departureAt_year', 'legs1_departureAt_part_of_day', 'legs1_departureAt_hour_sin', 'legs1_departureAt_hour_cos', 'legs1_arrivalAt_hour', 'legs1_arrivalAt_minute', 'legs1_arrivalAt_is_weekend', 'legs1_arrivalAt_day', 'legs1_arrivalAt_month', 'legs1_arrivalAt_year', 'legs1_arrivalAt_part_of_day', 'legs1_arrivalAt_hour_sin', 'legs1_arrivalAt_hour_cos']"
      ],
      "metadata": {
        "id": "N_h0OvYDHUG6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Feature Importance**"
      ],
      "metadata": {
        "id": "-ZCzqZ2oSsZW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "0                                           is_min_segments_leg0  2512.625244\n",
        "1                                                 is_direct_leg0   252.625687\n",
        "2                                                n_segments_leg0   222.089539\n",
        "3                                                  free_exchange   170.093369\n",
        "4                                                n_segments_leg1   115.357239\n",
        "5                                               is_cross_country    55.688885\n",
        "6                                                    both_direct    51.249695\n",
        "7                                legs0_segments0_cabinClass_is_2    51.106506\n",
        "8                                           is_min_segments_leg1    49.711380\n",
        "9                                legs0_segments0_cabinClass_is_1    49.309460\n",
        "10                                                   free_cancel    40.257221\n",
        "11                                        pricingInfo_isAccessTP    34.591415\n",
        "12                                          is_major_carrier_0_0    26.813438\n",
        "13                                                         isVip    25.694996\n",
        "14                                            contains_capitials    22.130260\n",
        "15                     legs0_segments0_baggageAllowance_quantity    21.239143\n",
        "16                                            is_direct_cheapest    20.692394\n",
        "17                                           is_exact_round_trip    19.788628\n",
        "18                                            corporate_vip_flag    18.943798\n",
        "19                                           is_cheaper_than_avg    18.558277\n",
        "20      legs0_segments0_marketingCarrier_code_log_selected_count    18.139412\n",
        "21                               legs1_segments0_cabinClass_is_2    17.824265\n",
        "22                                                legs0_duration    16.884428\n",
        "23                                          rank_interaction_sum    16.179651\n",
        "24                                    corporate_policy_compliant    15.583480\n",
        "25        legs0_segments0_baggageAllowance_weightMeasurementType    15.426142\n",
        "26         legs0_segments0_marketingCarrier_code_log_total_count    15.376082\n",
        "27                                                is_direct_leg1    14.998496\n",
        "28                                            has_business_class    14.756565\n",
        "29                                arrival_airport_Country_CodeA2    14.615512\n",
        "30     legs0_segments0_marketingCarrier_code_cabin2_select_ratio    14.346004\n",
        "31                               legs0_segments0_cabinClass_is_4    14.239492\n",
        "32                                        miniRules1_statusInfos    14.119366\n",
        "33                                                    isAccess3D    13.768279\n",
        "34                                          rank_interaction_mul    13.539866\n",
        "35       legs0_segments0_marketingCarrier_code_company_diversity    12.877114\n",
        "36                                              is_top3_cheapest    12.729091\n",
        "37                                                    is_one_way    12.495940\n",
        "38                                                 is_short_trip    12.136695\n",
        "39                               legs1_segments0_cabinClass_is_1    11.995763\n",
        "40      legs1_segments0_marketingCarrier_code_log_selected_count    11.955055\n",
        "41                                        duration_quantile_rank    11.719626\n",
        "42                                                total_duration    11.601267\n",
        "43                                                   nationality    11.372430\n",
        "44                                              is_popular_route    11.370732\n",
        "45          legs0_segments0_marketingCarrier_code_user_diversity    11.263096\n",
        "46                                        outbound_route_hotness    11.175965\n",
        "47          legs0_segments0_marketingCarrier_code_avg_price_rank    10.893168\n",
        "48                                                legs1_duration    10.702594\n",
        "49       legs0_segments0_marketingCarrier_code_avg_duration_rank    10.447308\n",
        "50                                              legs0_is_red_eye    10.440387\n",
        "51                                               company_avg_pct    10.395974\n",
        "52                                         price_relative_to_min    10.156937\n",
        "53         legs1_segments0_marketingCarrier_code_log_total_count    10.141954\n",
        "54             legs0_segments0_marketingCarrier_code_night_ratio    10.033763\n",
        "55                                               fee_ratio_rule0     9.780451\n",
        "56        legs0_segments0_marketingCarrier_code_in_frequentFlyer     9.732109\n",
        "57                                        miniRules0_statusInfos     9.699606\n",
        "58                                        legs1_departureAt_hour     9.657551\n",
        "59                                          return_route_hotness     9.541995\n",
        "60                                              carrier_pop_prod     9.521894\n",
        "61     legs0_segments0_marketingCarrier_code_cabin1_select_ratio     9.358589\n",
        "62                                    fee_ratio_rule1_is_missing     9.277889\n",
        "63                                               fee_ratio_rule1     9.266473\n",
        "64                               legs1_segments0_cabinClass_is_4     8.972970\n",
        "65                         legs0_segments0_marketingCarrier_code     8.833404\n",
        "66                                                   is_vip_freq     8.596709\n",
        "67                                      legs0_segments0_duration     8.381750\n",
        "68                                          legs1_arrivalAt_hour     8.328686\n",
        "69     legs0_segments0_marketingCarrier_code_cabin4_select_ratio     8.159398\n",
        "70                                             all_cabin_level_1     8.093809\n",
        "71                                            return_destination     7.964754\n",
        "72                                       stay_duration_hours_log     7.906754\n",
        "73                                      price_zscore_from_median     7.744307\n",
        "74                              departure_airport_Country_CodeA2     7.705009\n",
        "75                         legs0_segments0_operatingCarrier_code     7.601945\n",
        "76                                    fee_ratio_rule0_is_missing     7.598970\n",
        "77                                        legs0_departureAt_hour     7.588921\n",
        "78                              arrival_airport_UTC_Offset_Hours     7.545106\n",
        "79   legs0_segments0_marketingCarrier_code_is_only_frequentFlyer     7.497924\n",
        "80                                                     log_price     7.424724\n",
        "81                                           price_quantile_rank     7.422409\n",
        "82                                                group_size_log     7.409439\n",
        "83                                                 n_ff_programs     7.393448\n",
        "84                                   z_price_vs_company_selected     7.282055\n",
        "85                                                     log_taxes     7.224535\n",
        "86                                   leg0_duration_quantile_rank     7.219212\n",
        "87                                                duration_ratio     7.215049\n",
        "88                                          legs0_arrivalAt_hour     7.201886\n",
        "89                                 legs1_arrivalAt_business_time     7.185959\n",
        "90                                            std_selected_price     7.181143\n",
        "91                                      legs1_segments0_duration     7.174419\n",
        "92                                            avg_selected_price     7.147635\n",
        "93                                         selected_direct_ratio     7.035986\n",
        "94                                          selected_night_ratio     7.026170\n",
        "95                               legs0_departureAt_business_time     7.021380\n",
        "96                                               company_avg_dct     6.930465\n",
        "97                                   leg1_duration_quantile_rank     6.926739\n",
        "98                                                 timezone_diff     6.918768\n",
        "99                                   corporateTariffCode_hotness     6.907644\n",
        "100                                     log_company_select_count     6.899118\n",
        "101                                         is_expensive_outlier     6.885046\n",
        "102                       legs0_segments0_arrivalTo_airport_iata     6.838060\n",
        "103                                                 return_route     6.811344\n",
        "104                                    legs1_departureAt_weekday     6.796517\n",
        "105                                       is_codeshare_leg0_seg0     6.763454\n",
        "106                                      leg_dur_interaction_mul     6.718515\n",
        "107                           departure_airport_UTC_Offset_Hours     6.712487\n",
        "108                  legs0_segments0_arrivalTo_airport_city_iata     6.699299\n",
        "109                                          corporateTariffCode     6.671411\n",
        "110                              legs1_departureAt_business_time     6.657274\n",
        "111                                           is_direct_shortest     6.653126\n",
        "112                                                return_origin     6.596240\n",
        "113                                      user_selected_count_log     6.584061\n",
        "114                                legs0_arrivalAt_business_time     6.580869\n",
        "115                   legs0_segments0_departureFrom_airport_iata     6.561128\n",
        "116                                         rank_interaction_sub     6.503201\n",
        "117                                      leg_dur_interaction_sub     6.495512\n",
        "118                                      legs1_arrivalAt_weekday     6.473288\n",
        "119                                                    companyID     6.439044\n",
        "120                                   legs0_is_business_friendly     6.423227\n",
        "121                                               outbound_route     6.401344\n",
        "122                                              outbound_origin     6.395598\n",
        "123                                legs0_segments0_aircraft_code     6.348318\n",
        "124                                                     tax_rate     6.331712\n",
        "125                                    legs0_departureAt_weekday     6.307673\n",
        "126                                    leg_dur_interaction_ratio     6.293390\n",
        "127                                           hours_to_departure     6.235342\n",
        "128                                      legs0_arrivalAt_weekday     5.934218\n",
        "129                                         outbound_destination     5.882819\n",
        "130                               legs0_segments0_seatsAvailable     5.388764\n",
        "131                                         has_corporate_tariff     5.297897\n",
        "132                                                          sex     5.200131"
      ],
      "metadata": {
        "id": "Eg7K5FE1SvfN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Data standardization/normalization**"
      ],
      "metadata": {
        "id": "H6Of0JvmhD1C"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sfDjbEZ-hK5C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Feature.py**"
      ],
      "metadata": {
        "id": "m55y1aYkEuFd"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fPFvan72CC9l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import polars as pl\n",
        "import numpy as np\n",
        "from haversine import haversine\n",
        "from scipy.stats import gaussian_kde\n",
        "from polars.datatypes import Struct, List\n",
        "from .utils import timer\n",
        "\n",
        "\n",
        "###########################################################\n",
        "#                     Feature Engineering                 #\n",
        "###########################################################\n",
        "\n",
        "\n",
        "def dur_to_min(col):\n",
        "    \"\"\"More efficient duration to minutes converter\"\"\"\n",
        "    # Extract days and time parts in one pass\n",
        "    days = col.str.extract(r\"^(\\d+)\\.\", 1).cast(pl.Int64).fill_null(0) * 1440\n",
        "    time_str = (\n",
        "        pl.when(col.str.contains(r\"^\\d+\\.\"))\n",
        "        .then(col.str.replace(r\"^\\d+\\.\", \"\"))\n",
        "        .otherwise(col)\n",
        "    )\n",
        "    hours = time_str.str.extract(r\"^(\\d+):\", 1).cast(pl.Int64).fill_null(0) * 60\n",
        "    minutes = time_str.str.extract(r\":(\\d+):\", 1).cast(pl.Int64).fill_null(0)\n",
        "    return (days + hours + minutes).fill_null(0)\n",
        "\n",
        "\n",
        "def kde_mode(arr):\n",
        "    arr = arr[~np.isnan(arr)]\n",
        "    kde = gaussian_kde(arr)\n",
        "    xs = np.linspace(np.min(arr), np.max(arr), 1000)\n",
        "    ys = kde(xs)\n",
        "    mode = xs[np.argmax(ys)]\n",
        "    return mode\n",
        "\n",
        "\n",
        "@timer\n",
        "def initial_transformations(df, FULL):\n",
        "    # Precompute marketing carrier columns check\n",
        "    mc_cols = [\n",
        "        f\"legs{l}_segments{s}_marketingCarrier_code\" for l in (0, 1) for s in range(4)\n",
        "    ]\n",
        "    mc_exists = [col for col in mc_cols if col in df.columns]\n",
        "\n",
        "    piece_to_kg = 20\n",
        "    baggage_cols = [\n",
        "        f\"legs{l}_segments{s}_baggageAllowance\" for l in (0, 1) for s in range(2)\n",
        "    ]\n",
        "\n",
        "    df = df.with_columns(\n",
        "        [\n",
        "            # Price features\n",
        "            (pl.col(\"totalPrice\") / (pl.col(\"taxes\") + 1)).alias(\"price_per_tax\"),\n",
        "            (pl.col(\"taxes\") / (pl.col(\"totalPrice\") + 1)).alias(\"tax_rate\"),\n",
        "            pl.col(\"totalPrice\").log1p().alias(\"log_price\"),\n",
        "            # Duration features\n",
        "            (\n",
        "                pl.col(\"legs0_duration\").fill_null(0)\n",
        "                + pl.col(\"legs1_duration\").fill_null(0)\n",
        "            ).alias(\"total_duration\"),\n",
        "            pl.when(pl.col(\"legs1_duration\").fill_null(0) > 0)\n",
        "            .then(pl.col(\"legs0_duration\") / pl.col(\"legs1_duration\"))\n",
        "            .otherwise(-1)\n",
        "            .alias(\"duration_ratio\"),\n",
        "            (pl.col(\"legs0_duration\").rank(\"dense\").over(\"ranker_id\") <= 1)\n",
        "            .cast(pl.Int32)\n",
        "            .alias(\"is_top3_shortest_duration\"),\n",
        "            # Trip type\n",
        "            (\n",
        "                pl.col(\"legs1_duration\").is_null()\n",
        "                | (pl.col(\"legs1_duration\") == 0)\n",
        "                | pl.col(\"legs1_segments0_departureFrom_airport_iata\").is_null()\n",
        "            )\n",
        "            .cast(pl.Int32)\n",
        "            .alias(\"is_one_way\"),\n",
        "            # Total segments count\n",
        "            (\n",
        "                pl.sum_horizontal(\n",
        "                    pl.col(col).is_not_null().cast(pl.UInt8) for col in mc_exists\n",
        "                )\n",
        "                if mc_exists\n",
        "                else pl.lit(0)\n",
        "            ).alias(\"l0_seg\"),\n",
        "            # FF features\n",
        "            (\n",
        "                pl.col(\"frequentFlyer\").fill_null(\"\").str.count_matches(\"/\")\n",
        "                + (pl.col(\"frequentFlyer\").fill_null(\"\") != \"\").cast(pl.Int32)\n",
        "            ).alias(\"n_ff_programs\"),\n",
        "            pl.col(\"corporateTariffCode\")\n",
        "            .is_not_null()\n",
        "            .cast(pl.Int32)\n",
        "            .alias(\"has_corporate_tariff\"),\n",
        "            pl.when(\n",
        "                pl.col(\"corporateTariffCode\").is_not_null()\n",
        "                & (pl.col(\"pricingInfo_isAccessTP\") == 1.0)\n",
        "            )\n",
        "            .then(1)\n",
        "            .otherwise(0)\n",
        "            .alias(\"corporate_policy_compliant\"),\n",
        "            pl.when(\n",
        "                pl.col(\"corporateTariffCode\").is_not_null() & (pl.col(\"isVip\") == True)\n",
        "            )\n",
        "            .then(1)\n",
        "            .otherwise(0)\n",
        "            .alias(\"corporate_vip_flag\"),\n",
        "            # Baggage & fees\n",
        "            (\n",
        "                (\n",
        "                    pl.col(\"miniRules0_monetaryAmount\")\n",
        "                    / pl.col(\"totalPrice\").cast(pl.Float64)\n",
        "                )\n",
        "            ).alias(\"fee_ratio_rule0\"),\n",
        "            (\n",
        "                (\n",
        "                    pl.col(\"miniRules1_monetaryAmount\")\n",
        "                    / pl.col(\"totalPrice\").cast(pl.Float64)\n",
        "                )\n",
        "            ).alias(\"fee_ratio_rule1\"),\n",
        "            (\n",
        "                (pl.col(\"miniRules0_monetaryAmount\") == 0)\n",
        "                & (pl.col(\"miniRules0_statusInfos\") == 1)\n",
        "            )\n",
        "            .cast(pl.Int8)\n",
        "            .alias(\"free_cancel\"),\n",
        "            (\n",
        "                (pl.col(\"miniRules1_monetaryAmount\") == 0)\n",
        "                & (pl.col(\"miniRules1_statusInfos\") == 1)\n",
        "            )\n",
        "            .cast(pl.Int8)\n",
        "            .alias(\"free_exchange\"),\n",
        "            # Routes & carriers\n",
        "            pl.col(\"searchRoute\")\n",
        "            .is_in([\"MOWLED/LEDMOW\", \"LEDMOW/MOWLED\", \"MOWLED\", \"LEDMOW\"])\n",
        "            .cast(pl.Int32)\n",
        "            .alias(\"is_popular_route\"),\n",
        "            pl.col(\"searchRoute\")\n",
        "            .str.contains(\"MOW|LED\")\n",
        "            .cast(pl.Int32)\n",
        "            .alias(\"contains_capitials\"),\n",
        "            pl.col(\"legs0_segments0_flightNumber\")\n",
        "            .is_in([\"208\"])\n",
        "            .cast(pl.Int32)\n",
        "            .alias(\"is_popular_flight\"),\n",
        "            (\n",
        "                pl.col(\"legs0_segments0_marketingCarrier_code\")\n",
        "                != pl.col(\"legs0_segments0_operatingCarrier_code\")\n",
        "            )\n",
        "            .cast(pl.Int32)\n",
        "            .alias(\"is_codeshare_leg0_seg0\"),\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    # Search Route\n",
        "    df = df.with_columns(\n",
        "        [\n",
        "            pl.col(\"searchRoute\").cast(pl.Utf8),\n",
        "            pl.col(\"searchRoute\").str.split_exact(\"/\", 1).alias(\"route_struct\"),\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    df = df.with_columns(\n",
        "        [\n",
        "            pl.col(\"route_struct\").struct.field(\"field_0\").alias(\"outbound_route\"),\n",
        "            pl.col(\"route_struct\").struct.field(\"field_1\").alias(\"return_route\"),\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    df = df.with_columns(\n",
        "        [\n",
        "            pl.col(\"outbound_route\").str.slice(0, 3).alias(\"outbound_origin\"),\n",
        "            pl.col(\"outbound_route\").str.slice(3, 3).alias(\"outbound_destination\"),\n",
        "            pl.col(\"return_route\").str.slice(0, 3).alias(\"return_origin\"),\n",
        "            pl.col(\"return_route\").str.slice(3, 3).alias(\"return_destination\"),\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    df = df.with_columns(\n",
        "        [\n",
        "            (\n",
        "                (pl.col(\"outbound_origin\") == pl.col(\"return_destination\"))\n",
        "                & (pl.col(\"outbound_destination\") == pl.col(\"return_origin\"))\n",
        "            )\n",
        "            .cast(pl.Int8)\n",
        "            .alias(\"is_exact_round_trip\")\n",
        "            .fill_null(-1),\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    df = df.drop([\"route_struct\", \"searchRoute\"])\n",
        "\n",
        "    # Route hotness\n",
        "    train_size = 16487352 if not FULL else 18145372\n",
        "    train_df = df.slice(0, train_size)\n",
        "    selected_df = train_df.filter(pl.col(\"selected\") == 1)\n",
        "\n",
        "    outbound_hot = selected_df.group_by(\"outbound_route\").agg(\n",
        "        pl.count().alias(\"outbound_route_hotness\")\n",
        "    )\n",
        "\n",
        "    return_hot = selected_df.group_by(\"return_route\").agg(\n",
        "        pl.count().alias(\"return_route_hotness\")\n",
        "    )\n",
        "\n",
        "    df = (\n",
        "        df.join(outbound_hot, on=\"outbound_route\", how=\"left\")\n",
        "        .join(return_hot, on=\"return_route\", how=\"left\")\n",
        "        .with_columns(\n",
        "            [\n",
        "                pl.col(\"outbound_route_hotness\").fill_null(0),\n",
        "                pl.col(\"return_route_hotness\").fill_null(0),\n",
        "            ]\n",
        "        )\n",
        "    )\n",
        "\n",
        "    # Fill missing values using hand-craft rules\n",
        "    df = df.with_columns(\n",
        "        [\n",
        "            pl.col(\"fee_ratio_rule0\")\n",
        "            .is_null()\n",
        "            .cast(pl.Int8)\n",
        "            .alias(\"fee_ratio_rule0_is_missing\"),\n",
        "            pl.col(\"fee_ratio_rule1\")\n",
        "            .is_null()\n",
        "            .cast(pl.Int8)\n",
        "            .alias(\"fee_ratio_rule1_is_missing\"),\n",
        "            pl.col(\"pricingInfo_isAccessTP\").fill_null(-1).cast(pl.Int32),\n",
        "            pl.col(\"legs0_segments0_seatsAvailable\")\n",
        "            .fill_null(strategy=\"mean\")\n",
        "            .alias(\"legs0_segments0_seatsAvailable\"),\n",
        "            pl.col(\"miniRules0_statusInfos\").fill_null(-1).cast(pl.Int32),\n",
        "            pl.col(\"miniRules1_statusInfos\").fill_null(-1).cast(pl.Int32),\n",
        "        ]\n",
        "    )\n",
        "    # df = df.drop(\"legs0_segments0_seatsAvailable\")\n",
        "    return df\n",
        "\n",
        "\n",
        "@timer\n",
        "def build_segment_features(df):\n",
        "    # Segment counts - more efficient\n",
        "    seg_exprs = []\n",
        "    for leg in (0, 1):\n",
        "        seg_cols = [f\"legs{leg}_segments{s}_flightNumber\" for s in range(4)]\n",
        "        if seg_cols:\n",
        "            seg_exprs.append(\n",
        "                pl.sum_horizontal(pl.col(c).is_not_null() for c in seg_cols)\n",
        "                .cast(pl.Int32)\n",
        "                .alias(f\"n_segments_leg{leg}\")\n",
        "            )\n",
        "        else:\n",
        "            seg_exprs.append(pl.lit(0).cast(pl.Int32).alias(f\"n_segments_leg{leg}\"))\n",
        "\n",
        "    # First create segment counts\n",
        "    df = df.with_columns(seg_exprs)\n",
        "\n",
        "    # Then use them for derived features\n",
        "    df = df.with_columns(\n",
        "        [\n",
        "            # (pl.col(\"n_segments_leg0\") + pl.col(\"n_segments_leg1\")).alias(\n",
        "            #     \"total_segments\"\n",
        "            # ),\n",
        "            (pl.col(\"n_segments_leg0\") == 1).cast(pl.Int32).alias(\"is_direct_leg0\"),\n",
        "            pl.when(pl.col(\"is_one_way\") == 1)\n",
        "            .then(0)\n",
        "            .otherwise((pl.col(\"n_segments_leg1\") == 1).cast(pl.Int32))\n",
        "            .alias(\"is_direct_leg1\"),\n",
        "            (pl.col(\"l0_seg\") == pl.col(\"l0_seg\").min().over(\"ranker_id\"))\n",
        "            .cast(pl.Int32)\n",
        "            .alias(\"is_min_segments\"),\n",
        "            (\n",
        "                pl.col(\"n_segments_leg0\")\n",
        "                == pl.col(\"n_segments_leg0\").min().over(\"ranker_id\")\n",
        "            )\n",
        "            .cast(pl.Int32)\n",
        "            .alias(\"is_min_segments_leg0\"),\n",
        "            pl.when(pl.col(\"is_one_way\") == 1)\n",
        "            .then(0)\n",
        "            .otherwise(\n",
        "                (\n",
        "                    pl.col(\"n_segments_leg1\")\n",
        "                    == pl.col(\"n_segments_leg1\").min().over(\"ranker_id\")\n",
        "                ).cast(pl.Int32)\n",
        "            )\n",
        "            .alias(\"is_min_segments_leg1\"),\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    # Shortest direct\n",
        "    direct_shortest = (\n",
        "        df.filter(pl.col(\"is_direct_leg0\") == 1)\n",
        "        .group_by(\"ranker_id\")\n",
        "        .agg(pl.col(\"total_duration\").min().alias(\"min_direct\"))\n",
        "    )\n",
        "\n",
        "    df = (\n",
        "        df.join(direct_shortest, on=\"ranker_id\", how=\"left\")\n",
        "        .with_columns(\n",
        "            (\n",
        "                (pl.col(\"is_direct_leg0\") == 1)\n",
        "                & (pl.col(\"total_duration\") == pl.col(\"min_direct\"))\n",
        "            )\n",
        "            .cast(pl.Int32)\n",
        "            .fill_null(0)\n",
        "            .alias(\"is_direct_shortest\")\n",
        "        )\n",
        "        .drop(\"min_direct\")\n",
        "    )\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "@timer\n",
        "def build_time_features(df: pl.DataFrame) -> pl.DataFrame:\n",
        "    time_cols = [\n",
        "        \"legs0_departureAt\",\n",
        "        \"legs0_arrivalAt\",\n",
        "        \"legs1_departureAt\",\n",
        "        \"legs1_arrivalAt\",\n",
        "    ]\n",
        "\n",
        "    # Conver time format to datetime\n",
        "    dt_cols = [\n",
        "        pl.col(col).str.to_datetime(strict=False).alias(f\"{col}_dt\")\n",
        "        for col in time_cols\n",
        "    ]\n",
        "    df = df.with_columns(dt_cols)\n",
        "\n",
        "    # Original time features\n",
        "    time_exprs = []\n",
        "    for col in time_cols:\n",
        "        dt_col = f\"{col}_dt\"\n",
        "        h = pl.col(dt_col).dt.hour().fill_null(-1)\n",
        "\n",
        "        time_exprs.extend(\n",
        "            [\n",
        "                h.alias(f\"{col}_hour\"),\n",
        "                pl.col(dt_col).dt.weekday().fill_null(0).alias(f\"{col}_weekday\"),\n",
        "                ((h >= 6) & (h < 20)).cast(pl.Int32).alias(f\"{col}_business_time\"),\n",
        "                pl.when(h == -1)\n",
        "                .then(-1)\n",
        "                .when(h < 6)\n",
        "                .then(0)\n",
        "                .when(h < 9)\n",
        "                .then(1)\n",
        "                .when(h < 11)\n",
        "                .then(2)\n",
        "                .when(h < 13)\n",
        "                .then(3)\n",
        "                .when(h < 17)\n",
        "                .then(4)\n",
        "                .when(h < 20)\n",
        "                .then(5)\n",
        "                .otherwise(6)\n",
        "                .alias(f\"{col}_time_bin\"),\n",
        "            ]\n",
        "        )\n",
        "    df = df.with_columns(time_exprs)\n",
        "\n",
        "    # Combo features for sorting model (bin, red-eye, business-friendly)\n",
        "    combo_exprs = []\n",
        "    for leg in [\"legs0\"]:\n",
        "        dep_bin = f\"{leg}_departureAt_time_bin\"\n",
        "        arr_bin = f\"{leg}_arrivalAt_time_bin\"\n",
        "        dep_hour = f\"{leg}_departureAt_hour\"\n",
        "        arr_hour = f\"{leg}_arrivalAt_hour\"\n",
        "\n",
        "        # bin combination feature\n",
        "        combo_exprs.append(\n",
        "            (pl.col(dep_bin).cast(pl.Utf8) + \"_\" + pl.col(arr_bin).cast(pl.Utf8)).alias(\n",
        "                f\"{leg}_dep_arr_bin_combo\"\n",
        "            )\n",
        "        )\n",
        "\n",
        "        # business-friendly: both dep & arr in 6‚Äì10 or 17‚Äì20\n",
        "        combo_exprs.append(\n",
        "            (\n",
        "                ((pl.col(dep_hour) >= 6) & (pl.col(dep_hour) < 20))\n",
        "                & ((pl.col(arr_hour) >= 6) & (pl.col(arr_hour) < 20))\n",
        "            )\n",
        "            .cast(pl.Int8)\n",
        "            .alias(f\"{leg}_is_business_friendly\")\n",
        "        )\n",
        "\n",
        "        # red-eye flight: dep or arr hour < 6\n",
        "        combo_exprs.append(\n",
        "            ((pl.col(dep_hour) < 6) | (pl.col(arr_hour) < 6))\n",
        "            .cast(pl.Int8)\n",
        "            .alias(f\"{leg}_is_red_eye\")\n",
        "        )\n",
        "\n",
        "    df = df.with_columns(combo_exprs)\n",
        "\n",
        "    # Stay duration\n",
        "    df = df.with_columns(\n",
        "        (\n",
        "            (pl.col(\"legs1_departureAt_dt\") - pl.col(\"legs0_arrivalAt_dt\"))\n",
        "            .dt.total_microseconds()\n",
        "            .cast(pl.Float64)\n",
        "            / 1e6\n",
        "            / 3600.0\n",
        "        ).alias(\"stay_duration_hours\")\n",
        "    )\n",
        "\n",
        "    df = df.with_columns(\n",
        "        pl.when(pl.col(\"stay_duration_hours\") < 0)\n",
        "        .then(0)\n",
        "        .otherwise(pl.col(\"stay_duration_hours\"))\n",
        "        .alias(\"stay_duration_hours\")\n",
        "    )\n",
        "\n",
        "    df = df.with_columns(\n",
        "        pl.when(pl.col(\"is_one_way\") == 1)\n",
        "        .then(-1)\n",
        "        .otherwise(pl.col(\"stay_duration_hours\"))\n",
        "        .alias(\"stay_duration_hours\")\n",
        "    )\n",
        "\n",
        "    # Bins of stay duration\n",
        "    stay_exprs = [\n",
        "        pl.when(pl.col(\"stay_duration_hours\") == -1)\n",
        "        .then(-1)\n",
        "        .otherwise(pl.col(\"stay_duration_hours\").log1p())\n",
        "        .alias(\"stay_duration_hours_log\"),\n",
        "        pl.when(\n",
        "            (pl.col(\"stay_duration_hours\").is_not_null())\n",
        "            & (pl.col(\"stay_duration_hours\") >= 0)\n",
        "            & (pl.col(\"stay_duration_hours\") < 48)\n",
        "        )\n",
        "        .then(1)\n",
        "        .otherwise(0)\n",
        "        .cast(pl.Int8)\n",
        "        .alias(\"is_short_trip\"),\n",
        "        pl.when(pl.col(\"stay_duration_hours\") == -1)\n",
        "        .then(-1)\n",
        "        .when(pl.col(\"stay_duration_hours\") < 4)\n",
        "        .then(0)\n",
        "        .when(pl.col(\"stay_duration_hours\") < 12)\n",
        "        .then(1)\n",
        "        .when(pl.col(\"stay_duration_hours\") < 36)\n",
        "        .then(2)\n",
        "        .when(pl.col(\"stay_duration_hours\") < 72)\n",
        "        .then(3)\n",
        "        .when(pl.col(\"stay_duration_hours\") < 168)  # one week\n",
        "        .then(4)\n",
        "        .when(pl.col(\"stay_duration_hours\") < 336)  # two weeks\n",
        "        .then(5)\n",
        "        .otherwise(6)\n",
        "        .alias(\"stay_duration_bin\"),\n",
        "    ]\n",
        "    time_exprs.extend(stay_exprs)\n",
        "\n",
        "    # Interval between requestDate and boarding time\n",
        "    booking_exprs = [\n",
        "        (\n",
        "            (pl.col(\"legs0_departureAt_dt\") - pl.col(\"requestDate\"))\n",
        "            .dt.total_microseconds()\n",
        "            .cast(pl.Float64)\n",
        "            / 1e6\n",
        "            / 3600\n",
        "        ).alias(\"hours_to_departure\"),\n",
        "        (\n",
        "            (\n",
        "                (pl.col(\"legs0_departureAt_dt\") - pl.col(\"requestDate\"))\n",
        "                .dt.total_microseconds()\n",
        "                .cast(pl.Float64)\n",
        "                / 1e6\n",
        "                / 86400\n",
        "            )\n",
        "            .floor()\n",
        "            .cast(pl.Int32)\n",
        "        ).alias(\"days_to_departure\"),\n",
        "        # (\n",
        "        #     (\n",
        "        #         (pl.col(\"legs0_departureAt_dt\") - pl.col(\"requestDate\"))\n",
        "        #         .dt.total_microseconds()\n",
        "        #         .cast(pl.Float64)\n",
        "        #         / 1e6\n",
        "        #         < 48 * 3600\n",
        "        #     )\n",
        "        # )\n",
        "        # .cast(pl.Int8)\n",
        "        # .alias(\"is_last_minute_booking\"),\n",
        "    ]\n",
        "    time_exprs.extend(booking_exprs)\n",
        "\n",
        "    df = df.with_columns(time_exprs)\n",
        "    df = df.drop(time_cols + [f\"{col}_dt\" for col in time_cols] + [\"requestDate\"])\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "@timer\n",
        "def build_rank_features(df):\n",
        "    # First apply the columns that will be used for ranking\n",
        "    # Price and duration basic ranks\n",
        "    rank_exprs = []\n",
        "    for col, alias in [\n",
        "        (\"totalPrice\", \"price\"),\n",
        "        (\"total_duration\", \"duration\"),\n",
        "        (\"legs0_duration\", \"leg0_duration\"),\n",
        "        (\"legs1_duration\", \"leg1_duration\"),\n",
        "    ]:\n",
        "        min_col = pl.col(col).min().over(\"ranker_id\")\n",
        "        max_col = pl.col(col).max().over(\"ranker_id\")\n",
        "        rank_exprs.extend(\n",
        "            [\n",
        "                ((pl.col(col) - min_col) / (max_col - min_col + 1e-9)).alias(\n",
        "                    f\"{alias}_quantile_rank\"\n",
        "                ),\n",
        "            ]\n",
        "        )\n",
        "\n",
        "    df = df.with_columns(rank_exprs)\n",
        "\n",
        "    # Interaction between ranks\n",
        "    eps = 1e-6\n",
        "    df = df.with_columns(\n",
        "        [\n",
        "            (pl.col(\"price_quantile_rank\") * pl.col(\"duration_quantile_rank\")).alias(\n",
        "                \"rank_interaction_mul\"\n",
        "            ),\n",
        "            (\n",
        "                (\n",
        "                    (pl.col(\"price_quantile_rank\") + eps)\n",
        "                    / (pl.col(\"duration_quantile_rank\") + eps)\n",
        "                ).clip(0.01, 100)\n",
        "            ).alias(\"rank_interaction_ratio\"),\n",
        "            (pl.col(\"price_quantile_rank\") + pl.col(\"duration_quantile_rank\")).alias(\n",
        "                \"rank_interaction_sum\"\n",
        "            ),\n",
        "            (pl.col(\"price_quantile_rank\") - pl.col(\"duration_quantile_rank\")).alias(\n",
        "                \"rank_interaction_sub\"\n",
        "            ),\n",
        "            (\n",
        "                pl.col(\"leg0_duration_quantile_rank\")\n",
        "                * pl.col(\"leg1_duration_quantile_rank\")\n",
        "            ).alias(\"leg_dur_interaction_mul\"),\n",
        "            (\n",
        "                (pl.col(\"leg0_duration_quantile_rank\") + eps)\n",
        "                / (pl.col(\"leg1_duration_quantile_rank\") + eps)\n",
        "            )\n",
        "            .clip(0.01, 100)\n",
        "            .alias(\"leg_dur_interaction_ratio\"),\n",
        "            (\n",
        "                pl.col(\"leg0_duration_quantile_rank\")\n",
        "                - pl.col(\"leg1_duration_quantile_rank\")\n",
        "            ).alias(\"leg_dur_interaction_sub\"),\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "@timer\n",
        "def build_price_features(df: pl.DataFrame) -> pl.DataFrame:\n",
        "    # ==== 1. ËÆ°ÁÆóÁªÑÂÜÖÁªüËÆ°ÈáèÔºàmedian, std, min, mean, maxÔºâ====\n",
        "    price_stats = df.group_by(\"ranker_id\").agg(\n",
        "        [\n",
        "            pl.col(\"totalPrice\").median().alias(\"grp_price_median\"),\n",
        "            pl.col(\"totalPrice\").std().alias(\"grp_price_std\"),\n",
        "            pl.col(\"totalPrice\").min().alias(\"grp_price_min\"),\n",
        "            pl.col(\"totalPrice\").mean().alias(\"grp_price_mean\"),\n",
        "            pl.col(\"totalPrice\").max().alias(\"grp_price_max\"),\n",
        "            pl.col(\"totalPrice\").quantile(0.25, \"nearest\").alias(\"grp_price_q25\"),\n",
        "            pl.col(\"totalPrice\").quantile(0.75, \"nearest\").alias(\"grp_price_q75\"),\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    price_stats = price_stats.with_columns(\n",
        "        [\n",
        "            (pl.col(\"grp_price_q75\") - pl.col(\"grp_price_q25\")).alias(\"grp_price_iqr\"),\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    df = df.join(price_stats, on=\"ranker_id\", how=\"left\")\n",
        "\n",
        "    # ==== 2. ÊûÑÈÄ†‰ª∑Ê†ºÁõ∏ÂÖ≥ÁâπÂæÅ ====\n",
        "    price_exprs = [\n",
        "        # ÊòØÂê¶ÊòØ ranker_id ÂÜÖ top3 ÊúÄ‰æøÂÆú\n",
        "        (\n",
        "            (pl.col(\"totalPrice\").rank(\"dense\").over(\"ranker_id\") <= 3)\n",
        "            .cast(pl.Int8)\n",
        "            .alias(\"is_top3_cheapest\")\n",
        "        ),\n",
        "        # z-scoreÔºàÁõ∏ÂØπ‰∏≠‰ΩçÊï∞Ôºâ\n",
        "        (\n",
        "            (pl.col(\"totalPrice\") - pl.col(\"grp_price_median\"))\n",
        "            / (pl.col(\"grp_price_std\") + 1)\n",
        "        )\n",
        "        .alias(\"price_zscore_from_median\")\n",
        "        .fill_null(0),\n",
        "        # Áõ∏ÂØπÊúÄÂ∞è‰ª∑Ê†ºÂ∑ÆÊØîÂÄº\n",
        "        (\n",
        "            (pl.col(\"totalPrice\") - pl.col(\"grp_price_min\"))\n",
        "            / (pl.col(\"grp_price_min\") + 1)\n",
        "        ).alias(\"price_relative_to_min\"),\n",
        "        # ÊòØÂê¶‰æøÂÆú‰∫éÂùá‰ª∑„ÄÅÊòØÂê¶ÊØîÂùá‰ª∑+stdËøòË¥µÔºàoutlierÔºâ\n",
        "        (pl.col(\"totalPrice\") < pl.col(\"grp_price_q25\"))\n",
        "        .cast(pl.Int8)\n",
        "        .alias(\"is_cheaper_than_avg\"),\n",
        "        (\n",
        "            pl.col(\"totalPrice\")\n",
        "            > (\n",
        "                pl.col(\"grp_price_q75\")\n",
        "                + 1.5 * (pl.col(\"grp_price_q75\") - pl.col(\"grp_price_q25\"))\n",
        "            )\n",
        "        )\n",
        "        .cast(pl.Int8)\n",
        "        .alias(\"is_expensive_outlier\"),\n",
        "    ]\n",
        "\n",
        "    df = df.with_columns(price_exprs)\n",
        "\n",
        "    # ==== 3. ÊûÑÈÄ†Áõ¥ËææËà™Áè≠‰∏≠ÊúÄ‰æøÂÆú ====\n",
        "    direct_cheapest = (\n",
        "        df.filter(pl.col(\"is_direct_leg0\") == 1)\n",
        "        .group_by(\"ranker_id\")\n",
        "        .agg(pl.col(\"totalPrice\").min().alias(\"min_direct_price\"))\n",
        "    )\n",
        "\n",
        "    df = (\n",
        "        df.join(direct_cheapest, on=\"ranker_id\", how=\"left\")\n",
        "        .with_columns(\n",
        "            (\n",
        "                (pl.col(\"is_direct_leg0\") == 1)\n",
        "                & (pl.col(\"totalPrice\") == pl.col(\"min_direct_price\"))\n",
        "            )\n",
        "            .cast(pl.Int8)\n",
        "            .fill_null(0)\n",
        "            .alias(\"is_direct_cheapest\")\n",
        "        )\n",
        "        .drop(\"min_direct_price\")\n",
        "    )\n",
        "\n",
        "    # ==== 4. Ê∏ÖÁêÜ‰∏≠Èó¥Âàó ====\n",
        "    df = df.drop(\n",
        "        [\n",
        "            \"grp_price_median\",\n",
        "            \"grp_price_std\",\n",
        "            \"grp_price_min\",\n",
        "            \"grp_price_mean\",\n",
        "            \"grp_price_max\",\n",
        "            \"grp_price_q25\",\n",
        "            \"grp_price_q75\",\n",
        "            \"grp_price_iqr\",\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "@timer\n",
        "def build_cabin_class_features(df):\n",
        "    # Cabin class\n",
        "    cabin_cols = [\n",
        "        \"legs0_segments0_cabinClass\",\n",
        "        \"legs1_segments0_cabinClass\",\n",
        "    ]\n",
        "    cabin_levels = [1, 2, 3, 4]\n",
        "    onehot_exprs = [\n",
        "        (pl.col(c) == l).fill_null(False).cast(pl.Int8).alias(f\"{c}_is_{l}\")\n",
        "        for c in cabin_cols\n",
        "        for l in cabin_levels\n",
        "    ]\n",
        "    df = df.with_columns(onehot_exprs)\n",
        "\n",
        "    # Average cabin class\n",
        "    def build_leg_ratio_exprs(leg: int):\n",
        "        return [\n",
        "            pl.when(pl.col(f\"n_segments_leg{leg}\") > 0)\n",
        "            .then(\n",
        "                pl.sum_horizontal(\n",
        "                    [\n",
        "                        pl.col(f\"legs{leg}_segments{s}_cabinClass_is_{lvl}\")\n",
        "                        for s in range(2)\n",
        "                        if f\"legs{leg}_segments{s}_cabinClass_is_{lvl}\" in df.columns\n",
        "                    ]\n",
        "                )\n",
        "                / pl.col(f\"n_segments_leg{leg}\")\n",
        "            )\n",
        "            .otherwise(0.0)\n",
        "            .alias(f\"leg{leg}_cabin_ratio_{lvl}\")\n",
        "            for lvl in cabin_levels\n",
        "        ]\n",
        "\n",
        "    def build_avg_cabin_expr(leg: int):\n",
        "        return (\n",
        "            (\n",
        "                pl.sum_horizontal(\n",
        "                    [\n",
        "                        pl.col(f\"legs{leg}_segments{s}_cabinClass\")\n",
        "                        for s in range(2)\n",
        "                        if f\"legs{leg}_segments{s}_cabinClass\" in df.columns\n",
        "                    ]\n",
        "                )\n",
        "                / pl.col(f\"n_segments_leg{leg}\")\n",
        "            )\n",
        "            .fill_nan(0.0)\n",
        "            .alias(f\"leg{leg}_avg_cabin_class\")\n",
        "        )\n",
        "\n",
        "    # df = df.with_columns(build_leg_ratio_exprs(0) + build_leg_ratio_exprs(1))\n",
        "\n",
        "    # Average bussiness cabin ratio\n",
        "    business_levels = [3, 4]\n",
        "    business_cols = [\n",
        "        f\"{col}_is_{business_level}\"\n",
        "        for col in cabin_cols\n",
        "        for business_level in business_levels\n",
        "    ]\n",
        "\n",
        "    df = df.with_columns(\n",
        "        [\n",
        "            pl.sum_horizontal([pl.col(c) for c in business_cols]).alias(\n",
        "                \"cabin_class_level_sum_3\"\n",
        "            )\n",
        "        ]\n",
        "    )\n",
        "    df = df.with_columns(\n",
        "        [\n",
        "            # (\n",
        "            #     pl.col(\"cabin_class_level_sum_3\") / (pl.col(\"total_segments\") + 1e-6)\n",
        "            # ).alias(\"business_class_ratio\"),\n",
        "            (pl.col(\"cabin_class_level_sum_3\") >= 1)\n",
        "            .cast(pl.Int8)\n",
        "            .alias(\"has_business_class\"),\n",
        "        ]\n",
        "    )\n",
        "    df = df.drop(\"cabin_class_level_sum_3\")\n",
        "\n",
        "    highest_expr = (\n",
        "        pl.max_horizontal(\n",
        "            [\n",
        "                pl.col(f\"{col}_is_{lvl}\").cast(pl.Boolean)\n",
        "                for col in cabin_cols\n",
        "                for lvl in range(1, 5)\n",
        "                if f\"{col}_is_{lvl}\" in df.columns\n",
        "            ]\n",
        "        )\n",
        "        .cast(pl.Int8)\n",
        "        .alias(\"cabin_class_highest\")\n",
        "    )\n",
        "\n",
        "    lowest_expr = (\n",
        "        pl.min_horizontal(\n",
        "            [\n",
        "                pl.col(f\"{col}_is_{lvl}\").cast(pl.Boolean)\n",
        "                for col in cabin_cols\n",
        "                for lvl in range(1, 5)\n",
        "                if f\"{col}_is_{lvl}\" in df.columns\n",
        "            ]\n",
        "        )\n",
        "        .cast(pl.Int8)\n",
        "        .alias(\"cabin_class_lowest\")\n",
        "    )\n",
        "\n",
        "    diversity_expr = pl.sum_horizontal(\n",
        "        [\n",
        "            pl.any_horizontal(\n",
        "                [\n",
        "                    pl.col(f\"{col}_is_{lvl}\").cast(pl.Boolean)\n",
        "                    for col in cabin_cols\n",
        "                    if f\"{col}_is_{lvl}\" in df.columns\n",
        "                ]\n",
        "            ).cast(pl.Int8)\n",
        "            for lvl in cabin_levels\n",
        "        ]\n",
        "    ).alias(\"cabin_class_diversity\")\n",
        "\n",
        "    all_level_1_expr = (\n",
        "        pl.all_horizontal(\n",
        "            [\n",
        "                ((pl.col(f\"{col}_is_1\") == 1) | (pl.col(f\"{col}_is_2\") == 1)).cast(\n",
        "                    pl.Boolean\n",
        "                )\n",
        "                for col in cabin_cols\n",
        "                if f\"{col}_is_1\" in df.columns or f\"{col}_is_2\" in df.columns\n",
        "            ]\n",
        "        )\n",
        "        .cast(pl.Int8)\n",
        "        .alias(\"all_cabin_level_1\")\n",
        "    )\n",
        "    # df = df.with_columns([highest_expr, lowest_expr, diversity_expr, all_level_1_expr])\n",
        "    df = df.with_columns([all_level_1_expr])\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "@timer\n",
        "def build_company_features(df, FULL, top_k=10):\n",
        "    train_size = 16487352 if not FULL else 18145372\n",
        "    train_df = df.slice(0, train_size)\n",
        "    selected_df = train_df.filter(pl.col(\"selected\") == 1)\n",
        "\n",
        "    avg_price = selected_df.select(pl.col(\"totalPrice\").mean()).item()\n",
        "    std_price = selected_df.select(pl.col(\"totalPrice\").std()).item()\n",
        "\n",
        "    company_pref = (\n",
        "        selected_df.group_by(\"companyID\")\n",
        "        .agg(\n",
        "            [\n",
        "                pl.count().alias(\"company_select_count\"),\n",
        "                pl.col(\"totalPrice\").mean().alias(\"avg_selected_price\"),\n",
        "                pl.col(\"totalPrice\").std().alias(\"std_selected_price\"),\n",
        "                # pl.col(\"cabin_class_highest\").mean().alias(\"avg_selected_cabin\"),\n",
        "                pl.col(\"both_direct\").mean().alias(\"selected_direct_ratio\"),\n",
        "                (pl.col(\"legs0_departureAt_hour\") < 6)\n",
        "                .cast(pl.Int32)\n",
        "                .mean()\n",
        "                .alias(\"selected_night_ratio\"),\n",
        "                pl.col(\"price_quantile_rank\").mean().alias(\"company_avg_pct\"),\n",
        "                pl.col(\"duration_quantile_rank\").mean().alias(\"company_avg_dct\"),\n",
        "            ]\n",
        "        )\n",
        "        .with_columns(\n",
        "            [\n",
        "                pl.when(pl.col(\"company_select_count\") <= 1)\n",
        "                .then(avg_price)\n",
        "                .otherwise(pl.col(\"avg_selected_price\"))\n",
        "                .alias(\"avg_selected_price\"),\n",
        "            ]\n",
        "        )\n",
        "        .with_columns(\n",
        "            [\n",
        "                pl.col(\"company_select_count\")\n",
        "                .log1p()\n",
        "                .alias(\"log_company_select_count\"),\n",
        "                (pl.col(\"company_select_count\") > 3000)\n",
        "                .cast(pl.Int32)\n",
        "                .alias(\"is_very_popular_company\"),\n",
        "                (\n",
        "                    (pl.col(\"company_select_count\") <= 3000)\n",
        "                    & (pl.col(\"company_select_count\") > 1000)\n",
        "                )\n",
        "                .cast(pl.Int32)\n",
        "                .alias(\"is_popular_company\"),\n",
        "            ]\n",
        "        )\n",
        "        .with_columns(\n",
        "            pl.col(\"company_select_count\")\n",
        "            .rank(\"dense\", descending=True)\n",
        "            .alias(\"company_rank\")\n",
        "        )\n",
        "        .with_columns(\n",
        "            (pl.col(\"company_rank\") <= top_k)\n",
        "            .cast(pl.Int32)\n",
        "            .alias(\"is_top_selected_company\")\n",
        "        )\n",
        "        .drop(\"company_rank\")\n",
        "    )\n",
        "\n",
        "    df = df.join(company_pref, on=\"companyID\", how=\"left\")\n",
        "\n",
        "    df = df.with_columns(\n",
        "        [\n",
        "            pl.col(\"company_select_count\").fill_null(0),\n",
        "            pl.col(\"log_company_select_count\").fill_null(0),\n",
        "            pl.col(\"avg_selected_price\").fill_null(avg_price),\n",
        "            pl.col(\"std_selected_price\").fill_null(std_price),\n",
        "            # pl.col(\"avg_selected_cabin\").fill_null(0),\n",
        "            pl.col(\"selected_direct_ratio\").fill_null(0),\n",
        "            pl.col(\"selected_night_ratio\").fill_null(0),\n",
        "            pl.col(\"is_very_popular_company\").fill_null(0),\n",
        "            pl.col(\"is_popular_company\").fill_null(0),\n",
        "            pl.col(\"is_top_selected_company\").fill_null(0),\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    df = df.with_columns(\n",
        "        [\n",
        "            (\n",
        "                (pl.col(\"totalPrice\") - pl.col(\"avg_selected_price\"))\n",
        "                / (pl.col(\"std_selected_price\") + 1e-6)\n",
        "            ).alias(\"z_price_vs_company_selected\"),\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "@timer\n",
        "def build_flight_features(df, FULL):\n",
        "    selected_col = \"legs0_segments0_marketingCarrier_code\"\n",
        "    train_size = 16487352 if not FULL else 18145372\n",
        "    train_df = df.slice(0, train_size)\n",
        "    selected_df = train_df.filter(pl.col(\"selected\") == 1)\n",
        "\n",
        "    # TODO: ËÆ°ÁÆóÂêÑ‰∏™‰∏çÂêåËà±‰ΩçÁöÑÈÄâÂèñÁéáÔºå‰Ωú‰∏∫ÂÆ¢Êà∑Áæ§‰ΩìÁâπÂæÅ\n",
        "    cabin_col = \"legs0_segments0_cabinClass\"\n",
        "    cabin_selected_df = selected_df.group_by([selected_col, cabin_col]).agg(\n",
        "        pl.count().alias(\"cabin_selected_count\")\n",
        "    )\n",
        "    total_selected_per_carrier = selected_df.group_by(selected_col).agg(\n",
        "        pl.count().alias(\"total_selected_count\")\n",
        "    )\n",
        "    cabin_stats_df = cabin_selected_df.join(\n",
        "        total_selected_per_carrier, on=selected_col, how=\"inner\"\n",
        "    ).with_columns(\n",
        "        (\n",
        "            pl.col(\"cabin_selected_count\") / (pl.col(\"total_selected_count\") + 1e-5)\n",
        "        ).alias(\"cabin_select_ratio\")\n",
        "    )\n",
        "    cabin_stats_df = cabin_stats_df.with_columns(pl.col(cabin_col).cast(pl.Utf8))\n",
        "\n",
        "    cabin_stats_wide_df = cabin_stats_df.pivot(\n",
        "        values=\"cabin_select_ratio\",\n",
        "        index=selected_col,\n",
        "        columns=cabin_col,\n",
        "        aggregate_function=\"first\",\n",
        "    )\n",
        "\n",
        "    existing_cols = cabin_stats_wide_df.columns\n",
        "    required_cols = {\n",
        "        \"1.0\": f\"{selected_col}_cabin1_select_ratio\",\n",
        "        \"2.0\": f\"{selected_col}_cabin2_select_ratio\",\n",
        "        \"3.0\": f\"{selected_col}_cabin3_select_ratio\",\n",
        "        \"4.0\": f\"{selected_col}_cabin4_select_ratio\",\n",
        "    }\n",
        "    for old, new in required_cols.items():\n",
        "        if old in existing_cols:\n",
        "            cabin_stats_wide_df = cabin_stats_wide_df.with_columns(\n",
        "                [pl.col(old).alias(new)]\n",
        "            )\n",
        "            cabin_stats_wide_df = cabin_stats_wide_df.drop(old)\n",
        "        else:\n",
        "            cabin_stats_wide_df = cabin_stats_wide_df.with_columns(\n",
        "                [pl.lit(None).alias(new)]\n",
        "            )\n",
        "\n",
        "    # ÁªüËÆ°ÊÄªÊ¨°Êï∞ & Ë¢´ÈÄâÊ¨°Êï∞\n",
        "    selected_count_df = selected_df.group_by(selected_col).agg(\n",
        "        pl.count().alias(\"selected_count\")\n",
        "    )\n",
        "    total_count_df = train_df.group_by(selected_col).agg(\n",
        "        pl.count().alias(\"total_count\")\n",
        "    )\n",
        "\n",
        "    # ËÆ°ÁÆóË¢´ÈÄâÊØî‰æã & logËÆ°Êï∞\n",
        "    stats_df = (\n",
        "        selected_count_df.join(total_count_df, on=selected_col, how=\"inner\")\n",
        "        .with_columns(\n",
        "            (pl.col(\"selected_count\") / (pl.col(\"total_count\") + 1e-5)).alias(\n",
        "                f\"{selected_col}_selection_rate\"\n",
        "            ),\n",
        "            pl.col(\"selected_count\")\n",
        "            .cast(pl.Float64)\n",
        "            .log1p()\n",
        "            .alias(f\"{selected_col}_log_selected_count\"),\n",
        "            pl.col(\"total_count\")\n",
        "            .cast(pl.Float64)\n",
        "            .log1p()\n",
        "            .alias(f\"{selected_col}_log_total_count\"),\n",
        "        )\n",
        "        .drop([\"selected_count\", \"total_count\"])\n",
        "    )\n",
        "\n",
        "    # ÊèêÂèñÂá∫ÂèëÂ∞èÊó∂Êñπ‰æøËÅöÂêàÊó∂Èó¥Áõ∏ÂÖ≥ÁâπÂæÅ\n",
        "    train_df = train_df.with_columns(pl.col(\"legs0_departureAt_hour\").alias(\"dep_hour\"))\n",
        "    selected_df = selected_df.with_columns(\n",
        "        pl.col(\"legs0_departureAt_hour\").alias(\"dep_hour\")\n",
        "    )\n",
        "\n",
        "    # ËÅöÂêà‰ª∑Ê†º„ÄÅËà™Áè≠ÊåÅÁª≠Êó∂Èó¥„ÄÅÊó∂Èó¥ÂàÜÂ∏É„ÄÅÂÖ¨Âè∏/Áî®Êà∑Â§öÊ†∑ÊÄßÁ≠âÁâπÂæÅ\n",
        "    more_stats_df = selected_df.group_by(selected_col).agg(\n",
        "        [\n",
        "            pl.col(\"price_quantile_rank\")\n",
        "            .mean()\n",
        "            .alias(f\"{selected_col}_avg_price_rank\"),\n",
        "            pl.col(\"duration_quantile_rank\")\n",
        "            .mean()\n",
        "            .alias(f\"{selected_col}_avg_duration_rank\"),\n",
        "            pl.col(\"dep_hour\").mean().alias(f\"{selected_col}_avg_dep_hour\"),\n",
        "            (pl.col(\"dep_hour\") < 6)\n",
        "            .cast(pl.Int32)\n",
        "            .mean()\n",
        "            .alias(f\"{selected_col}_night_ratio\"),\n",
        "            pl.col(\"companyID\").n_unique().alias(f\"{selected_col}_company_diversity\"),\n",
        "            pl.col(\"profileId\").n_unique().alias(f\"{selected_col}_user_diversity\"),\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    global_avg_price = selected_df.select(pl.col(\"price_quantile_rank\").mean()).item()\n",
        "    global_avg_duration = selected_df.select(\n",
        "        pl.col(\"duration_quantile_rank\").mean()\n",
        "    ).item()\n",
        "\n",
        "    stats_df = stats_df.join(more_stats_df, on=selected_col, how=\"left\")\n",
        "    stats_df = stats_df.join(cabin_stats_wide_df, on=selected_col, how=\"left\")\n",
        "    stats_df = stats_df.drop(\n",
        "        [\n",
        "            f\"{selected_col}_selection_rate\",\n",
        "            f\"{selected_col}_log_selected_count\",\n",
        "            f\"{selected_col}_log_total_count\",\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    df = df.join(stats_df, on=selected_col, how=\"left\").with_columns(\n",
        "        [\n",
        "            # pl.col(f\"{selected_col}_selection_rate\").fill_null(0.0),\n",
        "            # pl.col(f\"{selected_col}_log_selected_count\").fill_null(0.0),\n",
        "            # pl.col(f\"{selected_col}_log_total_count\").fill_null(0.0),\n",
        "            pl.col(f\"{selected_col}_avg_price_rank\").fill_null(global_avg_price),\n",
        "            pl.col(f\"{selected_col}_avg_duration_rank\").fill_null(global_avg_duration),\n",
        "            pl.col(f\"{selected_col}_avg_dep_hour\").fill_null(12.0),\n",
        "            pl.col(f\"{selected_col}_night_ratio\").fill_null(0.0),\n",
        "            pl.col(f\"{selected_col}_company_diversity\").fill_null(0),\n",
        "            pl.col(f\"{selected_col}_user_diversity\").fill_null(0),\n",
        "            pl.col(f\"{selected_col}_cabin1_select_ratio\").fill_null(0.0),\n",
        "            pl.col(f\"{selected_col}_cabin2_select_ratio\").fill_null(0.0),\n",
        "            pl.col(f\"{selected_col}_cabin3_select_ratio\").fill_null(0.0),\n",
        "            pl.col(f\"{selected_col}_cabin4_select_ratio\").fill_null(0.0),\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "def get_rank_bin_expr(rank_col: str, bin_edges: list[int], bin_col: str):\n",
        "    expr = pl.when(pl.col(rank_col) <= bin_edges[0]).then(1)\n",
        "    for i in range(1, len(bin_edges)):\n",
        "        expr = expr.when(pl.col(rank_col) <= bin_edges[i]).then(i + 1)\n",
        "    expr = expr.otherwise(len(bin_edges) + 1).cast(pl.Int8).alias(bin_col)\n",
        "    return expr\n",
        "\n",
        "\n",
        "@timer\n",
        "def build_carrier_features(\n",
        "    df, carrier_col: str, FULL: bool, bin_edges: list[int] = [1, 2, 5, 12, 17, 28]\n",
        "):\n",
        "    carrier_col += \"_segments0_marketingCarrier_code\"\n",
        "    select_rate_col = f\"{carrier_col}_selection_rate\"\n",
        "    bin_col = f\"{carrier_col}_selected_rank_bin\"\n",
        "    log_total_col = f\"{carrier_col}_log_total_count\"\n",
        "    log_selected_col = f\"{carrier_col}_log_selected_count\"\n",
        "    rank_col = \"selected_rank\"\n",
        "\n",
        "    train_size = 16487352 if not FULL else 18145372\n",
        "    train_df = df.slice(0, train_size)\n",
        "\n",
        "    selected_cnt_df = (\n",
        "        train_df.filter(pl.col(\"selected\") == 1)\n",
        "        .group_by(carrier_col)\n",
        "        .agg(pl.count().alias(\"selected_count\"))\n",
        "    )\n",
        "\n",
        "    total_cnt_df = train_df.group_by(carrier_col).agg(pl.count().alias(\"total_count\"))\n",
        "\n",
        "    rate_df = (\n",
        "        selected_cnt_df.join(total_cnt_df, on=carrier_col, how=\"inner\")\n",
        "        .with_columns(\n",
        "            (pl.col(\"selected_count\") / (pl.col(\"total_count\") + 1e-5)).alias(\n",
        "                select_rate_col\n",
        "            ),\n",
        "            pl.col(\"total_count\").cast(pl.Float64).log1p().alias(log_total_col),\n",
        "            pl.col(\"selected_count\").cast(pl.Float64).log1p().alias(log_selected_col),\n",
        "        )\n",
        "        .with_columns(\n",
        "            pl.col(\"selected_count\").rank(\"dense\", descending=True).alias(rank_col)\n",
        "        )\n",
        "        .with_columns(get_rank_bin_expr(rank_col, bin_edges, bin_col))\n",
        "        .select(\n",
        "            [carrier_col, select_rate_col, log_total_col, log_selected_col, bin_col]\n",
        "        )\n",
        "    )\n",
        "\n",
        "    df = df.join(rate_df, on=carrier_col, how=\"left\").with_columns(\n",
        "        pl.col(select_rate_col).fill_null(0.0),\n",
        "        pl.col(log_total_col).fill_null(0.0),\n",
        "        pl.col(log_selected_col).fill_null(0.0),\n",
        "        pl.col(bin_col).fill_null(0),\n",
        "    )\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "@timer\n",
        "def build_frequent_flyer_features(\n",
        "    df: pl.DataFrame, major_carriers: list[str]\n",
        ") -> pl.DataFrame:\n",
        "    for leg in [0]:\n",
        "        carrier_col = f\"legs{leg}_segments0_marketingCarrier_code\"\n",
        "        cabin_col = f\"legs{leg}_segments0_cabinClass\"\n",
        "\n",
        "        # ÊòØÂê¶ÊòØ frequentFlyer ÁöÑ‰ºöÂëòËà™Âè∏\n",
        "        flag_ff_col = f\"{carrier_col}_in_frequentFlyer\"\n",
        "        df = df.with_columns(\n",
        "            pl.col(\"frequentFlyer\")\n",
        "            .fill_null(\"\")\n",
        "            .str.split(\"/\")\n",
        "            .list.contains(pl.col(carrier_col))\n",
        "            .cast(pl.Int8)\n",
        "            .alias(flag_ff_col)\n",
        "        )\n",
        "\n",
        "        # Only one\n",
        "        df = df.with_columns(\n",
        "            (\n",
        "                (pl.col(\"frequentFlyer\").fill_null(\"\").str.split(\"/\").list.len() == 1)\n",
        "                & pl.col(\"frequentFlyer\")\n",
        "                .fill_null(\"\")\n",
        "                .str.contains(pl.col(carrier_col))\n",
        "            )\n",
        "            .cast(pl.Int8)\n",
        "            .alias(f\"{carrier_col}_is_only_frequentFlyer\")\n",
        "        )\n",
        "\n",
        "        # ÊòØÂê¶ÊòØ major carrier\n",
        "        flag_major_col = f\"is_major_carrier_{leg}_0\"\n",
        "        df = df.with_columns(\n",
        "            pl.col(carrier_col)\n",
        "            .is_in(major_carriers)\n",
        "            .cast(pl.Int8)\n",
        "            .alias(flag_major_col)\n",
        "        )\n",
        "\n",
        "        # frequent flyer + ‰ΩéËà±‰Ωç\n",
        "        df = df.with_columns(\n",
        "            (\n",
        "                (pl.col(flag_ff_col) == 1)\n",
        "                & ((pl.col(cabin_col) == 1) | (pl.col(cabin_col) == 2))\n",
        "            )\n",
        "            .cast(pl.Int8)\n",
        "            .alias(f\"{carrier_col}_ff_and_economic\")\n",
        "        )\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "@timer\n",
        "def build_profile_features(df, FULL=False):\n",
        "    train_size = 16487352 if not FULL else 18145372\n",
        "    print(\"Using train size: \", train_size)\n",
        "    train_df = df.slice(0, train_size)\n",
        "    train_selected = train_df.filter(pl.col(\"selected\") == 1)\n",
        "\n",
        "    agg = train_selected.group_by(\"profileId\").agg(\n",
        "        [\n",
        "            pl.count().alias(\"user_selected_count\"),\n",
        "            pl.mean(\"price_quantile_rank\").alias(\"user_avg_price_rank\"),\n",
        "            pl.mean(\"duration_quantile_rank\").alias(\"user_avg_duration_rank\"),\n",
        "            pl.mean(\"legs0_segments0_cabinClass\").alias(\n",
        "                \"user_avg_cabinClass_leg0_seg0\"\n",
        "            ),\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    total_counts = train_selected.group_by(\"profileId\").agg(\n",
        "        pl.count().alias(\"user_total_count\")\n",
        "    )\n",
        "    profile_stats = agg.join(total_counts, on=\"profileId\", how=\"left\")\n",
        "\n",
        "    profile_stats = profile_stats.with_columns(\n",
        "        [\n",
        "            (pl.col(\"user_total_count\") > 0).cast(pl.Int32).alias(\"user_in_train\"),\n",
        "            pl.col(\"user_selected_count\").log1p().alias(\"user_selected_count_log\"),\n",
        "        ]\n",
        "    ).drop(\"user_total_count\")\n",
        "\n",
        "    # Use kde to approximate the peak\n",
        "    price_arr = train_selected.select(\"price_quantile_rank\").to_numpy().flatten()\n",
        "    duration_arr = train_selected.select(\"duration_quantile_rank\").to_numpy().flatten()\n",
        "    cabin_arr = train_selected.select(\"legs0_segments0_cabinClass\").to_numpy().flatten()\n",
        "\n",
        "    price_mode = kde_mode(price_arr)\n",
        "    duration_mode = kde_mode(duration_arr)\n",
        "    cabin_mode = kde_mode(cabin_arr)\n",
        "\n",
        "    fill_na_dict = {\n",
        "        \"user_selected_count\": 0,\n",
        "        \"user_selected_count_log\": 0,\n",
        "        \"user_in_train\": 0,\n",
        "        \"user_avg_price_rank\": price_mode,\n",
        "        \"user_avg_duration_rank\": duration_mode,\n",
        "        \"user_avg_cabinClass_leg0_seg0\": cabin_mode,\n",
        "    }\n",
        "\n",
        "    print(fill_na_dict)\n",
        "\n",
        "    df = df.join(profile_stats, on=\"profileId\", how=\"left\")\n",
        "    df = df.with_columns([pl.col(c).fill_null(v) for c, v in fill_na_dict.items()])\n",
        "\n",
        "    df = df.with_columns(\n",
        "        [\n",
        "            (pl.col(\"price_quantile_rank\") - pl.col(\"user_avg_price_rank\")).alias(\n",
        "                \"price_rank_diff\"\n",
        "            ),\n",
        "            (pl.col(\"duration_quantile_rank\") - pl.col(\"user_avg_duration_rank\")).alias(\n",
        "                \"duration_rank_diff\"\n",
        "            ),\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    df = df.drop([\"user_avg_price_rank\", \"user_avg_duration_rank\"])\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "@timer\n",
        "def build_route_features(df, FULL):\n",
        "    pass\n",
        "\n",
        "\n",
        "@timer\n",
        "def build_airport_feature(df):\n",
        "    airport = pl.read_csv(\"/home/zhengxiang/FlightRank/data/airports.csv\")\n",
        "\n",
        "    # Ëµ∑È£ûÊú∫Âú∫Â≠óÊÆµ‰øùÁïôÁöÑÂàó\n",
        "    departure_cols = [\n",
        "        \"IATA\",\n",
        "        \"UTC_Offset_Hours\",\n",
        "        \"Country_CodeA2\",\n",
        "        \"GeoPointLat\",\n",
        "        \"GeoPointLong\",\n",
        "    ]\n",
        "    departure_airport_info = airport.select(departure_cols).rename(\n",
        "        {col: f\"departure_airport_{col}\" for col in departure_cols if col != \"IATA\"}\n",
        "    )\n",
        "\n",
        "    # Âà∞ËææÊú∫Âú∫Â≠óÊÆµ‰øùÁïôÁöÑÂàó\n",
        "    arrival_cols = [\n",
        "        \"IATA\",\n",
        "        \"UTC_Offset_Hours\",\n",
        "        \"Country_CodeA2\",\n",
        "        \"GeoPointLat\",\n",
        "        \"GeoPointLong\",\n",
        "    ]\n",
        "    arrival_airport_info = airport.select(arrival_cols).rename(\n",
        "        {col: f\"arrival_airport_{col}\" for col in arrival_cols if col != \"IATA\"}\n",
        "    )\n",
        "\n",
        "    # join Ëµ∑È£ûÊú∫Âú∫‰ø°ÊÅØ\n",
        "    df = df.join(\n",
        "        departure_airport_info,\n",
        "        left_on=\"legs0_segments0_departureFrom_airport_iata\",\n",
        "        right_on=\"IATA\",\n",
        "        how=\"left\",\n",
        "    )\n",
        "\n",
        "    # join Âà∞ËææÊú∫Âú∫‰ø°ÊÅØ\n",
        "    df = df.join(\n",
        "        arrival_airport_info,\n",
        "        left_on=\"legs0_segments0_arrivalTo_airport_iata\",\n",
        "        right_on=\"IATA\",\n",
        "        how=\"left\",\n",
        "    )\n",
        "\n",
        "    def haversine_distance(row):\n",
        "        vals = list(row.values())\n",
        "        if any(v is None for v in vals):\n",
        "            return None\n",
        "        lat1, lon1, lat2, lon2 = map(float, vals)\n",
        "        return haversine((lat1, lon1), (lat2, lon2))\n",
        "\n",
        "    df = df.with_columns(\n",
        "        [\n",
        "            # ÊòØÂê¶Ë∑®ÂõΩÔºà‰∏çÂêåÂõΩÂÆ∂Ôºâ\n",
        "            (\n",
        "                pl.col(\"departure_airport_Country_CodeA2\")\n",
        "                != pl.col(\"arrival_airport_Country_CodeA2\")\n",
        "            )\n",
        "            .cast(pl.Int8)\n",
        "            .alias(\"is_cross_country\"),\n",
        "            # Êó∂Âå∫Â∑ÆÔºàÁªùÂØπÂÄºÔºâ\n",
        "            (\n",
        "                pl.col(\"departure_airport_UTC_Offset_Hours\")\n",
        "                - pl.col(\"arrival_airport_UTC_Offset_Hours\")\n",
        "            ).alias(\"timezone_diff\"),\n",
        "            # # ÁªèÁ∫¨Â∫¶Ë∑ùÁ¶ªÔºàhaversineÔºâ\n",
        "            # pl.struct(\n",
        "            #     [\n",
        "            #         pl.col(\"departure_airport_GeoPointLat\"),\n",
        "            #         pl.col(\"departure_airport_GeoPointLong\"),\n",
        "            #         pl.col(\"arrival_airport_GeoPointLat\"),\n",
        "            #         pl.col(\"arrival_airport_GeoPointLong\"),\n",
        "            #     ]\n",
        "            # )\n",
        "            # .map_elements(haversine_distance)\n",
        "            # .alias(\"geo_distance_km\"),\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "@timer\n",
        "def build_corporateTariffCode_feature(df, FULL):\n",
        "    train_size = 16487352 if not FULL else 18145372\n",
        "    train_df = df.slice(0, train_size)\n",
        "    selected_df = train_df.filter(pl.col(\"selected\") == 1)\n",
        "\n",
        "    ctc_df = selected_df.group_by(\"corporateTariffCode\").agg(\n",
        "        [\n",
        "            pl.count().alias(\"corporateTariffCode_hotness\"),\n",
        "            pl.col(\"price_quantile_rank\")\n",
        "            .mean()\n",
        "            .alias(\"corporateTariffCode_price_rank_mean\"),\n",
        "            pl.col(\"duration_quantile_rank\")\n",
        "            .mean()\n",
        "            .alias(\"corporateTariffCode_duration_rank_mean\"),\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    no_ctc_df = selected_df.filter(pl.col(\"corporateTariffCode\").is_null())\n",
        "    mean_price_rank_no_ctc = no_ctc_df[\"price_quantile_rank\"].mean()\n",
        "    mean_duration_rank_no_ctc = no_ctc_df[\"duration_quantile_rank\"].mean()\n",
        "\n",
        "    df = df.join(ctc_df, on=\"corporateTariffCode\", how=\"left\").with_columns(\n",
        "        [\n",
        "            pl.col(\"corporateTariffCode_hotness\").fill_null(0),\n",
        "            pl.col(\"corporateTariffCode_price_rank_mean\").fill_null(\n",
        "                mean_price_rank_no_ctc\n",
        "            ),\n",
        "            pl.col(\"corporateTariffCode_duration_rank_mean\").fill_null(\n",
        "                mean_duration_rank_no_ctc\n",
        "            ),\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "@timer\n",
        "def handle_features_with_extreme(df):\n",
        "    # Taxes\n",
        "    df = df.with_columns((pl.col(\"taxes\") + 1e-3).log().alias(\"log_taxes\"))\n",
        "    # Winsorization of price per tax\n",
        "    low = df.select(pl.col(\"price_per_tax\").quantile(0.01)).item()\n",
        "    high = df.select(pl.col(\"price_per_tax\").quantile(0.99)).item()\n",
        "\n",
        "    df = df.with_columns(\n",
        "        pl.when(pl.col(\"price_per_tax\") < low)\n",
        "        .then(low)\n",
        "        .when(pl.col(\"price_per_tax\") > high)\n",
        "        .then(high)\n",
        "        .otherwise(pl.col(\"price_per_tax\"))\n",
        "        .alias(\"price_per_tax\")\n",
        "    )\n",
        "\n",
        "    df = df.with_columns(\n",
        "        [\n",
        "            (pl.col(\"legs0_duration\").log1p().alias(\"legs0_duration\")),\n",
        "            (pl.col(\"legs1_duration\").log1p().alias(\"legs1_duration\")),\n",
        "            (\n",
        "                pl.col(\"legs0_segments0_duration\")\n",
        "                .log1p()\n",
        "                .alias(\"legs0_segments0_duration\")\n",
        "            ),\n",
        "            (\n",
        "                pl.col(\"legs0_segments1_duration\")\n",
        "                .log1p()\n",
        "                .alias(\"legs0_segments1_duration\")\n",
        "            ),\n",
        "            (\n",
        "                pl.col(\"legs1_segments0_duration\")\n",
        "                .log1p()\n",
        "                .alias(\"legs1_segments0_duration\")\n",
        "            ),\n",
        "            (\n",
        "                pl.col(\"legs1_segments1_duration\")\n",
        "                .log1p()\n",
        "                .alias(\"legs1_segments1_duration\")\n",
        "            ),\n",
        "            (pl.col(\"total_duration\").log1p().alias(\"total_duration\")),\n",
        "            (pl.col(\"hours_to_departure\").log1p().alias(\"hours_to_departure\")),\n",
        "            # (\n",
        "            #     pl.col(\"legs0_segments0_marketingCarrier_code_company_diversity\")\n",
        "            #     .log1p()\n",
        "            #     .alias(\"legs0_segments0_marketingCarrier_code_company_diversity\")\n",
        "            # ),\n",
        "            # (\n",
        "            #     pl.col(\"legs0_segments0_marketingCarrier_code_user_diversity\")\n",
        "            #     .log1p()\n",
        "            #     .alias(\"legs0_segments0_marketingCarrier_code_user_diversity\")\n",
        "            # ),\n",
        "            # (\n",
        "            #     pl.col(\"outbound_route_hotness\")\n",
        "            #     .log1p()\n",
        "            #     .alias(\"outbound_route_hotness\")\n",
        "            # ),\n",
        "            # (\n",
        "            #     pl.col(\"return_route_hotness\")\n",
        "            #     .log1p()\n",
        "            #     .alias(\"return_route_hotness\")\n",
        "            # ),\n",
        "        ]\n",
        "    )\n",
        "    return df\n",
        "\n",
        "\n",
        "@timer\n",
        "def feature_engineering(data_raw, full):\n",
        "    df = data_raw.clone()\n",
        "\n",
        "    # Process duration columns\n",
        "    dur_cols = [\"legs0_duration\", \"legs1_duration\"] + [\n",
        "        f\"legs{l}_segments{s}_duration\" for l in (0, 1) for s in range(4)\n",
        "    ]\n",
        "    dur_exprs = [dur_to_min(pl.col(c)).alias(c) for c in dur_cols if c in df.columns]\n",
        "\n",
        "    # Apply duration transformations first\n",
        "    if dur_exprs:\n",
        "        df = df.with_columns(dur_exprs)\n",
        "\n",
        "    # Combine all initial transformations\n",
        "    df = initial_transformations(df, full)\n",
        "\n",
        "    # Segment feature\n",
        "    df = build_segment_features(df)\n",
        "\n",
        "    # More derived features\n",
        "    df = df.with_columns(\n",
        "        [\n",
        "            (pl.col(\"is_direct_leg0\") & pl.col(\"is_direct_leg1\"))\n",
        "            .cast(pl.Int32)\n",
        "            .alias(\"both_direct\"),\n",
        "            ((pl.col(\"isVip\") == 1) | (pl.col(\"n_ff_programs\") > 0))\n",
        "            .cast(pl.Int32)\n",
        "            .alias(\"is_vip_freq\"),\n",
        "            # pl.col(\"baggage_min\")\n",
        "            # .fill_null(-1)\n",
        "            # .map_elements(\n",
        "            #     lambda x: 1 if x > 0 else (0 if x == 0 else -1), return_dtype=pl.Int32\n",
        "            # )\n",
        "            # .cast(pl.Int32)\n",
        "            # .alias(\"has_baggage\"),\n",
        "            # (pl.col(\"total_fees\") > 0).cast(pl.Int32).alias(\"has_fees\"),\n",
        "            # (pl.col(\"total_fees\") / (pl.col(\"totalPrice\") + 1)).alias(\"fee_rate\"),\n",
        "            pl.col(\"Id\").count().over(\"ranker_id\").alias(\"group_size\"),\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    df = df.with_columns(\n",
        "        [\n",
        "            pl.col(\"legs0_segments0_baggageAllowance_weightMeasurementType\").fill_null(\n",
        "                -1\n",
        "            ),\n",
        "            pl.col(\"legs0_segments0_baggageAllowance_quantity\").fill_null(-1),\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    df = df.with_columns(pl.col(\"group_size\").log1p().alias(\"group_size_log\"))\n",
        "\n",
        "    # Time features - batch process\n",
        "    df = build_time_features(df)\n",
        "\n",
        "    # Batch rank computations - more efficient with single pass\n",
        "    df = build_rank_features(df)\n",
        "\n",
        "    # Price-specific features\n",
        "    df = build_price_features(df)\n",
        "\n",
        "    # Cabin class features\n",
        "    df = build_cabin_class_features(df)\n",
        "\n",
        "    # Company features\n",
        "    df = build_company_features(df, full)\n",
        "\n",
        "    # Flight features\n",
        "    # NOTE: The flight features are not good online\n",
        "    df = build_flight_features(df, full)\n",
        "\n",
        "    # Carrier features\n",
        "    df = build_carrier_features(df, \"legs0\", full)\n",
        "    df = build_carrier_features(df, \"legs1\", full, [1, 2, 3, 5, 10, 24])\n",
        "\n",
        "    # Frequent Flyer features\n",
        "    major_carriers = [\"SU\", \"S7\"]\n",
        "    df = build_frequent_flyer_features(df, major_carriers)\n",
        "\n",
        "    # major_carriers = [\"SU\", \"FV\", \"S7\"]\n",
        "    # flag_major_col = \"is_operate_carrier_0_0\"\n",
        "    # df = df.with_columns(\n",
        "    #     pl.col(\"legs0_segments0_operatingCarrier_code\")\n",
        "    #     .is_in(major_carriers)\n",
        "    #     .cast(pl.Int8)\n",
        "    #     .alias(flag_major_col)\n",
        "    # )\n",
        "\n",
        "    # Profile features\n",
        "    df = build_profile_features(df, full)\n",
        "\n",
        "    # Route features\n",
        "    # df = build_route_features(df, full)\n",
        "\n",
        "    # Airport features\n",
        "    df = build_airport_feature(df)\n",
        "\n",
        "    # corporateTariffCode features\n",
        "    df = build_corporateTariffCode_feature(df, full)\n",
        "\n",
        "    # Handle abnormal features\n",
        "    df = handle_features_with_extreme(df)\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "###########################################################\n",
        "#                      Feature Selection                  #\n",
        "###########################################################\n",
        "\n",
        "\n",
        "def feature_selection(data, trial=None):\n",
        "    # Categorical features\n",
        "    cat_features = [\n",
        "        # Orignal features\n",
        "        \"bySelf\",\n",
        "        \"companyID\",\n",
        "        \"corporateTariffCode\",\n",
        "        \"nationality\",\n",
        "        \"isAccess3D\",\n",
        "        \"isVip\",\n",
        "        # legs0_segments0\n",
        "        \"legs0_segments0_aircraft_code\",\n",
        "        \"legs0_segments0_arrivalTo_airport_city_iata\",\n",
        "        \"legs0_segments0_arrivalTo_airport_iata\",\n",
        "        \"legs0_segments0_baggageAllowance_weightMeasurementType\",\n",
        "        \"legs0_segments0_departureFrom_airport_iata\",\n",
        "        \"legs0_segments0_marketingCarrier_code\",\n",
        "        \"legs0_segments0_operatingCarrier_code\",\n",
        "        # initial transformations\n",
        "        \"is_top3_shortest_duration\",\n",
        "        \"miniRules0_statusInfos\",\n",
        "        \"miniRules1_statusInfos\",\n",
        "        \"pricingInfo_isAccessTP\",\n",
        "        \"sex\",\n",
        "        \"is_one_way\",\n",
        "        \"has_corporate_tariff\",\n",
        "        \"corporate_policy_compliant\",\n",
        "        \"corporate_vip_flag\",\n",
        "        \"free_cancel\",\n",
        "        \"free_exchange\",\n",
        "        \"is_popular_route\",\n",
        "        \"fee_ratio_rule0_is_missing\",\n",
        "        \"fee_ratio_rule1_is_missing\",\n",
        "        \"contains_capitials\",\n",
        "        \"is_popular_flight\",\n",
        "        \"is_codeshare_leg0_seg0\",\n",
        "        \"outbound_origin\",\n",
        "        \"outbound_destination\",\n",
        "        \"return_origin\",\n",
        "        \"return_destination\",\n",
        "        \"outbound_route\",\n",
        "        \"return_route\",\n",
        "        \"is_exact_round_trip\",\n",
        "        # segment features\n",
        "        \"is_direct_leg0\",\n",
        "        \"is_direct_leg1\",\n",
        "        \"is_direct_shortest\",\n",
        "        \"both_direct\",\n",
        "        \"is_min_segments_leg0\",\n",
        "        \"is_min_segments_leg1\",\n",
        "        \"is_vip_freq\",\n",
        "        # time features\n",
        "        \"legs0_departureAt_hour\",\n",
        "        \"legs0_departureAt_weekday\",\n",
        "        \"legs0_departureAt_business_time\",\n",
        "        \"legs0_departureAt_time_bin\",\n",
        "        \"legs0_arrivalAt_hour\",\n",
        "        \"legs0_arrivalAt_weekday\",\n",
        "        \"legs0_arrivalAt_business_time\",\n",
        "        \"legs0_arrivalAt_time_bin\",\n",
        "        \"legs1_departureAt_hour\",\n",
        "        \"legs1_departureAt_weekday\",\n",
        "        \"legs1_departureAt_business_time\",\n",
        "        \"legs1_departureAt_time_bin\",\n",
        "        \"legs1_arrivalAt_hour\",\n",
        "        \"legs1_arrivalAt_weekday\",\n",
        "        \"legs1_arrivalAt_business_time\",\n",
        "        \"legs1_arrivalAt_time_bin\",\n",
        "        \"is_short_trip\",\n",
        "        \"stay_duration_bin\",\n",
        "        \"is_booking_today\",\n",
        "        \"is_booking_3days\",\n",
        "        \"is_booking_week\",\n",
        "        \"is_departure_in_past\",\n",
        "        \"is_top3_cheapest\",\n",
        "        \"is_min_segments\",\n",
        "        \"is_direct_cheapest\",\n",
        "        \"legs0_dep_arr_bin_combo\",\n",
        "        \"legs0_is_business_friendly\",\n",
        "        \"legs0_is_red_eye\",\n",
        "        # cabin class features\n",
        "        \"legs0_segments0_cabinClass_is_1\",\n",
        "        \"legs0_segments0_cabinClass_is_2\",\n",
        "        \"legs0_segments0_cabinClass_is_3\",\n",
        "        \"legs0_segments0_cabinClass_is_4\",\n",
        "        \"legs1_segments0_cabinClass_is_1\",\n",
        "        \"legs1_segments0_cabinClass_is_2\",\n",
        "        \"legs1_segments0_cabinClass_is_3\",\n",
        "        \"legs1_segments0_cabinClass_is_4\",\n",
        "        \"has_business_class\",\n",
        "        # \"cabin_class_highest\",\n",
        "        # \"cabin_class_lowest\",\n",
        "        # \"cabin_class_diversity\",\n",
        "        \"all_cabin_level_1\",\n",
        "        # company features\n",
        "        \"is_very_popular_company\",\n",
        "        \"is_popular_company\",\n",
        "        \"is_top_selected_company\",\n",
        "        # flight features\n",
        "        \"legs0_segments0_flightNumber_popularity_bin\",\n",
        "        # carrier features\n",
        "        \"legs0_segments0_marketingCarrier_code_selected_rank_bin\",\n",
        "        \"legs1_segments0_marketingCarrier_code_selected_rank_bin\",\n",
        "        # ff features\n",
        "        \"legs0_segments0_marketingCarrier_code_in_frequentFlyer\",\n",
        "        \"legs0_segments0_marketingCarrier_code_is_only_frequentFlyer\",\n",
        "        \"is_major_carrier_0_0\",\n",
        "        \"is_operate_carrier_0_0\",\n",
        "        # \"legs0_segments0_marketingCarrier_code_ff_and_economic\",\n",
        "        # profile features\n",
        "        \"user_in_train\",\n",
        "        # airport features\n",
        "        \"departure_airport_Country_CodeA2\",\n",
        "        \"arrival_airport_Country_CodeA2\",\n",
        "        \"is_cross_country\",\n",
        "        # price features\n",
        "        \"is_cheaper_than_avg\",\n",
        "        \"is_expensive_outlier\",\n",
        "    ]\n",
        "\n",
        "    # Numerical features\n",
        "    num_features = [\n",
        "        \"legs0_duration\",\n",
        "        \"legs0_segments0_baggageAllowance_quantity\",\n",
        "        \"legs0_segments0_seatsAvailable\",\n",
        "        \"legs0_segments0_duration\",\n",
        "        \"legs0_segments1_duration\",\n",
        "        \"legs1_duration\",\n",
        "        \"legs1_segments0_duration\",\n",
        "        \"legs1_segments1_duration\",\n",
        "        \"taxes\",\n",
        "        \"log_taxes\",\n",
        "        \"totalPrice\",\n",
        "        \"price_per_tax\",\n",
        "        \"tax_rate\",\n",
        "        \"log_price\",\n",
        "        \"total_duration\",\n",
        "        \"duration_ratio\",\n",
        "        \"l0_seg\",\n",
        "        \"n_ff_programs\",\n",
        "        \"fee_ratio_rule0\",\n",
        "        \"fee_ratio_rule1\",\n",
        "        \"n_segments_leg0\",\n",
        "        \"n_segments_leg1\",\n",
        "        \"group_size\",\n",
        "        \"group_size_log\",\n",
        "        \"stay_duration_hours\",\n",
        "        \"stay_duration_hours_log\",\n",
        "        \"hours_to_departure\",\n",
        "        \"days_to_departure\",\n",
        "        # rank features\n",
        "        \"price_quantile_rank\",\n",
        "        \"duration_quantile_rank\",\n",
        "        \"leg0_duration_quantile_rank\",\n",
        "        \"leg1_duration_quantile_rank\",\n",
        "        \"rank_interaction_mul\",\n",
        "        \"rank_interaction_ratio\",\n",
        "        \"rank_interaction_sum\",\n",
        "        \"rank_interaction_sub\",\n",
        "        \"leg_dur_interaction_mul\",\n",
        "        \"leg_dur_interaction_ratio\",\n",
        "        \"leg_dur_interaction_sub\",\n",
        "        # price features\n",
        "        \"price_zscore_from_median\",\n",
        "        \"price_relative_to_min\",\n",
        "        # company features\n",
        "        \"cabin_class_level_sum_3\",\n",
        "        \"company_select_count\",\n",
        "        \"avg_selected_price\",\n",
        "        \"std_selected_price\",\n",
        "        \"selected_direct_ratio\",\n",
        "        \"selected_night_ratio\",\n",
        "        \"log_company_select_count\",\n",
        "        \"z_price_vs_company_selected\",\n",
        "        \"company_avg_pct\",\n",
        "        \"company_avg_dct\",\n",
        "        # \"company_carrier_select_ratio\",\n",
        "        \"legs0_segments0_marketingCarrier_code_selection_rate\",\n",
        "        \"legs0_segments0_marketingCarrier_code_log_total_count\",\n",
        "        \"legs0_segments0_marketingCarrier_code_log_selected_count\",\n",
        "        \"legs1_segments0_marketingCarrier_code_selection_rate\",\n",
        "        \"legs1_segments0_marketingCarrier_code_log_total_count\",\n",
        "        \"legs1_segments0_marketingCarrier_code_log_selected_count\",\n",
        "        \"user_selected_count\",\n",
        "        \"user_avg_cabinClass_leg0_seg0\",\n",
        "        \"user_selected_count_log\",\n",
        "        \"price_rank_diff\",\n",
        "        \"duration_rank_diff\",\n",
        "        # flight features\n",
        "        \"legs0_segments0_marketingCarrier_code_avg_price_rank\",\n",
        "        \"legs0_segments0_marketingCarrier_code_avg_duration_rank\",\n",
        "        \"legs0_segments0_marketingCarrier_code_avg_dep_hour\",\n",
        "        \"legs0_segments0_marketingCarrier_code_night_ratio\",\n",
        "        \"legs0_segments0_marketingCarrier_code_company_diversity\",\n",
        "        \"legs0_segments0_marketingCarrier_code_user_diversity\",\n",
        "        \"legs0_segments0_marketingCarrier_code_selection_rate_right\",\n",
        "        \"legs0_segments0_marketingCarrier_code_log_total_count_right\",\n",
        "        \"legs0_segments0_marketingCarrier_code_cabin1_select_ratio\",\n",
        "        \"legs0_segments0_marketingCarrier_code_cabin2_select_ratio\",\n",
        "        \"legs0_segments0_marketingCarrier_code_cabin3_select_ratio\",\n",
        "        \"legs0_segments0_marketingCarrier_code_cabin4_select_ratio\",\n",
        "        # route hotness\n",
        "        \"outbound_route_hotness\",\n",
        "        \"return_route_hotness\",\n",
        "        # airport features\n",
        "        \"departure_airport_UTC_Offset_Hours\",\n",
        "        \"departure_airport_GeoPointLat\",\n",
        "        \"departure_airport_GeoPointLong\",\n",
        "        \"arrival_airport_UTC_Offset_Hours\",\n",
        "        \"arrival_airport_GeoPointLat\",\n",
        "        \"arrival_airport_GeoPointLong\",\n",
        "        \"timezone_diff\",\n",
        "        \"geo_distance_km\",\n",
        "        # corporateTariffCode features\n",
        "        \"corporateTariffCode_hotness\",\n",
        "        \"corporateTariffCode_price_rank_mean\",\n",
        "        \"corporateTariffCode_duration_rank_mean\",\n",
        "    ]\n",
        "\n",
        "    # Columns to exclude (uninformative or problematic)\n",
        "    exclude_cols = [\n",
        "        \"Id\",\n",
        "        \"ranker_id\",\n",
        "        \"profileId\",\n",
        "        \"selected\",\n",
        "        \"requestDate\",\n",
        "        \"legs0_departureAt\",\n",
        "        \"legs0_arrivalAt\",\n",
        "        \"legs1_departureAt\",\n",
        "        \"legs1_arrivalAt\",\n",
        "        \"miniRules0_percentage\",\n",
        "        \"miniRules1_percentage\",  # >90% missing\n",
        "        \"frequentFlyer\",  # Already processed\n",
        "        \"pricingInfo_passengerCount\",  # Exclude constant columns\n",
        "        # \"pricingInfo_isAccessTP\",\n",
        "        # \"total_fees\",\n",
        "        \"miniRules0_monetaryAmount\",\n",
        "        \"miniRules1_monetaryAmount\",\n",
        "        # company features\n",
        "        \"is_very_popular_company\",\n",
        "        \"is_popular_company\",\n",
        "        \"is_top_selected_company\",\n",
        "        # \"avg_selected_price\",\n",
        "        # \"std_selected_price\",\n",
        "        # \"selected_direct_ratio\",\n",
        "        # \"selected_night_ratio\",\n",
        "        \"company_select_count\",\n",
        "        # \"log_company_select_count\",\n",
        "        # \"z_price_vs_company_selected\",\n",
        "        # price features\n",
        "        \"totalPrice\",\n",
        "        \"group_size\",\n",
        "        \"taxes\",\n",
        "        # \"log_taxes\",\n",
        "        \"price_per_tax\",\n",
        "        # rank features\n",
        "        \"rank_interaction_ratio\",\n",
        "        \"is_min_segments\",\n",
        "        \"l0_seg\",\n",
        "        # analysis of validation set\n",
        "        \"is_top3_shortest_duration\",\n",
        "        # \"is_direct_shortest\",\n",
        "        # \"rank_interaction_mul\",\n",
        "        # \"rank_interaction_sum\",\n",
        "        # \"rank_interaction_sub\",\n",
        "        # profile features\n",
        "        \"price_rank_diff\",\n",
        "        \"duration_rank_diff\",\n",
        "        \"user_avg_cabinClass_leg0_seg0\",\n",
        "        \"user_in_train\",\n",
        "        \"user_selected_count\",\n",
        "        # timer features\n",
        "        # \"legs0_departureAt_business_time\",\n",
        "        # \"legs0_arrivalAt_business_time\",\n",
        "        # \"legs1_departureAt_business_time\",\n",
        "        # \"legs1_arrivalAt_business_time\",\n",
        "        \"stay_duration_hours\",\n",
        "        # max bin (for lightgbm)\n",
        "        \"companyID\",\n",
        "        # \"legs0_segments0_arrivalTo_airport_city_iata\",\n",
        "        # \"legs0_segments0_arrivalTo_airport_iata\",\n",
        "        # \"legs0_segments0_departureFrom_airport_iata\",\n",
        "        \"outbound_route\",\n",
        "        \"return_route\",\n",
        "        # carrier code\n",
        "        \"legs0_segments0_marketingCarrier_code_selected_rank_bin\",\n",
        "        \"legs1_segments0_marketingCarrier_code_selected_rank_bin\",\n",
        "        # \"legs0_segments0_marketingCarrier_code_log_selected_count\",\n",
        "        # \"legs1_segments0_marketingCarrier_code_log_selected_count\",\n",
        "        # \"legs0_segments0_marketingCarrier_code_log_total_count\",\n",
        "        # \"legs1_segments0_marketingCarrier_code_log_total_count\",\n",
        "        # duplicate cols\n",
        "        \"legs0_segments0_marketingCarrier_code_selection_rate_right\",\n",
        "        \"legs0_segments0_marketingCarrier_code_log_selected_count_right\",\n",
        "        \"legs0_segments0_marketingCarrier_code_log_total_count_right\",\n",
        "        \"legs0_segments0_marketingCarrier_code_avg_dep_hour\",\n",
        "        # 20250715\n",
        "        # \"duration_ratio\",\n",
        "        # \"legs0_segments0_marketingCarrier_code_selection_rate\",\n",
        "        # \"legs1_segments0_marketingCarrier_code_selection_rate\",\n",
        "        # \"price_from_median\",\n",
        "        # \"selected_night_ratio\",\n",
        "        # \"total_duration\",\n",
        "        \"cabin_class_level_sum_3\",\n",
        "        # \"legs0_is_business_friendly\",\n",
        "        \"days_to_departure\",\n",
        "        \"legs0_segments0_marketingCarrier_code_ff_and_economic\",\n",
        "        # 20250716\n",
        "        # \"leg_dur_interaction_mul\",\n",
        "        # \"leg_dur_interaction_ratio\",\n",
        "        \"legs0_arrivalAt_time_bin\",\n",
        "        \"legs0_departureAt_time_bin\",\n",
        "        \"legs1_arrivalAt_time_bin\",\n",
        "        \"legs1_departureAt_time_bin\",\n",
        "        \"legs0_dep_arr_bin_combo\",\n",
        "        \"legs1_dep_arr_bin_combo\",\n",
        "        \"stay_duration_bin\",\n",
        "        \"departure_airport_GeoPointLat\",\n",
        "        \"departure_airport_GeoPointLong\",\n",
        "        \"arrival_airport_GeoPointLat\",\n",
        "        \"arrival_airport_GeoPointLong\",\n",
        "        \"legs0_segments1_duration\",\n",
        "        \"legs1_segments1_duration\",\n",
        "        # 0.53344\n",
        "        \"legs0_segments0_marketingCarrier_code_selection_rate\",\n",
        "        \"legs1_segments0_marketingCarrier_code_selection_rate\",\n",
        "        # \"rank_interaction_sum\",\n",
        "        # \"corporateTariffCode_hotness\",\n",
        "        \"corporateTariffCode_price_rank_mean\",\n",
        "        \"corporateTariffCode_duration_rank_mean\",\n",
        "        \"geo_distance_km\",\n",
        "        \"is_popular_flight\",\n",
        "        # 0.53817\n",
        "    ]\n",
        "\n",
        "    # Exclude columns with large missing ratio\n",
        "    for leg in [0, 1]:\n",
        "        for seg in [0, 1]:\n",
        "            if leg == 0 and seg == 0:\n",
        "                suffixes = [\"cabinClass\", \"flightNumber\"]\n",
        "            else:\n",
        "                suffixes = [\n",
        "                    # Missing\n",
        "                    \"cabinClass\",\n",
        "                    \"seatsAvailable\",\n",
        "                    \"baggageAllowance_quantity\",\n",
        "                    \"baggageAllowance_weightMeasurementType\",\n",
        "                    \"aircraft_code\",\n",
        "                    \"arrivalTo_airport_city_iata\",\n",
        "                    \"arrivalTo_airport_iata\",\n",
        "                    \"departureFrom_airport_iata\",\n",
        "                    \"flightNumber\",\n",
        "                    \"marketingCarrier_code\",\n",
        "                    \"operatingCarrier_code\",\n",
        "                ]\n",
        "            for suffix in suffixes:\n",
        "                exclude_cols.append(f\"legs{leg}_segments{seg}_{suffix}\")\n",
        "\n",
        "    # Exclude segment 2-3 columns (>98% missing)\n",
        "    for leg in [0, 1]:\n",
        "        for seg in [2, 3]:\n",
        "            for suffix in [\n",
        "                \"aircraft_code\",\n",
        "                \"arrivalTo_airport_city_iata\",\n",
        "                \"arrivalTo_airport_iata\",\n",
        "                \"baggageAllowance_quantity\",\n",
        "                \"baggageAllowance_weightMeasurementType\",\n",
        "                \"cabinClass\",\n",
        "                \"departureFrom_airport_iata\",\n",
        "                \"duration\",\n",
        "                \"flightNumber\",\n",
        "                \"marketingCarrier_code\",\n",
        "                \"operatingCarrier_code\",\n",
        "                \"seatsAvailable\",\n",
        "            ]:\n",
        "                exclude_cols.append(f\"legs{leg}_segments{seg}_{suffix}\")\n",
        "\n",
        "    available_cols = set(data.columns)\n",
        "    all_features = [f for f in cat_features + num_features if f in available_cols]\n",
        "    if trial:\n",
        "        all_features = [\n",
        "            f for f in all_features if trial.suggest_categorical(f, [True, False])\n",
        "        ]\n",
        "\n",
        "    feature_cols = [col for col in all_features if col not in exclude_cols]\n",
        "    cat_features_final = [col for col in cat_features if col in feature_cols]\n",
        "    num_features_final = [col for col in num_features if col in feature_cols]\n",
        "\n",
        "    diff = set(feature_cols) - set(cat_features_final) - set(num_features_final)\n",
        "    print(\n",
        "        \"Features in feature_cols but not in cat_features_final or num_features_final:\",\n",
        "        diff,\n",
        "    )\n",
        "\n",
        "    assert len(cat_features_final) + len(num_features_final) == len(\n",
        "        feature_cols\n",
        "    ), f\"Using {len(feature_cols)} features ({len(cat_features_final)} categorical, {len(num_features_final)} numerical)\"\n",
        "\n",
        "    print(\n",
        "        f\"Using {len(feature_cols)} features ({len(cat_features_final)} categorical, {len(num_features_final)} numerical)\"\n",
        "    )\n",
        "\n",
        "    X = data.select(feature_cols)\n",
        "    y = data.select(\"selected\")\n",
        "    groups = data.select(\"ranker_id\")\n",
        "\n",
        "    return X, y, groups, cat_features_final, num_features_final"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 400
        },
        "id": "CdFmI4T-EvmV",
        "outputId": "5bab2e3f-b111-4629-9b67-3fd52dc2a513"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "attempted relative import with no known parent package",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-6-144314296.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpolars\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpolars\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatatypes\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mStruct\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtimer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: attempted relative import with no known parent package",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Trial**"
      ],
      "metadata": {
        "id": "G3CzHTL83-yN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile train_pipeline.py\n",
        "import os, time, pytz, datetime\n",
        "import optuna\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import polars as pl\n",
        "import xgboost as xgb\n",
        "import lightgbm as lgb\n",
        "from src.utils import fill_missing, evaluate_hitrate_at_3, make_submission\n",
        "from src.feature import feature_engineering, feature_selection\n",
        "from src.plot import plot_hitrate_at_k, plot_ndcg_curve\n",
        "from src.data import split_dataset\n",
        "from src.params import get_hyper_params\n",
        "\n",
        "FULL = True\n",
        "MODEL = \"xgboost\"\n",
        "DEBUG = False\n",
        "DATA_DIR = \"./data\"\n",
        "RANDOM_STATE = 42\n",
        "tz = pytz.timezone(\"Europe/Bucharest\")\n",
        "TIME_TAG = datetime.datetime.now(tz).strftime(\"%Y%m%d%H%M%S\")\n",
        "print(\"Time Tag:\", TIME_TAG)\n",
        "\n",
        "MODEL_DIR = \"model\"\n",
        "SUBMIT_DIR = \"submission\"\n",
        "os.makedirs(MODEL_DIR, exist_ok=True)\n",
        "os.makedirs(SUBMIT_DIR, exist_ok=True)\n",
        "\n",
        "if not DEBUG:\n",
        "    train_full = pl.read_parquet(f\"{DATA_DIR}/train.parquet\").drop(\"__index_level_0__\")\n",
        "\n",
        "    sampled_ids = train_full[\"ranker_id\"].unique().sample(fraction=0.5, seed=42)\n",
        "\n",
        "    train = train_full.filter(pl.col(\"ranker_id\").is_in(sampled_ids))\n",
        "\n",
        "    test = pl.read_parquet(f\"{DATA_DIR}/test.parquet\").drop(\"__index_level_0__\").with_columns(\n",
        "        pl.lit(0, dtype=pl.Int64).alias(\"selected\")\n",
        "    )\n",
        "\n",
        "    df = pl.concat((train, test))\n",
        "else:\n",
        "    train_full = pl.read_parquet(f\"{DATA_DIR}/train.parquet\").drop(\"__index_level_0__\")\n",
        "    sampled_ids = train_full[\"ranker_id\"].unique().sample(fraction=0.9, seed=42)\n",
        "    df = train_full.filter(pl.col(\"ranker_id\").is_in(sampled_ids))\n",
        "    train = df\n",
        "print(\"‚úÖ Successfully loaded parquet files!\")\n",
        "\n",
        "df = feature_engineering(df)\n",
        "print(\"‚úÖ Feature engineering finished!\")\n",
        "\n",
        "schema = df.schema\n",
        "dtype_df = pl.DataFrame({\"column\": list(schema.keys()), \"dtype\": [str(v) for v in schema.values()]})\n",
        "na_infos = (\n",
        "    df.select([pl.col(col).is_null().sum().alias(col) for col in df.columns])\n",
        "    .melt(variable_name=\"column\", value_name=\"null_count\")\n",
        "    .filter(pl.col(\"null_count\") > 0)\n",
        "    .join(dtype_df, on=\"column\", how=\"left\")\n",
        "    .sort(\"null_count\", descending=True)\n",
        ")\n",
        "print(na_infos)\n",
        "\n",
        "df = df.with_columns(\n",
        "    [pl.col(c).fill_null(0) for c in df.select(pl.selectors.numeric()).columns] +\n",
        "    [pl.col(c).fill_null(\"missing\") for c in df.select(pl.selectors.string()).columns]\n",
        ")\n",
        "\n",
        "X, y, groups, cat_features_final = feature_selection(df)\n",
        "print(X.columns)\n",
        "\n",
        "dtrain, dval, dtest, dfull, y_va, groups_va = split_dataset(train, X, y, groups, cat_features_final, MODEL)\n",
        "best_params = get_hyper_params(MODEL)\n",
        "\n",
        "print(f\"üöÄ Training final {MODEL} model...\")\n",
        "if MODEL == \"xgboost\":\n",
        "    evals_result = {}\n",
        "    model = xgb.train(\n",
        "        best_params,\n",
        "        dfull if FULL else dtrain,\n",
        "        num_boost_round=2000,\n",
        "        evals=[(dfull, \"train\")] if FULL else [(dtrain, \"train\"), (dval, \"val\")],\n",
        "        verbose_eval=50,\n",
        "        maximize=True,\n",
        "        evals_result=evals_result,\n",
        "    )\n",
        "elif MODEL == \"lightgbm\":\n",
        "    model = lgb.train(\n",
        "        best_params,\n",
        "        dfull if FULL else dtrain,\n",
        "        num_boost_round=750,\n",
        "        valid_sets=[dfull] if FULL else [dtrain, dval],\n",
        "        callbacks=[lgb.log_evaluation(10), lgb.callback.record_evaluation({})],\n",
        "    )\n",
        "\n",
        "if FULL:\n",
        "    model_path = os.path.join(MODEL_DIR, f\"{MODEL}_{TIME_TAG}.json\")\n",
        "    model.save_model(model_path)\n",
        "    print(f\"‚úÖ Model saved to: {model_path}\")\n",
        "\n",
        "if not FULL:\n",
        "    va_preds = evaluate_hitrate_at_3(dval, y_va, groups_va, model)\n",
        "\n",
        "    importance_df = (\n",
        "        pl.DataFrame(\n",
        "            [{\"feature\": k, \"importance\": v} for k, v in model.get_score(importance_type=\"gain\").items()]\n",
        "        ).sort(\"importance\", descending=True)\n",
        "    )\n",
        "    print(importance_df.to_pandas().to_string())\n",
        "\n",
        "    curves = plot_hitrate_at_k(groups_va, va_preds, y_va)\n",
        "    print(f\"\\nüìå HitRate@1: {curves['All groups (>10)'][0]:.3f}\")\n",
        "    print(f\"üìå HitRate@3: {curves['All groups (>10)'][2]:.3f}\")\n",
        "    print(f\"üìå HitRate@5: {curves['All groups (>10)'][4]:.3f}\")\n",
        "    print(f\"üìå HitRate@10: {curves['All groups (>10)'][9]:.3f}\")\n",
        "\n",
        "if FULL:\n",
        "    submission_path = os.path.join(SUBMIT_DIR, f\"submission_{TIME_TAG}.csv\")\n",
        "    make_submission(test, dtest, model, submission_path)\n",
        "    print(f\"‚úÖ Submission file saved to: {submission_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ejTJh0oz4Dru",
        "outputId": "5816bf89-baea-4487-862a-7702a118e488"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting train_pipeline.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**DLRanker v1**"
      ],
      "metadata": {
        "id": "nPEKFnjqSlYU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile deeprec_validate.py\n",
        "import os\n",
        "import time\n",
        "import random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import defaultdict\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "import polars as pl\n",
        "from tqdm import tqdm\n",
        "from src.feature import feature_engineering, feature_selection\n",
        "from transformers import get_scheduler\n",
        "from collections import Counter\n",
        "\n",
        "class RankDataset(Dataset):\n",
        "    def __init__(\n",
        "        self,\n",
        "        X: pl.DataFrame,\n",
        "        y: pl.Series,\n",
        "        groups: pl.DataFrame,\n",
        "        cat_features: list[str],\n",
        "        num_features: list[str],\n",
        "    ):\n",
        "        self.cat_features = cat_features\n",
        "        self.num_features = num_features\n",
        "        self.X_cat = {c: X[c].to_numpy() for c in cat_features}\n",
        "        self.X_num = X[self.num_features].to_numpy()\n",
        "        self.y = y.to_numpy()\n",
        "        self.groups = groups[\"ranker_id\"].to_numpy()\n",
        "\n",
        "        self.group_to_indices = defaultdict(list)\n",
        "        for i, g in enumerate(self.groups):\n",
        "            self.group_to_indices[g].append(i)\n",
        "        self.group_keys = list(self.group_to_indices.keys())\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.group_keys)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        g = self.group_keys[idx]\n",
        "        inds = self.group_to_indices[g]\n",
        "        length = len(inds)\n",
        "\n",
        "        x_cat = {\n",
        "            c: torch.LongTensor([\n",
        "                self.X_cat[c][i] if self.X_cat[c][i] >= 0 else 0 for i in inds\n",
        "            ])\n",
        "            for c in self.cat_features\n",
        "        }\n",
        "\n",
        "        x_num = torch.FloatTensor(self.X_num[inds])\n",
        "        y = torch.FloatTensor(self.y[inds]).reshape(-1)\n",
        "\n",
        "        return x_cat, x_num, y, length\n",
        "\n",
        "def collate_fn(batch):\n",
        "    batch_size = len(batch)\n",
        "    lengths = [b[3] for b in batch]\n",
        "    max_len = max(lengths)\n",
        "\n",
        "    padded_x_cat = {key: [] for key in batch[0][0].keys()}\n",
        "    padded_x_num = []\n",
        "    padded_y = []\n",
        "\n",
        "    num_dim = batch[0][1].shape[1]\n",
        "\n",
        "    for x_cat, x_num, y, length in batch:\n",
        "        pad_len = max_len - length\n",
        "\n",
        "        for key in padded_x_cat:\n",
        "            val = x_cat[key]\n",
        "            if pad_len > 0:\n",
        "                val = torch.cat([val, torch.zeros(pad_len, dtype=torch.long)])\n",
        "            padded_x_cat[key].append(val)\n",
        "\n",
        "        if pad_len > 0:\n",
        "            x_num = torch.cat([x_num, torch.zeros(pad_len, num_dim)])\n",
        "            y = torch.cat([y, torch.zeros(pad_len)])\n",
        "\n",
        "        padded_x_num.append(x_num)\n",
        "        padded_y.append(y)\n",
        "\n",
        "    padded_x_cat = {k: torch.stack(v) for k, v in padded_x_cat.items()}\n",
        "    padded_x_num = torch.stack(padded_x_num)\n",
        "    padded_y = torch.stack(padded_y)\n",
        "    lengths = torch.tensor(lengths, dtype=torch.long)\n",
        "\n",
        "    return padded_x_cat, padded_x_num, padded_y, lengths\n",
        "\n",
        "class DLRanker(nn.Module):\n",
        "    def __init__(self, cat_dims, num_numeric_feats, emb_dim=64, hidden=[512, 256, 128, 64]):\n",
        "        super().__init__()\n",
        "\n",
        "        self.embeddings = nn.ModuleDict({\n",
        "            f: nn.Embedding(cat_dims[f], emb_dim, padding_idx=0) for f in cat_dims\n",
        "        })\n",
        "        self.linear_cat = nn.ModuleDict({\n",
        "            f: nn.Embedding(cat_dims[f], 1, padding_idx=0) for f in cat_dims\n",
        "        })\n",
        "\n",
        "        for emb in list(self.embeddings.values()) + list(self.linear_cat.values()):\n",
        "            nn.init.xavier_uniform_(emb.weight)\n",
        "\n",
        "        self.linear_num = nn.Linear(num_numeric_feats, 1)\n",
        "        nn.init.xavier_uniform_(self.linear_num.weight)\n",
        "\n",
        "        input_dim = emb_dim * len(cat_dims) + num_numeric_feats\n",
        "        layers = []\n",
        "        for h in hidden:\n",
        "            layers.append(nn.Linear(input_dim, h))\n",
        "            layers.append(nn.BatchNorm1d(h))\n",
        "            layers.append(nn.ReLU())\n",
        "            layers.append(nn.Dropout(0.1))\n",
        "            input_dim = h\n",
        "        self.mlp = nn.Sequential(*layers)\n",
        "        self.output = nn.Linear(input_dim, 1)\n",
        "\n",
        "    def forward(self, x_cat, x_num):\n",
        "        batch_size, group_size = x_num.shape[:2]\n",
        "\n",
        "        linear_cat_sum = torch.stack([\n",
        "            self.linear_cat[f](x_cat[f]).squeeze(-1)\n",
        "            for f in self.linear_cat\n",
        "        ], dim=0).sum(dim=0)\n",
        "\n",
        "        linear_num_out = self.linear_num(x_num).squeeze(-1)\n",
        "        linear_out = linear_cat_sum + linear_num_out\n",
        "\n",
        "        embs = torch.stack([\n",
        "            self.embeddings[f](x_cat[f]) for f in self.embeddings\n",
        "        ], dim=2)\n",
        "\n",
        "        sum_emb = embs.sum(dim=2)\n",
        "        sum_emb_square = sum_emb ** 2\n",
        "        square_emb_sum = (embs ** 2).sum(dim=2)\n",
        "        fm_out = 0.0\n",
        "        # fm_out = 0.5 * (sum_emb_square - square_emb_sum).sum(dim=2)\n",
        "\n",
        "        embs_cat = embs.reshape(batch_size * group_size, -1)\n",
        "        x_num_flat = x_num.reshape(batch_size * group_size, -1)\n",
        "        deep_input = torch.cat([embs_cat, x_num_flat], dim=1)\n",
        "        deep_out = self.mlp(deep_input)\n",
        "        deep_out = self.output(deep_out).view(batch_size, group_size)\n",
        "\n",
        "        return linear_out + fm_out + deep_out\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "def listmle_loss(scores, labels, lengths):\n",
        "    batch_size = scores.size(0)\n",
        "    total_loss = torch.tensor(0.0, device=scores.device, requires_grad=True)\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "\n",
        "        _, idx = torch.sort(y, descending=True)\n",
        "        s_sorted = s[idx]\n",
        "\n",
        "        parts = (\n",
        "            torch.logsumexp(s_sorted.unsqueeze(0).expand(l, -1).triu(diagonal=0), dim=1)\n",
        "            - s_sorted\n",
        "        )\n",
        "\n",
        "        total_loss = total_loss + parts.sum()\n",
        "\n",
        "    return total_loss / batch_size\n",
        "\"\"\"\n",
        "\n",
        "def hitrate_at_k(scores, labels, lengths, k=3, min_group_size=10):\n",
        "    batch_size = scores.size(0)\n",
        "    hits = 0\n",
        "    valid_count = 0\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        if l < min_group_size:\n",
        "            continue\n",
        "        length = min(l, k)\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "        _, topk_idx = torch.topk(s, length)\n",
        "        topk_labels = y[topk_idx]\n",
        "        hits += (topk_labels > 0).any().float()\n",
        "        valid_count += 1\n",
        "    return hits / valid_count if valid_count > 0 else torch.tensor(0.0, device=scores.device)\n",
        "\n",
        "\n",
        "def ndcg_at_k(scores, labels, lengths, k=3, min_group_size=10):\n",
        "    batch_size = scores.size(0)\n",
        "    total_ndcg = 0.0\n",
        "    valid_count = 0\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        if l < min_group_size:\n",
        "            continue\n",
        "\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "\n",
        "        _, idx_pred = torch.topk(s, min(k, l))\n",
        "        _, idx_ideal = torch.topk(y, min(k, l))\n",
        "\n",
        "        dcg = (y[idx_pred] / torch.log2(torch.arange(2, 2 + len(idx_pred), device=y.device).float())).sum()\n",
        "        idcg = (y[idx_ideal] / torch.log2(torch.arange(2, 2 + len(idx_ideal), device=y.device).float())).sum()\n",
        "\n",
        "        ndcg = dcg / idcg if idcg > 0 else 0.0\n",
        "        total_ndcg += ndcg\n",
        "        valid_count += 1\n",
        "\n",
        "    return total_ndcg / valid_count if valid_count > 0 else torch.tensor(0.0, device=scores.device)\n",
        "\n",
        "\n",
        "def map_at_k(scores, labels, lengths, k=3, min_group_size=10):\n",
        "    batch_size = scores.size(0)\n",
        "    total_ap = 0.0\n",
        "    valid_count = 0\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        if l < min_group_size:\n",
        "            continue\n",
        "\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "\n",
        "        _, idx_pred = torch.topk(s, min(k, l))\n",
        "        y_true = y[idx_pred] > 0\n",
        "\n",
        "        if y_true.sum() == 0:\n",
        "            continue\n",
        "\n",
        "        precisions = [(y_true[:j+1].float().sum() / (j+1)) for j in range(len(y_true)) if y_true[j]]\n",
        "        ap = torch.stack(precisions).mean()\n",
        "        total_ap += ap\n",
        "        valid_count += 1\n",
        "\n",
        "    return total_ap / valid_count if valid_count > 0 else torch.tensor(0.0, device=scores.device)\n",
        "\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "def listnet_loss(scores, labels, lengths):\n",
        "    batch_size = scores.size(0)\n",
        "    total_loss = 0.0\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "\n",
        "        s_softmax = torch.nn.functional.log_softmax(s, dim=0)\n",
        "        y_softmax = torch.nn.functional.softmax(y, dim=0)\n",
        "\n",
        "        loss = -torch.sum(y_softmax * s_softmax)\n",
        "        total_loss += loss\n",
        "\n",
        "    return total_loss / batch_size\n",
        "\"\"\"\n",
        "\n",
        "def ranknet_loss(scores, labels, lengths):\n",
        "    batch_size = scores.size(0)\n",
        "    total_loss = 0.0\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "\n",
        "        diff_scores = s.unsqueeze(1) - s.unsqueeze(0)\n",
        "        rel = y.unsqueeze(1) > y.unsqueeze(0)\n",
        "        label_diff = rel.float()\n",
        "\n",
        "        log_sigmoid = torch.nn.functional.logsigmoid(diff_scores)\n",
        "        pair_loss = -label_diff * log_sigmoid\n",
        "\n",
        "        total_loss += pair_loss.sum()\n",
        "\n",
        "    return total_loss / batch_size\n",
        "\n",
        "def xranknet_loss(scores, labels, lengths, temperature=1.0, margin=0.2, focus_topk=3):\n",
        "    \"\"\"\n",
        "    xRankNet with emphasis on top-K items (based on labels, not scores).\n",
        "    \"\"\"\n",
        "    batch_size = scores.size(0)\n",
        "    total_loss = 0.0\n",
        "    total_pairs = 0\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        if l < 2:\n",
        "            continue\n",
        "\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "\n",
        "        # Top-K mask based on ground truth labels\n",
        "        topk = min(focus_topk, l)\n",
        "        _, topk_idx = torch.topk(y, topk)\n",
        "        topk_mask = torch.zeros_like(y, dtype=torch.bool)\n",
        "        topk_mask[topk_idx] = True\n",
        "\n",
        "        # Create pairwise difference matrices\n",
        "        score_diff = s.unsqueeze(1) - s.unsqueeze(0)\n",
        "        label_diff = y.unsqueeze(1) - y.unsqueeze(0)\n",
        "\n",
        "        # valid pair: y_i > y_j and at least one of i, j is in top-K\n",
        "        valid_pairs = (label_diff > 0) & (\n",
        "            topk_mask.unsqueeze(1) | topk_mask.unsqueeze(0)\n",
        "        )\n",
        "\n",
        "        if valid_pairs.sum() == 0:\n",
        "            continue\n",
        "\n",
        "        importance = (label_diff.abs() * valid_pairs).float()\n",
        "\n",
        "        if margin > 0.0:\n",
        "            score_diff = score_diff - margin\n",
        "\n",
        "        score_diff = score_diff / temperature\n",
        "        pairwise_loss = -F.logsigmoid(score_diff) * importance\n",
        "\n",
        "        total_loss += pairwise_loss.sum()\n",
        "        total_pairs += importance.sum()\n",
        "\n",
        "    if total_pairs == 0:\n",
        "        return torch.tensor(0.0, device=scores.device, requires_grad=True)\n",
        "\n",
        "    return total_loss / total_pairs\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "def bpr_loss(scores, labels, lengths):\n",
        "    batch_size = scores.size(0)\n",
        "    total_loss = 0.0\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "\n",
        "        pos_mask = y > 0\n",
        "        neg_mask = y <= 0\n",
        "\n",
        "        pos_scores = s[pos_mask]\n",
        "        neg_scores = s[neg_mask]\n",
        "\n",
        "        if len(pos_scores) == 0 or len(neg_scores) == 0:\n",
        "            continue\n",
        "\n",
        "        pair_diff = pos_scores.unsqueeze(1) - neg_scores.unsqueeze(0)\n",
        "        loss = -F.logsigmoid(pair_diff).mean()\n",
        "        total_loss += loss\n",
        "\n",
        "    return total_loss / batch_size\n",
        "\"\"\"\n",
        "\n",
        "\"\"\"\n",
        "def lambdarank_loss(scores, labels, lengths, eps=1e-10):\n",
        "    batch_size = scores.size(0)\n",
        "    total_loss = 0.0\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "\n",
        "        if l < 2:\n",
        "            continue\n",
        "\n",
        "        _, rank_order = torch.sort(s, descending=True)\n",
        "        ideal_order = torch.sort(y, descending=True).indices\n",
        "\n",
        "        gain = 2 ** y - 1\n",
        "        discount = torch.log2(torch.arange(2, l + 2, device=y.device).float())\n",
        "\n",
        "        ideal_dcg = (gain[ideal_order] / discount).sum()\n",
        "        if ideal_dcg < eps:\n",
        "            continue\n",
        "\n",
        "        delta_ndcg = torch.zeros((l, l), device=y.device)\n",
        "\n",
        "        for i_idx in range(l):\n",
        "            for j_idx in range(l):\n",
        "                if y[i_idx] > y[j_idx]:\n",
        "                    change = (\n",
        "                        (1.0 / torch.log2(rank_order[i_idx] + 2.0))\n",
        "                        - (1.0 / torch.log2(rank_order[j_idx] + 2.0))\n",
        "                    ).abs()\n",
        "                    delta = (2 ** y[i_idx] - 2 ** y[j_idx]).abs() * change\n",
        "                    delta_ndcg[i_idx, j_idx] = delta / ideal_dcg\n",
        "\n",
        "        score_diffs = s.unsqueeze(1) - s.unsqueeze(0)\n",
        "        lambdas = -F.logsigmoid(score_diffs) * delta_ndcg\n",
        "        total_loss += lambdas.sum()\n",
        "\n",
        "    return total_loss / batch_size\n",
        "\"\"\"\n",
        "\n",
        "def train_one_epoch(model, loader, optimizer, device, scheduler):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "\n",
        "    for x_cat, x_num, y, lengths in tqdm(loader, desc=\"Training\", leave=False):\n",
        "        x_num, y = x_num.to(device), y.to(device)\n",
        "        if not isinstance(lengths, torch.Tensor):\n",
        "            lengths = torch.tensor(lengths)\n",
        "        lengths = lengths.detach().clone().to(device)\n",
        "        x_cat = {k: v.to(device) for k, v in x_cat.items()}\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        scores = model(x_cat, x_num)\n",
        "        loss = xranknet_loss(scores, y, lengths, temperature=1.0, margin=0.2, focus_topk=3)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    return total_loss / len(loader)\n",
        "\n",
        "\n",
        "def validate(model, loader, device, min_group_size=10):\n",
        "    model.eval()\n",
        "    total_hitrate = 0\n",
        "    total_ndcg = 0\n",
        "    total_map = 0\n",
        "    total_loss = 0\n",
        "    count = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for x_cat, x_num, y, lengths in tqdm(loader, desc=\"Validating\", leave=False):\n",
        "            x_num, y = x_num.to(device), y.to(device)\n",
        "            lengths = torch.tensor(lengths).to(device)\n",
        "            x_cat = {k: v.to(device) for k, v in x_cat.items()}\n",
        "\n",
        "            scores = model(x_cat, x_num)\n",
        "\n",
        "            hitrate = hitrate_at_k(scores, y, lengths, k=3, min_group_size=min_group_size)\n",
        "            ndcg = ndcg_at_k(scores, y, lengths, k=3, min_group_size=min_group_size)\n",
        "            map3 = map_at_k(scores, y, lengths, k=3, min_group_size=min_group_size)\n",
        "            loss = xranknet_loss(scores, y, lengths, temperature=1.0, margin=0.2, focus_topk=3)\n",
        "\n",
        "            batch_size = scores.size(0)\n",
        "            total_hitrate += hitrate * batch_size\n",
        "            total_ndcg += ndcg * batch_size\n",
        "            total_map += map3 * batch_size\n",
        "            total_loss += loss.item() * batch_size\n",
        "            count += batch_size\n",
        "\n",
        "    return total_loss / count, total_hitrate / count, total_ndcg / count, total_map / count\n",
        "\n",
        "\n",
        "def build_cat_dims(X, cat_features):\n",
        "    cat_dims = {}\n",
        "    for c in cat_features:\n",
        "        max_val = X[c].max()\n",
        "        if max_val < 0:\n",
        "            max_val = 0\n",
        "        cat_dims[c] = max_val + 1\n",
        "    return cat_dims\n",
        "\n",
        "\n",
        "def normalize_numeric_features(X, numeric_features, train_mask):\n",
        "    for col in numeric_features:\n",
        "        values = X[col].to_numpy()\n",
        "        train_vals = values[train_mask]\n",
        "        mean = train_vals.mean()\n",
        "        std = train_vals.std() if train_vals.std() > 0 else 1.0\n",
        "        norm_vals = (values - mean) / std\n",
        "        X = X.with_columns(pl.Series(col, norm_vals).alias(col))\n",
        "    return X\n",
        "\n",
        "\n",
        "def load_or_prepare_data(\n",
        "    data_dir,\n",
        "    train_file=\"train.parquet\",\n",
        "    test_file=\"test.parquet\",\n",
        "    cache_file=\"feature_engineered_val.parquet\",\n",
        "):\n",
        "    cache_path = os.path.join(data_dir, cache_file)\n",
        "\n",
        "    if os.path.exists(cache_path):\n",
        "        print(f\"Loading cached feature-engineered data from {cache_path} ...\")\n",
        "        df = pl.read_parquet(cache_path)\n",
        "\n",
        "        test = pl.read_parquet(os.path.join(data_dir, test_file)).drop(\"__index_level_0__\")\n",
        "        test_ids = test[\"Id\"]\n",
        "        test_rankers = test[\"ranker_id\"]\n",
        "    else:\n",
        "        print(\"Cached file not found, processing raw data ...\")\n",
        "\n",
        "        train = pl.read_parquet(os.path.join(data_dir, train_file)).drop(\"__index_level_0__\")\n",
        "        test = (\n",
        "            pl.read_parquet(os.path.join(data_dir, test_file))\n",
        "            .drop(\"__index_level_0__\")\n",
        "            .with_columns(pl.lit(0, dtype=pl.Int64).alias(\"selected\"))\n",
        "        )\n",
        "\n",
        "        test_ids = test[\"Id\"]\n",
        "        test_rankers = test[\"ranker_id\"]\n",
        "\n",
        "        df = pl.concat((train, test))\n",
        "        df = feature_engineering(df, full=True)\n",
        "\n",
        "        df = df.with_columns(\n",
        "            [pl.col(c).fill_null(0) for c in df.select(pl.selectors.numeric()).columns] +\n",
        "            [pl.col(c).fill_null(\"missing\") for c in df.select(pl.selectors.string()).columns]\n",
        "        )\n",
        "\n",
        "        os.makedirs(data_dir, exist_ok=True)\n",
        "        df.write_parquet(cache_path)\n",
        "        print(f\"Saved feature-engineered data to {cache_path}\")\n",
        "\n",
        "    return df, test_ids, test_rankers\n",
        "\n",
        "\n",
        "def prepare_data(data_dir):\n",
        "    df, test_ids, test_rankers = load_or_prepare_data(data_dir)\n",
        "\n",
        "    id_column = df[\"Id\"]\n",
        "    X, y, groups, cat_features, num_features = feature_selection(df)\n",
        "\n",
        "    X = X.with_columns(pl.Series(\"Id\", id_column[:X.shape[0]]))\n",
        "\n",
        "    X = X.with_columns(\n",
        "        [\n",
        "            (pl.col(c).rank(\"dense\") - 1).fill_null(-1).cast(pl.Int32)\n",
        "            for c in cat_features\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    train_size = 18145372\n",
        "    train_mask = np.arange(X.height) < train_size\n",
        "    X = normalize_numeric_features(X, num_features, train_mask)\n",
        "\n",
        "    return X, y, groups, cat_features, num_features, train_size, test_ids, test_rankers\n",
        "\n",
        "\n",
        "class EarlyStopping:\n",
        "    def __init__(self, patience=3, min_delta=0.00005):\n",
        "        self.patience = patience\n",
        "        self.min_delta = min_delta\n",
        "        self.best = float(\"-inf\")\n",
        "        self.counter = 0\n",
        "\n",
        "    def step(self, metric):\n",
        "        if metric > self.best + self.min_delta:\n",
        "            self.best = metric\n",
        "            self.counter = 0\n",
        "        else:\n",
        "            self.counter += 1\n",
        "        return self.counter >= self.patience\n",
        "\n",
        "\n",
        "def plot_group_size_distribution(dataset, save_path=None):\n",
        "    group_sizes = [len(v) for v in dataset.group_to_indices.values()]\n",
        "    plt.figure()\n",
        "    plt.hist(group_sizes, bins=100, log=True)\n",
        "    plt.xlabel(\"Group size (number of items per ranker_id)\")\n",
        "    plt.ylabel(\"Frequency (log scale)\")\n",
        "    plt.title(\"Distribution of Group Sizes\")\n",
        "    plt.grid(True)\n",
        "    if save_path:\n",
        "        plt.savefig(save_path)\n",
        "    else:\n",
        "        plt.show()\n",
        "    plt.close()\n",
        "\n",
        "\n",
        "def main():\n",
        "    DATA_DIR = \"./data\"\n",
        "    MODEL_DIR = \"model\"\n",
        "    SUBMIT_DIR = \"submission\"\n",
        "\n",
        "    best_val_loss = float(\"inf\")\n",
        "    best_hitrate = 0.0\n",
        "    model_path = os.path.join(MODEL_DIR, \"best_dl_ranker.pt\")\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "    val_hitrates = []\n",
        "    val_ndcgs = []\n",
        "    val_maps = []\n",
        "    learning_rates = []\n",
        "\n",
        "    os.makedirs(MODEL_DIR, exist_ok=True)\n",
        "    os.makedirs(SUBMIT_DIR, exist_ok=True)\n",
        "\n",
        "    early_stopper = EarlyStopping(patience=3, min_delta=0.001)\n",
        "\n",
        "    X, y, groups, cat_features, num_features, train_size, test_ids, test_rankers = prepare_data(DATA_DIR)\n",
        "\n",
        "    # Fill missing values\n",
        "    float_cols = [c for c, t in zip(X.columns, X.dtypes) if t == pl.Float64]\n",
        "    for col in float_cols:\n",
        "        X = X.with_columns(\n",
        "            pl.when(pl.col(col).is_nan()).then(0).otherwise(pl.col(col)).alias(col)\n",
        "        )\n",
        "\n",
        "    n1 = 16487352\n",
        "    # n1 = 17487300\n",
        "    n2 = train_size\n",
        "\n",
        "    X_tr, X_va, X_te = X[:n1], X[n1:n2], X[n2:]\n",
        "    y_tr, y_va, y_te = y[:n1], y[n1:n2], y[n2:]\n",
        "    groups_tr, groups_va, groups_te = groups[:n1], groups[n1:n2], groups[n2:]\n",
        "\n",
        "    # Inspect group sizes in validation set\n",
        "    val_rankers = groups_va[\"ranker_id\"].to_numpy()\n",
        "    val_group_counts = Counter(val_rankers)\n",
        "\n",
        "    print(\"\\nüìã Validation group statistics:\")\n",
        "    # Save detailed group info to file\n",
        "    group_info_path = os.path.join(MODEL_DIR, \"validation_groups_info.txt\")\n",
        "    with open(group_info_path, \"w\") as f:\n",
        "        f.write(f\"Total groups: {len(val_group_counts)}\\n\\n\")\n",
        "        f.write(\"GroupID\\tSize\\tStartIdx\\tEndIdx\\n\")\n",
        "\n",
        "        group_to_rows = defaultdict(list)\n",
        "        for i, g in enumerate(val_rankers):\n",
        "            group_to_rows[g].append(i)\n",
        "\n",
        "        for group_id, indices in sorted(group_to_rows.items()):\n",
        "            start_idx = indices[0]\n",
        "            end_idx = indices[-1]\n",
        "            size = len(indices)\n",
        "            f.write(f\"{group_id}\\t{size}\\t{start_idx}\\t{end_idx}\\n\")\n",
        "\n",
        "    print(f\"üìÅ Saved validation group info to {group_info_path}\")\n",
        "\n",
        "\n",
        "    cat_dims = build_cat_dims(X, cat_features)\n",
        "    num_numeric_feats = len(num_features)\n",
        "\n",
        "    train_dataset = RankDataset(X_tr, y_tr, groups_tr, cat_features, num_features)\n",
        "    val_dataset = RankDataset(X_va, y_va, groups_va, cat_features, num_features)\n",
        "    test_dataset = RankDataset(X_te, y_te, groups_te, cat_features, num_features)\n",
        "\n",
        "    plot_group_size_distribution(train_dataset, save_path=os.path.join(MODEL_DIR, \"group_sizes.png\"))\n",
        "    print(\"üìä Group size distribution saved.\")\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True, collate_fn=collate_fn)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=4, shuffle=False, collate_fn=collate_fn)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False, collate_fn=collate_fn)\n",
        "\n",
        "    print(\"‚úÖ Data loaders created.\")\n",
        "\n",
        "    num_epochs = 10\n",
        "    num_training_steps = num_epochs * len(train_loader)\n",
        "    num_warmup_steps = int(0.1 * num_training_steps)\n",
        "\n",
        "    learning_rate = 1e-3\n",
        "\n",
        "    model = DLRanker(cat_dims, num_numeric_feats).to(device)\n",
        "\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=0.01)\n",
        "\n",
        "    scheduler = get_scheduler(\n",
        "        \"linear\",\n",
        "        optimizer=optimizer,\n",
        "        num_warmup_steps=num_warmup_steps,\n",
        "        num_training_steps=num_training_steps\n",
        "    )\n",
        "\n",
        "    best_hitrate = 0\n",
        "    for epoch in range(num_epochs):\n",
        "        print(f\"\\n--- Epoch {epoch+1}/{num_epochs} ---\")\n",
        "        start_time = time.time()\n",
        "\n",
        "        train_loss = train_one_epoch(model, train_loader, optimizer, device, scheduler)\n",
        "        val_loss, val_hitrate, val_ndcg, val_map = validate(model, val_loader, device, min_group_size=10)\n",
        "\n",
        "        train_losses.append(train_loss)\n",
        "        val_losses.append(val_loss)\n",
        "        val_hitrates.append(val_hitrate.item())\n",
        "        val_ndcgs.append(val_ndcg.item())\n",
        "        val_maps.append(val_map.item())\n",
        "\n",
        "        current_lr = scheduler.get_last_lr()\n",
        "        learning_rates.append(current_lr[0])\n",
        "\n",
        "        elapsed = time.time() - start_time\n",
        "        print(\n",
        "            f\"Epoch {epoch+1}: \"\n",
        "            f\"Train Loss={train_loss:.4f}, \"\n",
        "            f\"Val Loss={val_loss:.4f}, \"\n",
        "            f\"HitRate@3={val_hitrate:.4f}, \"\n",
        "            f\"NDCG@3={val_ndcg:.4f}, \"\n",
        "            f\"MAP@3={val_map:.4f}, \"\n",
        "            f\"LR={current_lr[0]:.6f} \"\n",
        "            f\"({elapsed:.1f}s)\"\n",
        "        )\n",
        "\n",
        "\n",
        "        if val_loss < best_val_loss and val_hitrate > best_hitrate:\n",
        "            best_val_loss = val_loss\n",
        "            best_hitrate = val_hitrate\n",
        "            torch.save(model.state_dict(), model_path)\n",
        "            print(\"üíæ Model improved (loss ‚Üì and hitrate ‚Üë), saved.\")\n",
        "\n",
        "        if early_stopper.step(-val_loss):\n",
        "            print(\"‚õî Early stopping triggered.\")\n",
        "            break\n",
        "\n",
        "    # Plot metrics\n",
        "    epochs = list(range(1, len(train_losses) + 1))\n",
        "\n",
        "    # Plot Loss Curve\n",
        "    plt.figure()\n",
        "    plt.plot(epochs, train_losses, label=\"Train Loss\")\n",
        "    plt.plot(epochs, val_losses, label=\"Val Loss\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.title(\"Training & Validation Loss\")\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.savefig(os.path.join(MODEL_DIR, \"loss_curve.png\"))\n",
        "    plt.close()\n",
        "\n",
        "    # Plot HitRate@3\n",
        "    plt.figure()\n",
        "    plt.plot(epochs, val_hitrates, label=\"Val HitRate@3\", color=\"green\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"HitRate@3\")\n",
        "    plt.title(\"Validation HitRate@3\")\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.savefig(os.path.join(MODEL_DIR, \"hitrate_curve.png\"))\n",
        "    plt.close()\n",
        "\n",
        "    # Plot Learning Rate\n",
        "    plt.figure()\n",
        "    plt.plot(epochs, learning_rates, label=\"Learning Rate\", color=\"orange\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"LR\")\n",
        "    plt.title(\"Learning Rate Schedule\")\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.savefig(os.path.join(MODEL_DIR, \"lr_curve.png\"))\n",
        "    plt.close()\n",
        "\n",
        "    # Plot NDCG@3\n",
        "    plt.figure()\n",
        "    plt.plot(epochs, val_ndcgs, label=\"Val NDCG@3\", color=\"purple\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"NDCG@3\")\n",
        "    plt.title(\"Validation NDCG@3\")\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.savefig(os.path.join(MODEL_DIR, \"ndcg_curve.png\"))\n",
        "    plt.close()\n",
        "\n",
        "    # Plot MAP@3\n",
        "    plt.figure()\n",
        "    plt.plot(epochs, val_maps, label=\"Val MAP@3\", color=\"red\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"MAP@3\")\n",
        "    plt.title(\"Validation MAP@3\")\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.savefig(os.path.join(MODEL_DIR, \"map_curve.png\"))\n",
        "    plt.close()\n",
        "\n",
        "    print(\"üìä Saved metric plots to model/\")\n",
        "\n",
        "    # Predict test set\n",
        "    model.load_state_dict(torch.load(model_path))\n",
        "    model.eval()\n",
        "\n",
        "    val_ids = X_va[\"Id\"]\n",
        "    val_rankers = groups_va[\"ranker_id\"]\n",
        "    val_labels = y_va\n",
        "\n",
        "    all_val_scores = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for x_cat, x_num, _, lengths in tqdm(val_loader, desc=\"Predicting validation set\"):\n",
        "            x_num = x_num.to(device)\n",
        "            x_cat = {k: v.to(device) for k, v in x_cat.items()}\n",
        "            scores = model(x_cat, x_num)\n",
        "\n",
        "            for i in range(scores.size(0)):\n",
        "                l = lengths[i]\n",
        "                all_val_scores.append(scores[i, :l].cpu().numpy())\n",
        "\n",
        "    all_val_scores = np.concatenate(all_val_scores)\n",
        "\n",
        "    assert len(all_val_scores) == X_va.shape[0], \\\n",
        "        f\"Mismatch: {len(all_val_scores)} scores vs {X_va.shape[0]} rows\"\n",
        "\n",
        "    val_df = X_va.with_columns([\n",
        "        pl.Series(\"Id\", val_ids),\n",
        "        pl.Series(\"ranker_id\", val_rankers),\n",
        "        pl.Series(\"score\", all_val_scores),\n",
        "        pl.Series(\"label\", val_labels)\n",
        "    ])\n",
        "\n",
        "    val_df = val_df.with_columns(\n",
        "        pl.col(\"score\")\n",
        "        .rank(method=\"ordinal\", descending=True)\n",
        "        .over(\"ranker_id\")\n",
        "        .cast(pl.Int32)\n",
        "        .alias(\"selected\")\n",
        "    )\n",
        "\n",
        "    val_save_path = os.path.join(MODEL_DIR, \"validation_preds_dl_full.csv\")\n",
        "    val_df.write_csv(val_save_path)\n",
        "    print(f\"‚úÖ Saved full validation predictions (with features) to {val_save_path}\")\n",
        "\n",
        "    all_scores = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for x_cat, x_num, _, lengths in tqdm(test_loader, desc=\"Predicting test set\"):\n",
        "            x_num = x_num.to(device)\n",
        "            x_cat = {k: v.to(device) for k, v in x_cat.items()}\n",
        "            scores = model(x_cat, x_num)\n",
        "\n",
        "            for i in range(scores.size(0)):\n",
        "                l = lengths[i]\n",
        "                all_scores.append(scores[i, :l].cpu().numpy())\n",
        "\n",
        "    all_scores = np.concatenate(all_scores)\n",
        "\n",
        "    assert len(all_scores) == X_te.shape[0], \\\n",
        "        f\"Mismatch: {len(all_scores)} scores vs {X_te.shape[0]} rows in X_te\"\n",
        "\n",
        "    submission_df = pl.DataFrame({\n",
        "        \"Id\": test_ids,\n",
        "        \"ranker_id\": test_rankers,\n",
        "        \"score\": all_scores\n",
        "    })\n",
        "\n",
        "    submission = (\n",
        "        submission_df\n",
        "        .with_columns(\n",
        "            pl.col(\"score\")\n",
        "            .rank(method=\"ordinal\", descending=True)\n",
        "            .over(\"ranker_id\")\n",
        "            .cast(pl.Int32)\n",
        "            .alias(\"selected\")\n",
        "        )\n",
        "        .select([\"Id\", \"ranker_id\", \"score\", \"selected\"])\n",
        "    )\n",
        "\n",
        "    submission_path = os.path.join(SUBMIT_DIR, \"submission_dl_ranker.csv\")\n",
        "    submission.write_csv(submission_path)\n",
        "    print(f\"‚úÖ Submission saved to {submission_path}\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7zE4xb8bd6j9",
        "outputId": "b6dd151b-befe-4276-bea6-86ca33036877"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting deeprec_validate.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2>DlRanker with Attention<h2>"
      ],
      "metadata": {
        "id": "PW1CD1sXStoU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile deeprec_validate.py\n",
        "import os\n",
        "import time\n",
        "import random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import defaultdict\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "import polars as pl\n",
        "from tqdm import tqdm\n",
        "from src.feature import feature_engineering, feature_selection\n",
        "from transformers import get_scheduler\n",
        "from collections import Counter\n",
        "\n",
        "class RankDataset(Dataset):\n",
        "    def __init__(\n",
        "        self,\n",
        "        X: pl.DataFrame,\n",
        "        y: pl.Series,\n",
        "        groups: pl.DataFrame,\n",
        "        cat_features: list[str],\n",
        "        num_features: list[str],\n",
        "    ):\n",
        "        self.cat_features = cat_features\n",
        "        self.num_features = num_features\n",
        "        self.X_cat = {c: X[c].to_numpy() for c in cat_features}\n",
        "        self.X_num = X[self.num_features].to_numpy()\n",
        "        self.y = y.to_numpy()\n",
        "        self.groups = groups[\"ranker_id\"].to_numpy()\n",
        "\n",
        "        self.group_to_indices = defaultdict(list)\n",
        "        for i, g in enumerate(self.groups):\n",
        "            self.group_to_indices[g].append(i)\n",
        "        self.group_keys = list(self.group_to_indices.keys())\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.group_keys)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        g = self.group_keys[idx]\n",
        "        inds = self.group_to_indices[g]\n",
        "        length = len(inds)\n",
        "\n",
        "        x_cat = {\n",
        "            c: torch.LongTensor([\n",
        "                self.X_cat[c][i] if self.X_cat[c][i] >= 0 else 0 for i in inds\n",
        "            ])\n",
        "            for c in self.cat_features\n",
        "        }\n",
        "\n",
        "        x_num = torch.FloatTensor(self.X_num[inds])\n",
        "        y = torch.FloatTensor(self.y[inds]).reshape(-1)\n",
        "\n",
        "        return x_cat, x_num, y, length\n",
        "\n",
        "def collate_fn(batch):\n",
        "    batch_size = len(batch)\n",
        "    lengths = [b[3] for b in batch]\n",
        "    max_len = max(lengths)\n",
        "\n",
        "    padded_x_cat = {key: [] for key in batch[0][0].keys()}\n",
        "    padded_x_num = []\n",
        "    padded_y = []\n",
        "\n",
        "    num_dim = batch[0][1].shape[1]\n",
        "\n",
        "    for x_cat, x_num, y, length in batch:\n",
        "        pad_len = max_len - length\n",
        "\n",
        "        for key in padded_x_cat:\n",
        "            val = x_cat[key]\n",
        "            if pad_len > 0:\n",
        "                val = torch.cat([val, torch.zeros(pad_len, dtype=torch.long)])\n",
        "            padded_x_cat[key].append(val)\n",
        "\n",
        "        if pad_len > 0:\n",
        "            x_num = torch.cat([x_num, torch.zeros(pad_len, num_dim)])\n",
        "            y = torch.cat([y, torch.zeros(pad_len)])\n",
        "\n",
        "        padded_x_num.append(x_num)\n",
        "        padded_y.append(y)\n",
        "\n",
        "    padded_x_cat = {k: torch.stack(v) for k, v in padded_x_cat.items()}\n",
        "    padded_x_num = torch.stack(padded_x_num)\n",
        "    padded_y = torch.stack(padded_y)\n",
        "    lengths = torch.tensor(lengths, dtype=torch.long)\n",
        "\n",
        "    return padded_x_cat, padded_x_num, padded_y, lengths\n",
        "\n",
        "class DLRankerWithAttention(nn.Module):\n",
        "    def __init__(self, cat_dims, num_numeric_feats, emb_dim=64, hidden=[512, 256, 128, 64], num_heads=4):\n",
        "        super().__init__()\n",
        "\n",
        "        self.embeddings = nn.ModuleDict({\n",
        "            f: nn.Embedding(cat_dims[f], emb_dim, padding_idx=0) for f in cat_dims\n",
        "        })\n",
        "        self.linear_cat = nn.ModuleDict({\n",
        "            f: nn.Embedding(cat_dims[f], 1, padding_idx=0) for f in cat_dims\n",
        "        })\n",
        "\n",
        "        for emb in list(self.embeddings.values()) + list(self.linear_cat.values()):\n",
        "            nn.init.xavier_uniform_(emb.weight)\n",
        "\n",
        "        self.linear_num = nn.Linear(num_numeric_feats, 1)\n",
        "        nn.init.xavier_uniform_(self.linear_num.weight)\n",
        "\n",
        "        # Deep input\n",
        "        input_dim = emb_dim * len(cat_dims) + num_numeric_feats\n",
        "        layers = []\n",
        "        for h in hidden:\n",
        "            layers.append(nn.Linear(input_dim, h))\n",
        "            layers.append(nn.BatchNorm1d(h))\n",
        "            layers.append(nn.ReLU())\n",
        "            layers.append(nn.Dropout(0.1))\n",
        "            input_dim = h\n",
        "        self.mlp = nn.Sequential(*layers)\n",
        "\n",
        "        # Attention block\n",
        "        self.attn = nn.MultiheadAttention(embed_dim=input_dim, num_heads=num_heads, batch_first=True)\n",
        "        self.attn_norm = nn.LayerNorm(input_dim)\n",
        "\n",
        "        self.output = nn.Linear(input_dim, 1)\n",
        "\n",
        "    def forward(self, x_cat, x_num):\n",
        "        batch_size, group_size = x_num.shape[:2]\n",
        "\n",
        "        # Linear interaction\n",
        "        linear_cat_sum = torch.stack([\n",
        "            self.linear_cat[f](x_cat[f]).squeeze(-1)\n",
        "            for f in self.linear_cat\n",
        "        ], dim=0).sum(dim=0)\n",
        "\n",
        "        linear_num_out = self.linear_num(x_num).squeeze(-1)\n",
        "        linear_out = linear_cat_sum + linear_num_out\n",
        "\n",
        "        # Deep features\n",
        "        embs = torch.stack([\n",
        "            self.embeddings[f](x_cat[f]) for f in self.embeddings\n",
        "        ], dim=2)  # [B, G, F, D]\n",
        "\n",
        "        embs_cat = embs.reshape(batch_size * group_size, -1)\n",
        "        x_num_flat = x_num.reshape(batch_size * group_size, -1)\n",
        "        deep_input = torch.cat([embs_cat, x_num_flat], dim=1)\n",
        "        deep_out = self.mlp(deep_input)  # [B*G, H]\n",
        "        deep_out = deep_out.view(batch_size, group_size, -1)  # [B, G, H]\n",
        "\n",
        "        # Self-attention over group\n",
        "        attn_out, _ = self.attn(deep_out, deep_out, deep_out)  # [B, G, H]\n",
        "        attn_out = self.attn_norm(attn_out + deep_out)\n",
        "\n",
        "        final_scores = self.output(attn_out).squeeze(-1)  # [B, G]\n",
        "\n",
        "        # Optional FM component (disabled by default)\n",
        "        fm_out = 0.0\n",
        "        # fm_out = 0.5 * (sum_emb_square - square_emb_sum).sum(dim=2)\n",
        "\n",
        "        return linear_out + fm_out + final_scores\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "def listmle_loss(scores, labels, lengths):\n",
        "    batch_size = scores.size(0)\n",
        "    total_loss = torch.tensor(0.0, device=scores.device, requires_grad=True)\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "\n",
        "        _, idx = torch.sort(y, descending=True)\n",
        "        s_sorted = s[idx]\n",
        "\n",
        "        parts = (\n",
        "            torch.logsumexp(s_sorted.unsqueeze(0).expand(l, -1).triu(diagonal=0), dim=1)\n",
        "            - s_sorted\n",
        "        )\n",
        "\n",
        "        total_loss = total_loss + parts.sum()\n",
        "\n",
        "    return total_loss / batch_size\n",
        "\"\"\"\n",
        "\n",
        "def hitrate_at_k(scores, labels, lengths, k=3, min_group_size=10):\n",
        "    batch_size = scores.size(0)\n",
        "    hits = 0\n",
        "    valid_count = 0\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        if l < min_group_size:\n",
        "            continue\n",
        "        length = min(l, k)\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "        _, topk_idx = torch.topk(s, length)\n",
        "        topk_labels = y[topk_idx]\n",
        "        hits += (topk_labels > 0).any().float()\n",
        "        valid_count += 1\n",
        "    return hits / valid_count if valid_count > 0 else torch.tensor(0.0, device=scores.device)\n",
        "\n",
        "\n",
        "def ndcg_at_k(scores, labels, lengths, k=3, min_group_size=10):\n",
        "    batch_size = scores.size(0)\n",
        "    total_ndcg = 0.0\n",
        "    valid_count = 0\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        if l < min_group_size:\n",
        "            continue\n",
        "\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "\n",
        "        _, idx_pred = torch.topk(s, min(k, l))\n",
        "        _, idx_ideal = torch.topk(y, min(k, l))\n",
        "\n",
        "        dcg = (y[idx_pred] / torch.log2(torch.arange(2, 2 + len(idx_pred), device=y.device).float())).sum()\n",
        "        idcg = (y[idx_ideal] / torch.log2(torch.arange(2, 2 + len(idx_ideal), device=y.device).float())).sum()\n",
        "\n",
        "        ndcg = dcg / idcg if idcg > 0 else 0.0\n",
        "        total_ndcg += ndcg\n",
        "        valid_count += 1\n",
        "\n",
        "    return total_ndcg / valid_count if valid_count > 0 else torch.tensor(0.0, device=scores.device)\n",
        "\n",
        "\n",
        "def map_at_k(scores, labels, lengths, k=3, min_group_size=10):\n",
        "    batch_size = scores.size(0)\n",
        "    total_ap = 0.0\n",
        "    valid_count = 0\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        if l < min_group_size:\n",
        "            continue\n",
        "\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "\n",
        "        _, idx_pred = torch.topk(s, min(k, l))\n",
        "        y_true = y[idx_pred] > 0\n",
        "\n",
        "        if y_true.sum() == 0:\n",
        "            continue\n",
        "\n",
        "        precisions = [(y_true[:j+1].float().sum() / (j+1)) for j in range(len(y_true)) if y_true[j]]\n",
        "        ap = torch.stack(precisions).mean()\n",
        "        total_ap += ap\n",
        "        valid_count += 1\n",
        "\n",
        "    return total_ap / valid_count if valid_count > 0 else torch.tensor(0.0, device=scores.device)\n",
        "\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "def listnet_loss(scores, labels, lengths):\n",
        "    batch_size = scores.size(0)\n",
        "    total_loss = 0.0\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "\n",
        "        s_softmax = torch.nn.functional.log_softmax(s, dim=0)\n",
        "        y_softmax = torch.nn.functional.softmax(y, dim=0)\n",
        "\n",
        "        loss = -torch.sum(y_softmax * s_softmax)\n",
        "        total_loss += loss\n",
        "\n",
        "    return total_loss / batch_size\n",
        "\"\"\"\n",
        "\n",
        "def ranknet_loss(scores, labels, lengths):\n",
        "    batch_size = scores.size(0)\n",
        "    total_loss = 0.0\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "\n",
        "        diff_scores = s.unsqueeze(1) - s.unsqueeze(0)\n",
        "        rel = y.unsqueeze(1) > y.unsqueeze(0)\n",
        "        label_diff = rel.float()\n",
        "\n",
        "        log_sigmoid = torch.nn.functional.logsigmoid(diff_scores)\n",
        "        pair_loss = -label_diff * log_sigmoid\n",
        "\n",
        "        total_loss += pair_loss.sum()\n",
        "\n",
        "    return total_loss / batch_size\n",
        "\n",
        "def xranknet_loss(scores, labels, lengths, temperature=1.0, margin=0.2, focus_topk=3):\n",
        "    \"\"\"\n",
        "    xRankNet with emphasis on top-K items (based on labels, not scores).\n",
        "    \"\"\"\n",
        "    batch_size = scores.size(0)\n",
        "    total_loss = 0.0\n",
        "    total_pairs = 0\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        if l < 2:\n",
        "            continue\n",
        "\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "\n",
        "        # Top-K mask based on ground truth labels\n",
        "        topk = min(focus_topk, l)\n",
        "        _, topk_idx = torch.topk(y, topk)\n",
        "        topk_mask = torch.zeros_like(y, dtype=torch.bool)\n",
        "        topk_mask[topk_idx] = True\n",
        "\n",
        "        # Create pairwise difference matrices\n",
        "        score_diff = s.unsqueeze(1) - s.unsqueeze(0)\n",
        "        label_diff = y.unsqueeze(1) - y.unsqueeze(0)\n",
        "\n",
        "        # valid pair: y_i > y_j and at least one of i, j is in top-K\n",
        "        valid_pairs = (label_diff > 0) & (\n",
        "            topk_mask.unsqueeze(1) | topk_mask.unsqueeze(0)\n",
        "        )\n",
        "\n",
        "        if valid_pairs.sum() == 0:\n",
        "            continue\n",
        "\n",
        "        importance = (label_diff.abs() * valid_pairs).float()\n",
        "\n",
        "        if margin > 0.0:\n",
        "            score_diff = score_diff - margin\n",
        "\n",
        "        score_diff = score_diff / temperature\n",
        "        pairwise_loss = -F.logsigmoid(score_diff) * importance\n",
        "\n",
        "        total_loss += pairwise_loss.sum()\n",
        "        total_pairs += importance.sum()\n",
        "\n",
        "    if total_pairs == 0:\n",
        "        return torch.tensor(0.0, device=scores.device, requires_grad=True)\n",
        "\n",
        "    return total_loss / total_pairs\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "def bpr_loss(scores, labels, lengths):\n",
        "    batch_size = scores.size(0)\n",
        "    total_loss = 0.0\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "\n",
        "        pos_mask = y > 0\n",
        "        neg_mask = y <= 0\n",
        "\n",
        "        pos_scores = s[pos_mask]\n",
        "        neg_scores = s[neg_mask]\n",
        "\n",
        "        if len(pos_scores) == 0 or len(neg_scores) == 0:\n",
        "            continue\n",
        "\n",
        "        pair_diff = pos_scores.unsqueeze(1) - neg_scores.unsqueeze(0)\n",
        "        loss = -F.logsigmoid(pair_diff).mean()\n",
        "        total_loss += loss\n",
        "\n",
        "    return total_loss / batch_size\n",
        "\"\"\"\n",
        "\n",
        "\"\"\"\n",
        "def lambdarank_loss(scores, labels, lengths, eps=1e-10):\n",
        "    batch_size = scores.size(0)\n",
        "    total_loss = 0.0\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "\n",
        "        if l < 2:\n",
        "            continue\n",
        "\n",
        "        _, rank_order = torch.sort(s, descending=True)\n",
        "        ideal_order = torch.sort(y, descending=True).indices\n",
        "\n",
        "        gain = 2 ** y - 1\n",
        "        discount = torch.log2(torch.arange(2, l + 2, device=y.device).float())\n",
        "\n",
        "        ideal_dcg = (gain[ideal_order] / discount).sum()\n",
        "        if ideal_dcg < eps:\n",
        "            continue\n",
        "\n",
        "        delta_ndcg = torch.zeros((l, l), device=y.device)\n",
        "\n",
        "        for i_idx in range(l):\n",
        "            for j_idx in range(l):\n",
        "                if y[i_idx] > y[j_idx]:\n",
        "                    change = (\n",
        "                        (1.0 / torch.log2(rank_order[i_idx] + 2.0))\n",
        "                        - (1.0 / torch.log2(rank_order[j_idx] + 2.0))\n",
        "                    ).abs()\n",
        "                    delta = (2 ** y[i_idx] - 2 ** y[j_idx]).abs() * change\n",
        "                    delta_ndcg[i_idx, j_idx] = delta / ideal_dcg\n",
        "\n",
        "        score_diffs = s.unsqueeze(1) - s.unsqueeze(0)\n",
        "        lambdas = -F.logsigmoid(score_diffs) * delta_ndcg\n",
        "        total_loss += lambdas.sum()\n",
        "\n",
        "    return total_loss / batch_size\n",
        "\"\"\"\n",
        "\n",
        "def train_one_epoch(model, loader, optimizer, device, scheduler):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "\n",
        "    for x_cat, x_num, y, lengths in tqdm(loader, desc=\"Training\", leave=False):\n",
        "        x_num, y = x_num.to(device), y.to(device)\n",
        "        if not isinstance(lengths, torch.Tensor):\n",
        "            lengths = torch.tensor(lengths)\n",
        "        lengths = lengths.detach().clone().to(device)\n",
        "        x_cat = {k: v.to(device) for k, v in x_cat.items()}\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        scores = model(x_cat, x_num)\n",
        "        loss = xranknet_loss(scores, y, lengths, temperature=1.0, margin=0.2, focus_topk=3)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    return total_loss / len(loader)\n",
        "\n",
        "\n",
        "def validate(model, loader, device, min_group_size=10):\n",
        "    model.eval()\n",
        "    total_hitrate = 0\n",
        "    total_ndcg = 0\n",
        "    total_map = 0\n",
        "    total_loss = 0\n",
        "    count = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for x_cat, x_num, y, lengths in tqdm(loader, desc=\"Validating\", leave=False):\n",
        "            x_num, y = x_num.to(device), y.to(device)\n",
        "            lengths = torch.tensor(lengths).to(device)\n",
        "            x_cat = {k: v.to(device) for k, v in x_cat.items()}\n",
        "\n",
        "            scores = model(x_cat, x_num)\n",
        "\n",
        "            hitrate = hitrate_at_k(scores, y, lengths, k=3, min_group_size=min_group_size)\n",
        "            ndcg = ndcg_at_k(scores, y, lengths, k=3, min_group_size=min_group_size)\n",
        "            map3 = map_at_k(scores, y, lengths, k=3, min_group_size=min_group_size)\n",
        "            loss = xranknet_loss(scores, y, lengths, temperature=1.0, margin=0.2, focus_topk=3)\n",
        "\n",
        "            batch_size = scores.size(0)\n",
        "            total_hitrate += hitrate * batch_size\n",
        "            total_ndcg += ndcg * batch_size\n",
        "            total_map += map3 * batch_size\n",
        "            total_loss += loss.item() * batch_size\n",
        "            count += batch_size\n",
        "\n",
        "    return total_loss / count, total_hitrate / count, total_ndcg / count, total_map / count\n",
        "\n",
        "\n",
        "def build_cat_dims(X, cat_features):\n",
        "    cat_dims = {}\n",
        "    for c in cat_features:\n",
        "        max_val = X[c].max()\n",
        "        if max_val < 0:\n",
        "            max_val = 0\n",
        "        cat_dims[c] = max_val + 1\n",
        "    return cat_dims\n",
        "\n",
        "\n",
        "def normalize_numeric_features(X, numeric_features, train_mask):\n",
        "    for col in numeric_features:\n",
        "        values = X[col].to_numpy()\n",
        "        train_vals = values[train_mask]\n",
        "        mean = train_vals.mean()\n",
        "        std = train_vals.std() if train_vals.std() > 0 else 1.0\n",
        "        norm_vals = (values - mean) / std\n",
        "        X = X.with_columns(pl.Series(col, norm_vals).alias(col))\n",
        "    return X\n",
        "\n",
        "\n",
        "def load_or_prepare_data(\n",
        "    data_dir,\n",
        "    train_file=\"train.parquet\",\n",
        "    test_file=\"test.parquet\",\n",
        "    cache_file=\"feature_engineered_val.parquet\",\n",
        "):\n",
        "    cache_path = os.path.join(data_dir, cache_file)\n",
        "\n",
        "    if os.path.exists(cache_path):\n",
        "        print(f\"Loading cached feature-engineered data from {cache_path} ...\")\n",
        "        df = pl.read_parquet(cache_path)\n",
        "\n",
        "        test = pl.read_parquet(os.path.join(data_dir, test_file)).drop(\"__index_level_0__\")\n",
        "        test_ids = test[\"Id\"]\n",
        "        test_rankers = test[\"ranker_id\"]\n",
        "    else:\n",
        "        print(\"Cached file not found, processing raw data ...\")\n",
        "\n",
        "        train = pl.read_parquet(os.path.join(data_dir, train_file)).drop(\"__index_level_0__\")\n",
        "        test = (\n",
        "            pl.read_parquet(os.path.join(data_dir, test_file))\n",
        "            .drop(\"__index_level_0__\")\n",
        "            .with_columns(pl.lit(0, dtype=pl.Int64).alias(\"selected\"))\n",
        "        )\n",
        "\n",
        "        test_ids = test[\"Id\"]\n",
        "        test_rankers = test[\"ranker_id\"]\n",
        "\n",
        "        df = pl.concat((train, test))\n",
        "        df = feature_engineering(df, full=True)\n",
        "\n",
        "        df = df.with_columns(\n",
        "            [pl.col(c).fill_null(0) for c in df.select(pl.selectors.numeric()).columns] +\n",
        "            [pl.col(c).fill_null(\"missing\") for c in df.select(pl.selectors.string()).columns]\n",
        "        )\n",
        "\n",
        "        os.makedirs(data_dir, exist_ok=True)\n",
        "        df.write_parquet(cache_path)\n",
        "        print(f\"Saved feature-engineered data to {cache_path}\")\n",
        "\n",
        "    return df, test_ids, test_rankers\n",
        "\n",
        "\n",
        "def prepare_data(data_dir):\n",
        "    df, test_ids, test_rankers = load_or_prepare_data(data_dir)\n",
        "\n",
        "    id_column = df[\"Id\"]\n",
        "    X, y, groups, cat_features, num_features = feature_selection(df)\n",
        "\n",
        "    X = X.with_columns(pl.Series(\"Id\", id_column[:X.shape[0]]))\n",
        "\n",
        "    X = X.with_columns(\n",
        "        [\n",
        "            (pl.col(c).rank(\"dense\") - 1).fill_null(-1).cast(pl.Int32)\n",
        "            for c in cat_features\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    train_size = 18145372\n",
        "    train_mask = np.arange(X.height) < train_size\n",
        "    X = normalize_numeric_features(X, num_features, train_mask)\n",
        "\n",
        "    return X, y, groups, cat_features, num_features, train_size, test_ids, test_rankers\n",
        "\n",
        "\n",
        "class EarlyStopping:\n",
        "    def __init__(self, patience=3, min_delta=0.00005):\n",
        "        self.patience = patience\n",
        "        self.min_delta = min_delta\n",
        "        self.best = float(\"-inf\")\n",
        "        self.counter = 0\n",
        "\n",
        "    def step(self, metric):\n",
        "        if metric > self.best + self.min_delta:\n",
        "            self.best = metric\n",
        "            self.counter = 0\n",
        "        else:\n",
        "            self.counter += 1\n",
        "        return self.counter >= self.patience\n",
        "\n",
        "\n",
        "def plot_group_size_distribution(dataset, save_path=None):\n",
        "    group_sizes = [len(v) for v in dataset.group_to_indices.values()]\n",
        "    plt.figure()\n",
        "    plt.hist(group_sizes, bins=100, log=True)\n",
        "    plt.xlabel(\"Group size (number of items per ranker_id)\")\n",
        "    plt.ylabel(\"Frequency (log scale)\")\n",
        "    plt.title(\"Distribution of Group Sizes\")\n",
        "    plt.grid(True)\n",
        "    if save_path:\n",
        "        plt.savefig(save_path)\n",
        "    else:\n",
        "        plt.show()\n",
        "    plt.close()\n",
        "\n",
        "\n",
        "def main():\n",
        "    DATA_DIR = \"./data\"\n",
        "    MODEL_DIR = \"model\"\n",
        "    SUBMIT_DIR = \"submission\"\n",
        "\n",
        "    best_val_loss = float(\"inf\")\n",
        "    best_hitrate = 0.0\n",
        "    model_path = os.path.join(MODEL_DIR, \"best_dl_ranker.pt\")\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "    val_hitrates = []\n",
        "    val_ndcgs = []\n",
        "    val_maps = []\n",
        "    learning_rates = []\n",
        "\n",
        "    os.makedirs(MODEL_DIR, exist_ok=True)\n",
        "    os.makedirs(SUBMIT_DIR, exist_ok=True)\n",
        "\n",
        "    early_stopper = EarlyStopping(patience=3, min_delta=0.001)\n",
        "\n",
        "    X, y, groups, cat_features, num_features, train_size, test_ids, test_rankers = prepare_data(DATA_DIR)\n",
        "\n",
        "    # Fill missing values\n",
        "    float_cols = [c for c, t in zip(X.columns, X.dtypes) if t == pl.Float64]\n",
        "    for col in float_cols:\n",
        "        X = X.with_columns(\n",
        "            pl.when(pl.col(col).is_nan()).then(0).otherwise(pl.col(col)).alias(col)\n",
        "        )\n",
        "\n",
        "    n1 = 16487352\n",
        "    # n1 = 17487300\n",
        "    n2 = train_size\n",
        "\n",
        "    X_tr, X_va, X_te = X[:n1], X[n1:n2], X[n2:]\n",
        "    y_tr, y_va, y_te = y[:n1], y[n1:n2], y[n2:]\n",
        "    groups_tr, groups_va, groups_te = groups[:n1], groups[n1:n2], groups[n2:]\n",
        "\n",
        "    # Inspect group sizes in validation set\n",
        "    val_rankers = groups_va[\"ranker_id\"].to_numpy()\n",
        "    val_group_counts = Counter(val_rankers)\n",
        "\n",
        "    print(\"\\nüìã Validation group statistics:\")\n",
        "    # Save detailed group info to file\n",
        "    group_info_path = os.path.join(MODEL_DIR, \"validation_groups_info.txt\")\n",
        "    with open(group_info_path, \"w\") as f:\n",
        "        f.write(f\"Total groups: {len(val_group_counts)}\\n\\n\")\n",
        "        f.write(\"GroupID\\tSize\\tStartIdx\\tEndIdx\\n\")\n",
        "\n",
        "        group_to_rows = defaultdict(list)\n",
        "        for i, g in enumerate(val_rankers):\n",
        "            group_to_rows[g].append(i)\n",
        "\n",
        "        for group_id, indices in sorted(group_to_rows.items()):\n",
        "            start_idx = indices[0]\n",
        "            end_idx = indices[-1]\n",
        "            size = len(indices)\n",
        "            f.write(f\"{group_id}\\t{size}\\t{start_idx}\\t{end_idx}\\n\")\n",
        "\n",
        "    print(f\"üìÅ Saved validation group info to {group_info_path}\")\n",
        "\n",
        "\n",
        "    cat_dims = build_cat_dims(X, cat_features)\n",
        "    num_numeric_feats = len(num_features)\n",
        "\n",
        "    train_dataset = RankDataset(X_tr, y_tr, groups_tr, cat_features, num_features)\n",
        "    val_dataset = RankDataset(X_va, y_va, groups_va, cat_features, num_features)\n",
        "    test_dataset = RankDataset(X_te, y_te, groups_te, cat_features, num_features)\n",
        "\n",
        "    plot_group_size_distribution(train_dataset, save_path=os.path.join(MODEL_DIR, \"group_sizes.png\"))\n",
        "    print(\"üìä Group size distribution saved.\")\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True, collate_fn=collate_fn)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=4, shuffle=False, collate_fn=collate_fn)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False, collate_fn=collate_fn)\n",
        "\n",
        "    print(\"‚úÖ Data loaders created.\")\n",
        "\n",
        "    num_epochs = 10\n",
        "    num_training_steps = num_epochs * len(train_loader)\n",
        "    num_warmup_steps = int(0.1 * num_training_steps)\n",
        "\n",
        "    learning_rate = 1e-3\n",
        "\n",
        "    model = DLRankerWithAttention(\n",
        "        cat_dims=cat_dims,\n",
        "        num_numeric_feats=num_numeric_feats,\n",
        "        emb_dim=64,\n",
        "        hidden=[512, 256, 128, 64],\n",
        "        num_heads=4\n",
        "    ).to(device)\n",
        "\n",
        "\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=0.01)\n",
        "\n",
        "    scheduler = get_scheduler(\n",
        "        \"linear\",\n",
        "        optimizer=optimizer,\n",
        "        num_warmup_steps=num_warmup_steps,\n",
        "        num_training_steps=num_training_steps\n",
        "    )\n",
        "\n",
        "    best_hitrate = 0\n",
        "    for epoch in range(num_epochs):\n",
        "        print(f\"\\n--- Epoch {epoch+1}/{num_epochs} ---\")\n",
        "        start_time = time.time()\n",
        "\n",
        "        train_loss = train_one_epoch(model, train_loader, optimizer, device, scheduler)\n",
        "        val_loss, val_hitrate, val_ndcg, val_map = validate(model, val_loader, device, min_group_size=10)\n",
        "\n",
        "        train_losses.append(train_loss)\n",
        "        val_losses.append(val_loss)\n",
        "        val_hitrates.append(val_hitrate.item())\n",
        "        val_ndcgs.append(val_ndcg.item())\n",
        "        val_maps.append(val_map.item())\n",
        "\n",
        "        current_lr = scheduler.get_last_lr()\n",
        "        learning_rates.append(current_lr[0])\n",
        "\n",
        "        elapsed = time.time() - start_time\n",
        "        print(\n",
        "            f\"Epoch {epoch+1}: \"\n",
        "            f\"Train Loss={train_loss:.4f}, \"\n",
        "            f\"Val Loss={val_loss:.4f}, \"\n",
        "            f\"HitRate@3={val_hitrate:.4f}, \"\n",
        "            f\"NDCG@3={val_ndcg:.4f}, \"\n",
        "            f\"MAP@3={val_map:.4f}, \"\n",
        "            f\"LR={current_lr[0]:.6f} \"\n",
        "            f\"({elapsed:.1f}s)\"\n",
        "        )\n",
        "\n",
        "\n",
        "        if val_loss < best_val_loss and val_hitrate > best_hitrate:\n",
        "            best_val_loss = val_loss\n",
        "            best_hitrate = val_hitrate\n",
        "            torch.save(model.state_dict(), model_path)\n",
        "            print(\"üíæ Model improved (loss ‚Üì and hitrate ‚Üë), saved.\")\n",
        "\n",
        "        if early_stopper.step(-val_loss):\n",
        "            print(\"‚õî Early stopping triggered.\")\n",
        "            break\n",
        "\n",
        "    # Plot metrics\n",
        "    epochs = list(range(1, len(train_losses) + 1))\n",
        "\n",
        "    # Plot Loss Curve\n",
        "    plt.figure()\n",
        "    plt.plot(epochs, train_losses, label=\"Train Loss\")\n",
        "    plt.plot(epochs, val_losses, label=\"Val Loss\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.title(\"Training & Validation Loss\")\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.savefig(os.path.join(MODEL_DIR, \"loss_curve.png\"))\n",
        "    plt.close()\n",
        "\n",
        "    # Plot HitRate@3\n",
        "    plt.figure()\n",
        "    plt.plot(epochs, val_hitrates, label=\"Val HitRate@3\", color=\"green\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"HitRate@3\")\n",
        "    plt.title(\"Validation HitRate@3\")\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.savefig(os.path.join(MODEL_DIR, \"hitrate_curve.png\"))\n",
        "    plt.close()\n",
        "\n",
        "    # Plot Learning Rate\n",
        "    plt.figure()\n",
        "    plt.plot(epochs, learning_rates, label=\"Learning Rate\", color=\"orange\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"LR\")\n",
        "    plt.title(\"Learning Rate Schedule\")\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.savefig(os.path.join(MODEL_DIR, \"lr_curve.png\"))\n",
        "    plt.close()\n",
        "\n",
        "    # Plot NDCG@3\n",
        "    plt.figure()\n",
        "    plt.plot(epochs, val_ndcgs, label=\"Val NDCG@3\", color=\"purple\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"NDCG@3\")\n",
        "    plt.title(\"Validation NDCG@3\")\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.savefig(os.path.join(MODEL_DIR, \"ndcg_curve.png\"))\n",
        "    plt.close()\n",
        "\n",
        "    # Plot MAP@3\n",
        "    plt.figure()\n",
        "    plt.plot(epochs, val_maps, label=\"Val MAP@3\", color=\"red\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"MAP@3\")\n",
        "    plt.title(\"Validation MAP@3\")\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.savefig(os.path.join(MODEL_DIR, \"map_curve.png\"))\n",
        "    plt.close()\n",
        "\n",
        "    print(\"üìä Saved metric plots to model/\")\n",
        "\n",
        "    # Predict test set\n",
        "    model.load_state_dict(torch.load(model_path))\n",
        "    model.eval()\n",
        "\n",
        "    val_ids = X_va[\"Id\"]\n",
        "    val_rankers = groups_va[\"ranker_id\"]\n",
        "    val_labels = y_va\n",
        "\n",
        "    all_val_scores = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for x_cat, x_num, _, lengths in tqdm(val_loader, desc=\"Predicting validation set\"):\n",
        "            x_num = x_num.to(device)\n",
        "            x_cat = {k: v.to(device) for k, v in x_cat.items()}\n",
        "            scores = model(x_cat, x_num)\n",
        "\n",
        "            for i in range(scores.size(0)):\n",
        "                l = lengths[i]\n",
        "                all_val_scores.append(scores[i, :l].cpu().numpy())\n",
        "\n",
        "    all_val_scores = np.concatenate(all_val_scores)\n",
        "\n",
        "    assert len(all_val_scores) == X_va.shape[0], \\\n",
        "        f\"Mismatch: {len(all_val_scores)} scores vs {X_va.shape[0]} rows\"\n",
        "\n",
        "    val_df = X_va.with_columns([\n",
        "        pl.Series(\"Id\", val_ids),\n",
        "        pl.Series(\"ranker_id\", val_rankers),\n",
        "        pl.Series(\"score\", all_val_scores),\n",
        "        pl.Series(\"label\", val_labels)\n",
        "    ])\n",
        "\n",
        "    val_df = val_df.with_columns(\n",
        "        pl.col(\"score\")\n",
        "        .rank(method=\"ordinal\", descending=True)\n",
        "        .over(\"ranker_id\")\n",
        "        .cast(pl.Int32)\n",
        "        .alias(\"selected\")\n",
        "    )\n",
        "\n",
        "    val_save_path = os.path.join(MODEL_DIR, \"validation_preds_dl_full.csv\")\n",
        "    val_df.write_csv(val_save_path)\n",
        "    print(f\"‚úÖ Saved full validation predictions (with features) to {val_save_path}\")\n",
        "\n",
        "    all_scores = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for x_cat, x_num, _, lengths in tqdm(test_loader, desc=\"Predicting test set\"):\n",
        "            x_num = x_num.to(device)\n",
        "            x_cat = {k: v.to(device) for k, v in x_cat.items()}\n",
        "            scores = model(x_cat, x_num)\n",
        "\n",
        "            for i in range(scores.size(0)):\n",
        "                l = lengths[i]\n",
        "                all_scores.append(scores[i, :l].cpu().numpy())\n",
        "\n",
        "    all_scores = np.concatenate(all_scores)\n",
        "\n",
        "    assert len(all_scores) == X_te.shape[0], \\\n",
        "        f\"Mismatch: {len(all_scores)} scores vs {X_te.shape[0]} rows in X_te\"\n",
        "\n",
        "    submission_df = pl.DataFrame({\n",
        "        \"Id\": test_ids,\n",
        "        \"ranker_id\": test_rankers,\n",
        "        \"score\": all_scores\n",
        "    })\n",
        "\n",
        "    submission = (\n",
        "        submission_df\n",
        "        .with_columns(\n",
        "            pl.col(\"score\")\n",
        "            .rank(method=\"ordinal\", descending=True)\n",
        "            .over(\"ranker_id\")\n",
        "            .cast(pl.Int32)\n",
        "            .alias(\"selected\")\n",
        "        )\n",
        "        .select([\"Id\", \"ranker_id\", \"score\", \"selected\"])\n",
        "    )\n",
        "\n",
        "    submission_path = os.path.join(SUBMIT_DIR, \"submission_dl_ranker.csv\")\n",
        "    submission.write_csv(submission_path)\n",
        "    print(f\"‚úÖ Submission saved to {submission_path}\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Men_U6dDHnx7",
        "outputId": "8345e7b7-fe67-4637-e9c8-191e0973ff40"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting deeprec_validate.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**DLRanker v1 full training**"
      ],
      "metadata": {
        "id": "O6RMZ7-xSn0s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile deeprec_validate.py\n",
        "import os\n",
        "import time\n",
        "import random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F_torch\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import defaultdict\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "import polars as pl\n",
        "from tqdm import tqdm\n",
        "from src.feature import feature_engineering, feature_selection\n",
        "from transformers import get_scheduler\n",
        "from collections import Counter\n",
        "\n",
        "class RankDataset(Dataset):\n",
        "    def __init__(\n",
        "        self,\n",
        "        X: pl.DataFrame,\n",
        "        y: pl.Series,\n",
        "        groups: pl.DataFrame,\n",
        "        cat_features: list[str],\n",
        "        num_features: list[str],\n",
        "    ):\n",
        "        self.cat_features = cat_features\n",
        "        self.num_features = num_features\n",
        "        self.X_cat = {c: X[c].to_numpy() for c in cat_features}\n",
        "        self.X_num = X[self.num_features].to_numpy()\n",
        "        self.y = y.to_numpy()\n",
        "        self.groups = groups[\"ranker_id\"].to_numpy()\n",
        "\n",
        "        self.group_to_indices = defaultdict(list)\n",
        "        for i, g in enumerate(self.groups):\n",
        "            self.group_to_indices[g].append(i)\n",
        "        self.group_keys = list(self.group_to_indices.keys())\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.group_keys)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        g = self.group_keys[idx]\n",
        "        inds = self.group_to_indices[g]\n",
        "        length = len(inds)\n",
        "\n",
        "        x_cat = {\n",
        "            c: torch.LongTensor([\n",
        "                self.X_cat[c][i] if self.X_cat[c][i] >= 0 else 0 for i in inds\n",
        "            ])\n",
        "            for c in self.cat_features\n",
        "        }\n",
        "\n",
        "        x_num = torch.FloatTensor(self.X_num[inds])\n",
        "        y = torch.FloatTensor(self.y[inds]).reshape(-1)\n",
        "\n",
        "        return x_cat, x_num, y, length\n",
        "\n",
        "def collate_fn(batch):\n",
        "    batch_size = len(batch)\n",
        "    lengths = [b[3] for b in batch]\n",
        "    max_len = max(lengths)\n",
        "\n",
        "    padded_x_cat = {key: [] for key in batch[0][0].keys()}\n",
        "    padded_x_num = []\n",
        "    padded_y = []\n",
        "\n",
        "    num_dim = batch[0][1].shape[1]\n",
        "\n",
        "    for x_cat, x_num, y, length in batch:\n",
        "        pad_len = max_len - length\n",
        "\n",
        "        for key in padded_x_cat:\n",
        "            val = x_cat[key]\n",
        "            if pad_len > 0:\n",
        "                val = torch.cat([val, torch.zeros(pad_len, dtype=torch.long)])\n",
        "            padded_x_cat[key].append(val)\n",
        "\n",
        "        if pad_len > 0:\n",
        "            x_num = torch.cat([x_num, torch.zeros(pad_len, num_dim)])\n",
        "            y = torch.cat([y, torch.zeros(pad_len)])\n",
        "\n",
        "        padded_x_num.append(x_num)\n",
        "        padded_y.append(y)\n",
        "\n",
        "    padded_x_cat = {k: torch.stack(v) for k, v in padded_x_cat.items()}\n",
        "    padded_x_num = torch.stack(padded_x_num)\n",
        "    padded_y = torch.stack(padded_y)\n",
        "    lengths = torch.tensor(lengths, dtype=torch.long)\n",
        "\n",
        "    return padded_x_cat, padded_x_num, padded_y, lengths\n",
        "\n",
        "class FiBiNetRanker(nn.Module):\n",
        "    def __init__(self, cat_dims, num_numeric_feats, emb_dim=64, hidden=[512, 256, 128, 64], reduction=4, use_senet=True):\n",
        "        super().__init__()\n",
        "        self.cat_fields = list(cat_dims.keys())\n",
        "        self.emb_dim = emb_dim\n",
        "        self.num_fields = len(self.cat_fields)\n",
        "        self.use_senet = use_senet\n",
        "\n",
        "        # Embedding layers\n",
        "        self.embeddings = nn.ModuleDict({\n",
        "            f: nn.Embedding(cat_dims[f], emb_dim, padding_idx=0) for f in self.cat_fields\n",
        "        })\n",
        "        self.linear_cat = nn.ModuleDict({\n",
        "            f: nn.Embedding(cat_dims[f], 1, padding_idx=0) for f in self.cat_fields\n",
        "        })\n",
        "        self.linear_num = nn.Linear(num_numeric_feats, 1)\n",
        "\n",
        "        for emb in list(self.embeddings.values()) + list(self.linear_cat.values()):\n",
        "            nn.init.xavier_uniform_(emb.weight)\n",
        "        nn.init.xavier_uniform_(self.linear_num.weight)\n",
        "\n",
        "        # SENet\n",
        "        if self.use_senet:\n",
        "            self.se_fc1 = nn.Linear(self.num_fields * emb_dim, self.num_fields * emb_dim // reduction)\n",
        "            self.se_fc2 = nn.Linear(self.num_fields * emb_dim // reduction, self.num_fields * emb_dim)\n",
        "\n",
        "        # Bilinear layer (shared)\n",
        "        self.bilinear = nn.Linear(emb_dim, emb_dim, bias=False)\n",
        "\n",
        "        # MLP (deeper + stronger)\n",
        "        input_dim = emb_dim + num_numeric_feats\n",
        "        layers = []\n",
        "        for h in hidden:\n",
        "            layers.append(nn.Linear(input_dim, h))\n",
        "            layers.append(nn.LayerNorm(h))  # normalize\n",
        "            layers.append(nn.ReLU())\n",
        "            layers.append(nn.Dropout(0.2))  # slightly increased dropout\n",
        "            input_dim = h\n",
        "        self.mlp = nn.Sequential(*layers)\n",
        "        self.output = nn.Linear(input_dim, 1)\n",
        "\n",
        "    def senet(self, embs):\n",
        "        B, F, D = embs.shape\n",
        "        z = embs.view(B, -1)\n",
        "        a = F_torch.relu(self.se_fc1(z))\n",
        "        s = torch.sigmoid(self.se_fc2(a)).view(B, F, D)\n",
        "        return embs * s\n",
        "\n",
        "    def bilinear_interaction(self, embs):\n",
        "        transformed = self.bilinear(embs)  # [B*G, F, D]\n",
        "        interaction = (embs * transformed).mean(dim=1)  # [B*G, D]\n",
        "        return interaction\n",
        "\n",
        "    def forward(self, x_cat, x_num):\n",
        "        B, G = x_num.shape[:2]\n",
        "        F, D = self.num_fields, self.emb_dim\n",
        "\n",
        "        # Embedding stacking\n",
        "        embs = torch.stack([self.embeddings[f](x_cat[f]) for f in self.cat_fields], dim=2)  # [B, G, F, D]\n",
        "\n",
        "        # Linear logits\n",
        "        linear_cat_sum = torch.stack([\n",
        "            self.linear_cat[f](x_cat[f]).squeeze(-1) for f in self.cat_fields\n",
        "        ], dim=0).sum(dim=0)  # [B, G]\n",
        "\n",
        "        linear_num_out = self.linear_num(x_num).squeeze(-1)  # [B, G]\n",
        "        linear_out = linear_cat_sum + linear_num_out  # [B, G]\n",
        "\n",
        "        # Feature interactions\n",
        "        embs = embs.view(B * G, F, D)\n",
        "        if self.use_senet:\n",
        "            embs = self.senet(embs)\n",
        "        bi = self.bilinear_interaction(embs)  # [B*G, D]\n",
        "\n",
        "        # Deep part\n",
        "        x_num_flat = x_num.view(B * G, -1)\n",
        "        deep_input = torch.cat([bi, x_num_flat], dim=1)\n",
        "        deep_out = self.mlp(deep_input)\n",
        "        scores = self.output(deep_out).view(B, G)\n",
        "\n",
        "        return scores + linear_out  # [B, G]\n",
        "\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "def listmle_loss(scores, labels, lengths):\n",
        "    batch_size = scores.size(0)\n",
        "    total_loss = torch.tensor(0.0, device=scores.device, requires_grad=True)\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "\n",
        "        _, idx = torch.sort(y, descending=True)\n",
        "        s_sorted = s[idx]\n",
        "\n",
        "        parts = (\n",
        "            torch.logsumexp(s_sorted.unsqueeze(0).expand(l, -1).triu(diagonal=0), dim=1)\n",
        "            - s_sorted\n",
        "        )\n",
        "\n",
        "        total_loss = total_loss + parts.sum()\n",
        "\n",
        "    return total_loss / batch_size\n",
        "\"\"\"\n",
        "\n",
        "def hitrate_at_k(scores, labels, lengths, k=3, min_group_size=10):\n",
        "    batch_size = scores.size(0)\n",
        "    hits = 0\n",
        "    valid_count = 0\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        if l < min_group_size:\n",
        "            continue\n",
        "        length = min(l, k)\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "        _, topk_idx = torch.topk(s, length)\n",
        "        topk_labels = y[topk_idx]\n",
        "        hits += (topk_labels > 0).any().float()\n",
        "        valid_count += 1\n",
        "    return hits / valid_count if valid_count > 0 else torch.tensor(0.0, device=scores.device)\n",
        "\n",
        "\n",
        "def ndcg_at_k(scores, labels, lengths, k=3, min_group_size=10):\n",
        "    batch_size = scores.size(0)\n",
        "    total_ndcg = 0.0\n",
        "    valid_count = 0\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        if l < min_group_size:\n",
        "            continue\n",
        "\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "\n",
        "        _, idx_pred = torch.topk(s, min(k, l))\n",
        "        _, idx_ideal = torch.topk(y, min(k, l))\n",
        "\n",
        "        dcg = (y[idx_pred] / torch.log2(torch.arange(2, 2 + len(idx_pred), device=y.device).float())).sum()\n",
        "        idcg = (y[idx_ideal] / torch.log2(torch.arange(2, 2 + len(idx_ideal), device=y.device).float())).sum()\n",
        "\n",
        "        ndcg = dcg / idcg if idcg > 0 else 0.0\n",
        "        total_ndcg += ndcg\n",
        "        valid_count += 1\n",
        "\n",
        "    return total_ndcg / valid_count if valid_count > 0 else torch.tensor(0.0, device=scores.device)\n",
        "\n",
        "\n",
        "def map_at_k(scores, labels, lengths, k=3, min_group_size=10):\n",
        "    batch_size = scores.size(0)\n",
        "    total_ap = 0.0\n",
        "    valid_count = 0\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        if l < min_group_size:\n",
        "            continue\n",
        "\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "\n",
        "        _, idx_pred = torch.topk(s, min(k, l))\n",
        "        y_true = y[idx_pred] > 0\n",
        "\n",
        "        if y_true.sum() == 0:\n",
        "            continue\n",
        "\n",
        "        precisions = [(y_true[:j+1].float().sum() / (j+1)) for j in range(len(y_true)) if y_true[j]]\n",
        "        ap = torch.stack(precisions).mean()\n",
        "        total_ap += ap\n",
        "        valid_count += 1\n",
        "\n",
        "    return total_ap / valid_count if valid_count > 0 else torch.tensor(0.0, device=scores.device)\n",
        "\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "def listnet_loss(scores, labels, lengths):\n",
        "    batch_size = scores.size(0)\n",
        "    total_loss = 0.0\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "\n",
        "        s_softmax = torch.nn.functional.log_softmax(s, dim=0)\n",
        "        y_softmax = torch.nn.functional.softmax(y, dim=0)\n",
        "\n",
        "        loss = -torch.sum(y_softmax * s_softmax)\n",
        "        total_loss += loss\n",
        "\n",
        "    return total_loss / batch_size\n",
        "\"\"\"\n",
        "\n",
        "def ranknet_loss(scores, labels, lengths):\n",
        "    batch_size = scores.size(0)\n",
        "    total_loss = 0.0\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "\n",
        "        diff_scores = s.unsqueeze(1) - s.unsqueeze(0)\n",
        "        rel = y.unsqueeze(1) > y.unsqueeze(0)\n",
        "        label_diff = rel.float()\n",
        "\n",
        "        log_sigmoid = torch.nn.functional.logsigmoid(diff_scores)\n",
        "        pair_loss = -label_diff * log_sigmoid\n",
        "\n",
        "        total_loss += pair_loss.sum()\n",
        "\n",
        "    return total_loss / batch_size\n",
        "\n",
        "def xranknet_loss(scores, labels, lengths, temperature=1.0, margin=0.2, focus_topk=3):\n",
        "    \"\"\"\n",
        "    xRankNet with emphasis on top-K items (based on labels, not scores).\n",
        "    \"\"\"\n",
        "    batch_size = scores.size(0)\n",
        "    total_loss = 0.0\n",
        "    total_pairs = 0\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        if l < 2:\n",
        "            continue\n",
        "\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "\n",
        "        # Top-K mask based on ground truth labels\n",
        "        topk = min(focus_topk, l)\n",
        "        _, topk_idx = torch.topk(y, topk)\n",
        "        topk_mask = torch.zeros_like(y, dtype=torch.bool)\n",
        "        topk_mask[topk_idx] = True\n",
        "\n",
        "        # Create pairwise difference matrices\n",
        "        score_diff = s.unsqueeze(1) - s.unsqueeze(0)\n",
        "        label_diff = y.unsqueeze(1) - y.unsqueeze(0)\n",
        "\n",
        "        # valid pair: y_i > y_j and at least one of i, j is in top-K\n",
        "        valid_pairs = (label_diff > 0) & (\n",
        "            topk_mask.unsqueeze(1) | topk_mask.unsqueeze(0)\n",
        "        )\n",
        "\n",
        "        if valid_pairs.sum() == 0:\n",
        "            continue\n",
        "\n",
        "        importance = (label_diff.abs() * valid_pairs).float()\n",
        "\n",
        "        if margin > 0.0:\n",
        "            score_diff = score_diff - margin\n",
        "\n",
        "        score_diff = score_diff / temperature\n",
        "        pairwise_loss = -F_torch.logsigmoid(score_diff) * importance\n",
        "\n",
        "        total_loss += pairwise_loss.sum()\n",
        "        total_pairs += importance.sum()\n",
        "\n",
        "    if total_pairs == 0:\n",
        "        return torch.tensor(0.0, device=scores.device, requires_grad=True)\n",
        "\n",
        "    return total_loss / total_pairs\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "def bpr_loss(scores, labels, lengths):\n",
        "    batch_size = scores.size(0)\n",
        "    total_loss = 0.0\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "\n",
        "        pos_mask = y > 0\n",
        "        neg_mask = y <= 0\n",
        "\n",
        "        pos_scores = s[pos_mask]\n",
        "        neg_scores = s[neg_mask]\n",
        "\n",
        "        if len(pos_scores) == 0 or len(neg_scores) == 0:\n",
        "            continue\n",
        "\n",
        "        pair_diff = pos_scores.unsqueeze(1) - neg_scores.unsqueeze(0)\n",
        "        loss = -F.logsigmoid(pair_diff).mean()\n",
        "        total_loss += loss\n",
        "\n",
        "    return total_loss / batch_size\n",
        "\"\"\"\n",
        "\n",
        "\"\"\"\n",
        "def lambdarank_loss(scores, labels, lengths, eps=1e-10):\n",
        "    batch_size = scores.size(0)\n",
        "    total_loss = 0.0\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "\n",
        "        if l < 2:\n",
        "            continue\n",
        "\n",
        "        _, rank_order = torch.sort(s, descending=True)\n",
        "        ideal_order = torch.sort(y, descending=True).indices\n",
        "\n",
        "        gain = 2 ** y - 1\n",
        "        discount = torch.log2(torch.arange(2, l + 2, device=y.device).float())\n",
        "\n",
        "        ideal_dcg = (gain[ideal_order] / discount).sum()\n",
        "        if ideal_dcg < eps:\n",
        "            continue\n",
        "\n",
        "        delta_ndcg = torch.zeros((l, l), device=y.device)\n",
        "\n",
        "        for i_idx in range(l):\n",
        "            for j_idx in range(l):\n",
        "                if y[i_idx] > y[j_idx]:\n",
        "                    change = (\n",
        "                        (1.0 / torch.log2(rank_order[i_idx] + 2.0))\n",
        "                        - (1.0 / torch.log2(rank_order[j_idx] + 2.0))\n",
        "                    ).abs()\n",
        "                    delta = (2 ** y[i_idx] - 2 ** y[j_idx]).abs() * change\n",
        "                    delta_ndcg[i_idx, j_idx] = delta / ideal_dcg\n",
        "\n",
        "        score_diffs = s.unsqueeze(1) - s.unsqueeze(0)\n",
        "        lambdas = -F.logsigmoid(score_diffs) * delta_ndcg\n",
        "        total_loss += lambdas.sum()\n",
        "\n",
        "    return total_loss / batch_size\n",
        "\"\"\"\n",
        "\n",
        "def train_one_epoch(model, loader, optimizer, device, scheduler):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "\n",
        "    for x_cat, x_num, y, lengths in tqdm(loader, desc=\"Training\", leave=False):\n",
        "        x_num, y = x_num.to(device), y.to(device)\n",
        "        if not isinstance(lengths, torch.Tensor):\n",
        "            lengths = torch.tensor(lengths)\n",
        "        lengths = lengths.detach().clone().to(device)\n",
        "        x_cat = {k: v.to(device) for k, v in x_cat.items()}\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        scores = model(x_cat, x_num)\n",
        "        loss = xranknet_loss(scores, y, lengths, temperature=1.0, margin=0.2, focus_topk=3)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    return total_loss / len(loader)\n",
        "\n",
        "\n",
        "def validate(model, loader, device, min_group_size=10):\n",
        "    model.eval()\n",
        "    total_hitrate = 0\n",
        "    total_ndcg = 0\n",
        "    total_map = 0\n",
        "    total_loss = 0\n",
        "    count = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for x_cat, x_num, y, lengths in tqdm(loader, desc=\"Validating\", leave=False):\n",
        "            x_num, y = x_num.to(device), y.to(device)\n",
        "            lengths = torch.tensor(lengths).to(device)\n",
        "            x_cat = {k: v.to(device) for k, v in x_cat.items()}\n",
        "\n",
        "            scores = model(x_cat, x_num)\n",
        "\n",
        "            hitrate = hitrate_at_k(scores, y, lengths, k=3, min_group_size=min_group_size)\n",
        "            ndcg = ndcg_at_k(scores, y, lengths, k=3, min_group_size=min_group_size)\n",
        "            map3 = map_at_k(scores, y, lengths, k=3, min_group_size=min_group_size)\n",
        "            loss = xranknet_loss(scores, y, lengths, temperature=1.0, margin=0.2, focus_topk=3)\n",
        "\n",
        "            batch_size = scores.size(0)\n",
        "            total_hitrate += hitrate * batch_size\n",
        "            total_ndcg += ndcg * batch_size\n",
        "            total_map += map3 * batch_size\n",
        "            total_loss += loss.item() * batch_size\n",
        "            count += batch_size\n",
        "\n",
        "    return total_loss / count, total_hitrate / count, total_ndcg / count, total_map / count\n",
        "\n",
        "\n",
        "def build_cat_dims(X, cat_features):\n",
        "    cat_dims = {}\n",
        "    for c in cat_features:\n",
        "        max_val = X[c].max()\n",
        "        if max_val < 0:\n",
        "            max_val = 0\n",
        "        cat_dims[c] = max_val + 1\n",
        "    return cat_dims\n",
        "\n",
        "\n",
        "def normalize_numeric_features(X, numeric_features, train_mask):\n",
        "    for col in numeric_features:\n",
        "        values = X[col].to_numpy()\n",
        "        train_vals = values[train_mask]\n",
        "        mean = train_vals.mean()\n",
        "        std = train_vals.std() if train_vals.std() > 0 else 1.0\n",
        "        norm_vals = (values - mean) / std\n",
        "        X = X.with_columns(pl.Series(col, norm_vals).alias(col))\n",
        "    return X\n",
        "\n",
        "\n",
        "def load_or_prepare_data(\n",
        "    data_dir,\n",
        "    train_file=\"train.parquet\",\n",
        "    test_file=\"test.parquet\",\n",
        "    cache_file=\"feature_engineered_val.parquet\",\n",
        "):\n",
        "    cache_path = os.path.join(data_dir, cache_file)\n",
        "\n",
        "    if os.path.exists(cache_path):\n",
        "        print(f\"Loading cached feature-engineered data from {cache_path} ...\")\n",
        "        df = pl.read_parquet(cache_path)\n",
        "\n",
        "        test = pl.read_parquet(os.path.join(data_dir, test_file)).drop(\"__index_level_0__\")\n",
        "        test_ids = test[\"Id\"]\n",
        "        test_rankers = test[\"ranker_id\"]\n",
        "    else:\n",
        "        print(\"Cached file not found, processing raw data ...\")\n",
        "\n",
        "        train = pl.read_parquet(os.path.join(data_dir, train_file)).drop(\"__index_level_0__\")\n",
        "        test = (\n",
        "            pl.read_parquet(os.path.join(data_dir, test_file))\n",
        "            .drop(\"__index_level_0__\")\n",
        "            .with_columns(pl.lit(0, dtype=pl.Int64).alias(\"selected\"))\n",
        "        )\n",
        "\n",
        "        test_ids = test[\"Id\"]\n",
        "        test_rankers = test[\"ranker_id\"]\n",
        "\n",
        "        df = pl.concat((train, test))\n",
        "        df = feature_engineering(df, full=True)\n",
        "\n",
        "        df = df.with_columns(\n",
        "            [pl.col(c).fill_null(0) for c in df.select(pl.selectors.numeric()).columns] +\n",
        "            [pl.col(c).fill_null(\"missing\") for c in df.select(pl.selectors.string()).columns]\n",
        "        )\n",
        "\n",
        "        os.makedirs(data_dir, exist_ok=True)\n",
        "        df.write_parquet(cache_path)\n",
        "        print(f\"Saved feature-engineered data to {cache_path}\")\n",
        "\n",
        "    return df, test_ids, test_rankers\n",
        "\n",
        "\n",
        "def prepare_data(data_dir):\n",
        "    df, test_ids, test_rankers = load_or_prepare_data(data_dir)\n",
        "\n",
        "    id_column = df[\"Id\"]\n",
        "    X, y, groups, cat_features, num_features = feature_selection(df)\n",
        "\n",
        "    X = X.with_columns(pl.Series(\"Id\", id_column[:X.shape[0]]))\n",
        "\n",
        "    X = X.with_columns(\n",
        "        [\n",
        "            (pl.col(c).rank(\"dense\") - 1).fill_null(-1).cast(pl.Int32)\n",
        "            for c in cat_features\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    train_size = 18145372\n",
        "    train_mask = np.arange(X.height) < train_size\n",
        "    X = normalize_numeric_features(X, num_features, train_mask)\n",
        "\n",
        "    return X, y, groups, cat_features, num_features, train_size, test_ids, test_rankers\n",
        "\n",
        "\n",
        "class EarlyStopping:\n",
        "    def __init__(self, patience=3, min_delta=0.00005):\n",
        "        self.patience = patience\n",
        "        self.min_delta = min_delta\n",
        "        self.best = float(\"-inf\")\n",
        "        self.counter = 0\n",
        "\n",
        "    def step(self, metric):\n",
        "        if metric > self.best + self.min_delta:\n",
        "            self.best = metric\n",
        "            self.counter = 0\n",
        "        else:\n",
        "            self.counter += 1\n",
        "        return self.counter >= self.patience\n",
        "\n",
        "\n",
        "def plot_group_size_distribution(dataset, save_path=None):\n",
        "    group_sizes = [len(v) for v in dataset.group_to_indices.values()]\n",
        "    plt.figure()\n",
        "    plt.hist(group_sizes, bins=100, log=True)\n",
        "    plt.xlabel(\"Group size (number of items per ranker_id)\")\n",
        "    plt.ylabel(\"Frequency (log scale)\")\n",
        "    plt.title(\"Distribution of Group Sizes\")\n",
        "    plt.grid(True)\n",
        "    if save_path:\n",
        "        plt.savefig(save_path)\n",
        "    else:\n",
        "        plt.show()\n",
        "    plt.close()\n",
        "\n",
        "\n",
        "def main():\n",
        "    DATA_DIR = \"./data\"\n",
        "    MODEL_DIR = \"model\"\n",
        "    SUBMIT_DIR = \"submission\"\n",
        "\n",
        "    best_val_loss = float(\"inf\")\n",
        "    best_hitrate = 0.0\n",
        "    model_path = os.path.join(MODEL_DIR, \"best_dl_ranker.pt\")\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "    val_hitrates = []\n",
        "    val_ndcgs = []\n",
        "    val_maps = []\n",
        "    learning_rates = []\n",
        "\n",
        "    os.makedirs(MODEL_DIR, exist_ok=True)\n",
        "    os.makedirs(SUBMIT_DIR, exist_ok=True)\n",
        "\n",
        "    early_stopper = EarlyStopping(patience=3, min_delta=0.001)\n",
        "\n",
        "    X, y, groups, cat_features, num_features, train_size, test_ids, test_rankers = prepare_data(DATA_DIR)\n",
        "\n",
        "    # Fill missing values\n",
        "    float_cols = [c for c, t in zip(X.columns, X.dtypes) if t == pl.Float64]\n",
        "    for col in float_cols:\n",
        "        X = X.with_columns(\n",
        "            pl.when(pl.col(col).is_nan()).then(0).otherwise(pl.col(col)).alias(col)\n",
        "        )\n",
        "\n",
        "    n1 = 16487352\n",
        "    # n1 = 17487300\n",
        "    n2 = train_size\n",
        "\n",
        "    X_tr, X_va, X_te = X[:n1], X[n1:n2], X[n2:]\n",
        "    y_tr, y_va, y_te = y[:n1], y[n1:n2], y[n2:]\n",
        "    groups_tr, groups_va, groups_te = groups[:n1], groups[n1:n2], groups[n2:]\n",
        "\n",
        "    # Inspect group sizes in validation set\n",
        "    val_rankers = groups_va[\"ranker_id\"].to_numpy()\n",
        "    val_group_counts = Counter(val_rankers)\n",
        "\n",
        "    print(\"\\nüìã Validation group statistics:\")\n",
        "    # Save detailed group info to file\n",
        "    group_info_path = os.path.join(MODEL_DIR, \"validation_groups_info.txt\")\n",
        "    with open(group_info_path, \"w\") as f:\n",
        "        f.write(f\"Total groups: {len(val_group_counts)}\\n\\n\")\n",
        "        f.write(\"GroupID\\tSize\\tStartIdx\\tEndIdx\\n\")\n",
        "\n",
        "        group_to_rows = defaultdict(list)\n",
        "        for i, g in enumerate(val_rankers):\n",
        "            group_to_rows[g].append(i)\n",
        "\n",
        "        for group_id, indices in sorted(group_to_rows.items()):\n",
        "            start_idx = indices[0]\n",
        "            end_idx = indices[-1]\n",
        "            size = len(indices)\n",
        "            f.write(f\"{group_id}\\t{size}\\t{start_idx}\\t{end_idx}\\n\")\n",
        "\n",
        "    print(f\"üìÅ Saved validation group info to {group_info_path}\")\n",
        "\n",
        "\n",
        "    cat_dims = build_cat_dims(X, cat_features)\n",
        "    num_numeric_feats = len(num_features)\n",
        "\n",
        "    train_dataset = RankDataset(X_tr, y_tr, groups_tr, cat_features, num_features)\n",
        "    val_dataset = RankDataset(X_va, y_va, groups_va, cat_features, num_features)\n",
        "    test_dataset = RankDataset(X_te, y_te, groups_te, cat_features, num_features)\n",
        "\n",
        "    plot_group_size_distribution(train_dataset, save_path=os.path.join(MODEL_DIR, \"group_sizes.png\"))\n",
        "    print(\"üìä Group size distribution saved.\")\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True, collate_fn=collate_fn)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=4, shuffle=False, collate_fn=collate_fn)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False, collate_fn=collate_fn)\n",
        "\n",
        "    print(\"‚úÖ Data loaders created.\")\n",
        "\n",
        "    num_epochs = 10\n",
        "    num_training_steps = num_epochs * len(train_loader)\n",
        "    num_warmup_steps = int(0.1 * num_training_steps)\n",
        "\n",
        "    learning_rate = 7e-4\n",
        "\n",
        "    model = FiBiNetRanker(\n",
        "        cat_dims=cat_dims,\n",
        "        num_numeric_feats=num_numeric_feats,\n",
        "        emb_dim=64,\n",
        "        hidden=[512, 256, 128, 64]\n",
        "    ).to(device)\n",
        "\n",
        "\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=0.01)\n",
        "\n",
        "    scheduler = get_scheduler(\n",
        "        \"linear\",\n",
        "        optimizer=optimizer,\n",
        "        num_warmup_steps=num_warmup_steps,\n",
        "        num_training_steps=num_training_steps\n",
        "    )\n",
        "\n",
        "    best_hitrate = 0\n",
        "    for epoch in range(num_epochs):\n",
        "        print(f\"\\n--- Epoch {epoch+1}/{num_epochs} ---\")\n",
        "        start_time = time.time()\n",
        "\n",
        "        train_loss = train_one_epoch(model, train_loader, optimizer, device, scheduler)\n",
        "        val_loss, val_hitrate, val_ndcg, val_map = validate(model, val_loader, device, min_group_size=10)\n",
        "\n",
        "        train_losses.append(train_loss)\n",
        "        val_losses.append(val_loss)\n",
        "        val_hitrates.append(val_hitrate.item())\n",
        "        val_ndcgs.append(val_ndcg.item())\n",
        "        val_maps.append(val_map.item())\n",
        "\n",
        "        current_lr = scheduler.get_last_lr()\n",
        "        learning_rates.append(current_lr[0])\n",
        "\n",
        "        elapsed = time.time() - start_time\n",
        "        print(\n",
        "            f\"Epoch {epoch+1}: \"\n",
        "            f\"Train Loss={train_loss:.4f}, \"\n",
        "            f\"Val Loss={val_loss:.4f}, \"\n",
        "            f\"HitRate@3={val_hitrate:.4f}, \"\n",
        "            f\"NDCG@3={val_ndcg:.4f}, \"\n",
        "            f\"MAP@3={val_map:.4f}, \"\n",
        "            f\"LR={current_lr[0]:.6f} \"\n",
        "            f\"({elapsed:.1f}s)\"\n",
        "        )\n",
        "\n",
        "\n",
        "        if val_loss < best_val_loss and val_hitrate > best_hitrate:\n",
        "            best_val_loss = val_loss\n",
        "            best_hitrate = val_hitrate\n",
        "            torch.save(model.state_dict(), model_path)\n",
        "            print(\"üíæ Model improved (loss ‚Üì and hitrate ‚Üë), saved.\")\n",
        "\n",
        "        if early_stopper.step(-val_loss):\n",
        "            print(\"‚õî Early stopping triggered.\")\n",
        "            break\n",
        "\n",
        "    # Plot metrics\n",
        "    epochs = list(range(1, len(train_losses) + 1))\n",
        "\n",
        "    # Plot Loss Curve\n",
        "    plt.figure()\n",
        "    plt.plot(epochs, train_losses, label=\"Train Loss\")\n",
        "    plt.plot(epochs, val_losses, label=\"Val Loss\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.title(\"Training & Validation Loss\")\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.savefig(os.path.join(MODEL_DIR, \"loss_curve.png\"))\n",
        "    plt.close()\n",
        "\n",
        "    # Plot HitRate@3\n",
        "    plt.figure()\n",
        "    plt.plot(epochs, val_hitrates, label=\"Val HitRate@3\", color=\"green\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"HitRate@3\")\n",
        "    plt.title(\"Validation HitRate@3\")\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.savefig(os.path.join(MODEL_DIR, \"hitrate_curve.png\"))\n",
        "    plt.close()\n",
        "\n",
        "    # Plot Learning Rate\n",
        "    plt.figure()\n",
        "    plt.plot(epochs, learning_rates, label=\"Learning Rate\", color=\"orange\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"LR\")\n",
        "    plt.title(\"Learning Rate Schedule\")\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.savefig(os.path.join(MODEL_DIR, \"lr_curve.png\"))\n",
        "    plt.close()\n",
        "\n",
        "    # Plot NDCG@3\n",
        "    plt.figure()\n",
        "    plt.plot(epochs, val_ndcgs, label=\"Val NDCG@3\", color=\"purple\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"NDCG@3\")\n",
        "    plt.title(\"Validation NDCG@3\")\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.savefig(os.path.join(MODEL_DIR, \"ndcg_curve.png\"))\n",
        "    plt.close()\n",
        "\n",
        "    # Plot MAP@3\n",
        "    plt.figure()\n",
        "    plt.plot(epochs, val_maps, label=\"Val MAP@3\", color=\"red\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"MAP@3\")\n",
        "    plt.title(\"Validation MAP@3\")\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.savefig(os.path.join(MODEL_DIR, \"map_curve.png\"))\n",
        "    plt.close()\n",
        "\n",
        "    print(\"üìä Saved metric plots to model/\")\n",
        "\n",
        "    # Predict test set\n",
        "    model.load_state_dict(torch.load(model_path))\n",
        "    model.eval()\n",
        "\n",
        "    val_ids = X_va[\"Id\"]\n",
        "    val_rankers = groups_va[\"ranker_id\"]\n",
        "    val_labels = y_va\n",
        "\n",
        "    all_val_scores = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for x_cat, x_num, _, lengths in tqdm(val_loader, desc=\"Predicting validation set\"):\n",
        "            x_num = x_num.to(device)\n",
        "            x_cat = {k: v.to(device) for k, v in x_cat.items()}\n",
        "            scores = model(x_cat, x_num)\n",
        "\n",
        "            for i in range(scores.size(0)):\n",
        "                l = lengths[i]\n",
        "                all_val_scores.append(scores[i, :l].cpu().numpy())\n",
        "\n",
        "    all_val_scores = np.concatenate(all_val_scores)\n",
        "\n",
        "    assert len(all_val_scores) == X_va.shape[0], \\\n",
        "        f\"Mismatch: {len(all_val_scores)} scores vs {X_va.shape[0]} rows\"\n",
        "\n",
        "    val_df = X_va.with_columns([\n",
        "        pl.Series(\"Id\", val_ids),\n",
        "        pl.Series(\"ranker_id\", val_rankers),\n",
        "        pl.Series(\"score\", all_val_scores),\n",
        "        pl.Series(\"label\", val_labels)\n",
        "    ])\n",
        "\n",
        "    val_df = val_df.with_columns(\n",
        "        pl.col(\"score\")\n",
        "        .rank(method=\"ordinal\", descending=True)\n",
        "        .over(\"ranker_id\")\n",
        "        .cast(pl.Int32)\n",
        "        .alias(\"selected\")\n",
        "    )\n",
        "\n",
        "    val_save_path = os.path.join(MODEL_DIR, \"validation_preds_dl_full.csv\")\n",
        "    val_df.write_csv(val_save_path)\n",
        "    print(f\"‚úÖ Saved full validation predictions (with features) to {val_save_path}\")\n",
        "\n",
        "    all_scores = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for x_cat, x_num, _, lengths in tqdm(test_loader, desc=\"Predicting test set\"):\n",
        "            x_num = x_num.to(device)\n",
        "            x_cat = {k: v.to(device) for k, v in x_cat.items()}\n",
        "            scores = model(x_cat, x_num)\n",
        "\n",
        "            for i in range(scores.size(0)):\n",
        "                l = lengths[i]\n",
        "                all_scores.append(scores[i, :l].cpu().numpy())\n",
        "\n",
        "    all_scores = np.concatenate(all_scores)\n",
        "\n",
        "    assert len(all_scores) == X_te.shape[0], \\\n",
        "        f\"Mismatch: {len(all_scores)} scores vs {X_te.shape[0]} rows in X_te\"\n",
        "\n",
        "    submission_df = pl.DataFrame({\n",
        "        \"Id\": test_ids,\n",
        "        \"ranker_id\": test_rankers,\n",
        "        \"score\": all_scores\n",
        "    })\n",
        "\n",
        "    submission = (\n",
        "        submission_df\n",
        "        .with_columns(\n",
        "            pl.col(\"score\")\n",
        "            .rank(method=\"ordinal\", descending=True)\n",
        "            .over(\"ranker_id\")\n",
        "            .cast(pl.Int32)\n",
        "            .alias(\"selected\")\n",
        "        )\n",
        "        .select([\"Id\", \"ranker_id\", \"score\", \"selected\"])\n",
        "    )\n",
        "\n",
        "    submission_path = os.path.join(SUBMIT_DIR, \"submission_dl_ranker.csv\")\n",
        "    submission.write_csv(submission_path)\n",
        "    print(f\"‚úÖ Submission saved to {submission_path}\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "aMwHmnhjv-iP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile deeprec_full_training.py\n",
        "import os\n",
        "import time\n",
        "import random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F_torch\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import defaultdict\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "import polars as pl\n",
        "from tqdm import tqdm\n",
        "from src.feature import feature_engineering, feature_selection\n",
        "from transformers import get_scheduler\n",
        "\n",
        "class RankDataset(Dataset):\n",
        "    def __init__(\n",
        "        self,\n",
        "        X: pl.DataFrame,\n",
        "        y: pl.Series,\n",
        "        groups: pl.DataFrame,\n",
        "        cat_features: list[str],\n",
        "        num_features: list[str],\n",
        "    ):\n",
        "        self.cat_features = cat_features\n",
        "        self.num_features = num_features\n",
        "        self.X_cat = {c: X[c].to_numpy() for c in cat_features}\n",
        "        self.X_num = X[self.num_features].to_numpy()\n",
        "        self.y = y.to_numpy()\n",
        "        self.groups = groups[\"ranker_id\"].to_numpy()\n",
        "\n",
        "        self.group_to_indices = defaultdict(list)\n",
        "        for i, g in enumerate(self.groups):\n",
        "            self.group_to_indices[g].append(i)\n",
        "        self.group_keys = list(self.group_to_indices.keys())\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.group_keys)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        g = self.group_keys[idx]\n",
        "        inds = self.group_to_indices[g]\n",
        "        length = len(inds)\n",
        "\n",
        "        x_cat = {\n",
        "            c: torch.LongTensor([\n",
        "                self.X_cat[c][i] if self.X_cat[c][i] >= 0 else 0 for i in inds\n",
        "            ])\n",
        "            for c in self.cat_features\n",
        "        }\n",
        "\n",
        "        x_num = torch.FloatTensor(self.X_num[inds])\n",
        "        y = torch.FloatTensor(self.y[inds]).reshape(-1)\n",
        "\n",
        "        return x_cat, x_num, y, length\n",
        "\n",
        "def collate_fn(batch):\n",
        "    batch_size = len(batch)\n",
        "    lengths = [b[3] for b in batch]\n",
        "    max_len = max(lengths)\n",
        "\n",
        "    padded_x_cat = {key: [] for key in batch[0][0].keys()}\n",
        "    padded_x_num = []\n",
        "    padded_y = []\n",
        "\n",
        "    num_dim = batch[0][1].shape[1]\n",
        "\n",
        "    for x_cat, x_num, y, length in batch:\n",
        "        pad_len = max_len - length\n",
        "\n",
        "        for key in padded_x_cat:\n",
        "            val = x_cat[key]\n",
        "            if pad_len > 0:\n",
        "                val = torch.cat([val, torch.zeros(pad_len, dtype=torch.long)])\n",
        "            padded_x_cat[key].append(val)\n",
        "\n",
        "        if pad_len > 0:\n",
        "            x_num = torch.cat([x_num, torch.zeros(pad_len, num_dim)])\n",
        "            y = torch.cat([y, torch.zeros(pad_len)])\n",
        "\n",
        "        padded_x_num.append(x_num)\n",
        "        padded_y.append(y)\n",
        "\n",
        "    padded_x_cat = {k: torch.stack(v) for k, v in padded_x_cat.items()}\n",
        "    padded_x_num = torch.stack(padded_x_num)\n",
        "    padded_y = torch.stack(padded_y)\n",
        "    lengths = torch.tensor(lengths, dtype=torch.long)\n",
        "\n",
        "    return padded_x_cat, padded_x_num, padded_y, lengths\n",
        "\n",
        "\n",
        "class FiBiNetRanker(nn.Module):\n",
        "    def __init__(self, cat_dims, num_numeric_feats, emb_dim=64, hidden=[512, 256, 128, 64], reduction=4, use_senet=True):\n",
        "        super().__init__()\n",
        "        self.cat_fields = list(cat_dims.keys())\n",
        "        self.emb_dim = emb_dim\n",
        "        self.num_fields = len(self.cat_fields)\n",
        "        self.use_senet = use_senet\n",
        "\n",
        "        # Embedding layers\n",
        "        self.embeddings = nn.ModuleDict({\n",
        "            f: nn.Embedding(cat_dims[f], emb_dim, padding_idx=0) for f in self.cat_fields\n",
        "        })\n",
        "        self.linear_cat = nn.ModuleDict({\n",
        "            f: nn.Embedding(cat_dims[f], 1, padding_idx=0) for f in self.cat_fields\n",
        "        })\n",
        "        self.linear_num = nn.Linear(num_numeric_feats, 1)\n",
        "\n",
        "        for emb in list(self.embeddings.values()) + list(self.linear_cat.values()):\n",
        "            nn.init.xavier_uniform_(emb.weight)\n",
        "        nn.init.xavier_uniform_(self.linear_num.weight)\n",
        "\n",
        "        # SENet\n",
        "        if self.use_senet:\n",
        "            self.se_fc1 = nn.Linear(self.num_fields * emb_dim, self.num_fields * emb_dim // reduction)\n",
        "            self.se_fc2 = nn.Linear(self.num_fields * emb_dim // reduction, self.num_fields * emb_dim)\n",
        "\n",
        "        # Bilinear layer (shared)\n",
        "        self.bilinear = nn.Linear(emb_dim, emb_dim, bias=False)\n",
        "\n",
        "        # MLP (deeper + stronger)\n",
        "        input_dim = emb_dim + num_numeric_feats\n",
        "        layers = []\n",
        "        for h in hidden:\n",
        "            layers.append(nn.Linear(input_dim, h))\n",
        "            layers.append(nn.LayerNorm(h))  # normalize\n",
        "            layers.append(nn.ReLU())\n",
        "            layers.append(nn.Dropout(0.2))  # slightly increased dropout\n",
        "            input_dim = h\n",
        "        self.mlp = nn.Sequential(*layers)\n",
        "        self.output = nn.Linear(input_dim, 1)\n",
        "\n",
        "    def senet(self, embs):\n",
        "        B, F, D = embs.shape\n",
        "        z = embs.view(B, -1)\n",
        "        a = F_torch.relu(self.se_fc1(z))\n",
        "        s = torch.sigmoid(self.se_fc2(a)).view(B, F, D)\n",
        "        return embs * s\n",
        "\n",
        "    def bilinear_interaction(self, embs):\n",
        "        transformed = self.bilinear(embs)  # [B*G, F, D]\n",
        "        interaction = (embs * transformed).mean(dim=1)  # [B*G, D]\n",
        "        return interaction\n",
        "\n",
        "    def forward(self, x_cat, x_num):\n",
        "        B, G = x_num.shape[:2]\n",
        "        F, D = self.num_fields, self.emb_dim\n",
        "\n",
        "        # Embedding stacking\n",
        "        embs = torch.stack([self.embeddings[f](x_cat[f]) for f in self.cat_fields], dim=2)  # [B, G, F, D]\n",
        "\n",
        "        # Linear logits\n",
        "        linear_cat_sum = torch.stack([\n",
        "            self.linear_cat[f](x_cat[f]).squeeze(-1) for f in self.cat_fields\n",
        "        ], dim=0).sum(dim=0)  # [B, G]\n",
        "\n",
        "        linear_num_out = self.linear_num(x_num).squeeze(-1)  # [B, G]\n",
        "        linear_out = linear_cat_sum + linear_num_out  # [B, G]\n",
        "\n",
        "        # Feature interactions\n",
        "        embs = embs.view(B * G, F, D)\n",
        "        if self.use_senet:\n",
        "            embs = self.senet(embs)\n",
        "        bi = self.bilinear_interaction(embs)  # [B*G, D]\n",
        "\n",
        "        # Deep part\n",
        "        x_num_flat = x_num.view(B * G, -1)\n",
        "        deep_input = torch.cat([bi, x_num_flat], dim=1)\n",
        "        deep_out = self.mlp(deep_input)\n",
        "        scores = self.output(deep_out).view(B, G)\n",
        "\n",
        "        return scores + linear_out  # [B, G]\n",
        "\n",
        "\"\"\"\n",
        "def listmle_loss(scores, labels, lengths):\n",
        "    batch_size = scores.size(0)\n",
        "    total_loss = torch.tensor(0.0, device=scores.device, requires_grad=True)\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "\n",
        "        _, idx = torch.sort(y, descending=True)\n",
        "        s_sorted = s[idx]\n",
        "\n",
        "        parts = (\n",
        "            torch.logsumexp(s_sorted.unsqueeze(0).expand(l, -1).triu(diagonal=0), dim=1)\n",
        "            - s_sorted\n",
        "        )\n",
        "\n",
        "        total_loss = total_loss + parts.sum()\n",
        "\n",
        "    return total_loss / batch_size\n",
        "\"\"\"\n",
        "\n",
        "def hitrate_at_k(scores, labels, lengths, k=3):\n",
        "    batch_size = scores.size(0)\n",
        "    hits = 0\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        length = min(l, k)\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "        _, topk_idx = torch.topk(s, length)\n",
        "        topk_labels = y[topk_idx]\n",
        "        hits += (topk_labels > 0).any().float()\n",
        "    return hits / batch_size\n",
        "\n",
        "\"\"\"\n",
        "def listnet_loss(scores, labels, lengths):\n",
        "    batch_size = scores.size(0)\n",
        "    total_loss = 0.0\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "\n",
        "        s_softmax = torch.nn.functional.log_softmax(s, dim=0)\n",
        "        y_softmax = torch.nn.functional.softmax(y, dim=0)\n",
        "\n",
        "        loss = -torch.sum(y_softmax * s_softmax)\n",
        "        total_loss += loss\n",
        "\n",
        "    return total_loss / batch_size\n",
        "\"\"\"\n",
        "\n",
        "def ranknet_loss(scores, labels, lengths):\n",
        "    batch_size = scores.size(0)\n",
        "    total_loss = 0.0\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "\n",
        "        diff_scores = s.unsqueeze(1) - s.unsqueeze(0)\n",
        "        rel = y.unsqueeze(1) > y.unsqueeze(0)\n",
        "        label_diff = rel.float()\n",
        "\n",
        "        log_sigmoid = torch.nn.functional.logsigmoid(diff_scores)\n",
        "        pair_loss = -label_diff * log_sigmoid\n",
        "\n",
        "        total_loss += pair_loss.sum()\n",
        "\n",
        "    return total_loss / batch_size\n",
        "\n",
        "def xranknet_loss(scores, labels, lengths, temperature=1.0, margin=0.2, focus_topk=3):\n",
        "    \"\"\"\n",
        "    xRankNet with emphasis on top-K items (based on labels, not scores).\n",
        "    \"\"\"\n",
        "    batch_size = scores.size(0)\n",
        "    total_loss = 0.0\n",
        "    total_pairs = 0\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        if l < 2:\n",
        "            continue\n",
        "\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "\n",
        "        # Top-K mask based on ground truth labels\n",
        "        topk = min(focus_topk, l)\n",
        "        _, topk_idx = torch.topk(y, topk)\n",
        "        topk_mask = torch.zeros_like(y, dtype=torch.bool)\n",
        "        topk_mask[topk_idx] = True\n",
        "\n",
        "        # Create pairwise difference matrices\n",
        "        score_diff = s.unsqueeze(1) - s.unsqueeze(0)\n",
        "        label_diff = y.unsqueeze(1) - y.unsqueeze(0)\n",
        "\n",
        "        # valid pair: y_i > y_j and at least one of i, j is in top-K\n",
        "        valid_pairs = (label_diff > 0) & (\n",
        "            topk_mask.unsqueeze(1) | topk_mask.unsqueeze(0)\n",
        "        )\n",
        "\n",
        "        if valid_pairs.sum() == 0:\n",
        "            continue\n",
        "\n",
        "        importance = (label_diff.abs() * valid_pairs).float()\n",
        "\n",
        "        if margin > 0.0:\n",
        "            score_diff = score_diff - margin\n",
        "\n",
        "        score_diff = score_diff / temperature\n",
        "        pairwise_loss = -F_torch.logsigmoid(score_diff) * importance\n",
        "\n",
        "        total_loss += pairwise_loss.sum()\n",
        "        total_pairs += importance.sum()\n",
        "\n",
        "    if total_pairs == 0:\n",
        "        return torch.tensor(0.0, device=scores.device, requires_grad=True)\n",
        "\n",
        "    return total_loss / total_pairs\n",
        "\n",
        "def train_one_epoch(model, loader, optimizer, device, scheduler):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "\n",
        "    for x_cat, x_num, y, lengths in tqdm(loader, desc=\"Training\", leave=False):\n",
        "        x_num, y = x_num.to(device), y.to(device)\n",
        "        if not isinstance(lengths, torch.Tensor):\n",
        "            lengths = torch.tensor(lengths)\n",
        "        lengths = lengths.detach().clone().to(device)\n",
        "        x_cat = {k: v.to(device) for k, v in x_cat.items()}\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        scores = model(x_cat, x_num)\n",
        "        loss = xranknet_loss(scores, y, lengths, temperature=1.0, margin=0.2, focus_topk=3)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    return total_loss / len(loader)\n",
        "\n",
        "\n",
        "def validate(model, loader, device):\n",
        "    model.eval()\n",
        "    total_hitrate = 0\n",
        "    total_loss = 0\n",
        "    count = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for x_cat, x_num, y, lengths in tqdm(loader, desc=\"Validating\", leave=False):\n",
        "\n",
        "            x_num, y = x_num.to(device), y.to(device)\n",
        "            lengths = torch.tensor(lengths).to(device)\n",
        "            x_cat = {k: v.to(device) for k, v in x_cat.items()}\n",
        "            scores = model(x_cat, x_num)\n",
        "\n",
        "            hitrate = hitrate_at_k(scores, y, lengths, k=3)\n",
        "            loss = xranknet_loss(scores, y, lengths, temperature=1.0, margin=0.2, focus_topk=3)\n",
        "\n",
        "            total_hitrate += hitrate * scores.size(0)\n",
        "            total_loss += loss.item() * scores.size(0)\n",
        "            count += scores.size(0)\n",
        "\n",
        "    avg_hitrate = total_hitrate / count\n",
        "    avg_loss = total_loss / count\n",
        "    return avg_loss, avg_hitrate\n",
        "\n",
        "\n",
        "def build_cat_dims(X, cat_features):\n",
        "    cat_dims = {}\n",
        "    for c in cat_features:\n",
        "        max_val = X[c].max()\n",
        "        if max_val < 0:\n",
        "            max_val = 0\n",
        "        cat_dims[c] = max_val + 1\n",
        "    return cat_dims\n",
        "\n",
        "\n",
        "def normalize_numeric_features(X, numeric_features, train_mask):\n",
        "    for col in numeric_features:\n",
        "        values = X[col].to_numpy()\n",
        "        train_vals = values[train_mask]\n",
        "        mean = train_vals.mean()\n",
        "        std = train_vals.std() if train_vals.std() > 0 else 1.0\n",
        "        norm_vals = (values - mean) / std\n",
        "        X = X.with_columns(pl.Series(col, norm_vals).alias(col))\n",
        "    return X\n",
        "\n",
        "\n",
        "def load_or_prepare_data(\n",
        "    data_dir,\n",
        "    train_file=\"train.parquet\",\n",
        "    test_file=\"test.parquet\",\n",
        "    cache_file=\"feature_engineered_val.parquet\",\n",
        "):\n",
        "    cache_path = os.path.join(data_dir, cache_file)\n",
        "\n",
        "    if os.path.exists(cache_path):\n",
        "        print(f\"Loading cached feature-engineered data from {cache_path} ...\")\n",
        "        df = pl.read_parquet(cache_path)\n",
        "\n",
        "        test = pl.read_parquet(os.path.join(data_dir, test_file)).drop(\"__index_level_0__\")\n",
        "        test_ids = test[\"Id\"]\n",
        "        test_rankers = test[\"ranker_id\"]\n",
        "    else:\n",
        "        print(\"Cached file not found, processing raw data ...\")\n",
        "\n",
        "        train = pl.read_parquet(os.path.join(data_dir, train_file)).drop(\"__index_level_0__\")\n",
        "        test = (\n",
        "            pl.read_parquet(os.path.join(data_dir, test_file))\n",
        "            .drop(\"__index_level_0__\")\n",
        "            .with_columns(pl.lit(0, dtype=pl.Int64).alias(\"selected\"))\n",
        "        )\n",
        "\n",
        "        test_ids = test[\"Id\"]\n",
        "        test_rankers = test[\"ranker_id\"]\n",
        "\n",
        "        df = pl.concat((train, test))\n",
        "        df = feature_engineering(df, full=True)\n",
        "\n",
        "        df = df.with_columns(\n",
        "            [pl.col(c).fill_null(0) for c in df.select(pl.selectors.numeric()).columns] +\n",
        "            [pl.col(c).fill_null(\"missing\") for c in df.select(pl.selectors.string()).columns]\n",
        "        )\n",
        "\n",
        "        os.makedirs(data_dir, exist_ok=True)\n",
        "        df.write_parquet(cache_path)\n",
        "        print(f\"Saved feature-engineered data to {cache_path}\")\n",
        "\n",
        "    return df, test_ids, test_rankers\n",
        "\n",
        "\n",
        "def prepare_data(data_dir):\n",
        "    df, test_ids, test_rankers = load_or_prepare_data(data_dir)\n",
        "\n",
        "    id_column = df[\"Id\"]\n",
        "    X, y, groups, cat_features, num_features = feature_selection(df)\n",
        "\n",
        "    X = X.with_columns(pl.Series(\"Id\", id_column[:X.shape[0]]))\n",
        "\n",
        "    X = X.with_columns(\n",
        "        [\n",
        "            (pl.col(c).rank(\"dense\") - 1).fill_null(-1).cast(pl.Int32)\n",
        "            for c in cat_features\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    train_size = 18145372\n",
        "    train_mask = np.arange(X.height) < train_size\n",
        "    X = normalize_numeric_features(X, num_features, train_mask)\n",
        "\n",
        "    return X, y, groups, cat_features, num_features, train_size, test_ids, test_rankers\n",
        "\n",
        "\n",
        "class EarlyStopping:\n",
        "    def __init__(self, patience=3, min_delta=0.001):\n",
        "        self.patience = patience\n",
        "        self.min_delta = min_delta\n",
        "        self.best = float(\"-inf\")\n",
        "        self.counter = 0\n",
        "\n",
        "    def step(self, metric):\n",
        "        if metric > self.best + self.min_delta:\n",
        "            self.best = metric\n",
        "            self.counter = 0\n",
        "        else:\n",
        "            self.counter += 1\n",
        "        return self.counter >= self.patience\n",
        "\n",
        "\n",
        "def plot_group_size_distribution(dataset, save_path=None):\n",
        "    group_sizes = [len(v) for v in dataset.group_to_indices.values()]\n",
        "    plt.figure()\n",
        "    plt.hist(group_sizes, bins=100, log=True)\n",
        "    plt.xlabel(\"Group size (number of items per ranker_id)\")\n",
        "    plt.ylabel(\"Frequency (log scale)\")\n",
        "    plt.title(\"Distribution of Group Sizes\")\n",
        "    plt.grid(True)\n",
        "    if save_path:\n",
        "        plt.savefig(save_path)\n",
        "    else:\n",
        "        plt.show()\n",
        "    plt.close()\n",
        "\n",
        "\n",
        "def main():\n",
        "    DATA_DIR = \"./data\"\n",
        "    MODEL_DIR = \"model\"\n",
        "    SUBMIT_DIR = \"submission\"\n",
        "\n",
        "    model_path = os.path.join(MODEL_DIR, \"best_dl_ranker.pt\")\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    train_losses = []\n",
        "    learning_rates = []\n",
        "\n",
        "    os.makedirs(MODEL_DIR, exist_ok=True)\n",
        "    os.makedirs(SUBMIT_DIR, exist_ok=True)\n",
        "\n",
        "    early_stopper = EarlyStopping(patience=3, min_delta=0.001)\n",
        "\n",
        "    X, y, groups, cat_features, num_features, train_size, test_ids, test_rankers = prepare_data(DATA_DIR)\n",
        "\n",
        "    # Fill missing values\n",
        "    float_cols = [c for c, t in zip(X.columns, X.dtypes) if t == pl.Float64]\n",
        "    for col in float_cols:\n",
        "        X = X.with_columns(\n",
        "            pl.when(pl.col(col).is_nan()).then(0).otherwise(pl.col(col)).alias(col)\n",
        "        )\n",
        "\n",
        "    n2 = train_size\n",
        "\n",
        "    X_tr, X_te = X[:n2], X[n2:]\n",
        "    y_tr, y_te = y[:n2], y[n2:]\n",
        "    groups_tr, groups_te = groups[:n2], groups[n2:]\n",
        "\n",
        "    cat_dims = build_cat_dims(X, cat_features)\n",
        "    num_numeric_feats = len(num_features)\n",
        "\n",
        "    train_dataset = RankDataset(X_tr, y_tr, groups_tr, cat_features, num_features)\n",
        "    test_dataset = RankDataset(X_te, y_te, groups_te, cat_features, num_features)\n",
        "\n",
        "    plot_group_size_distribution(train_dataset, save_path=os.path.join(MODEL_DIR, \"group_sizes.png\"))\n",
        "    print(\"üìä Group size distribution saved.\")\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True, collate_fn=collate_fn)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, collate_fn=collate_fn)\n",
        "\n",
        "    print(\"‚úÖ Data loaders created.\")\n",
        "\n",
        "    num_epochs = 10\n",
        "    num_training_steps = num_epochs * len(train_loader)\n",
        "    num_warmup_steps = int(0.1 * num_training_steps)\n",
        "\n",
        "    learning_rate = 7e-4\n",
        "\n",
        "    model = FiBiNetRanker(\n",
        "        cat_dims=cat_dims,\n",
        "        num_numeric_feats=num_numeric_feats,\n",
        "        emb_dim=64,\n",
        "        hidden=[512, 256, 128, 64]\n",
        "    ).to(device)\n",
        "\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=0.05)\n",
        "\n",
        "    scheduler = get_scheduler(\n",
        "        \"linear\",\n",
        "        optimizer=optimizer,\n",
        "        num_warmup_steps=num_warmup_steps,\n",
        "        num_training_steps=num_training_steps\n",
        "    )\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print(f\"\\n--- Epoch {epoch+1}/{num_epochs} ---\")\n",
        "        start_time = time.time()\n",
        "\n",
        "        train_loss = train_one_epoch(model, train_loader, optimizer, device, scheduler)\n",
        "\n",
        "        train_losses.append(train_loss)\n",
        "\n",
        "        current_lr = scheduler.get_last_lr()\n",
        "        learning_rates.append(current_lr[0])\n",
        "\n",
        "        elapsed = time.time() - start_time\n",
        "        print(\n",
        "            f\"Epoch {epoch+1}: \"\n",
        "            f\"Train Loss={train_loss:.4f}, \"\n",
        "            f\"LR={current_lr[0]:.6f} \"\n",
        "            f\"({elapsed:.1f}s)\"\n",
        "        )\n",
        "\n",
        "        torch.save(model.state_dict(), model_path)\n",
        "        print(\"üíæ Model improved (loss ‚Üì and hitrate ‚Üë), saved.\")\n",
        "\n",
        "    # Plot metrics\n",
        "    epochs = list(range(1, len(train_losses) + 1))\n",
        "\n",
        "    # Predict test set\n",
        "    model.load_state_dict(torch.load(model_path))\n",
        "    model.eval()\n",
        "    all_scores = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for x_cat, x_num, _, lengths in tqdm(test_loader, desc=\"Predicting test set\"):\n",
        "            x_num = x_num.to(device)\n",
        "            x_cat = {k: v.to(device) for k, v in x_cat.items()}\n",
        "            scores = model(x_cat, x_num)\n",
        "\n",
        "            for i in range(scores.size(0)):\n",
        "                l = lengths[i]\n",
        "                all_scores.append(scores[i, :l].cpu().numpy())\n",
        "\n",
        "    all_scores = np.concatenate(all_scores)\n",
        "\n",
        "    assert len(all_scores) == X_te.shape[0], \\\n",
        "        f\"Mismatch: {len(all_scores)} scores vs {X_te.shape[0]} rows in X_te\"\n",
        "\n",
        "    submission_df = pl.DataFrame({\n",
        "        \"Id\": test_ids,\n",
        "        \"ranker_id\": test_rankers,\n",
        "        \"score\": all_scores\n",
        "    })\n",
        "\n",
        "    submission = (\n",
        "        submission_df\n",
        "        .with_columns(\n",
        "            pl.col(\"score\")\n",
        "            .rank(method=\"ordinal\", descending=True)\n",
        "            .over(\"ranker_id\")\n",
        "            .cast(pl.Int32)\n",
        "            .alias(\"selected\")\n",
        "        )\n",
        "        .select([\"Id\", \"ranker_id\", \"selected\"])\n",
        "    )\n",
        "\n",
        "\n",
        "    submission_path = os.path.join(SUBMIT_DIR, \"submission_dl_ranker.parquet\")\n",
        "    submission.write_parquet(submission_path)\n",
        "    print(f\"‚úÖ Submission saved to {submission_path}\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ne8qucIKvAJM",
        "outputId": "35ea053b-87c0-41ca-e870-01490f25a484"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing deeprec_full_training.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile deeprec_full_training.py\n",
        "import os\n",
        "import time\n",
        "import random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import defaultdict\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "import polars as pl\n",
        "from tqdm import tqdm\n",
        "from src.feature import feature_engineering, feature_selection\n",
        "from transformers import get_scheduler\n",
        "\n",
        "SEED = 42\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed(SEED)\n",
        "torch.cuda.manual_seed_all(SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "\n",
        "class RankDataset(Dataset):\n",
        "    def __init__(\n",
        "        self,\n",
        "        X: pl.DataFrame,\n",
        "        y: pl.Series,\n",
        "        groups: pl.DataFrame,\n",
        "        cat_features: list[str],\n",
        "        num_features: list[str],\n",
        "    ):\n",
        "        self.cat_features = cat_features\n",
        "        self.num_features = num_features\n",
        "        self.X_cat = {c: X[c].to_numpy() for c in cat_features}\n",
        "        self.X_num = X[self.num_features].to_numpy()\n",
        "        self.y = y.to_numpy()\n",
        "        self.groups = groups[\"ranker_id\"].to_numpy()\n",
        "\n",
        "        self.group_to_indices = defaultdict(list)\n",
        "        for i, g in enumerate(self.groups):\n",
        "            self.group_to_indices[g].append(i)\n",
        "        self.group_keys = list(self.group_to_indices.keys())\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.group_keys)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        g = self.group_keys[idx]\n",
        "        inds = self.group_to_indices[g]\n",
        "        length = len(inds)\n",
        "\n",
        "        x_cat = {\n",
        "            c: torch.LongTensor([\n",
        "                self.X_cat[c][i] if self.X_cat[c][i] >= 0 else 0 for i in inds\n",
        "            ])\n",
        "            for c in self.cat_features\n",
        "        }\n",
        "\n",
        "        x_num = torch.FloatTensor(self.X_num[inds])\n",
        "        y = torch.FloatTensor(self.y[inds]).reshape(-1)\n",
        "\n",
        "        return x_cat, x_num, y, length\n",
        "\n",
        "def collate_fn(batch):\n",
        "    batch_size = len(batch)\n",
        "    lengths = [b[3] for b in batch]\n",
        "    max_len = max(lengths)\n",
        "\n",
        "    padded_x_cat = {key: [] for key in batch[0][0].keys()}\n",
        "    padded_x_num = []\n",
        "    padded_y = []\n",
        "\n",
        "    num_dim = batch[0][1].shape[1]\n",
        "\n",
        "    for x_cat, x_num, y, length in batch:\n",
        "        pad_len = max_len - length\n",
        "\n",
        "        for key in padded_x_cat:\n",
        "            val = x_cat[key]\n",
        "            if pad_len > 0:\n",
        "                val = torch.cat([val, torch.zeros(pad_len, dtype=torch.long)])\n",
        "            padded_x_cat[key].append(val)\n",
        "\n",
        "        if pad_len > 0:\n",
        "            x_num = torch.cat([x_num, torch.zeros(pad_len, num_dim)])\n",
        "            y = torch.cat([y, torch.zeros(pad_len)])\n",
        "\n",
        "        padded_x_num.append(x_num)\n",
        "        padded_y.append(y)\n",
        "\n",
        "    padded_x_cat = {k: torch.stack(v) for k, v in padded_x_cat.items()}\n",
        "    padded_x_num = torch.stack(padded_x_num)\n",
        "    padded_y = torch.stack(padded_y)\n",
        "    lengths = torch.tensor(lengths, dtype=torch.long)\n",
        "\n",
        "    return padded_x_cat, padded_x_num, padded_y, lengths\n",
        "\n",
        "\n",
        "class DLRanker(nn.Module):\n",
        "    def __init__(self, cat_dims, num_numeric_feats, emb_dim=64, hidden=[512, 256, 128, 64]):\n",
        "        super().__init__()\n",
        "\n",
        "        self.embeddings = nn.ModuleDict({\n",
        "            f: nn.Embedding(cat_dims[f], emb_dim, padding_idx=0) for f in cat_dims\n",
        "        })\n",
        "        self.linear_cat = nn.ModuleDict({\n",
        "            f: nn.Embedding(cat_dims[f], 1, padding_idx=0) for f in cat_dims\n",
        "        })\n",
        "\n",
        "        for emb in list(self.embeddings.values()) + list(self.linear_cat.values()):\n",
        "            nn.init.xavier_uniform_(emb.weight)\n",
        "\n",
        "        self.linear_num = nn.Linear(num_numeric_feats, 1)\n",
        "        nn.init.xavier_uniform_(self.linear_num.weight)\n",
        "\n",
        "        input_dim = emb_dim * len(cat_dims) + num_numeric_feats\n",
        "        layers = []\n",
        "        for h in hidden:\n",
        "            layers.append(nn.Linear(input_dim, h))\n",
        "            layers.append(nn.BatchNorm1d(h))\n",
        "            layers.append(nn.ReLU())\n",
        "            layers.append(nn.Dropout(0.1))\n",
        "            input_dim = h\n",
        "        self.mlp = nn.Sequential(*layers)\n",
        "        self.output = nn.Linear(input_dim, 1)\n",
        "\n",
        "    def forward(self, x_cat, x_num):\n",
        "        batch_size, group_size = x_num.shape[:2]\n",
        "\n",
        "        linear_cat_sum = torch.stack([\n",
        "            self.linear_cat[f](x_cat[f]).squeeze(-1)\n",
        "            for f in self.linear_cat\n",
        "        ], dim=0).sum(dim=0)\n",
        "\n",
        "        linear_num_out = self.linear_num(x_num).squeeze(-1)\n",
        "        linear_out = linear_cat_sum + linear_num_out\n",
        "\n",
        "        embs = torch.stack([\n",
        "            self.embeddings[f](x_cat[f]) for f in self.embeddings\n",
        "        ], dim=2)\n",
        "\n",
        "        sum_emb = embs.sum(dim=2)\n",
        "        sum_emb_square = sum_emb ** 2\n",
        "        square_emb_sum = (embs ** 2).sum(dim=2)\n",
        "        fm_out = 0.0\n",
        "        # fm_out = 0.5 * (sum_emb_square - square_emb_sum).sum(dim=2)\n",
        "\n",
        "        embs_cat = embs.reshape(batch_size * group_size, -1)\n",
        "        x_num_flat = x_num.reshape(batch_size * group_size, -1)\n",
        "        deep_input = torch.cat([embs_cat, x_num_flat], dim=1)\n",
        "        deep_out = self.mlp(deep_input)\n",
        "        deep_out = self.output(deep_out).view(batch_size, group_size)\n",
        "\n",
        "        return linear_out + fm_out + deep_out\n",
        "\n",
        "\"\"\"\n",
        "def listmle_loss(scores, labels, lengths):\n",
        "    batch_size = scores.size(0)\n",
        "    total_loss = torch.tensor(0.0, device=scores.device, requires_grad=True)\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "\n",
        "        _, idx = torch.sort(y, descending=True)\n",
        "        s_sorted = s[idx]\n",
        "\n",
        "        parts = (\n",
        "            torch.logsumexp(s_sorted.unsqueeze(0).expand(l, -1).triu(diagonal=0), dim=1)\n",
        "            - s_sorted\n",
        "        )\n",
        "\n",
        "        total_loss = total_loss + parts.sum()\n",
        "\n",
        "    return total_loss / batch_size\n",
        "\"\"\"\n",
        "\n",
        "def hitrate_at_k(scores, labels, lengths, k=3):\n",
        "    batch_size = scores.size(0)\n",
        "    hits = 0\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        length = min(l, k)\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "        _, topk_idx = torch.topk(s, length)\n",
        "        topk_labels = y[topk_idx]\n",
        "        hits += (topk_labels > 0).any().float()\n",
        "    return hits / batch_size\n",
        "\n",
        "\"\"\"\n",
        "def listnet_loss(scores, labels, lengths):\n",
        "    batch_size = scores.size(0)\n",
        "    total_loss = 0.0\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "\n",
        "        s_softmax = torch.nn.functional.log_softmax(s, dim=0)\n",
        "        y_softmax = torch.nn.functional.softmax(y, dim=0)\n",
        "\n",
        "        loss = -torch.sum(y_softmax * s_softmax)\n",
        "        total_loss += loss\n",
        "\n",
        "    return total_loss / batch_size\n",
        "\"\"\"\n",
        "\n",
        "def ranknet_loss(scores, labels, lengths):\n",
        "    batch_size = scores.size(0)\n",
        "    total_loss = 0.0\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "\n",
        "        diff_scores = s.unsqueeze(1) - s.unsqueeze(0)\n",
        "        rel = y.unsqueeze(1) > y.unsqueeze(0)\n",
        "        label_diff = rel.float()\n",
        "\n",
        "        log_sigmoid = torch.nn.functional.logsigmoid(diff_scores)\n",
        "        pair_loss = -label_diff * log_sigmoid\n",
        "\n",
        "        total_loss += pair_loss.sum()\n",
        "\n",
        "    return total_loss / batch_size\n",
        "\n",
        "def xranknet_loss(scores, labels, lengths, temperature=1.0, margin=0.2, focus_topk=3):\n",
        "    \"\"\"\n",
        "    xRankNet with emphasis on top-K items (based on labels, not scores).\n",
        "    \"\"\"\n",
        "    batch_size = scores.size(0)\n",
        "    total_loss = 0.0\n",
        "    total_pairs = 0\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        if l < 2:\n",
        "            continue\n",
        "\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "\n",
        "        # Top-K mask based on ground truth labels\n",
        "        topk = min(focus_topk, l)\n",
        "        _, topk_idx = torch.topk(y, topk)\n",
        "        topk_mask = torch.zeros_like(y, dtype=torch.bool)\n",
        "        topk_mask[topk_idx] = True\n",
        "\n",
        "        # Create pairwise difference matrices\n",
        "        score_diff = s.unsqueeze(1) - s.unsqueeze(0)\n",
        "        label_diff = y.unsqueeze(1) - y.unsqueeze(0)\n",
        "\n",
        "        # valid pair: y_i > y_j and at least one of i, j is in top-K\n",
        "        valid_pairs = (label_diff > 0) & (\n",
        "            topk_mask.unsqueeze(1) | topk_mask.unsqueeze(0)\n",
        "        )\n",
        "\n",
        "        if valid_pairs.sum() == 0:\n",
        "            continue\n",
        "\n",
        "        importance = (label_diff.abs() * valid_pairs).float()\n",
        "\n",
        "        if margin > 0.0:\n",
        "            score_diff = score_diff - margin\n",
        "\n",
        "        score_diff = score_diff / temperature\n",
        "        pairwise_loss = -F.logsigmoid(score_diff) * importance\n",
        "\n",
        "        total_loss += pairwise_loss.sum()\n",
        "        total_pairs += importance.sum()\n",
        "\n",
        "    if total_pairs == 0:\n",
        "        return torch.tensor(0.0, device=scores.device, requires_grad=True)\n",
        "\n",
        "    return total_loss / total_pairs\n",
        "\n",
        "def train_one_epoch(model, loader, optimizer, device, scheduler):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "\n",
        "    for x_cat, x_num, y, lengths in tqdm(loader, desc=\"Training\", leave=False):\n",
        "        x_num, y = x_num.to(device), y.to(device)\n",
        "        if not isinstance(lengths, torch.Tensor):\n",
        "            lengths = torch.tensor(lengths)\n",
        "        lengths = lengths.detach().clone().to(device)\n",
        "        x_cat = {k: v.to(device) for k, v in x_cat.items()}\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        scores = model(x_cat, x_num)\n",
        "        loss = xranknet_loss(scores, y, lengths, temperature=1.0, margin=0.0, focus_topk=3)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    return total_loss / len(loader)\n",
        "\n",
        "\n",
        "def validate(model, loader, device):\n",
        "    model.eval()\n",
        "    total_hitrate = 0\n",
        "    total_loss = 0\n",
        "    count = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for x_cat, x_num, y, lengths in tqdm(loader, desc=\"Validating\", leave=False):\n",
        "\n",
        "            x_num, y = x_num.to(device), y.to(device)\n",
        "            lengths = torch.tensor(lengths).to(device)\n",
        "            x_cat = {k: v.to(device) for k, v in x_cat.items()}\n",
        "            scores = model(x_cat, x_num)\n",
        "\n",
        "            hitrate = hitrate_at_k(scores, y, lengths, k=3)\n",
        "            loss = xranknet_loss(scores, y, lengths, temperature=1.0, margin=0.0, focus_topk=3)\n",
        "\n",
        "            total_hitrate += hitrate * scores.size(0)\n",
        "            total_loss += loss.item() * scores.size(0)\n",
        "            count += scores.size(0)\n",
        "\n",
        "    avg_hitrate = total_hitrate / count\n",
        "    avg_loss = total_loss / count\n",
        "    return avg_loss, avg_hitrate\n",
        "\n",
        "\n",
        "def build_cat_dims(X, cat_features):\n",
        "    cat_dims = {}\n",
        "    for c in cat_features:\n",
        "        max_val = X[c].max()\n",
        "        if max_val < 0:\n",
        "            max_val = 0\n",
        "        cat_dims[c] = max_val + 1\n",
        "    return cat_dims\n",
        "\n",
        "\n",
        "def normalize_numeric_features(X, numeric_features, train_mask):\n",
        "    for col in numeric_features:\n",
        "        values = X[col].to_numpy()\n",
        "        train_vals = values[train_mask]\n",
        "        mean = train_vals.mean()\n",
        "        std = train_vals.std() if train_vals.std() > 0 else 1.0\n",
        "        norm_vals = (values - mean) / std\n",
        "        X = X.with_columns(pl.Series(col, norm_vals).alias(col))\n",
        "    return X\n",
        "\n",
        "\n",
        "def load_or_prepare_data(\n",
        "    data_dir,\n",
        "    train_file=\"train.parquet\",\n",
        "    test_file=\"test.parquet\",\n",
        "    cache_file=\"feature_engineered_val.parquet\",\n",
        "):\n",
        "    cache_path = os.path.join(data_dir, cache_file)\n",
        "\n",
        "    if os.path.exists(cache_path):\n",
        "        print(f\"Loading cached feature-engineered data from {cache_path} ...\")\n",
        "        df = pl.read_parquet(cache_path)\n",
        "\n",
        "        test = pl.read_parquet(os.path.join(data_dir, test_file)).drop(\"__index_level_0__\")\n",
        "        test_ids = test[\"Id\"]\n",
        "        test_rankers = test[\"ranker_id\"]\n",
        "    else:\n",
        "        print(\"Cached file not found, processing raw data ...\")\n",
        "\n",
        "        train = pl.read_parquet(os.path.join(data_dir, train_file)).drop(\"__index_level_0__\")\n",
        "        test = (\n",
        "            pl.read_parquet(os.path.join(data_dir, test_file))\n",
        "            .drop(\"__index_level_0__\")\n",
        "            .with_columns(pl.lit(0, dtype=pl.Int64).alias(\"selected\"))\n",
        "        )\n",
        "\n",
        "        test_ids = test[\"Id\"]\n",
        "        test_rankers = test[\"ranker_id\"]\n",
        "\n",
        "        df = pl.concat((train, test))\n",
        "        df = feature_engineering(df, full=True)\n",
        "\n",
        "        df = df.with_columns(\n",
        "            [pl.col(c).fill_null(0) for c in df.select(pl.selectors.numeric()).columns] +\n",
        "            [pl.col(c).fill_null(\"missing\") for c in df.select(pl.selectors.string()).columns]\n",
        "        )\n",
        "\n",
        "        os.makedirs(data_dir, exist_ok=True)\n",
        "        df.write_parquet(cache_path)\n",
        "        print(f\"Saved feature-engineered data to {cache_path}\")\n",
        "\n",
        "    return df, test_ids, test_rankers\n",
        "\n",
        "\n",
        "def prepare_data(data_dir):\n",
        "    df, test_ids, test_rankers = load_or_prepare_data(data_dir)\n",
        "\n",
        "    id_column = df[\"Id\"]\n",
        "    X, y, groups, cat_features, num_features = feature_selection(df)\n",
        "\n",
        "    X = X.with_columns(pl.Series(\"Id\", id_column[:X.shape[0]]))\n",
        "\n",
        "    X = X.with_columns(\n",
        "        [\n",
        "            (pl.col(c).rank(\"dense\") - 1).fill_null(-1).cast(pl.Int32)\n",
        "            for c in cat_features\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    train_size = 18145372\n",
        "    train_mask = np.arange(X.height) < train_size\n",
        "    X = normalize_numeric_features(X, num_features, train_mask)\n",
        "\n",
        "    return X, y, groups, cat_features, num_features, train_size, test_ids, test_rankers\n",
        "\n",
        "\n",
        "class EarlyStopping:\n",
        "    def __init__(self, patience=3, min_delta=0.001):\n",
        "        self.patience = patience\n",
        "        self.min_delta = min_delta\n",
        "        self.best = float(\"-inf\")\n",
        "        self.counter = 0\n",
        "\n",
        "    def step(self, metric):\n",
        "        if metric > self.best + self.min_delta:\n",
        "            self.best = metric\n",
        "            self.counter = 0\n",
        "        else:\n",
        "            self.counter += 1\n",
        "        return self.counter >= self.patience\n",
        "\n",
        "\n",
        "def plot_group_size_distribution(dataset, save_path=None):\n",
        "    group_sizes = [len(v) for v in dataset.group_to_indices.values()]\n",
        "    plt.figure()\n",
        "    plt.hist(group_sizes, bins=100, log=True)\n",
        "    plt.xlabel(\"Group size (number of items per ranker_id)\")\n",
        "    plt.ylabel(\"Frequency (log scale)\")\n",
        "    plt.title(\"Distribution of Group Sizes\")\n",
        "    plt.grid(True)\n",
        "    if save_path:\n",
        "        plt.savefig(save_path)\n",
        "    else:\n",
        "        plt.show()\n",
        "    plt.close()\n",
        "\n",
        "\n",
        "def main():\n",
        "    DATA_DIR = \"./data\"\n",
        "    MODEL_DIR = \"model\"\n",
        "    SUBMIT_DIR = \"submission\"\n",
        "\n",
        "    model_path = os.path.join(MODEL_DIR, \"best_dl_ranker.pt\")\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    train_losses = []\n",
        "    learning_rates = []\n",
        "\n",
        "    os.makedirs(MODEL_DIR, exist_ok=True)\n",
        "    os.makedirs(SUBMIT_DIR, exist_ok=True)\n",
        "\n",
        "    early_stopper = EarlyStopping(patience=3, min_delta=0.001)\n",
        "\n",
        "    X, y, groups, cat_features, num_features, train_size, test_ids, test_rankers = prepare_data(DATA_DIR)\n",
        "\n",
        "    # Fill missing values\n",
        "    float_cols = [c for c, t in zip(X.columns, X.dtypes) if t == pl.Float64]\n",
        "    for col in float_cols:\n",
        "        X = X.with_columns(\n",
        "            pl.when(pl.col(col).is_nan()).then(0).otherwise(pl.col(col)).alias(col)\n",
        "        )\n",
        "\n",
        "    n2 = train_size\n",
        "\n",
        "    X_tr, X_te = X[:n2], X[n2:]\n",
        "    y_tr, y_te = y[:n2], y[n2:]\n",
        "    groups_tr, groups_te = groups[:n2], groups[n2:]\n",
        "\n",
        "    cat_dims = build_cat_dims(X, cat_features)\n",
        "    num_numeric_feats = len(num_features)\n",
        "\n",
        "    train_dataset = RankDataset(X_tr, y_tr, groups_tr, cat_features, num_features)\n",
        "    test_dataset = RankDataset(X_te, y_te, groups_te, cat_features, num_features)\n",
        "\n",
        "    plot_group_size_distribution(train_dataset, save_path=os.path.join(MODEL_DIR, \"group_sizes.png\"))\n",
        "    print(\"üìä Group size distribution saved.\")\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, collate_fn=collate_fn)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, collate_fn=collate_fn)\n",
        "\n",
        "    print(\"‚úÖ Data loaders created.\")\n",
        "\n",
        "    num_epochs = 10\n",
        "    num_training_steps = num_epochs * len(train_loader)\n",
        "    num_warmup_steps = int(0.1 * num_training_steps)\n",
        "\n",
        "    learning_rate = 1e-3\n",
        "\n",
        "    model = DLRanker(cat_dims, num_numeric_feats).to(device)\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=0.05)\n",
        "\n",
        "    scheduler = get_scheduler(\n",
        "        \"linear\",\n",
        "        optimizer=optimizer,\n",
        "        num_warmup_steps=num_warmup_steps,\n",
        "        num_training_steps=num_training_steps\n",
        "    )\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print(f\"\\n--- Epoch {epoch+1}/{num_epochs} ---\")\n",
        "        start_time = time.time()\n",
        "\n",
        "        train_loss = train_one_epoch(model, train_loader, optimizer, device, scheduler)\n",
        "\n",
        "        train_losses.append(train_loss)\n",
        "\n",
        "        current_lr = scheduler.get_last_lr()\n",
        "        learning_rates.append(current_lr[0])\n",
        "\n",
        "        elapsed = time.time() - start_time\n",
        "        print(\n",
        "            f\"Epoch {epoch+1}: \"\n",
        "            f\"Train Loss={train_loss:.4f}, \"\n",
        "            f\"LR={current_lr[0]:.6f} \"\n",
        "            f\"({elapsed:.1f}s)\"\n",
        "        )\n",
        "\n",
        "        torch.save(model.state_dict(), model_path)\n",
        "        print(\"üíæ Model improved (loss ‚Üì and hitrate ‚Üë), saved.\")\n",
        "\n",
        "    # Plot metrics\n",
        "    epochs = list(range(1, len(train_losses) + 1))\n",
        "\n",
        "    # Predict test set\n",
        "    model.load_state_dict(torch.load(model_path))\n",
        "    model.eval()\n",
        "    all_scores = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for x_cat, x_num, _, lengths in tqdm(test_loader, desc=\"Predicting test set\"):\n",
        "            x_num = x_num.to(device)\n",
        "            x_cat = {k: v.to(device) for k, v in x_cat.items()}\n",
        "            scores = model(x_cat, x_num)\n",
        "\n",
        "            for i in range(scores.size(0)):\n",
        "                l = lengths[i]\n",
        "                all_scores.append(scores[i, :l].cpu().numpy())\n",
        "\n",
        "    all_scores = np.concatenate(all_scores)\n",
        "\n",
        "    assert len(all_scores) == X_te.shape[0], \\\n",
        "        f\"Mismatch: {len(all_scores)} scores vs {X_te.shape[0]} rows in X_te\"\n",
        "\n",
        "    submission_df = pl.DataFrame({\n",
        "        \"Id\": test_ids,\n",
        "        \"ranker_id\": test_rankers,\n",
        "        \"score\": all_scores\n",
        "    })\n",
        "\n",
        "    submission = (\n",
        "        submission_df\n",
        "        .with_columns(\n",
        "            pl.col(\"score\")\n",
        "            .rank(method=\"ordinal\", descending=True)\n",
        "            .over(\"ranker_id\")\n",
        "            .cast(pl.Int32)\n",
        "            .alias(\"selected\")\n",
        "        )\n",
        "        .select([\"Id\", \"ranker_id\", \"selected\"])\n",
        "    )\n",
        "\n",
        "\n",
        "    submission_path = os.path.join(SUBMIT_DIR, \"submission_dl_ranker.parquet\")\n",
        "    submission.write_parquet(submission_path)\n",
        "    print(f\"‚úÖ Submission saved to {submission_path}\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZnNrTWGLNhZg",
        "outputId": "babd026c-e390-43e4-d263-397ba628dc29"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing deeprec_full_training.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "--- Epoch 1/10 ---\n",
        "Epoch 1: Train Loss=0.3564, LR=0.001000 (569.4s)\n",
        "üíæ Model improved (loss ‚Üì and hitrate ‚Üë), saved.\n",
        "\n",
        "--- Epoch 2/10 ---\n",
        "Epoch 2: Train Loss=0.2492, LR=0.000889 (573.5s)\n",
        "üíæ Model improved (loss ‚Üì and hitrate ‚Üë), saved.\n",
        "\n",
        "--- Epoch 3/10 ---\n",
        "Epoch 3: Train Loss=0.2312, LR=0.000778 (573.1s)\n",
        "üíæ Model improved (loss ‚Üì and hitrate ‚Üë), saved.\n",
        "\n",
        "--- Epoch 4/10 ---\n",
        "Epoch 4: Train Loss=0.2243, LR=0.000667 (574.3s)\n",
        "üíæ Model improved (loss ‚Üì and hitrate ‚Üë), saved.\n",
        "\n",
        "--- Epoch 5/10 ---\n",
        "Epoch 5: Train Loss=0.2171, LR=0.000556 (571.1s)\n",
        "üíæ Model improved (loss ‚Üì and hitrate ‚Üë), saved.\n",
        "\n",
        "--- Epoch 6/10 ---\n",
        "Epoch 6: Train Loss=0.2105, LR=0.000444 (574.2s)\n",
        "üíæ Model improved (loss ‚Üì and hitrate ‚Üë), saved.\n",
        "\n",
        "--- Epoch 7/10 ---\n",
        "Epoch 7: Train Loss=0.2025, LR=0.000333 (568.6s)\n",
        "üíæ Model improved (loss ‚Üì and hitrate ‚Üë), saved.\n",
        "\n",
        "--- Epoch 8/10 ---\n",
        "Epoch 8: Train Loss=0.1936, LR=0.000222 (571.2s)\n",
        "üíæ Model improved (loss ‚Üì and hitrate ‚Üë), saved.\n",
        "\n",
        "--- Epoch 9/10 ---\n",
        "Epoch 9: Train Loss=0.1815, LR=0.000111 (569.9s)\n",
        "üíæ Model improved (loss ‚Üì and hitrate ‚Üë), saved.\n",
        "\n",
        "--- Epoch 10/10 ---\n",
        "Epoch 10: Train Loss=0.1667, LR=0.000000 (566.6s)\n",
        "üíæ Model improved (loss ‚Üì and hitrate ‚Üë), saved."
      ],
      "metadata": {
        "id": "c-SMI1VDe-u8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "--- Epoch 1/10 ---\n",
        "Epoch 1: Train Loss=0.3411, LR=0.001000 (1224.7s)\n",
        "üíæ Model improved (loss ‚Üì and hitrate ‚Üë), saved.\n",
        "\n",
        "--- Epoch 2/10 ---\n",
        "Epoch 2: Train Loss=0.2722, LR=0.000889 (1229.7s)\n",
        "üíæ Model improved (loss ‚Üì and hitrate ‚Üë), saved.\n",
        "\n",
        "--- Epoch 3/10 ---\n",
        "Epoch 3: Train Loss=0.2459, LR=0.000778 (1225.9s)\n",
        "üíæ Model improved (loss ‚Üì and hitrate ‚Üë), saved.\n",
        "\n",
        "--- Epoch 4/10 ---\n",
        "Epoch 4: Train Loss=0.2291, LR=0.000667 (1225.6s)\n",
        "üíæ Model improved (loss ‚Üì and hitrate ‚Üë), saved.\n",
        "\n",
        "--- Epoch 5/10 ---\n",
        "Epoch 5: Train Loss=0.2150, LR=0.000556 (1229.9s)\n",
        "üíæ Model improved (loss ‚Üì and hitrate ‚Üë), saved.\n",
        "\n",
        "--- Epoch 6/10 ---\n",
        "Epoch 6: Train Loss=0.2010, LR=0.000444 (1222.5s)\n",
        "üíæ Model improved (loss ‚Üì and hitrate ‚Üë), saved.\n",
        "\n",
        "--- Epoch 7/10 ---\n",
        "Epoch 7: Train Loss=0.1888, LR=0.000333 (1226.2s)\n",
        "üíæ Model improved (loss ‚Üì and hitrate ‚Üë), saved.\n",
        "\n",
        "--- Epoch 8/10 ---\n",
        "Epoch 8: Train Loss=0.1746, LR=0.000222 (1231.7s)\n",
        "üíæ Model improved (loss ‚Üì and hitrate ‚Üë), saved.\n",
        "\n",
        "--- Epoch 9/10 ---\n",
        "Epoch 9: Train Loss=0.1594, LR=0.000111 (1226.1s)\n",
        "üíæ Model improved (loss ‚Üì and hitrate ‚Üë), saved.\n",
        "\n",
        "--- Epoch 10/10 ---\n",
        "Epoch 10: Train Loss=0.1468, LR=0.000000 (1229.2s)\n",
        "üíæ Model improved (loss ‚Üì and hitrate ‚Üë), saved."
      ],
      "metadata": {
        "id": "OEIEVO5W3MFg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile deeprec_validate.py\n",
        "import os\n",
        "import time\n",
        "import random\n",
        "import torch\n",
        "import math\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import defaultdict\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "import polars as pl\n",
        "from tqdm import tqdm\n",
        "from src.feature import feature_engineering, feature_selection\n",
        "from transformers import get_scheduler\n",
        "from collections import Counter\n",
        "\n",
        "class RankDataset(Dataset):\n",
        "    def __init__(\n",
        "        self,\n",
        "        X: pl.DataFrame,\n",
        "        y: pl.Series,\n",
        "        groups: pl.DataFrame,\n",
        "        cat_features: list[str],\n",
        "        num_features: list[str],\n",
        "    ):\n",
        "        self.cat_features = cat_features\n",
        "        self.num_features = num_features\n",
        "        self.X_cat = {c: X[c].to_numpy() for c in cat_features}\n",
        "        self.X_num = X[self.num_features].to_numpy()\n",
        "        self.y = y.to_numpy()\n",
        "        self.groups = groups[\"ranker_id\"].to_numpy()\n",
        "\n",
        "        self.group_to_indices = defaultdict(list)\n",
        "        for i, g in enumerate(self.groups):\n",
        "            self.group_to_indices[g].append(i)\n",
        "        self.group_keys = list(self.group_to_indices.keys())\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.group_keys)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        g = self.group_keys[idx]\n",
        "        inds = self.group_to_indices[g]\n",
        "        length = len(inds)\n",
        "\n",
        "        x_cat = {\n",
        "            c: torch.LongTensor([\n",
        "                self.X_cat[c][i] if self.X_cat[c][i] >= 0 else 0 for i in inds\n",
        "            ])\n",
        "            for c in self.cat_features\n",
        "        }\n",
        "\n",
        "        x_num = torch.FloatTensor(self.X_num[inds])\n",
        "        y = torch.FloatTensor(self.y[inds]).reshape(-1)\n",
        "\n",
        "        return x_cat, x_num, y, length\n",
        "\n",
        "def collate_fn(batch):\n",
        "    batch_size = len(batch)\n",
        "    lengths = [b[3] for b in batch]\n",
        "    max_len = max(lengths)\n",
        "\n",
        "    padded_x_cat = {key: [] for key in batch[0][0].keys()}\n",
        "    padded_x_num = []\n",
        "    padded_y = []\n",
        "\n",
        "    num_dim = batch[0][1].shape[1]\n",
        "\n",
        "    for x_cat, x_num, y, length in batch:\n",
        "        pad_len = max_len - length\n",
        "\n",
        "        for key in padded_x_cat:\n",
        "            val = x_cat[key]\n",
        "            if pad_len > 0:\n",
        "                val = torch.cat([val, torch.zeros(pad_len, dtype=torch.long)])\n",
        "            padded_x_cat[key].append(val)\n",
        "\n",
        "        if pad_len > 0:\n",
        "            x_num = torch.cat([x_num, torch.zeros(pad_len, num_dim)])\n",
        "            y = torch.cat([y, torch.zeros(pad_len)])\n",
        "\n",
        "        padded_x_num.append(x_num)\n",
        "        padded_y.append(y)\n",
        "\n",
        "    padded_x_cat = {k: torch.stack(v) for k, v in padded_x_cat.items()}\n",
        "    padded_x_num = torch.stack(padded_x_num)\n",
        "    padded_y = torch.stack(padded_y)\n",
        "    lengths = torch.tensor(lengths, dtype=torch.long)\n",
        "\n",
        "    return padded_x_cat, padded_x_num, padded_y, lengths\n",
        "\n",
        "class DLRanker(nn.Module):\n",
        "    def __init__(self, cat_dims, num_numeric_feats, emb_dim=64, hidden=[512, 256, 128, 64]):\n",
        "        super().__init__()\n",
        "\n",
        "        self.embeddings = nn.ModuleDict({\n",
        "            f: nn.Embedding(cat_dims[f], emb_dim, padding_idx=0) for f in cat_dims\n",
        "        })\n",
        "        self.linear_cat = nn.ModuleDict({\n",
        "            f: nn.Embedding(cat_dims[f], 1, padding_idx=0) for f in cat_dims\n",
        "        })\n",
        "\n",
        "        for emb in list(self.embeddings.values()) + list(self.linear_cat.values()):\n",
        "            nn.init.xavier_uniform_(emb.weight)\n",
        "\n",
        "        self.linear_num = nn.Linear(num_numeric_feats, 1)\n",
        "        nn.init.xavier_uniform_(self.linear_num.weight)\n",
        "\n",
        "        input_dim = emb_dim * len(cat_dims) + num_numeric_feats\n",
        "        layers = []\n",
        "        for h in hidden:\n",
        "            layers.append(nn.Linear(input_dim, h))\n",
        "            layers.append(nn.BatchNorm1d(h))\n",
        "            layers.append(nn.ReLU())\n",
        "            layers.append(nn.Dropout(0.1))\n",
        "            input_dim = h\n",
        "        self.mlp = nn.Sequential(*layers)\n",
        "        self.output = nn.Linear(input_dim, 1)\n",
        "\n",
        "    def forward(self, x_cat, x_num):\n",
        "        batch_size, group_size = x_num.shape[:2]\n",
        "\n",
        "        linear_cat_sum = torch.stack([\n",
        "            self.linear_cat[f](x_cat[f]).squeeze(-1)\n",
        "            for f in self.linear_cat\n",
        "        ], dim=0).sum(dim=0)\n",
        "\n",
        "        linear_num_out = self.linear_num(x_num).squeeze(-1)\n",
        "        linear_out = linear_cat_sum + linear_num_out\n",
        "\n",
        "        embs = torch.stack([\n",
        "            self.embeddings[f](x_cat[f]) for f in self.embeddings\n",
        "        ], dim=2)\n",
        "\n",
        "        sum_emb = embs.sum(dim=2)\n",
        "        sum_emb_square = sum_emb ** 2\n",
        "        square_emb_sum = (embs ** 2).sum(dim=2)\n",
        "        fm_out = 0.0\n",
        "        # fm_out = 0.5 * (sum_emb_square - square_emb_sum).sum(dim=2)\n",
        "\n",
        "        embs_cat = embs.reshape(batch_size * group_size, -1)\n",
        "        x_num_flat = x_num.reshape(batch_size * group_size, -1)\n",
        "        deep_input = torch.cat([embs_cat, x_num_flat], dim=1)\n",
        "        deep_out = self.mlp(deep_input)\n",
        "        deep_out = self.output(deep_out).view(batch_size, group_size)\n",
        "\n",
        "        return linear_out + fm_out + deep_out\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "def listmle_loss(scores, labels, lengths):\n",
        "    batch_size = scores.size(0)\n",
        "    total_loss = torch.tensor(0.0, device=scores.device, requires_grad=True)\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "\n",
        "        _, idx = torch.sort(y, descending=True)\n",
        "        s_sorted = s[idx]\n",
        "\n",
        "        parts = (\n",
        "            torch.logsumexp(s_sorted.unsqueeze(0).expand(l, -1).triu(diagonal=0), dim=1)\n",
        "            - s_sorted\n",
        "        )\n",
        "\n",
        "        total_loss = total_loss + parts.sum()\n",
        "\n",
        "    return total_loss / batch_size\n",
        "\"\"\"\n",
        "\n",
        "def hitrate_at_k(scores, labels, lengths, k=3, min_group_size=10):\n",
        "    batch_size = scores.size(0)\n",
        "    hits = 0\n",
        "    valid_count = 0\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        if l < min_group_size:\n",
        "            continue\n",
        "        length = min(l, k)\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "        _, topk_idx = torch.topk(s, length)\n",
        "        topk_labels = y[topk_idx]\n",
        "        hits += (topk_labels > 0).any().float()\n",
        "        valid_count += 1\n",
        "    return hits / valid_count if valid_count > 0 else torch.tensor(0.0, device=scores.device)\n",
        "\n",
        "\n",
        "def ndcg_at_k(scores, labels, lengths, k=3, min_group_size=10):\n",
        "    batch_size = scores.size(0)\n",
        "    total_ndcg = 0.0\n",
        "    valid_count = 0\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        if l < min_group_size:\n",
        "            continue\n",
        "\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "\n",
        "        _, idx_pred = torch.topk(s, min(k, l))\n",
        "        _, idx_ideal = torch.topk(y, min(k, l))\n",
        "\n",
        "        dcg = (y[idx_pred] / torch.log2(torch.arange(2, 2 + len(idx_pred), device=y.device).float())).sum()\n",
        "        idcg = (y[idx_ideal] / torch.log2(torch.arange(2, 2 + len(idx_ideal), device=y.device).float())).sum()\n",
        "\n",
        "        ndcg = dcg / idcg if idcg > 0 else 0.0\n",
        "        total_ndcg += ndcg\n",
        "        valid_count += 1\n",
        "\n",
        "    return total_ndcg / valid_count if valid_count > 0 else torch.tensor(0.0, device=scores.device)\n",
        "\n",
        "\n",
        "def map_at_k(scores, labels, lengths, k=3, min_group_size=10):\n",
        "    batch_size = scores.size(0)\n",
        "    total_ap = 0.0\n",
        "    valid_count = 0\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        if l < min_group_size:\n",
        "            continue\n",
        "\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "\n",
        "        _, idx_pred = torch.topk(s, min(k, l))\n",
        "        y_true = y[idx_pred] > 0\n",
        "\n",
        "        if y_true.sum() == 0:\n",
        "            continue\n",
        "\n",
        "        precisions = [(y_true[:j+1].float().sum() / (j+1)) for j in range(len(y_true)) if y_true[j]]\n",
        "        ap = torch.stack(precisions).mean()\n",
        "        total_ap += ap\n",
        "        valid_count += 1\n",
        "\n",
        "    return total_ap / valid_count if valid_count > 0 else torch.tensor(0.0, device=scores.device)\n",
        "\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "def listnet_loss(scores, labels, lengths):\n",
        "    batch_size = scores.size(0)\n",
        "    total_loss = 0.0\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "\n",
        "        s_softmax = torch.nn.functional.log_softmax(s, dim=0)\n",
        "        y_softmax = torch.nn.functional.softmax(y, dim=0)\n",
        "\n",
        "        loss = -torch.sum(y_softmax * s_softmax)\n",
        "        total_loss += loss\n",
        "\n",
        "    return total_loss / batch_size\n",
        "\"\"\"\n",
        "\n",
        "def ranknet_loss(scores, labels, lengths):\n",
        "    batch_size = scores.size(0)\n",
        "    total_loss = 0.0\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "\n",
        "        diff_scores = s.unsqueeze(1) - s.unsqueeze(0)\n",
        "        rel = y.unsqueeze(1) > y.unsqueeze(0)\n",
        "        label_diff = rel.float()\n",
        "\n",
        "        log_sigmoid = torch.nn.functional.logsigmoid(diff_scores)\n",
        "        pair_loss = -label_diff * log_sigmoid\n",
        "\n",
        "        total_loss += pair_loss.sum()\n",
        "\n",
        "    return total_loss / batch_size\n",
        "\n",
        "def xranknet_loss(scores, labels, lengths, temperature=1.0, margin=0.2, focus_topk=3):\n",
        "    \"\"\"\n",
        "    xRankNet with emphasis on top-K items (based on labels, not scores).\n",
        "    \"\"\"\n",
        "    batch_size = scores.size(0)\n",
        "    total_loss = 0.0\n",
        "    total_pairs = 0\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        if l < 2:\n",
        "            continue\n",
        "\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "\n",
        "        # Top-K mask based on ground truth labels\n",
        "        topk = min(focus_topk, l)\n",
        "        _, topk_idx = torch.topk(y, topk)\n",
        "        topk_mask = torch.zeros_like(y, dtype=torch.bool)\n",
        "        topk_mask[topk_idx] = True\n",
        "\n",
        "        # Create pairwise difference matrices\n",
        "        score_diff = s.unsqueeze(1) - s.unsqueeze(0)\n",
        "        label_diff = y.unsqueeze(1) - y.unsqueeze(0)\n",
        "\n",
        "        # valid pair: y_i > y_j and at least one of i, j is in top-K\n",
        "        valid_pairs = (label_diff > 0) & (\n",
        "            topk_mask.unsqueeze(1) | topk_mask.unsqueeze(0)\n",
        "        )\n",
        "\n",
        "        if valid_pairs.sum() == 0:\n",
        "            continue\n",
        "\n",
        "        importance = (label_diff.abs() * valid_pairs).float()\n",
        "\n",
        "        if margin > 0.0:\n",
        "            score_diff = score_diff - margin\n",
        "\n",
        "        score_diff = score_diff / temperature\n",
        "        pairwise_loss = -F.logsigmoid(score_diff) * importance\n",
        "\n",
        "        total_loss += pairwise_loss.sum()\n",
        "        total_pairs += importance.sum()\n",
        "\n",
        "    if total_pairs == 0:\n",
        "        return torch.tensor(0.0, device=scores.device, requires_grad=True)\n",
        "\n",
        "    return total_loss / total_pairs\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "def bpr_loss(scores, labels, lengths):\n",
        "    batch_size = scores.size(0)\n",
        "    total_loss = 0.0\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "\n",
        "        pos_mask = y > 0\n",
        "        neg_mask = y <= 0\n",
        "\n",
        "        pos_scores = s[pos_mask]\n",
        "        neg_scores = s[neg_mask]\n",
        "\n",
        "        if len(pos_scores) == 0 or len(neg_scores) == 0:\n",
        "            continue\n",
        "\n",
        "        pair_diff = pos_scores.unsqueeze(1) - neg_scores.unsqueeze(0)\n",
        "        loss = -F.logsigmoid(pair_diff).mean()\n",
        "        total_loss += loss\n",
        "\n",
        "    return total_loss / batch_size\n",
        "\"\"\"\n",
        "\n",
        "\"\"\"\n",
        "def lambdarank_loss(scores, labels, lengths, eps=1e-10):\n",
        "    batch_size = scores.size(0)\n",
        "    total_loss = 0.0\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "\n",
        "        if l < 2:\n",
        "            continue\n",
        "\n",
        "        _, rank_order = torch.sort(s, descending=True)\n",
        "        ideal_order = torch.sort(y, descending=True).indices\n",
        "\n",
        "        gain = 2 ** y - 1\n",
        "        discount = torch.log2(torch.arange(2, l + 2, device=y.device).float())\n",
        "\n",
        "        ideal_dcg = (gain[ideal_order] / discount).sum()\n",
        "        if ideal_dcg < eps:\n",
        "            continue\n",
        "\n",
        "        delta_ndcg = torch.zeros((l, l), device=y.device)\n",
        "\n",
        "        for i_idx in range(l):\n",
        "            for j_idx in range(l):\n",
        "                if y[i_idx] > y[j_idx]:\n",
        "                    change = (\n",
        "                        (1.0 / torch.log2(rank_order[i_idx] + 2.0))\n",
        "                        - (1.0 / torch.log2(rank_order[j_idx] + 2.0))\n",
        "                    ).abs()\n",
        "                    delta = (2 ** y[i_idx] - 2 ** y[j_idx]).abs() * change\n",
        "                    delta_ndcg[i_idx, j_idx] = delta / ideal_dcg\n",
        "\n",
        "        score_diffs = s.unsqueeze(1) - s.unsqueeze(0)\n",
        "        lambdas = -F.logsigmoid(score_diffs) * delta_ndcg\n",
        "        total_loss += lambdas.sum()\n",
        "\n",
        "    return total_loss / batch_size\n",
        "\"\"\"\n",
        "\n",
        "def train_one_epoch(model, loader, optimizer, device, scheduler):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "\n",
        "    for x_cat, x_num, y, lengths in tqdm(loader, desc=\"Training\", leave=False):\n",
        "        x_num, y = x_num.to(device), y.to(device)\n",
        "        if not isinstance(lengths, torch.Tensor):\n",
        "            lengths = torch.tensor(lengths)\n",
        "        lengths = lengths.detach().clone().to(device)\n",
        "        x_cat = {k: v.to(device) for k, v in x_cat.items()}\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        scores = model(x_cat, x_num)\n",
        "        loss = xranknet_loss(scores, y, lengths, temperature=1.0, margin=0.0, focus_topk=3)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    return total_loss / len(loader)\n",
        "\n",
        "\n",
        "def validate(model, loader, device, min_group_size=10):\n",
        "    model.eval()\n",
        "    total_hitrate = 0\n",
        "    total_ndcg = 0\n",
        "    total_map = 0\n",
        "    total_loss = 0\n",
        "    count = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for x_cat, x_num, y, lengths in tqdm(loader, desc=\"Validating\", leave=False):\n",
        "            x_num, y = x_num.to(device), y.to(device)\n",
        "            lengths = torch.tensor(lengths).to(device)\n",
        "            x_cat = {k: v.to(device) for k, v in x_cat.items()}\n",
        "\n",
        "            scores = model(x_cat, x_num)\n",
        "\n",
        "            hitrate = hitrate_at_k(scores, y, lengths, k=3, min_group_size=min_group_size)\n",
        "            ndcg = ndcg_at_k(scores, y, lengths, k=3, min_group_size=min_group_size)\n",
        "            map3 = map_at_k(scores, y, lengths, k=3, min_group_size=min_group_size)\n",
        "            loss = xranknet_loss(scores, y, lengths, temperature=1.0, margin=0.0, focus_topk=3)\n",
        "\n",
        "            batch_size = scores.size(0)\n",
        "            total_hitrate += hitrate * batch_size\n",
        "            total_ndcg += ndcg * batch_size\n",
        "            total_map += map3 * batch_size\n",
        "            total_loss += loss.item() * batch_size\n",
        "            count += batch_size\n",
        "\n",
        "    return total_loss / count, total_hitrate / count, total_ndcg / count, total_map / count\n",
        "\n",
        "\n",
        "def build_cat_dims(X, cat_features):\n",
        "    cat_dims = {}\n",
        "    for c in cat_features:\n",
        "        max_val = X[c].max()\n",
        "        if max_val < 0:\n",
        "            max_val = 0\n",
        "        cat_dims[c] = max_val + 1\n",
        "    return cat_dims\n",
        "\n",
        "\n",
        "def normalize_numeric_features(X, numeric_features, train_mask):\n",
        "    for col in numeric_features:\n",
        "        values = X[col].to_numpy()\n",
        "        train_vals = values[train_mask]\n",
        "        mean = train_vals.mean()\n",
        "        std = train_vals.std() if train_vals.std() > 0 else 1.0\n",
        "        norm_vals = (values - mean) / std\n",
        "        X = X.with_columns(pl.Series(col, norm_vals).alias(col))\n",
        "    return X\n",
        "\n",
        "\n",
        "def load_or_prepare_data(\n",
        "    data_dir,\n",
        "    train_file=\"train.parquet\",\n",
        "    test_file=\"test.parquet\",\n",
        "    cache_file=\"feature_engineered_val.parquet\",\n",
        "):\n",
        "    cache_path = os.path.join(data_dir, cache_file)\n",
        "\n",
        "    if os.path.exists(cache_path):\n",
        "        print(f\"Loading cached feature-engineered data from {cache_path} ...\")\n",
        "        df = pl.read_parquet(cache_path)\n",
        "\n",
        "        test = pl.read_parquet(os.path.join(data_dir, test_file)).drop(\"__index_level_0__\")\n",
        "        test_ids = test[\"Id\"]\n",
        "        test_rankers = test[\"ranker_id\"]\n",
        "    else:\n",
        "        print(\"Cached file not found, processing raw data ...\")\n",
        "\n",
        "        train = pl.read_parquet(os.path.join(data_dir, train_file)).drop(\"__index_level_0__\")\n",
        "        test = (\n",
        "            pl.read_parquet(os.path.join(data_dir, test_file))\n",
        "            .drop(\"__index_level_0__\")\n",
        "            .with_columns(pl.lit(0, dtype=pl.Int64).alias(\"selected\"))\n",
        "        )\n",
        "\n",
        "        test_ids = test[\"Id\"]\n",
        "        test_rankers = test[\"ranker_id\"]\n",
        "\n",
        "        df = pl.concat((train, test))\n",
        "        df = feature_engineering(df, full=True)\n",
        "\n",
        "        df = df.with_columns(\n",
        "            [pl.col(c).fill_null(0) for c in df.select(pl.selectors.numeric()).columns] +\n",
        "            [pl.col(c).fill_null(\"missing\") for c in df.select(pl.selectors.string()).columns]\n",
        "        )\n",
        "\n",
        "        os.makedirs(data_dir, exist_ok=True)\n",
        "        df.write_parquet(cache_path)\n",
        "        print(f\"Saved feature-engineered data to {cache_path}\")\n",
        "\n",
        "    return df, test_ids, test_rankers\n",
        "\n",
        "\n",
        "def prepare_data(data_dir):\n",
        "    df, test_ids, test_rankers = load_or_prepare_data(data_dir)\n",
        "\n",
        "    id_column = df[\"Id\"]\n",
        "    X, y, groups, cat_features, num_features = feature_selection(df)\n",
        "\n",
        "    X = X.with_columns(pl.Series(\"Id\", id_column[:X.shape[0]]))\n",
        "\n",
        "    X = X.with_columns(\n",
        "        [\n",
        "            (pl.col(c).rank(\"dense\") - 1).fill_null(-1).cast(pl.Int32)\n",
        "            for c in cat_features\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    train_size = 18145372\n",
        "    train_mask = np.arange(X.height) < train_size\n",
        "    X = normalize_numeric_features(X, num_features, train_mask)\n",
        "\n",
        "    return X, y, groups, cat_features, num_features, train_size, test_ids, test_rankers\n",
        "\n",
        "\n",
        "class EarlyStopping:\n",
        "    def __init__(self, patience=3, min_delta=0.00005):\n",
        "        self.patience = patience\n",
        "        self.min_delta = min_delta\n",
        "        self.best = float(\"-inf\")\n",
        "        self.counter = 0\n",
        "\n",
        "    def step(self, metric):\n",
        "        if metric > self.best + self.min_delta:\n",
        "            self.best = metric\n",
        "            self.counter = 0\n",
        "        else:\n",
        "            self.counter += 1\n",
        "        return self.counter >= self.patience\n",
        "\n",
        "\n",
        "def plot_group_size_distribution(dataset, save_path=None):\n",
        "    group_sizes = [len(v) for v in dataset.group_to_indices.values()]\n",
        "    plt.figure()\n",
        "    plt.hist(group_sizes, bins=100, log=True)\n",
        "    plt.xlabel(\"Group size (number of items per ranker_id)\")\n",
        "    plt.ylabel(\"Frequency (log scale)\")\n",
        "    plt.title(\"Distribution of Group Sizes\")\n",
        "    plt.grid(True)\n",
        "    if save_path:\n",
        "        plt.savefig(save_path)\n",
        "    else:\n",
        "        plt.show()\n",
        "    plt.close()\n",
        "\n",
        "\n",
        "def main():\n",
        "    DATA_DIR = \"./data\"\n",
        "    MODEL_DIR = \"model\"\n",
        "    SUBMIT_DIR = \"submission\"\n",
        "\n",
        "    best_val_loss = float(\"inf\")\n",
        "    best_hitrate = 0.0\n",
        "    model_path = os.path.join(MODEL_DIR, \"best_dl_ranker.pt\")\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "    val_hitrates = []\n",
        "    val_ndcgs = []\n",
        "    val_maps = []\n",
        "    learning_rates = []\n",
        "\n",
        "    os.makedirs(MODEL_DIR, exist_ok=True)\n",
        "    os.makedirs(SUBMIT_DIR, exist_ok=True)\n",
        "\n",
        "    early_stopper = EarlyStopping(patience=3, min_delta=0.001)\n",
        "\n",
        "    X, y, groups, cat_features, num_features, train_size, test_ids, test_rankers = prepare_data(DATA_DIR)\n",
        "\n",
        "    # Fill missing values\n",
        "    float_cols = [c for c, t in zip(X.columns, X.dtypes) if t == pl.Float64]\n",
        "    for col in float_cols:\n",
        "        X = X.with_columns(\n",
        "            pl.when(pl.col(col).is_nan()).then(0).otherwise(pl.col(col)).alias(col)\n",
        "        )\n",
        "\n",
        "    n1 = 16487352\n",
        "    # n1 = 17487300\n",
        "    n2 = train_size\n",
        "\n",
        "    X_tr, X_va, X_te = X[:n1], X[n1:n2], X[n2:]\n",
        "    y_tr, y_va, y_te = y[:n1], y[n1:n2], y[n2:]\n",
        "    groups_tr, groups_va, groups_te = groups[:n1], groups[n1:n2], groups[n2:]\n",
        "\n",
        "    print(\"\\nüìä Distribu»õia is_one_way √Æn setul de antrenare:\")\n",
        "    print(X_tr[\"is_one_way\"].value_counts().sort(\"is_one_way\"))\n",
        "\n",
        "    print(\"\\nüìä Distribu»õia is_one_way √Æn setul de validare:\")\n",
        "    print(X_va[\"is_one_way\"].value_counts().sort(\"is_one_way\"))\n",
        "\n",
        "    print(\"\\nüìä Distribu»õia is_one_way √Æn setul de test:\")\n",
        "    print(X_te[\"is_one_way\"].value_counts().sort(\"is_one_way\"))\n",
        "\n",
        "    # Inspect group sizes in validation set\n",
        "    val_rankers = groups_va[\"ranker_id\"].to_numpy()\n",
        "    val_group_counts = Counter(val_rankers)\n",
        "\n",
        "    print(\"\\nüìã Validation group statistics:\")\n",
        "    # Save detailed group info to file\n",
        "    group_info_path = os.path.join(MODEL_DIR, \"validation_groups_info.txt\")\n",
        "    with open(group_info_path, \"w\") as f:\n",
        "        f.write(f\"Total groups: {len(val_group_counts)}\\n\\n\")\n",
        "        f.write(\"GroupID\\tSize\\tStartIdx\\tEndIdx\\n\")\n",
        "\n",
        "        group_to_rows = defaultdict(list)\n",
        "        for i, g in enumerate(val_rankers):\n",
        "            group_to_rows[g].append(i)\n",
        "\n",
        "        for group_id, indices in sorted(group_to_rows.items()):\n",
        "            start_idx = indices[0]\n",
        "            end_idx = indices[-1]\n",
        "            size = len(indices)\n",
        "            f.write(f\"{group_id}\\t{size}\\t{start_idx}\\t{end_idx}\\n\")\n",
        "\n",
        "    print(f\"üìÅ Saved validation group info to {group_info_path}\")\n",
        "\n",
        "    cat_dims = build_cat_dims(X, cat_features)\n",
        "    num_numeric_feats = len(num_features)\n",
        "\n",
        "    train_dataset = RankDataset(X_tr, y_tr, groups_tr, cat_features, num_features)\n",
        "    val_dataset = RankDataset(X_va, y_va, groups_va, cat_features, num_features)\n",
        "    test_dataset = RankDataset(X_te, y_te, groups_te, cat_features, num_features)\n",
        "\n",
        "    plot_group_size_distribution(train_dataset, save_path=os.path.join(MODEL_DIR, \"group_sizes.png\"))\n",
        "    print(\"üìä Group size distribution saved.\")\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True, collate_fn=collate_fn)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=4, shuffle=False, collate_fn=collate_fn)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False, collate_fn=collate_fn)\n",
        "\n",
        "    print(\"‚úÖ Data loaders created.\")\n",
        "\n",
        "    num_epochs = 10\n",
        "    num_training_steps = num_epochs * len(train_loader)\n",
        "    num_warmup_steps = int(0.1 * num_training_steps)\n",
        "\n",
        "    learning_rate = 1e-3\n",
        "\n",
        "    model = DLRanker(cat_dims, num_numeric_feats).to(device)\n",
        "\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=0.01)\n",
        "\n",
        "    scheduler = get_scheduler(\n",
        "        \"linear\",\n",
        "        optimizer=optimizer,\n",
        "        num_warmup_steps=num_warmup_steps,\n",
        "        num_training_steps=num_training_steps\n",
        "    )\n",
        "\n",
        "    best_hitrate = 0\n",
        "    for epoch in range(num_epochs):\n",
        "        print(f\"\\n--- Epoch {epoch+1}/{num_epochs} ---\")\n",
        "        start_time = time.time()\n",
        "\n",
        "        train_loss = train_one_epoch(model, train_loader, optimizer, device, scheduler)\n",
        "        val_loss, val_hitrate, val_ndcg, val_map = validate(model, val_loader, device, min_group_size=10)\n",
        "\n",
        "        train_losses.append(train_loss)\n",
        "        val_losses.append(val_loss)\n",
        "        val_hitrates.append(val_hitrate.item())\n",
        "        val_ndcgs.append(val_ndcg.item())\n",
        "        val_maps.append(val_map.item())\n",
        "\n",
        "        current_lr = scheduler.get_last_lr()\n",
        "        learning_rates.append(current_lr[0])\n",
        "\n",
        "        elapsed = time.time() - start_time\n",
        "        print(\n",
        "            f\"Epoch {epoch+1}: \"\n",
        "            f\"Train Loss={train_loss:.4f}, \"\n",
        "            f\"Val Loss={val_loss:.4f}, \"\n",
        "            f\"HitRate@3={val_hitrate:.4f}, \"\n",
        "            f\"NDCG@3={val_ndcg:.4f}, \"\n",
        "            f\"MAP@3={val_map:.4f}, \"\n",
        "            f\"LR={current_lr[0]:.6f} \"\n",
        "            f\"({elapsed:.1f}s)\"\n",
        "        )\n",
        "\n",
        "\n",
        "        if val_loss < best_val_loss and val_hitrate > best_hitrate:\n",
        "            best_val_loss = val_loss\n",
        "            best_hitrate = val_hitrate\n",
        "            torch.save(model.state_dict(), model_path)\n",
        "            print(\"üíæ Model improved (loss ‚Üì and hitrate ‚Üë), saved.\")\n",
        "\n",
        "        if early_stopper.step(-val_loss):\n",
        "            print(\"‚õî Early stopping triggered.\")\n",
        "            break\n",
        "\n",
        "    # Plot metrics\n",
        "    epochs = list(range(1, len(train_losses) + 1))\n",
        "\n",
        "    # Plot Loss Curve\n",
        "    plt.figure()\n",
        "    plt.plot(epochs, train_losses, label=\"Train Loss\")\n",
        "    plt.plot(epochs, val_losses, label=\"Val Loss\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.title(\"Training & Validation Loss\")\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.savefig(os.path.join(MODEL_DIR, \"loss_curve.png\"))\n",
        "    plt.close()\n",
        "\n",
        "    # Plot HitRate@3\n",
        "    plt.figure()\n",
        "    plt.plot(epochs, val_hitrates, label=\"Val HitRate@3\", color=\"green\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"HitRate@3\")\n",
        "    plt.title(\"Validation HitRate@3\")\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.savefig(os.path.join(MODEL_DIR, \"hitrate_curve.png\"))\n",
        "    plt.close()\n",
        "\n",
        "    # Plot Learning Rate\n",
        "    plt.figure()\n",
        "    plt.plot(epochs, learning_rates, label=\"Learning Rate\", color=\"orange\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"LR\")\n",
        "    plt.title(\"Learning Rate Schedule\")\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.savefig(os.path.join(MODEL_DIR, \"lr_curve.png\"))\n",
        "    plt.close()\n",
        "\n",
        "    # Plot NDCG@3\n",
        "    plt.figure()\n",
        "    plt.plot(epochs, val_ndcgs, label=\"Val NDCG@3\", color=\"purple\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"NDCG@3\")\n",
        "    plt.title(\"Validation NDCG@3\")\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.savefig(os.path.join(MODEL_DIR, \"ndcg_curve.png\"))\n",
        "    plt.close()\n",
        "\n",
        "    # Plot MAP@3\n",
        "    plt.figure()\n",
        "    plt.plot(epochs, val_maps, label=\"Val MAP@3\", color=\"red\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"MAP@3\")\n",
        "    plt.title(\"Validation MAP@3\")\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.savefig(os.path.join(MODEL_DIR, \"map_curve.png\"))\n",
        "    plt.close()\n",
        "\n",
        "    print(\"üìä Saved metric plots to model/\")\n",
        "\n",
        "    # Predict test set\n",
        "    model.load_state_dict(torch.load(model_path))\n",
        "    model.eval()\n",
        "\n",
        "    val_ids = X_va[\"Id\"]\n",
        "    val_rankers = groups_va[\"ranker_id\"]\n",
        "    val_labels = y_va\n",
        "\n",
        "    all_val_scores = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for x_cat, x_num, _, lengths in tqdm(val_loader, desc=\"Predicting validation set\"):\n",
        "            x_num = x_num.to(device)\n",
        "            x_cat = {k: v.to(device) for k, v in x_cat.items()}\n",
        "            scores = model(x_cat, x_num)\n",
        "\n",
        "            for i in range(scores.size(0)):\n",
        "                l = lengths[i]\n",
        "                all_val_scores.append(scores[i, :l].cpu().numpy())\n",
        "\n",
        "    all_val_scores = np.concatenate(all_val_scores)\n",
        "\n",
        "    assert len(all_val_scores) == X_va.shape[0], \\\n",
        "        f\"Mismatch: {len(all_val_scores)} scores vs {X_va.shape[0]} rows\"\n",
        "\n",
        "    val_df = X_va.with_columns([\n",
        "        pl.Series(\"Id\", val_ids),\n",
        "        pl.Series(\"ranker_id\", val_rankers),\n",
        "        pl.Series(\"score\", all_val_scores),\n",
        "        pl.Series(\"label\", val_labels)\n",
        "    ])\n",
        "\n",
        "    val_df = val_df.with_columns(\n",
        "        pl.col(\"score\")\n",
        "        .rank(method=\"ordinal\", descending=True)\n",
        "        .over(\"ranker_id\")\n",
        "        .cast(pl.Int32)\n",
        "        .alias(\"selected\")\n",
        "    )\n",
        "\n",
        "    val_save_path = os.path.join(MODEL_DIR, \"validation_preds_dl_full.parquet\")\n",
        "    val_df.write_parquet(val_save_path)\n",
        "    print(f\"‚úÖ Saved full validation predictions (with features) to {val_save_path}\")\n",
        "\n",
        "    all_scores = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for x_cat, x_num, _, lengths in tqdm(test_loader, desc=\"Predicting test set\"):\n",
        "            x_num = x_num.to(device)\n",
        "            x_cat = {k: v.to(device) for k, v in x_cat.items()}\n",
        "            scores = model(x_cat, x_num)\n",
        "\n",
        "            for i in range(scores.size(0)):\n",
        "                l = lengths[i]\n",
        "                all_scores.append(scores[i, :l].cpu().numpy())\n",
        "\n",
        "    all_scores = np.concatenate(all_scores)\n",
        "\n",
        "    assert len(all_scores) == X_te.shape[0], \\\n",
        "        f\"Mismatch: {len(all_scores)} scores vs {X_te.shape[0]} rows in X_te\"\n",
        "\n",
        "    submission_df = pl.DataFrame({\n",
        "        \"Id\": test_ids,\n",
        "        \"ranker_id\": test_rankers,\n",
        "        \"score\": all_scores\n",
        "    })\n",
        "\n",
        "    submission = (\n",
        "        submission_df\n",
        "        .with_columns(\n",
        "            pl.col(\"score\")\n",
        "            .rank(method=\"ordinal\", descending=True)\n",
        "            .over(\"ranker_id\")\n",
        "            .cast(pl.Int32)\n",
        "            .alias(\"selected\")\n",
        "        )\n",
        "        .select([\"Id\", \"ranker_id\", \"score\", \"selected\"])\n",
        "    )\n",
        "\n",
        "    submission_path = os.path.join(SUBMIT_DIR, \"submission_dl_ranker.parquet\")\n",
        "    submission.write_parquet(submission_path)\n",
        "    print(f\"‚úÖ Submission saved to {submission_path}\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j2DWS7JvEjfv",
        "outputId": "edf62699-9533-4e8e-f1a4-db6d1ff43718"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting deeprec_validate.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **FibiNet**"
      ],
      "metadata": {
        "id": "SFrfi9fHZtv1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile deeprec_validate.py\n",
        "import os\n",
        "import time\n",
        "import random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F_torch\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import defaultdict\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "import polars as pl\n",
        "from tqdm import tqdm\n",
        "from src.feature import feature_engineering, feature_selection\n",
        "from transformers import get_scheduler\n",
        "from collections import Counter\n",
        "\n",
        "class RankDataset(Dataset):\n",
        "    def __init__(\n",
        "        self,\n",
        "        X: pl.DataFrame,\n",
        "        y: pl.Series,\n",
        "        groups: pl.DataFrame,\n",
        "        cat_features: list[str],\n",
        "        num_features: list[str],\n",
        "    ):\n",
        "        self.cat_features = cat_features\n",
        "        self.num_features = num_features\n",
        "        self.X_cat = {c: X[c].to_numpy() for c in cat_features}\n",
        "        self.X_num = X[self.num_features].to_numpy()\n",
        "        self.y = y.to_numpy()\n",
        "        self.groups = groups[\"ranker_id\"].to_numpy()\n",
        "\n",
        "        self.group_to_indices = defaultdict(list)\n",
        "        for i, g in enumerate(self.groups):\n",
        "            self.group_to_indices[g].append(i)\n",
        "        self.group_keys = list(self.group_to_indices.keys())\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.group_keys)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        g = self.group_keys[idx]\n",
        "        inds = self.group_to_indices[g]\n",
        "        length = len(inds)\n",
        "\n",
        "        x_cat = {\n",
        "            c: torch.LongTensor([\n",
        "                self.X_cat[c][i] if self.X_cat[c][i] >= 0 else 0 for i in inds\n",
        "            ])\n",
        "            for c in self.cat_features\n",
        "        }\n",
        "\n",
        "        x_num = torch.FloatTensor(self.X_num[inds])\n",
        "        y = torch.FloatTensor(self.y[inds]).reshape(-1)\n",
        "\n",
        "        return x_cat, x_num, y, length\n",
        "\n",
        "def collate_fn(batch):\n",
        "    batch_size = len(batch)\n",
        "    lengths = [b[3] for b in batch]\n",
        "    max_len = max(lengths)\n",
        "\n",
        "    padded_x_cat = {key: [] for key in batch[0][0].keys()}\n",
        "    padded_x_num = []\n",
        "    padded_y = []\n",
        "\n",
        "    num_dim = batch[0][1].shape[1]\n",
        "\n",
        "    for x_cat, x_num, y, length in batch:\n",
        "        pad_len = max_len - length\n",
        "\n",
        "        for key in padded_x_cat:\n",
        "            val = x_cat[key]\n",
        "            if pad_len > 0:\n",
        "                val = torch.cat([val, torch.zeros(pad_len, dtype=torch.long)])\n",
        "            padded_x_cat[key].append(val)\n",
        "\n",
        "        if pad_len > 0:\n",
        "            x_num = torch.cat([x_num, torch.zeros(pad_len, num_dim)])\n",
        "            y = torch.cat([y, torch.zeros(pad_len)])\n",
        "\n",
        "        padded_x_num.append(x_num)\n",
        "        padded_y.append(y)\n",
        "\n",
        "    padded_x_cat = {k: torch.stack(v) for k, v in padded_x_cat.items()}\n",
        "    padded_x_num = torch.stack(padded_x_num)\n",
        "    padded_y = torch.stack(padded_y)\n",
        "    lengths = torch.tensor(lengths, dtype=torch.long)\n",
        "\n",
        "    return padded_x_cat, padded_x_num, padded_y, lengths\n",
        "\n",
        "class FiBiNetRanker(nn.Module):\n",
        "    def __init__(self, cat_dims, num_numeric_feats, emb_dim=16, hidden=[256, 128], reduction=4, use_senet=True):\n",
        "        super().__init__()\n",
        "        self.cat_fields = list(cat_dims.keys())\n",
        "        self.emb_dim = emb_dim\n",
        "        self.num_fields = len(self.cat_fields)\n",
        "        self.use_senet = use_senet\n",
        "\n",
        "        self.embeddings = nn.ModuleDict({\n",
        "            f: nn.Embedding(cat_dims[f], emb_dim, padding_idx=0) for f in self.cat_fields\n",
        "        })\n",
        "\n",
        "        self.linear_cat = nn.ModuleDict({\n",
        "            f: nn.Embedding(cat_dims[f], 1, padding_idx=0) for f in self.cat_fields\n",
        "        })\n",
        "\n",
        "        self.linear_num = nn.Linear(num_numeric_feats, 1)\n",
        "\n",
        "        for emb in list(self.embeddings.values()) + list(self.linear_cat.values()):\n",
        "            nn.init.xavier_uniform_(emb.weight)\n",
        "        nn.init.xavier_uniform_(self.linear_num.weight)\n",
        "\n",
        "        if self.use_senet:\n",
        "            self.se_fc1 = nn.Linear(self.num_fields * emb_dim, self.num_fields * emb_dim // reduction)\n",
        "            self.se_fc2 = nn.Linear(self.num_fields * emb_dim // reduction, self.num_fields * emb_dim)\n",
        "\n",
        "        self.bilinear = nn.Linear(emb_dim, emb_dim, bias=False)\n",
        "\n",
        "        input_dim = emb_dim + num_numeric_feats\n",
        "        layers = []\n",
        "        for h in hidden:\n",
        "            layers.append(nn.Linear(input_dim, h))\n",
        "            layers.append(nn.ReLU())\n",
        "            layers.append(nn.Dropout(0.1))\n",
        "            input_dim = h\n",
        "\n",
        "        self.mlp = nn.Sequential(*layers)\n",
        "        self.output = nn.Linear(input_dim, 1)\n",
        "\n",
        "    def senet(self, embs):\n",
        "        B, F, D = embs.shape\n",
        "        z = embs.view(B, -1)\n",
        "        a = F_torch.relu(self.se_fc1(z))\n",
        "        s = torch.sigmoid(self.se_fc2(a)).view(B, F, D)\n",
        "        return embs * s\n",
        "\n",
        "    def bilinear_interaction(self, embs):\n",
        "        transformed = self.bilinear(embs)  # [B*G, F, D]\n",
        "        interaction = (embs * transformed).mean(dim=1)  # [B*G, D]\n",
        "        return interaction\n",
        "\n",
        "    def forward(self, x_cat, x_num):\n",
        "        B, G = x_num.shape[:2]\n",
        "        F, D = self.num_fields, self.emb_dim\n",
        "\n",
        "        embs = torch.stack([self.embeddings[f](x_cat[f]) for f in self.cat_fields], dim=2)  # [B, G, F, D]\n",
        "\n",
        "        linear_cat_sum = torch.stack([\n",
        "            self.linear_cat[f](x_cat[f]).squeeze(-1) for f in self.cat_fields\n",
        "        ], dim=0).sum(dim=0)  # [B, G]\n",
        "\n",
        "        linear_num_out = self.linear_num(x_num).squeeze(-1)  # [B, G]\n",
        "        linear_out = linear_cat_sum + linear_num_out  # [B, G]\n",
        "\n",
        "        embs = embs.view(B * G, F, D)\n",
        "\n",
        "        if self.use_senet:\n",
        "            embs = self.senet(embs)\n",
        "\n",
        "        bi = self.bilinear_interaction(embs)  # [B*G, D]\n",
        "\n",
        "        x_num_flat = x_num.view(B * G, -1)\n",
        "        deep_input = torch.cat([bi, x_num_flat], dim=1)  # [B*G, D+N]\n",
        "        deep_out = self.mlp(deep_input)\n",
        "        scores = self.output(deep_out).view(B, G)  # [B, G]\n",
        "\n",
        "        return scores + linear_out  # [B, G]\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "def listmle_loss(scores, labels, lengths):\n",
        "    batch_size = scores.size(0)\n",
        "    total_loss = torch.tensor(0.0, device=scores.device, requires_grad=True)\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "\n",
        "        _, idx = torch.sort(y, descending=True)\n",
        "        s_sorted = s[idx]\n",
        "\n",
        "        parts = (\n",
        "            torch.logsumexp(s_sorted.unsqueeze(0).expand(l, -1).triu(diagonal=0), dim=1)\n",
        "            - s_sorted\n",
        "        )\n",
        "\n",
        "        total_loss = total_loss + parts.sum()\n",
        "\n",
        "    return total_loss / batch_size\n",
        "\"\"\"\n",
        "\n",
        "def hitrate_at_k(scores, labels, lengths, k=3, min_group_size=10):\n",
        "    batch_size = scores.size(0)\n",
        "    hits = 0\n",
        "    valid_count = 0\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        if l < min_group_size:\n",
        "            continue\n",
        "        length = min(l, k)\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "        _, topk_idx = torch.topk(s, length)\n",
        "        topk_labels = y[topk_idx]\n",
        "        hits += (topk_labels > 0).any().float()\n",
        "        valid_count += 1\n",
        "    return hits / valid_count if valid_count > 0 else torch.tensor(0.0, device=scores.device)\n",
        "\n",
        "\n",
        "def ndcg_at_k(scores, labels, lengths, k=3, min_group_size=10):\n",
        "    batch_size = scores.size(0)\n",
        "    total_ndcg = 0.0\n",
        "    valid_count = 0\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        if l < min_group_size:\n",
        "            continue\n",
        "\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "\n",
        "        _, idx_pred = torch.topk(s, min(k, l))\n",
        "        _, idx_ideal = torch.topk(y, min(k, l))\n",
        "\n",
        "        dcg = (y[idx_pred] / torch.log2(torch.arange(2, 2 + len(idx_pred), device=y.device).float())).sum()\n",
        "        idcg = (y[idx_ideal] / torch.log2(torch.arange(2, 2 + len(idx_ideal), device=y.device).float())).sum()\n",
        "\n",
        "        ndcg = dcg / idcg if idcg > 0 else 0.0\n",
        "        total_ndcg += ndcg\n",
        "        valid_count += 1\n",
        "\n",
        "    return total_ndcg / valid_count if valid_count > 0 else torch.tensor(0.0, device=scores.device)\n",
        "\n",
        "\n",
        "def map_at_k(scores, labels, lengths, k=3, min_group_size=10):\n",
        "    batch_size = scores.size(0)\n",
        "    total_ap = 0.0\n",
        "    valid_count = 0\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        if l < min_group_size:\n",
        "            continue\n",
        "\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "\n",
        "        _, idx_pred = torch.topk(s, min(k, l))\n",
        "        y_true = y[idx_pred] > 0\n",
        "\n",
        "        if y_true.sum() == 0:\n",
        "            continue\n",
        "\n",
        "        precisions = [(y_true[:j+1].float().sum() / (j+1)) for j in range(len(y_true)) if y_true[j]]\n",
        "        ap = torch.stack(precisions).mean()\n",
        "        total_ap += ap\n",
        "        valid_count += 1\n",
        "\n",
        "    return total_ap / valid_count if valid_count > 0 else torch.tensor(0.0, device=scores.device)\n",
        "\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "def listnet_loss(scores, labels, lengths):\n",
        "    batch_size = scores.size(0)\n",
        "    total_loss = 0.0\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "\n",
        "        s_softmax = torch.nn.functional.log_softmax(s, dim=0)\n",
        "        y_softmax = torch.nn.functional.softmax(y, dim=0)\n",
        "\n",
        "        loss = -torch.sum(y_softmax * s_softmax)\n",
        "        total_loss += loss\n",
        "\n",
        "    return total_loss / batch_size\n",
        "\"\"\"\n",
        "\n",
        "def ranknet_loss(scores, labels, lengths):\n",
        "    batch_size = scores.size(0)\n",
        "    total_loss = 0.0\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "\n",
        "        diff_scores = s.unsqueeze(1) - s.unsqueeze(0)\n",
        "        rel = y.unsqueeze(1) > y.unsqueeze(0)\n",
        "        label_diff = rel.float()\n",
        "\n",
        "        log_sigmoid = torch.nn.functional.logsigmoid(diff_scores)\n",
        "        pair_loss = -label_diff * log_sigmoid\n",
        "\n",
        "        total_loss += pair_loss.sum()\n",
        "\n",
        "    return total_loss / batch_size\n",
        "\n",
        "def xranknet_loss(scores, labels, lengths, temperature=1.0, margin=0.2, focus_topk=3):\n",
        "    \"\"\"\n",
        "    xRankNet with emphasis on top-K items (based on labels, not scores).\n",
        "    \"\"\"\n",
        "    batch_size = scores.size(0)\n",
        "    total_loss = 0.0\n",
        "    total_pairs = 0\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        if l < 2:\n",
        "            continue\n",
        "\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "\n",
        "        # Top-K mask based on ground truth labels\n",
        "        topk = min(focus_topk, l)\n",
        "        _, topk_idx = torch.topk(y, topk)\n",
        "        topk_mask = torch.zeros_like(y, dtype=torch.bool)\n",
        "        topk_mask[topk_idx] = True\n",
        "\n",
        "        # Create pairwise difference matrices\n",
        "        score_diff = s.unsqueeze(1) - s.unsqueeze(0)\n",
        "        label_diff = y.unsqueeze(1) - y.unsqueeze(0)\n",
        "\n",
        "        # valid pair: y_i > y_j and at least one of i, j is in top-K\n",
        "        valid_pairs = (label_diff > 0) & (\n",
        "            topk_mask.unsqueeze(1) | topk_mask.unsqueeze(0)\n",
        "        )\n",
        "\n",
        "        if valid_pairs.sum() == 0:\n",
        "            continue\n",
        "\n",
        "        importance = (label_diff.abs() * valid_pairs).float()\n",
        "\n",
        "        if margin > 0.0:\n",
        "            score_diff = score_diff - margin\n",
        "\n",
        "        score_diff = score_diff / temperature\n",
        "        pairwise_loss = -F_torch.logsigmoid(score_diff) * importance\n",
        "\n",
        "        total_loss += pairwise_loss.sum()\n",
        "        total_pairs += importance.sum()\n",
        "\n",
        "    if total_pairs == 0:\n",
        "        return torch.tensor(0.0, device=scores.device, requires_grad=True)\n",
        "\n",
        "    return total_loss / total_pairs\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "def bpr_loss(scores, labels, lengths):\n",
        "    batch_size = scores.size(0)\n",
        "    total_loss = 0.0\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "\n",
        "        pos_mask = y > 0\n",
        "        neg_mask = y <= 0\n",
        "\n",
        "        pos_scores = s[pos_mask]\n",
        "        neg_scores = s[neg_mask]\n",
        "\n",
        "        if len(pos_scores) == 0 or len(neg_scores) == 0:\n",
        "            continue\n",
        "\n",
        "        pair_diff = pos_scores.unsqueeze(1) - neg_scores.unsqueeze(0)\n",
        "        loss = -F.logsigmoid(pair_diff).mean()\n",
        "        total_loss += loss\n",
        "\n",
        "    return total_loss / batch_size\n",
        "\"\"\"\n",
        "\n",
        "\"\"\"\n",
        "def lambdarank_loss(scores, labels, lengths, eps=1e-10):\n",
        "    batch_size = scores.size(0)\n",
        "    total_loss = 0.0\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "\n",
        "        if l < 2:\n",
        "            continue\n",
        "\n",
        "        _, rank_order = torch.sort(s, descending=True)\n",
        "        ideal_order = torch.sort(y, descending=True).indices\n",
        "\n",
        "        gain = 2 ** y - 1\n",
        "        discount = torch.log2(torch.arange(2, l + 2, device=y.device).float())\n",
        "\n",
        "        ideal_dcg = (gain[ideal_order] / discount).sum()\n",
        "        if ideal_dcg < eps:\n",
        "            continue\n",
        "\n",
        "        delta_ndcg = torch.zeros((l, l), device=y.device)\n",
        "\n",
        "        for i_idx in range(l):\n",
        "            for j_idx in range(l):\n",
        "                if y[i_idx] > y[j_idx]:\n",
        "                    change = (\n",
        "                        (1.0 / torch.log2(rank_order[i_idx] + 2.0))\n",
        "                        - (1.0 / torch.log2(rank_order[j_idx] + 2.0))\n",
        "                    ).abs()\n",
        "                    delta = (2 ** y[i_idx] - 2 ** y[j_idx]).abs() * change\n",
        "                    delta_ndcg[i_idx, j_idx] = delta / ideal_dcg\n",
        "\n",
        "        score_diffs = s.unsqueeze(1) - s.unsqueeze(0)\n",
        "        lambdas = -F.logsigmoid(score_diffs) * delta_ndcg\n",
        "        total_loss += lambdas.sum()\n",
        "\n",
        "    return total_loss / batch_size\n",
        "\"\"\"\n",
        "\n",
        "def train_one_epoch(model, loader, optimizer, device, scheduler):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "\n",
        "    for x_cat, x_num, y, lengths in tqdm(loader, desc=\"Training\", leave=False):\n",
        "        x_num, y = x_num.to(device), y.to(device)\n",
        "        if not isinstance(lengths, torch.Tensor):\n",
        "            lengths = torch.tensor(lengths)\n",
        "        lengths = lengths.detach().clone().to(device)\n",
        "        x_cat = {k: v.to(device) for k, v in x_cat.items()}\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        scores = model(x_cat, x_num)\n",
        "        loss = xranknet_loss(scores, y, lengths, temperature=1.0, margin=0.2, focus_topk=3)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    return total_loss / len(loader)\n",
        "\n",
        "\n",
        "def validate(model, loader, device, min_group_size=10):\n",
        "    model.eval()\n",
        "    total_hitrate = 0\n",
        "    total_ndcg = 0\n",
        "    total_map = 0\n",
        "    total_loss = 0\n",
        "    count = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for x_cat, x_num, y, lengths in tqdm(loader, desc=\"Validating\", leave=False):\n",
        "            x_num, y = x_num.to(device), y.to(device)\n",
        "            lengths = torch.tensor(lengths).to(device)\n",
        "            x_cat = {k: v.to(device) for k, v in x_cat.items()}\n",
        "\n",
        "            scores = model(x_cat, x_num)\n",
        "\n",
        "            hitrate = hitrate_at_k(scores, y, lengths, k=3, min_group_size=min_group_size)\n",
        "            ndcg = ndcg_at_k(scores, y, lengths, k=3, min_group_size=min_group_size)\n",
        "            map3 = map_at_k(scores, y, lengths, k=3, min_group_size=min_group_size)\n",
        "            loss = xranknet_loss(scores, y, lengths, temperature=1.0, margin=0.2, focus_topk=3)\n",
        "\n",
        "            batch_size = scores.size(0)\n",
        "            total_hitrate += hitrate * batch_size\n",
        "            total_ndcg += ndcg * batch_size\n",
        "            total_map += map3 * batch_size\n",
        "            total_loss += loss.item() * batch_size\n",
        "            count += batch_size\n",
        "\n",
        "    return total_loss / count, total_hitrate / count, total_ndcg / count, total_map / count\n",
        "\n",
        "\n",
        "def build_cat_dims(X, cat_features):\n",
        "    cat_dims = {}\n",
        "    for c in cat_features:\n",
        "        max_val = X[c].max()\n",
        "        if max_val < 0:\n",
        "            max_val = 0\n",
        "        cat_dims[c] = max_val + 1\n",
        "    return cat_dims\n",
        "\n",
        "\n",
        "def normalize_numeric_features(X, numeric_features, train_mask):\n",
        "    for col in numeric_features:\n",
        "        values = X[col].to_numpy()\n",
        "        train_vals = values[train_mask]\n",
        "        mean = train_vals.mean()\n",
        "        std = train_vals.std() if train_vals.std() > 0 else 1.0\n",
        "        norm_vals = (values - mean) / std\n",
        "        X = X.with_columns(pl.Series(col, norm_vals).alias(col))\n",
        "    return X\n",
        "\n",
        "\n",
        "def load_or_prepare_data(\n",
        "    data_dir,\n",
        "    train_file=\"train.parquet\",\n",
        "    test_file=\"test.parquet\",\n",
        "    cache_file=\"feature_engineered_val.parquet\",\n",
        "):\n",
        "    cache_path = os.path.join(data_dir, cache_file)\n",
        "\n",
        "    if os.path.exists(cache_path):\n",
        "        print(f\"Loading cached feature-engineered data from {cache_path} ...\")\n",
        "        df = pl.read_parquet(cache_path)\n",
        "\n",
        "        test = pl.read_parquet(os.path.join(data_dir, test_file)).drop(\"__index_level_0__\")\n",
        "        test_ids = test[\"Id\"]\n",
        "        test_rankers = test[\"ranker_id\"]\n",
        "    else:\n",
        "        print(\"Cached file not found, processing raw data ...\")\n",
        "\n",
        "        train = pl.read_parquet(os.path.join(data_dir, train_file)).drop(\"__index_level_0__\")\n",
        "        test = (\n",
        "            pl.read_parquet(os.path.join(data_dir, test_file))\n",
        "            .drop(\"__index_level_0__\")\n",
        "            .with_columns(pl.lit(0, dtype=pl.Int64).alias(\"selected\"))\n",
        "        )\n",
        "\n",
        "        test_ids = test[\"Id\"]\n",
        "        test_rankers = test[\"ranker_id\"]\n",
        "\n",
        "        df = pl.concat((train, test))\n",
        "        df = feature_engineering(df, full=True)\n",
        "\n",
        "        df = df.with_columns(\n",
        "            [pl.col(c).fill_null(0) for c in df.select(pl.selectors.numeric()).columns] +\n",
        "            [pl.col(c).fill_null(\"missing\") for c in df.select(pl.selectors.string()).columns]\n",
        "        )\n",
        "\n",
        "        os.makedirs(data_dir, exist_ok=True)\n",
        "        df.write_parquet(cache_path)\n",
        "        print(f\"Saved feature-engineered data to {cache_path}\")\n",
        "\n",
        "    return df, test_ids, test_rankers\n",
        "\n",
        "\n",
        "def prepare_data(data_dir):\n",
        "    df, test_ids, test_rankers = load_or_prepare_data(data_dir)\n",
        "\n",
        "    id_column = df[\"Id\"]\n",
        "    X, y, groups, cat_features, num_features = feature_selection(df)\n",
        "\n",
        "    X = X.with_columns(pl.Series(\"Id\", id_column[:X.shape[0]]))\n",
        "\n",
        "    X = X.with_columns(\n",
        "        [\n",
        "            (pl.col(c).rank(\"dense\") - 1).fill_null(-1).cast(pl.Int32)\n",
        "            for c in cat_features\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    train_size = 18145372\n",
        "    train_mask = np.arange(X.height) < train_size\n",
        "    X = normalize_numeric_features(X, num_features, train_mask)\n",
        "\n",
        "    return X, y, groups, cat_features, num_features, train_size, test_ids, test_rankers\n",
        "\n",
        "\n",
        "class EarlyStopping:\n",
        "    def __init__(self, patience=3, min_delta=0.00005):\n",
        "        self.patience = patience\n",
        "        self.min_delta = min_delta\n",
        "        self.best = float(\"-inf\")\n",
        "        self.counter = 0\n",
        "\n",
        "    def step(self, metric):\n",
        "        if metric > self.best + self.min_delta:\n",
        "            self.best = metric\n",
        "            self.counter = 0\n",
        "        else:\n",
        "            self.counter += 1\n",
        "        return self.counter >= self.patience\n",
        "\n",
        "\n",
        "def plot_group_size_distribution(dataset, save_path=None):\n",
        "    group_sizes = [len(v) for v in dataset.group_to_indices.values()]\n",
        "    plt.figure()\n",
        "    plt.hist(group_sizes, bins=100, log=True)\n",
        "    plt.xlabel(\"Group size (number of items per ranker_id)\")\n",
        "    plt.ylabel(\"Frequency (log scale)\")\n",
        "    plt.title(\"Distribution of Group Sizes\")\n",
        "    plt.grid(True)\n",
        "    if save_path:\n",
        "        plt.savefig(save_path)\n",
        "    else:\n",
        "        plt.show()\n",
        "    plt.close()\n",
        "\n",
        "\n",
        "def main():\n",
        "    DATA_DIR = \"./data\"\n",
        "    MODEL_DIR = \"model\"\n",
        "    SUBMIT_DIR = \"submission\"\n",
        "\n",
        "    best_val_loss = float(\"inf\")\n",
        "    best_hitrate = 0.0\n",
        "    model_path = os.path.join(MODEL_DIR, \"best_dl_ranker.pt\")\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "    val_hitrates = []\n",
        "    val_ndcgs = []\n",
        "    val_maps = []\n",
        "    learning_rates = []\n",
        "\n",
        "    os.makedirs(MODEL_DIR, exist_ok=True)\n",
        "    os.makedirs(SUBMIT_DIR, exist_ok=True)\n",
        "\n",
        "    early_stopper = EarlyStopping(patience=3, min_delta=0.001)\n",
        "\n",
        "    X, y, groups, cat_features, num_features, train_size, test_ids, test_rankers = prepare_data(DATA_DIR)\n",
        "\n",
        "    # Fill missing values\n",
        "    float_cols = [c for c, t in zip(X.columns, X.dtypes) if t == pl.Float64]\n",
        "    for col in float_cols:\n",
        "        X = X.with_columns(\n",
        "            pl.when(pl.col(col).is_nan()).then(0).otherwise(pl.col(col)).alias(col)\n",
        "        )\n",
        "\n",
        "    n1 = 16487352\n",
        "    # n1 = 17487300\n",
        "    n2 = train_size\n",
        "\n",
        "    X_tr, X_va, X_te = X[:n1], X[n1:n2], X[n2:]\n",
        "    y_tr, y_va, y_te = y[:n1], y[n1:n2], y[n2:]\n",
        "    groups_tr, groups_va, groups_te = groups[:n1], groups[n1:n2], groups[n2:]\n",
        "\n",
        "    # Inspect group sizes in validation set\n",
        "    val_rankers = groups_va[\"ranker_id\"].to_numpy()\n",
        "    val_group_counts = Counter(val_rankers)\n",
        "\n",
        "    print(\"\\nüìã Validation group statistics:\")\n",
        "    # Save detailed group info to file\n",
        "    group_info_path = os.path.join(MODEL_DIR, \"validation_groups_info.txt\")\n",
        "    with open(group_info_path, \"w\") as f:\n",
        "        f.write(f\"Total groups: {len(val_group_counts)}\\n\\n\")\n",
        "        f.write(\"GroupID\\tSize\\tStartIdx\\tEndIdx\\n\")\n",
        "\n",
        "        group_to_rows = defaultdict(list)\n",
        "        for i, g in enumerate(val_rankers):\n",
        "            group_to_rows[g].append(i)\n",
        "\n",
        "        for group_id, indices in sorted(group_to_rows.items()):\n",
        "            start_idx = indices[0]\n",
        "            end_idx = indices[-1]\n",
        "            size = len(indices)\n",
        "            f.write(f\"{group_id}\\t{size}\\t{start_idx}\\t{end_idx}\\n\")\n",
        "\n",
        "    print(f\"üìÅ Saved validation group info to {group_info_path}\")\n",
        "\n",
        "\n",
        "    cat_dims = build_cat_dims(X, cat_features)\n",
        "    num_numeric_feats = len(num_features)\n",
        "\n",
        "    train_dataset = RankDataset(X_tr, y_tr, groups_tr, cat_features, num_features)\n",
        "    val_dataset = RankDataset(X_va, y_va, groups_va, cat_features, num_features)\n",
        "    test_dataset = RankDataset(X_te, y_te, groups_te, cat_features, num_features)\n",
        "\n",
        "    plot_group_size_distribution(train_dataset, save_path=os.path.join(MODEL_DIR, \"group_sizes.png\"))\n",
        "    print(\"üìä Group size distribution saved.\")\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True, collate_fn=collate_fn)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=4, shuffle=False, collate_fn=collate_fn)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False, collate_fn=collate_fn)\n",
        "\n",
        "    print(\"‚úÖ Data loaders created.\")\n",
        "\n",
        "    num_epochs = 10\n",
        "    num_training_steps = num_epochs * len(train_loader)\n",
        "    num_warmup_steps = int(0.1 * num_training_steps)\n",
        "\n",
        "    learning_rate = 1e-3\n",
        "\n",
        "    model = FiBiNetRanker(\n",
        "        cat_dims=cat_dims,\n",
        "        num_numeric_feats=num_numeric_feats,\n",
        "        emb_dim=16,\n",
        "        hidden=[512, 256, 128]\n",
        "    ).to(device)\n",
        "\n",
        "\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=0.01)\n",
        "\n",
        "    scheduler = get_scheduler(\n",
        "        \"linear\",\n",
        "        optimizer=optimizer,\n",
        "        num_warmup_steps=num_warmup_steps,\n",
        "        num_training_steps=num_training_steps\n",
        "    )\n",
        "\n",
        "    best_hitrate = 0\n",
        "    for epoch in range(num_epochs):\n",
        "        print(f\"\\n--- Epoch {epoch+1}/{num_epochs} ---\")\n",
        "        start_time = time.time()\n",
        "\n",
        "        train_loss = train_one_epoch(model, train_loader, optimizer, device, scheduler)\n",
        "        val_loss, val_hitrate, val_ndcg, val_map = validate(model, val_loader, device, min_group_size=10)\n",
        "\n",
        "        train_losses.append(train_loss)\n",
        "        val_losses.append(val_loss)\n",
        "        val_hitrates.append(val_hitrate.item())\n",
        "        val_ndcgs.append(val_ndcg.item())\n",
        "        val_maps.append(val_map.item())\n",
        "\n",
        "        current_lr = scheduler.get_last_lr()\n",
        "        learning_rates.append(current_lr[0])\n",
        "\n",
        "        elapsed = time.time() - start_time\n",
        "        print(\n",
        "            f\"Epoch {epoch+1}: \"\n",
        "            f\"Train Loss={train_loss:.4f}, \"\n",
        "            f\"Val Loss={val_loss:.4f}, \"\n",
        "            f\"HitRate@3={val_hitrate:.4f}, \"\n",
        "            f\"NDCG@3={val_ndcg:.4f}, \"\n",
        "            f\"MAP@3={val_map:.4f}, \"\n",
        "            f\"LR={current_lr[0]:.6f} \"\n",
        "            f\"({elapsed:.1f}s)\"\n",
        "        )\n",
        "\n",
        "\n",
        "        if val_loss < best_val_loss and val_hitrate > best_hitrate:\n",
        "            best_val_loss = val_loss\n",
        "            best_hitrate = val_hitrate\n",
        "            torch.save(model.state_dict(), model_path)\n",
        "            print(\"üíæ Model improved (loss ‚Üì and hitrate ‚Üë), saved.\")\n",
        "\n",
        "        if early_stopper.step(-val_loss):\n",
        "            print(\"‚õî Early stopping triggered.\")\n",
        "            break\n",
        "\n",
        "    # Plot metrics\n",
        "    epochs = list(range(1, len(train_losses) + 1))\n",
        "\n",
        "    # Plot Loss Curve\n",
        "    plt.figure()\n",
        "    plt.plot(epochs, train_losses, label=\"Train Loss\")\n",
        "    plt.plot(epochs, val_losses, label=\"Val Loss\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.title(\"Training & Validation Loss\")\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.savefig(os.path.join(MODEL_DIR, \"loss_curve.png\"))\n",
        "    plt.close()\n",
        "\n",
        "    # Plot HitRate@3\n",
        "    plt.figure()\n",
        "    plt.plot(epochs, val_hitrates, label=\"Val HitRate@3\", color=\"green\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"HitRate@3\")\n",
        "    plt.title(\"Validation HitRate@3\")\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.savefig(os.path.join(MODEL_DIR, \"hitrate_curve.png\"))\n",
        "    plt.close()\n",
        "\n",
        "    # Plot Learning Rate\n",
        "    plt.figure()\n",
        "    plt.plot(epochs, learning_rates, label=\"Learning Rate\", color=\"orange\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"LR\")\n",
        "    plt.title(\"Learning Rate Schedule\")\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.savefig(os.path.join(MODEL_DIR, \"lr_curve.png\"))\n",
        "    plt.close()\n",
        "\n",
        "    # Plot NDCG@3\n",
        "    plt.figure()\n",
        "    plt.plot(epochs, val_ndcgs, label=\"Val NDCG@3\", color=\"purple\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"NDCG@3\")\n",
        "    plt.title(\"Validation NDCG@3\")\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.savefig(os.path.join(MODEL_DIR, \"ndcg_curve.png\"))\n",
        "    plt.close()\n",
        "\n",
        "    # Plot MAP@3\n",
        "    plt.figure()\n",
        "    plt.plot(epochs, val_maps, label=\"Val MAP@3\", color=\"red\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"MAP@3\")\n",
        "    plt.title(\"Validation MAP@3\")\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.savefig(os.path.join(MODEL_DIR, \"map_curve.png\"))\n",
        "    plt.close()\n",
        "\n",
        "    print(\"üìä Saved metric plots to model/\")\n",
        "\n",
        "    # Predict test set\n",
        "    model.load_state_dict(torch.load(model_path))\n",
        "    model.eval()\n",
        "\n",
        "    val_ids = X_va[\"Id\"]\n",
        "    val_rankers = groups_va[\"ranker_id\"]\n",
        "    val_labels = y_va\n",
        "\n",
        "    all_val_scores = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for x_cat, x_num, _, lengths in tqdm(val_loader, desc=\"Predicting validation set\"):\n",
        "            x_num = x_num.to(device)\n",
        "            x_cat = {k: v.to(device) for k, v in x_cat.items()}\n",
        "            scores = model(x_cat, x_num)\n",
        "\n",
        "            for i in range(scores.size(0)):\n",
        "                l = lengths[i]\n",
        "                all_val_scores.append(scores[i, :l].cpu().numpy())\n",
        "\n",
        "    all_val_scores = np.concatenate(all_val_scores)\n",
        "\n",
        "    assert len(all_val_scores) == X_va.shape[0], \\\n",
        "        f\"Mismatch: {len(all_val_scores)} scores vs {X_va.shape[0]} rows\"\n",
        "\n",
        "    val_df = X_va.with_columns([\n",
        "        pl.Series(\"Id\", val_ids),\n",
        "        pl.Series(\"ranker_id\", val_rankers),\n",
        "        pl.Series(\"score\", all_val_scores),\n",
        "        pl.Series(\"label\", val_labels)\n",
        "    ])\n",
        "\n",
        "    val_df = val_df.with_columns(\n",
        "        pl.col(\"score\")\n",
        "        .rank(method=\"ordinal\", descending=True)\n",
        "        .over(\"ranker_id\")\n",
        "        .cast(pl.Int32)\n",
        "        .alias(\"selected\")\n",
        "    )\n",
        "\n",
        "    val_save_path = os.path.join(MODEL_DIR, \"validation_preds_dl_full.csv\")\n",
        "    val_df.write_csv(val_save_path)\n",
        "    print(f\"‚úÖ Saved full validation predictions (with features) to {val_save_path}\")\n",
        "\n",
        "    all_scores = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for x_cat, x_num, _, lengths in tqdm(test_loader, desc=\"Predicting test set\"):\n",
        "            x_num = x_num.to(device)\n",
        "            x_cat = {k: v.to(device) for k, v in x_cat.items()}\n",
        "            scores = model(x_cat, x_num)\n",
        "\n",
        "            for i in range(scores.size(0)):\n",
        "                l = lengths[i]\n",
        "                all_scores.append(scores[i, :l].cpu().numpy())\n",
        "\n",
        "    all_scores = np.concatenate(all_scores)\n",
        "\n",
        "    assert len(all_scores) == X_te.shape[0], \\\n",
        "        f\"Mismatch: {len(all_scores)} scores vs {X_te.shape[0]} rows in X_te\"\n",
        "\n",
        "    submission_df = pl.DataFrame({\n",
        "        \"Id\": test_ids,\n",
        "        \"ranker_id\": test_rankers,\n",
        "        \"score\": all_scores\n",
        "    })\n",
        "\n",
        "    submission = (\n",
        "        submission_df\n",
        "        .with_columns(\n",
        "            pl.col(\"score\")\n",
        "            .rank(method=\"ordinal\", descending=True)\n",
        "            .over(\"ranker_id\")\n",
        "            .cast(pl.Int32)\n",
        "            .alias(\"selected\")\n",
        "        )\n",
        "        .select([\"Id\", \"ranker_id\", \"score\", \"selected\"])\n",
        "    )\n",
        "\n",
        "    submission_path = os.path.join(SUBMIT_DIR, \"submission_dl_ranker.csv\")\n",
        "    submission.write_csv(submission_path)\n",
        "    print(f\"‚úÖ Submission saved to {submission_path}\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "EN-q4f1kZuJF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "--- Epoch 1/10 ---\n",
        "Validating:   0%|          | 0/2636 [00:00<?, ?it/s]/home/ionut/test_whisper/test2/deeprec_validate.py:458: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
        "  lengths = torch.tensor(lengths).to(device)\n",
        "Epoch 1: Train Loss=0.3967, Val Loss=0.3252, HitRate@3=0.4560, NDCG@3=0.3643, MAP@3=0.6130, LR=0.001000 (446.5s)\n",
        "üíæ Model improved (loss ‚Üì and hitrate ‚Üë), saved.\n",
        "\n",
        "--- Epoch 2/10 ---\n",
        "Epoch 2: Train Loss=0.2916, Val Loss=0.2868, HitRate@3=0.4839, NDCG@3=0.3881, MAP@3=0.6312, LR=0.000889 (444.9s)\n",
        "üíæ Model improved (loss ‚Üì and hitrate ‚Üë), saved.\n",
        "\n",
        "--- Epoch 3/10 ---\n",
        "Epoch 3: Train Loss=0.2761, Val Loss=0.3020, HitRate@3=0.4949, NDCG@3=0.4003, MAP@3=0.6450, LR=0.000778 (444.7s)\n",
        "\n",
        "--- Epoch 4/10 ---\n",
        "Epoch 4: Train Loss=0.2681, Val Loss=0.2786, HitRate@3=0.4958, NDCG@3=0.3996, MAP@3=0.6447, LR=0.000667 (444.7s)\n",
        "üíæ Model improved (loss ‚Üì and hitrate ‚Üë), saved.\n",
        "\n",
        "--- Epoch 5/10 ---\n",
        "Epoch 5: Train Loss=0.2663, Val Loss=0.3014, HitRate@3=0.5050, NDCG@3=0.4056, MAP@3=0.6463, LR=0.000556 (444.6s)\n",
        "\n",
        "--- Epoch 6/10 ---\n",
        "Epoch 6: Train Loss=0.2586, Val Loss=0.2871, HitRate@3=0.5046, NDCG@3=0.4038, MAP@3=0.6426, LR=0.000444 (443.7s)"
      ],
      "metadata": {
        "id": "-uFqqJmycE87"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile deeprec_validate.py\n",
        "import os\n",
        "import time\n",
        "import random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F_torch\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import defaultdict\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "import polars as pl\n",
        "from tqdm import tqdm\n",
        "from src.feature import feature_engineering, feature_selection\n",
        "from transformers import get_scheduler\n",
        "from collections import Counter\n",
        "\n",
        "class RankDataset(Dataset):\n",
        "    def __init__(\n",
        "        self,\n",
        "        X: pl.DataFrame,\n",
        "        y: pl.Series,\n",
        "        groups: pl.DataFrame,\n",
        "        cat_features: list[str],\n",
        "        num_features: list[str],\n",
        "    ):\n",
        "        self.cat_features = cat_features\n",
        "        self.num_features = num_features\n",
        "        self.X_cat = {c: X[c].to_numpy() for c in cat_features}\n",
        "        self.X_num = X[self.num_features].to_numpy()\n",
        "        self.y = y.to_numpy()\n",
        "        self.groups = groups[\"ranker_id\"].to_numpy()\n",
        "\n",
        "        self.group_to_indices = defaultdict(list)\n",
        "        for i, g in enumerate(self.groups):\n",
        "            self.group_to_indices[g].append(i)\n",
        "        self.group_keys = list(self.group_to_indices.keys())\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.group_keys)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        g = self.group_keys[idx]\n",
        "        inds = self.group_to_indices[g]\n",
        "        length = len(inds)\n",
        "\n",
        "        x_cat = {\n",
        "            c: torch.LongTensor([\n",
        "                self.X_cat[c][i] if self.X_cat[c][i] >= 0 else 0 for i in inds\n",
        "            ])\n",
        "            for c in self.cat_features\n",
        "        }\n",
        "\n",
        "        x_num = torch.FloatTensor(self.X_num[inds])\n",
        "        y = torch.FloatTensor(self.y[inds]).reshape(-1)\n",
        "\n",
        "        return x_cat, x_num, y, length\n",
        "\n",
        "def collate_fn(batch):\n",
        "    batch_size = len(batch)\n",
        "    lengths = [b[3] for b in batch]\n",
        "    max_len = max(lengths)\n",
        "\n",
        "    padded_x_cat = {key: [] for key in batch[0][0].keys()}\n",
        "    padded_x_num = []\n",
        "    padded_y = []\n",
        "\n",
        "    num_dim = batch[0][1].shape[1]\n",
        "\n",
        "    for x_cat, x_num, y, length in batch:\n",
        "        pad_len = max_len - length\n",
        "\n",
        "        for key in padded_x_cat:\n",
        "            val = x_cat[key]\n",
        "            if pad_len > 0:\n",
        "                val = torch.cat([val, torch.zeros(pad_len, dtype=torch.long)])\n",
        "            padded_x_cat[key].append(val)\n",
        "\n",
        "        if pad_len > 0:\n",
        "            x_num = torch.cat([x_num, torch.zeros(pad_len, num_dim)])\n",
        "            y = torch.cat([y, torch.zeros(pad_len)])\n",
        "\n",
        "        padded_x_num.append(x_num)\n",
        "        padded_y.append(y)\n",
        "\n",
        "    padded_x_cat = {k: torch.stack(v) for k, v in padded_x_cat.items()}\n",
        "    padded_x_num = torch.stack(padded_x_num)\n",
        "    padded_y = torch.stack(padded_y)\n",
        "    lengths = torch.tensor(lengths, dtype=torch.long)\n",
        "\n",
        "    return padded_x_cat, padded_x_num, padded_y, lengths\n",
        "\n",
        "class FiBiNetRanker(nn.Module):\n",
        "    def __init__(self, cat_dims, num_numeric_feats, emb_dim=64, hidden=[512, 256, 128, 64], reduction=4, use_senet=True):\n",
        "        super().__init__()\n",
        "        self.cat_fields = list(cat_dims.keys())\n",
        "        self.emb_dim = emb_dim\n",
        "        self.num_fields = len(self.cat_fields)\n",
        "        self.use_senet = use_senet\n",
        "\n",
        "        # Embedding layers\n",
        "        self.embeddings = nn.ModuleDict({\n",
        "            f: nn.Embedding(cat_dims[f], emb_dim, padding_idx=0) for f in self.cat_fields\n",
        "        })\n",
        "        self.linear_cat = nn.ModuleDict({\n",
        "            f: nn.Embedding(cat_dims[f], 1, padding_idx=0) for f in self.cat_fields\n",
        "        })\n",
        "        self.linear_num = nn.Linear(num_numeric_feats, 1)\n",
        "\n",
        "        for emb in list(self.embeddings.values()) + list(self.linear_cat.values()):\n",
        "            nn.init.xavier_uniform_(emb.weight)\n",
        "        nn.init.xavier_uniform_(self.linear_num.weight)\n",
        "\n",
        "        # SENet\n",
        "        if self.use_senet:\n",
        "            self.se_fc1 = nn.Linear(self.num_fields * emb_dim, self.num_fields * emb_dim // reduction)\n",
        "            self.se_fc2 = nn.Linear(self.num_fields * emb_dim // reduction, self.num_fields * emb_dim)\n",
        "\n",
        "        # Bilinear layer (shared)\n",
        "        self.bilinear = nn.Linear(emb_dim, emb_dim, bias=False)\n",
        "\n",
        "        # MLP (deeper + stronger)\n",
        "        input_dim = emb_dim + num_numeric_feats\n",
        "        layers = []\n",
        "        for h in hidden:\n",
        "            layers.append(nn.Linear(input_dim, h))\n",
        "            layers.append(nn.LayerNorm(h))  # normalize\n",
        "            layers.append(nn.ReLU())\n",
        "            layers.append(nn.Dropout(0.2))  # slightly increased dropout\n",
        "            input_dim = h\n",
        "        self.mlp = nn.Sequential(*layers)\n",
        "        self.output = nn.Linear(input_dim, 1)\n",
        "\n",
        "    def senet(self, embs):\n",
        "        B, F, D = embs.shape\n",
        "        z = embs.view(B, -1)\n",
        "        a = F_torch.relu(self.se_fc1(z))\n",
        "        s = torch.sigmoid(self.se_fc2(a)).view(B, F, D)\n",
        "        return embs * s\n",
        "\n",
        "    def bilinear_interaction(self, embs):\n",
        "        transformed = self.bilinear(embs)  # [B*G, F, D]\n",
        "        interaction = (embs * transformed).mean(dim=1)  # [B*G, D]\n",
        "        return interaction\n",
        "\n",
        "    def forward(self, x_cat, x_num):\n",
        "        B, G = x_num.shape[:2]\n",
        "        F, D = self.num_fields, self.emb_dim\n",
        "\n",
        "        # Embedding stacking\n",
        "        embs = torch.stack([self.embeddings[f](x_cat[f]) for f in self.cat_fields], dim=2)  # [B, G, F, D]\n",
        "\n",
        "        # Linear logits\n",
        "        linear_cat_sum = torch.stack([\n",
        "            self.linear_cat[f](x_cat[f]).squeeze(-1) for f in self.cat_fields\n",
        "        ], dim=0).sum(dim=0)  # [B, G]\n",
        "\n",
        "        linear_num_out = self.linear_num(x_num).squeeze(-1)  # [B, G]\n",
        "        linear_out = linear_cat_sum + linear_num_out  # [B, G]\n",
        "\n",
        "        # Feature interactions\n",
        "        embs = embs.view(B * G, F, D)\n",
        "        if self.use_senet:\n",
        "            embs = self.senet(embs)\n",
        "        bi = self.bilinear_interaction(embs)  # [B*G, D]\n",
        "\n",
        "        # Deep part\n",
        "        x_num_flat = x_num.view(B * G, -1)\n",
        "        deep_input = torch.cat([bi, x_num_flat], dim=1)\n",
        "        deep_out = self.mlp(deep_input)\n",
        "        scores = self.output(deep_out).view(B, G)\n",
        "\n",
        "        return scores + linear_out  # [B, G]\n",
        "\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "def listmle_loss(scores, labels, lengths):\n",
        "    batch_size = scores.size(0)\n",
        "    total_loss = torch.tensor(0.0, device=scores.device, requires_grad=True)\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "\n",
        "        _, idx = torch.sort(y, descending=True)\n",
        "        s_sorted = s[idx]\n",
        "\n",
        "        parts = (\n",
        "            torch.logsumexp(s_sorted.unsqueeze(0).expand(l, -1).triu(diagonal=0), dim=1)\n",
        "            - s_sorted\n",
        "        )\n",
        "\n",
        "        total_loss = total_loss + parts.sum()\n",
        "\n",
        "    return total_loss / batch_size\n",
        "\"\"\"\n",
        "\n",
        "def hitrate_at_k(scores, labels, lengths, k=3, min_group_size=10):\n",
        "    batch_size = scores.size(0)\n",
        "    hits = 0\n",
        "    valid_count = 0\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        if l < min_group_size:\n",
        "            continue\n",
        "        length = min(l, k)\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "        _, topk_idx = torch.topk(s, length)\n",
        "        topk_labels = y[topk_idx]\n",
        "        hits += (topk_labels > 0).any().float()\n",
        "        valid_count += 1\n",
        "    return hits / valid_count if valid_count > 0 else torch.tensor(0.0, device=scores.device)\n",
        "\n",
        "\n",
        "def ndcg_at_k(scores, labels, lengths, k=3, min_group_size=10):\n",
        "    batch_size = scores.size(0)\n",
        "    total_ndcg = 0.0\n",
        "    valid_count = 0\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        if l < min_group_size:\n",
        "            continue\n",
        "\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "\n",
        "        _, idx_pred = torch.topk(s, min(k, l))\n",
        "        _, idx_ideal = torch.topk(y, min(k, l))\n",
        "\n",
        "        dcg = (y[idx_pred] / torch.log2(torch.arange(2, 2 + len(idx_pred), device=y.device).float())).sum()\n",
        "        idcg = (y[idx_ideal] / torch.log2(torch.arange(2, 2 + len(idx_ideal), device=y.device).float())).sum()\n",
        "\n",
        "        ndcg = dcg / idcg if idcg > 0 else 0.0\n",
        "        total_ndcg += ndcg\n",
        "        valid_count += 1\n",
        "\n",
        "    return total_ndcg / valid_count if valid_count > 0 else torch.tensor(0.0, device=scores.device)\n",
        "\n",
        "\n",
        "def map_at_k(scores, labels, lengths, k=3, min_group_size=10):\n",
        "    batch_size = scores.size(0)\n",
        "    total_ap = 0.0\n",
        "    valid_count = 0\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        if l < min_group_size:\n",
        "            continue\n",
        "\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "\n",
        "        _, idx_pred = torch.topk(s, min(k, l))\n",
        "        y_true = y[idx_pred] > 0\n",
        "\n",
        "        if y_true.sum() == 0:\n",
        "            continue\n",
        "\n",
        "        precisions = [(y_true[:j+1].float().sum() / (j+1)) for j in range(len(y_true)) if y_true[j]]\n",
        "        ap = torch.stack(precisions).mean()\n",
        "        total_ap += ap\n",
        "        valid_count += 1\n",
        "\n",
        "    return total_ap / valid_count if valid_count > 0 else torch.tensor(0.0, device=scores.device)\n",
        "\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "def listnet_loss(scores, labels, lengths):\n",
        "    batch_size = scores.size(0)\n",
        "    total_loss = 0.0\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "\n",
        "        s_softmax = torch.nn.functional.log_softmax(s, dim=0)\n",
        "        y_softmax = torch.nn.functional.softmax(y, dim=0)\n",
        "\n",
        "        loss = -torch.sum(y_softmax * s_softmax)\n",
        "        total_loss += loss\n",
        "\n",
        "    return total_loss / batch_size\n",
        "\"\"\"\n",
        "\n",
        "def ranknet_loss(scores, labels, lengths):\n",
        "    batch_size = scores.size(0)\n",
        "    total_loss = 0.0\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "\n",
        "        diff_scores = s.unsqueeze(1) - s.unsqueeze(0)\n",
        "        rel = y.unsqueeze(1) > y.unsqueeze(0)\n",
        "        label_diff = rel.float()\n",
        "\n",
        "        log_sigmoid = torch.nn.functional.logsigmoid(diff_scores)\n",
        "        pair_loss = -label_diff * log_sigmoid\n",
        "\n",
        "        total_loss += pair_loss.sum()\n",
        "\n",
        "    return total_loss / batch_size\n",
        "\n",
        "def xranknet_loss(scores, labels, lengths, temperature=1.0, margin=0.2, focus_topk=3):\n",
        "    \"\"\"\n",
        "    xRankNet with emphasis on top-K items (based on labels, not scores).\n",
        "    \"\"\"\n",
        "    batch_size = scores.size(0)\n",
        "    total_loss = 0.0\n",
        "    total_pairs = 0\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        if l < 2:\n",
        "            continue\n",
        "\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "\n",
        "        # Top-K mask based on ground truth labels\n",
        "        topk = min(focus_topk, l)\n",
        "        _, topk_idx = torch.topk(y, topk)\n",
        "        topk_mask = torch.zeros_like(y, dtype=torch.bool)\n",
        "        topk_mask[topk_idx] = True\n",
        "\n",
        "        # Create pairwise difference matrices\n",
        "        score_diff = s.unsqueeze(1) - s.unsqueeze(0)\n",
        "        label_diff = y.unsqueeze(1) - y.unsqueeze(0)\n",
        "\n",
        "        # valid pair: y_i > y_j and at least one of i, j is in top-K\n",
        "        valid_pairs = (label_diff > 0) & (\n",
        "            topk_mask.unsqueeze(1) | topk_mask.unsqueeze(0)\n",
        "        )\n",
        "\n",
        "        if valid_pairs.sum() == 0:\n",
        "            continue\n",
        "\n",
        "        importance = (label_diff.abs() * valid_pairs).float()\n",
        "\n",
        "        if margin > 0.0:\n",
        "            score_diff = score_diff - margin\n",
        "\n",
        "        score_diff = score_diff / temperature\n",
        "        pairwise_loss = -F_torch.logsigmoid(score_diff) * importance\n",
        "\n",
        "        total_loss += pairwise_loss.sum()\n",
        "        total_pairs += importance.sum()\n",
        "\n",
        "    if total_pairs == 0:\n",
        "        return torch.tensor(0.0, device=scores.device, requires_grad=True)\n",
        "\n",
        "    return total_loss / total_pairs\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "def bpr_loss(scores, labels, lengths):\n",
        "    batch_size = scores.size(0)\n",
        "    total_loss = 0.0\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "\n",
        "        pos_mask = y > 0\n",
        "        neg_mask = y <= 0\n",
        "\n",
        "        pos_scores = s[pos_mask]\n",
        "        neg_scores = s[neg_mask]\n",
        "\n",
        "        if len(pos_scores) == 0 or len(neg_scores) == 0:\n",
        "            continue\n",
        "\n",
        "        pair_diff = pos_scores.unsqueeze(1) - neg_scores.unsqueeze(0)\n",
        "        loss = -F.logsigmoid(pair_diff).mean()\n",
        "        total_loss += loss\n",
        "\n",
        "    return total_loss / batch_size\n",
        "\"\"\"\n",
        "\n",
        "\"\"\"\n",
        "def lambdarank_loss(scores, labels, lengths, eps=1e-10):\n",
        "    batch_size = scores.size(0)\n",
        "    total_loss = 0.0\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "\n",
        "        if l < 2:\n",
        "            continue\n",
        "\n",
        "        _, rank_order = torch.sort(s, descending=True)\n",
        "        ideal_order = torch.sort(y, descending=True).indices\n",
        "\n",
        "        gain = 2 ** y - 1\n",
        "        discount = torch.log2(torch.arange(2, l + 2, device=y.device).float())\n",
        "\n",
        "        ideal_dcg = (gain[ideal_order] / discount).sum()\n",
        "        if ideal_dcg < eps:\n",
        "            continue\n",
        "\n",
        "        delta_ndcg = torch.zeros((l, l), device=y.device)\n",
        "\n",
        "        for i_idx in range(l):\n",
        "            for j_idx in range(l):\n",
        "                if y[i_idx] > y[j_idx]:\n",
        "                    change = (\n",
        "                        (1.0 / torch.log2(rank_order[i_idx] + 2.0))\n",
        "                        - (1.0 / torch.log2(rank_order[j_idx] + 2.0))\n",
        "                    ).abs()\n",
        "                    delta = (2 ** y[i_idx] - 2 ** y[j_idx]).abs() * change\n",
        "                    delta_ndcg[i_idx, j_idx] = delta / ideal_dcg\n",
        "\n",
        "        score_diffs = s.unsqueeze(1) - s.unsqueeze(0)\n",
        "        lambdas = -F.logsigmoid(score_diffs) * delta_ndcg\n",
        "        total_loss += lambdas.sum()\n",
        "\n",
        "    return total_loss / batch_size\n",
        "\"\"\"\n",
        "\n",
        "def train_one_epoch(model, loader, optimizer, device, scheduler):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "\n",
        "    for x_cat, x_num, y, lengths in tqdm(loader, desc=\"Training\", leave=False):\n",
        "        x_num, y = x_num.to(device), y.to(device)\n",
        "        if not isinstance(lengths, torch.Tensor):\n",
        "            lengths = torch.tensor(lengths)\n",
        "        lengths = lengths.detach().clone().to(device)\n",
        "        x_cat = {k: v.to(device) for k, v in x_cat.items()}\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        scores = model(x_cat, x_num)\n",
        "        loss = xranknet_loss(scores, y, lengths, temperature=1.0, margin=0.2, focus_topk=3)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    return total_loss / len(loader)\n",
        "\n",
        "\n",
        "def validate(model, loader, device, min_group_size=10):\n",
        "    model.eval()\n",
        "    total_hitrate = 0\n",
        "    total_ndcg = 0\n",
        "    total_map = 0\n",
        "    total_loss = 0\n",
        "    count = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for x_cat, x_num, y, lengths in tqdm(loader, desc=\"Validating\", leave=False):\n",
        "            x_num, y = x_num.to(device), y.to(device)\n",
        "            lengths = torch.tensor(lengths).to(device)\n",
        "            x_cat = {k: v.to(device) for k, v in x_cat.items()}\n",
        "\n",
        "            scores = model(x_cat, x_num)\n",
        "\n",
        "            hitrate = hitrate_at_k(scores, y, lengths, k=3, min_group_size=min_group_size)\n",
        "            ndcg = ndcg_at_k(scores, y, lengths, k=3, min_group_size=min_group_size)\n",
        "            map3 = map_at_k(scores, y, lengths, k=3, min_group_size=min_group_size)\n",
        "            loss = xranknet_loss(scores, y, lengths, temperature=1.0, margin=0.2, focus_topk=3)\n",
        "\n",
        "            batch_size = scores.size(0)\n",
        "            total_hitrate += hitrate * batch_size\n",
        "            total_ndcg += ndcg * batch_size\n",
        "            total_map += map3 * batch_size\n",
        "            total_loss += loss.item() * batch_size\n",
        "            count += batch_size\n",
        "\n",
        "    return total_loss / count, total_hitrate / count, total_ndcg / count, total_map / count\n",
        "\n",
        "\n",
        "def build_cat_dims(X, cat_features):\n",
        "    cat_dims = {}\n",
        "    for c in cat_features:\n",
        "        max_val = X[c].max()\n",
        "        if max_val < 0:\n",
        "            max_val = 0\n",
        "        cat_dims[c] = max_val + 1\n",
        "    return cat_dims\n",
        "\n",
        "\n",
        "def normalize_numeric_features(X, numeric_features, train_mask):\n",
        "    for col in numeric_features:\n",
        "        values = X[col].to_numpy()\n",
        "        train_vals = values[train_mask]\n",
        "        mean = train_vals.mean()\n",
        "        std = train_vals.std() if train_vals.std() > 0 else 1.0\n",
        "        norm_vals = (values - mean) / std\n",
        "        X = X.with_columns(pl.Series(col, norm_vals).alias(col))\n",
        "    return X\n",
        "\n",
        "\n",
        "def load_or_prepare_data(\n",
        "    data_dir,\n",
        "    train_file=\"train.parquet\",\n",
        "    test_file=\"test.parquet\",\n",
        "    cache_file=\"feature_engineered_val.parquet\",\n",
        "):\n",
        "    cache_path = os.path.join(data_dir, cache_file)\n",
        "\n",
        "    if os.path.exists(cache_path):\n",
        "        print(f\"Loading cached feature-engineered data from {cache_path} ...\")\n",
        "        df = pl.read_parquet(cache_path)\n",
        "\n",
        "        test = pl.read_parquet(os.path.join(data_dir, test_file)).drop(\"__index_level_0__\")\n",
        "        test_ids = test[\"Id\"]\n",
        "        test_rankers = test[\"ranker_id\"]\n",
        "    else:\n",
        "        print(\"Cached file not found, processing raw data ...\")\n",
        "\n",
        "        train = pl.read_parquet(os.path.join(data_dir, train_file)).drop(\"__index_level_0__\")\n",
        "        test = (\n",
        "            pl.read_parquet(os.path.join(data_dir, test_file))\n",
        "            .drop(\"__index_level_0__\")\n",
        "            .with_columns(pl.lit(0, dtype=pl.Int64).alias(\"selected\"))\n",
        "        )\n",
        "\n",
        "        test_ids = test[\"Id\"]\n",
        "        test_rankers = test[\"ranker_id\"]\n",
        "\n",
        "        df = pl.concat((train, test))\n",
        "        df = feature_engineering(df, full=True)\n",
        "\n",
        "        df = df.with_columns(\n",
        "            [pl.col(c).fill_null(0) for c in df.select(pl.selectors.numeric()).columns] +\n",
        "            [pl.col(c).fill_null(\"missing\") for c in df.select(pl.selectors.string()).columns]\n",
        "        )\n",
        "\n",
        "        os.makedirs(data_dir, exist_ok=True)\n",
        "        df.write_parquet(cache_path)\n",
        "        print(f\"Saved feature-engineered data to {cache_path}\")\n",
        "\n",
        "    return df, test_ids, test_rankers\n",
        "\n",
        "\n",
        "def prepare_data(data_dir):\n",
        "    df, test_ids, test_rankers = load_or_prepare_data(data_dir)\n",
        "\n",
        "    id_column = df[\"Id\"]\n",
        "    X, y, groups, cat_features, num_features = feature_selection(df)\n",
        "\n",
        "    X = X.with_columns(pl.Series(\"Id\", id_column[:X.shape[0]]))\n",
        "\n",
        "    X = X.with_columns(\n",
        "        [\n",
        "            (pl.col(c).rank(\"dense\") - 1).fill_null(-1).cast(pl.Int32)\n",
        "            for c in cat_features\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    train_size = 18145372\n",
        "    train_mask = np.arange(X.height) < train_size\n",
        "    X = normalize_numeric_features(X, num_features, train_mask)\n",
        "\n",
        "    return X, y, groups, cat_features, num_features, train_size, test_ids, test_rankers\n",
        "\n",
        "\n",
        "class EarlyStopping:\n",
        "    def __init__(self, patience=3, min_delta=0.00005):\n",
        "        self.patience = patience\n",
        "        self.min_delta = min_delta\n",
        "        self.best = float(\"-inf\")\n",
        "        self.counter = 0\n",
        "\n",
        "    def step(self, metric):\n",
        "        if metric > self.best + self.min_delta:\n",
        "            self.best = metric\n",
        "            self.counter = 0\n",
        "        else:\n",
        "            self.counter += 1\n",
        "        return self.counter >= self.patience\n",
        "\n",
        "\n",
        "def plot_group_size_distribution(dataset, save_path=None):\n",
        "    group_sizes = [len(v) for v in dataset.group_to_indices.values()]\n",
        "    plt.figure()\n",
        "    plt.hist(group_sizes, bins=100, log=True)\n",
        "    plt.xlabel(\"Group size (number of items per ranker_id)\")\n",
        "    plt.ylabel(\"Frequency (log scale)\")\n",
        "    plt.title(\"Distribution of Group Sizes\")\n",
        "    plt.grid(True)\n",
        "    if save_path:\n",
        "        plt.savefig(save_path)\n",
        "    else:\n",
        "        plt.show()\n",
        "    plt.close()\n",
        "\n",
        "\n",
        "def main():\n",
        "    DATA_DIR = \"./data\"\n",
        "    MODEL_DIR = \"model\"\n",
        "    SUBMIT_DIR = \"submission\"\n",
        "\n",
        "    best_val_loss = float(\"inf\")\n",
        "    best_hitrate = 0.0\n",
        "    model_path = os.path.join(MODEL_DIR, \"best_dl_ranker.pt\")\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "    val_hitrates = []\n",
        "    val_ndcgs = []\n",
        "    val_maps = []\n",
        "    learning_rates = []\n",
        "\n",
        "    os.makedirs(MODEL_DIR, exist_ok=True)\n",
        "    os.makedirs(SUBMIT_DIR, exist_ok=True)\n",
        "\n",
        "    early_stopper = EarlyStopping(patience=3, min_delta=0.001)\n",
        "\n",
        "    X, y, groups, cat_features, num_features, train_size, test_ids, test_rankers = prepare_data(DATA_DIR)\n",
        "\n",
        "    # Fill missing values\n",
        "    float_cols = [c for c, t in zip(X.columns, X.dtypes) if t == pl.Float64]\n",
        "    for col in float_cols:\n",
        "        X = X.with_columns(\n",
        "            pl.when(pl.col(col).is_nan()).then(0).otherwise(pl.col(col)).alias(col)\n",
        "        )\n",
        "\n",
        "    n1 = 16487352\n",
        "    # n1 = 17487300\n",
        "    n2 = train_size\n",
        "\n",
        "    X_tr, X_va, X_te = X[:n1], X[n1:n2], X[n2:]\n",
        "    y_tr, y_va, y_te = y[:n1], y[n1:n2], y[n2:]\n",
        "    groups_tr, groups_va, groups_te = groups[:n1], groups[n1:n2], groups[n2:]\n",
        "\n",
        "    # Inspect group sizes in validation set\n",
        "    val_rankers = groups_va[\"ranker_id\"].to_numpy()\n",
        "    val_group_counts = Counter(val_rankers)\n",
        "\n",
        "    print(\"\\nüìã Validation group statistics:\")\n",
        "    # Save detailed group info to file\n",
        "    group_info_path = os.path.join(MODEL_DIR, \"validation_groups_info.txt\")\n",
        "    with open(group_info_path, \"w\") as f:\n",
        "        f.write(f\"Total groups: {len(val_group_counts)}\\n\\n\")\n",
        "        f.write(\"GroupID\\tSize\\tStartIdx\\tEndIdx\\n\")\n",
        "\n",
        "        group_to_rows = defaultdict(list)\n",
        "        for i, g in enumerate(val_rankers):\n",
        "            group_to_rows[g].append(i)\n",
        "\n",
        "        for group_id, indices in sorted(group_to_rows.items()):\n",
        "            start_idx = indices[0]\n",
        "            end_idx = indices[-1]\n",
        "            size = len(indices)\n",
        "            f.write(f\"{group_id}\\t{size}\\t{start_idx}\\t{end_idx}\\n\")\n",
        "\n",
        "    print(f\"üìÅ Saved validation group info to {group_info_path}\")\n",
        "\n",
        "\n",
        "    cat_dims = build_cat_dims(X, cat_features)\n",
        "    num_numeric_feats = len(num_features)\n",
        "\n",
        "    train_dataset = RankDataset(X_tr, y_tr, groups_tr, cat_features, num_features)\n",
        "    val_dataset = RankDataset(X_va, y_va, groups_va, cat_features, num_features)\n",
        "    test_dataset = RankDataset(X_te, y_te, groups_te, cat_features, num_features)\n",
        "\n",
        "    plot_group_size_distribution(train_dataset, save_path=os.path.join(MODEL_DIR, \"group_sizes.png\"))\n",
        "    print(\"üìä Group size distribution saved.\")\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True, collate_fn=collate_fn)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=4, shuffle=False, collate_fn=collate_fn)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False, collate_fn=collate_fn)\n",
        "\n",
        "    print(\"‚úÖ Data loaders created.\")\n",
        "\n",
        "    num_epochs = 10\n",
        "    num_training_steps = num_epochs * len(train_loader)\n",
        "    num_warmup_steps = int(0.1 * num_training_steps)\n",
        "\n",
        "    learning_rate = 7e-4\n",
        "\n",
        "    model = FiBiNetRanker(\n",
        "        cat_dims=cat_dims,\n",
        "        num_numeric_feats=num_numeric_feats,\n",
        "        emb_dim=64,\n",
        "        hidden=[512, 256, 128, 64]\n",
        "    ).to(device)\n",
        "\n",
        "\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=0.01)\n",
        "\n",
        "    scheduler = get_scheduler(\n",
        "        \"linear\",\n",
        "        optimizer=optimizer,\n",
        "        num_warmup_steps=num_warmup_steps,\n",
        "        num_training_steps=num_training_steps\n",
        "    )\n",
        "\n",
        "    best_hitrate = 0\n",
        "    for epoch in range(num_epochs):\n",
        "        print(f\"\\n--- Epoch {epoch+1}/{num_epochs} ---\")\n",
        "        start_time = time.time()\n",
        "\n",
        "        train_loss = train_one_epoch(model, train_loader, optimizer, device, scheduler)\n",
        "        val_loss, val_hitrate, val_ndcg, val_map = validate(model, val_loader, device, min_group_size=10)\n",
        "\n",
        "        train_losses.append(train_loss)\n",
        "        val_losses.append(val_loss)\n",
        "        val_hitrates.append(val_hitrate.item())\n",
        "        val_ndcgs.append(val_ndcg.item())\n",
        "        val_maps.append(val_map.item())\n",
        "\n",
        "        current_lr = scheduler.get_last_lr()\n",
        "        learning_rates.append(current_lr[0])\n",
        "\n",
        "        elapsed = time.time() - start_time\n",
        "        print(\n",
        "            f\"Epoch {epoch+1}: \"\n",
        "            f\"Train Loss={train_loss:.4f}, \"\n",
        "            f\"Val Loss={val_loss:.4f}, \"\n",
        "            f\"HitRate@3={val_hitrate:.4f}, \"\n",
        "            f\"NDCG@3={val_ndcg:.4f}, \"\n",
        "            f\"MAP@3={val_map:.4f}, \"\n",
        "            f\"LR={current_lr[0]:.6f} \"\n",
        "            f\"({elapsed:.1f}s)\"\n",
        "        )\n",
        "\n",
        "\n",
        "        if val_loss < best_val_loss and val_hitrate > best_hitrate:\n",
        "            best_val_loss = val_loss\n",
        "            best_hitrate = val_hitrate\n",
        "            torch.save(model.state_dict(), model_path)\n",
        "            print(\"üíæ Model improved (loss ‚Üì and hitrate ‚Üë), saved.\")\n",
        "\n",
        "        if early_stopper.step(-val_loss):\n",
        "            print(\"‚õî Early stopping triggered.\")\n",
        "            break\n",
        "\n",
        "    # Plot metrics\n",
        "    epochs = list(range(1, len(train_losses) + 1))\n",
        "\n",
        "    # Plot Loss Curve\n",
        "    plt.figure()\n",
        "    plt.plot(epochs, train_losses, label=\"Train Loss\")\n",
        "    plt.plot(epochs, val_losses, label=\"Val Loss\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.title(\"Training & Validation Loss\")\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.savefig(os.path.join(MODEL_DIR, \"loss_curve.png\"))\n",
        "    plt.close()\n",
        "\n",
        "    # Plot HitRate@3\n",
        "    plt.figure()\n",
        "    plt.plot(epochs, val_hitrates, label=\"Val HitRate@3\", color=\"green\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"HitRate@3\")\n",
        "    plt.title(\"Validation HitRate@3\")\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.savefig(os.path.join(MODEL_DIR, \"hitrate_curve.png\"))\n",
        "    plt.close()\n",
        "\n",
        "    # Plot Learning Rate\n",
        "    plt.figure()\n",
        "    plt.plot(epochs, learning_rates, label=\"Learning Rate\", color=\"orange\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"LR\")\n",
        "    plt.title(\"Learning Rate Schedule\")\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.savefig(os.path.join(MODEL_DIR, \"lr_curve.png\"))\n",
        "    plt.close()\n",
        "\n",
        "    # Plot NDCG@3\n",
        "    plt.figure()\n",
        "    plt.plot(epochs, val_ndcgs, label=\"Val NDCG@3\", color=\"purple\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"NDCG@3\")\n",
        "    plt.title(\"Validation NDCG@3\")\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.savefig(os.path.join(MODEL_DIR, \"ndcg_curve.png\"))\n",
        "    plt.close()\n",
        "\n",
        "    # Plot MAP@3\n",
        "    plt.figure()\n",
        "    plt.plot(epochs, val_maps, label=\"Val MAP@3\", color=\"red\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"MAP@3\")\n",
        "    plt.title(\"Validation MAP@3\")\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.savefig(os.path.join(MODEL_DIR, \"map_curve.png\"))\n",
        "    plt.close()\n",
        "\n",
        "    print(\"üìä Saved metric plots to model/\")\n",
        "\n",
        "    # Predict test set\n",
        "    model.load_state_dict(torch.load(model_path))\n",
        "    model.eval()\n",
        "\n",
        "    val_ids = X_va[\"Id\"]\n",
        "    val_rankers = groups_va[\"ranker_id\"]\n",
        "    val_labels = y_va\n",
        "\n",
        "    all_val_scores = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for x_cat, x_num, _, lengths in tqdm(val_loader, desc=\"Predicting validation set\"):\n",
        "            x_num = x_num.to(device)\n",
        "            x_cat = {k: v.to(device) for k, v in x_cat.items()}\n",
        "            scores = model(x_cat, x_num)\n",
        "\n",
        "            for i in range(scores.size(0)):\n",
        "                l = lengths[i]\n",
        "                all_val_scores.append(scores[i, :l].cpu().numpy())\n",
        "\n",
        "    all_val_scores = np.concatenate(all_val_scores)\n",
        "\n",
        "    assert len(all_val_scores) == X_va.shape[0], \\\n",
        "        f\"Mismatch: {len(all_val_scores)} scores vs {X_va.shape[0]} rows\"\n",
        "\n",
        "    val_df = X_va.with_columns([\n",
        "        pl.Series(\"Id\", val_ids),\n",
        "        pl.Series(\"ranker_id\", val_rankers),\n",
        "        pl.Series(\"score\", all_val_scores),\n",
        "        pl.Series(\"label\", val_labels)\n",
        "    ])\n",
        "\n",
        "    val_df = val_df.with_columns(\n",
        "        pl.col(\"score\")\n",
        "        .rank(method=\"ordinal\", descending=True)\n",
        "        .over(\"ranker_id\")\n",
        "        .cast(pl.Int32)\n",
        "        .alias(\"selected\")\n",
        "    )\n",
        "\n",
        "    val_save_path = os.path.join(MODEL_DIR, \"validation_preds_dl_full.csv\")\n",
        "    val_df.write_csv(val_save_path)\n",
        "    print(f\"‚úÖ Saved full validation predictions (with features) to {val_save_path}\")\n",
        "\n",
        "    all_scores = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for x_cat, x_num, _, lengths in tqdm(test_loader, desc=\"Predicting test set\"):\n",
        "            x_num = x_num.to(device)\n",
        "            x_cat = {k: v.to(device) for k, v in x_cat.items()}\n",
        "            scores = model(x_cat, x_num)\n",
        "\n",
        "            for i in range(scores.size(0)):\n",
        "                l = lengths[i]\n",
        "                all_scores.append(scores[i, :l].cpu().numpy())\n",
        "\n",
        "    all_scores = np.concatenate(all_scores)\n",
        "\n",
        "    assert len(all_scores) == X_te.shape[0], \\\n",
        "        f\"Mismatch: {len(all_scores)} scores vs {X_te.shape[0]} rows in X_te\"\n",
        "\n",
        "    submission_df = pl.DataFrame({\n",
        "        \"Id\": test_ids,\n",
        "        \"ranker_id\": test_rankers,\n",
        "        \"score\": all_scores\n",
        "    })\n",
        "\n",
        "    submission = (\n",
        "        submission_df\n",
        "        .with_columns(\n",
        "            pl.col(\"score\")\n",
        "            .rank(method=\"ordinal\", descending=True)\n",
        "            .over(\"ranker_id\")\n",
        "            .cast(pl.Int32)\n",
        "            .alias(\"selected\")\n",
        "        )\n",
        "        .select([\"Id\", \"ranker_id\", \"score\", \"selected\"])\n",
        "    )\n",
        "\n",
        "    submission_path = os.path.join(SUBMIT_DIR, \"submission_dl_ranker.csv\")\n",
        "    submission.write_csv(submission_path)\n",
        "    print(f\"‚úÖ Submission saved to {submission_path}\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eb-i6AVBcFql",
        "outputId": "dc5267cb-d4b2-4321-c364-bb4543be71c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing deeprec_validate.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "--- Epoch 1/10 ---\n",
        "Validating:   0%|          | 0/2636 [00:00<?, ?it/s]/home/ionut/test_whisper/test2/deeprec_validate.py:462: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
        "  lengths = torch.tensor(lengths).to(device)\n",
        "Epoch 1: Train Loss=0.3718, Val Loss=0.3083, HitRate@3=0.4674, NDCG@3=0.3711, MAP@3=0.6171, LR=0.001000 (727.9s)\n",
        "üíæ Model improved (loss ‚Üì and hitrate ‚Üë), saved.\n",
        "\n",
        "--- Epoch 2/10 ---\n",
        "Epoch 2: Train Loss=0.2933, Val Loss=0.2905, HitRate@3=0.4715, NDCG@3=0.3777, MAP@3=0.6251, LR=0.000889 (726.1s)\n",
        "üíæ Model improved (loss ‚Üì and hitrate ‚Üë), saved.\n",
        "\n",
        "--- Epoch 3/10 ---\n",
        "Epoch 3: Train Loss=0.2770, Val Loss=0.2795, HitRate@3=0.4868, NDCG@3=0.3905, MAP@3=0.6359, LR=0.000778 (724.0s)\n",
        "üíæ Model improved (loss ‚Üì and hitrate ‚Üë), saved.\n",
        "\n",
        "--- Epoch 4/10 ---\n",
        "Epoch 4: Train Loss=0.2668, Val Loss=0.2731, HitRate@3=0.4884, NDCG@3=0.3969, MAP@3=0.6470, LR=0.000667 (727.3s)\n",
        "üíæ Model improved (loss ‚Üì and hitrate ‚Üë), saved.\n",
        "\n",
        "--- Epoch 5/10 ---\n",
        "Epoch 5: Train Loss=0.2613, Val Loss=0.2762, HitRate@3=0.4931, NDCG@3=0.3990, MAP@3=0.6451, LR=0.000556 (728.7s)\n",
        "\n",
        "--- Epoch 6/10 ---\n",
        "Epoch 6: Train Loss=0.2558, Val Loss=0.2726, HitRate@3=0.4994, NDCG@3=0.4032, MAP@3=0.6499, LR=0.000444 (725.2s)\n",
        "üíæ Model improved (loss ‚Üì and hitrate ‚Üë), saved.\n",
        "\n",
        "--- Epoch 7/10 ---\n",
        "Epoch 7: Train Loss=0.2508, Val Loss=0.2646, HitRate@3=0.5053, NDCG@3=0.4106, MAP@3=0.6560, LR=0.000333 (730.9s)\n",
        "üíæ Model improved (loss ‚Üì and hitrate ‚Üë), saved.\n",
        "\n",
        "--- Epoch 8/10 ---\n",
        "Epoch 8: Train Loss=0.2453, Val Loss=0.2647, HitRate@3=0.5029, NDCG@3=0.4092, MAP@3=0.6563, LR=0.000222 (728.2s)\n",
        "\n",
        "--- Epoch 9/10 ---\n",
        "Epoch 9: Train Loss=0.2399, Val Loss=0.2643, HitRate@3=0.4992, NDCG@3=0.4064, MAP@3=0.6541, LR=0.000111 (727.0s)\n",
        "\n",
        "--- Epoch 10/10 ---\n",
        "Epoch 10: Train Loss=0.2346, Val Loss=0.2648, HitRate@3=0.5003, NDCG@3=0.4065, MAP@3=0.6563, LR=0.000000 (726.9s)"
      ],
      "metadata": {
        "id": "nV58_MleJROK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile deeprec_validate.py\n",
        "import os\n",
        "import time\n",
        "import random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F_torch\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import defaultdict\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "import polars as pl\n",
        "from tqdm import tqdm\n",
        "from src.feature import feature_engineering, feature_selection\n",
        "from transformers import get_scheduler\n",
        "from collections import Counter\n",
        "\n",
        "class RankDataset(Dataset):\n",
        "    def __init__(\n",
        "        self,\n",
        "        X: pl.DataFrame,\n",
        "        y: pl.Series,\n",
        "        groups: pl.DataFrame,\n",
        "        cat_features: list[str],\n",
        "        num_features: list[str],\n",
        "    ):\n",
        "        self.cat_features = cat_features\n",
        "        self.num_features = num_features\n",
        "        self.X_cat = {c: X[c].to_numpy() for c in cat_features}\n",
        "        self.X_num = X[self.num_features].to_numpy()\n",
        "        self.y = y.to_numpy()\n",
        "        self.groups = groups[\"ranker_id\"].to_numpy()\n",
        "\n",
        "        self.group_to_indices = defaultdict(list)\n",
        "        for i, g in enumerate(self.groups):\n",
        "            self.group_to_indices[g].append(i)\n",
        "        self.group_keys = list(self.group_to_indices.keys())\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.group_keys)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        g = self.group_keys[idx]\n",
        "        inds = self.group_to_indices[g]\n",
        "        length = len(inds)\n",
        "\n",
        "        x_cat = {\n",
        "            c: torch.LongTensor([\n",
        "                self.X_cat[c][i] if self.X_cat[c][i] >= 0 else 0 for i in inds\n",
        "            ])\n",
        "            for c in self.cat_features\n",
        "        }\n",
        "\n",
        "        x_num = torch.FloatTensor(self.X_num[inds])\n",
        "        y = torch.FloatTensor(self.y[inds]).reshape(-1)\n",
        "\n",
        "        return x_cat, x_num, y, length\n",
        "\n",
        "def collate_fn(batch):\n",
        "    batch = [b for b in batch if b[3] >= 2]\n",
        "    if len(batch) == 0:\n",
        "        return None\n",
        "\n",
        "    batch_size = len(batch)\n",
        "    lengths = [b[3] for b in batch]\n",
        "    max_len = max(lengths)\n",
        "\n",
        "    padded_x_cat = {key: [] for key in batch[0][0].keys()}\n",
        "    padded_x_num = []\n",
        "    padded_y = []\n",
        "\n",
        "    num_dim = batch[0][1].shape[1]\n",
        "\n",
        "    for x_cat, x_num, y, length in batch:\n",
        "        pad_len = max_len - length\n",
        "\n",
        "        for key in padded_x_cat:\n",
        "            val = x_cat[key]\n",
        "            if pad_len > 0:\n",
        "                val = torch.cat([val, torch.zeros(pad_len, dtype=torch.long)])\n",
        "            padded_x_cat[key].append(val)\n",
        "\n",
        "        if pad_len > 0:\n",
        "            x_num = torch.cat([x_num, torch.zeros(pad_len, num_dim)])\n",
        "            y = torch.cat([y, torch.zeros(pad_len)])\n",
        "\n",
        "        padded_x_num.append(x_num)\n",
        "        padded_y.append(y)\n",
        "\n",
        "    padded_x_cat = {k: torch.stack(v) for k, v in padded_x_cat.items()}\n",
        "    padded_x_num = torch.stack(padded_x_num)\n",
        "    padded_y = torch.stack(padded_y)\n",
        "    lengths = torch.tensor(lengths, dtype=torch.long)\n",
        "\n",
        "    return padded_x_cat, padded_x_num, padded_y, lengths\n",
        "\n",
        "\n",
        "class FiBiDLRanker(nn.Module):\n",
        "    def __init__(self, cat_dims, num_numeric_feats, emb_dim=64, hidden=[512, 256, 128, 64], reduction=4, use_senet=True):\n",
        "        super().__init__()\n",
        "        self.cat_fields = list(cat_dims.keys())\n",
        "        self.emb_dim = emb_dim\n",
        "        self.num_fields = len(self.cat_fields)\n",
        "        self.use_senet = use_senet\n",
        "\n",
        "        # Embedding layers\n",
        "        self.embeddings = nn.ModuleDict({\n",
        "            f: nn.Embedding(cat_dims[f], emb_dim, padding_idx=0) for f in self.cat_fields\n",
        "        })\n",
        "        self.linear_cat = nn.ModuleDict({\n",
        "            f: nn.Embedding(cat_dims[f], 1, padding_idx=0) for f in self.cat_fields\n",
        "        })\n",
        "        self.linear_num = nn.Linear(num_numeric_feats, 1)\n",
        "\n",
        "        for emb in list(self.embeddings.values()) + list(self.linear_cat.values()):\n",
        "            nn.init.xavier_uniform_(emb.weight)\n",
        "        nn.init.xavier_uniform_(self.linear_num.weight)\n",
        "\n",
        "        # SENet (with LayerNorm)\n",
        "        if self.use_senet:\n",
        "            self.se_fc1 = nn.Linear(self.num_fields * emb_dim, self.num_fields * emb_dim // reduction)\n",
        "            self.se_ln1 = nn.LayerNorm(self.num_fields * emb_dim // reduction)\n",
        "            self.se_dropout = nn.Dropout(0.1)\n",
        "            self.se_fc2 = nn.Linear(self.num_fields * emb_dim // reduction, self.num_fields * emb_dim)\n",
        "\n",
        "        # Bilinear layer (shared)\n",
        "        self.bilinear = nn.Linear(emb_dim, emb_dim, bias=False)\n",
        "\n",
        "        # MLP (using LayerNorm instead of BatchNorm)\n",
        "        input_dim = emb_dim + num_numeric_feats\n",
        "        layers = []\n",
        "        for h in hidden:\n",
        "            layers.append(nn.Linear(input_dim, h))\n",
        "            layers.append(nn.LayerNorm(h))     # replaced BatchNorm1d with LayerNorm\n",
        "            layers.append(nn.ReLU())\n",
        "            layers.append(nn.Dropout(0.2))\n",
        "            input_dim = h\n",
        "        self.mlp = nn.Sequential(*layers)\n",
        "        self.output = nn.Linear(input_dim, 1)\n",
        "\n",
        "    def senet(self, embs):\n",
        "        B, F, D = embs.shape\n",
        "        z = embs.view(B, -1)  # Flatten [B, F*D]\n",
        "        a = self.se_fc1(z)    # Linear\n",
        "        a = self.se_ln1(a)    # LayerNorm instead of BatchNorm\n",
        "        a = F_torch.relu(a)\n",
        "        a = self.se_dropout(a)\n",
        "        s = torch.sigmoid(self.se_fc2(a)).view(B, F, D)\n",
        "        return embs * s\n",
        "\n",
        "    def bilinear_interaction(self, embs):\n",
        "        transformed = self.bilinear(embs)\n",
        "        interaction = (embs * transformed).mean(dim=1)\n",
        "        return interaction\n",
        "\n",
        "    def forward(self, x_cat, x_num):\n",
        "        B, G = x_num.shape[:2]\n",
        "        F, D = self.num_fields, self.emb_dim\n",
        "\n",
        "        # Embeddings [B, G, F, D]\n",
        "        embs = torch.stack([self.embeddings[f](x_cat[f]) for f in self.cat_fields], dim=2)\n",
        "\n",
        "        # Linear output\n",
        "        linear_cat_sum = torch.stack([\n",
        "            self.linear_cat[f](x_cat[f]).squeeze(-1) for f in self.cat_fields\n",
        "        ], dim=0).sum(dim=0)\n",
        "        linear_num_out = self.linear_num(x_num).squeeze(-1)\n",
        "        linear_out = linear_cat_sum + linear_num_out  # [B, G]\n",
        "\n",
        "        # Feature interactions\n",
        "        embs = embs.view(B * G, F, D)\n",
        "        if self.use_senet:\n",
        "            embs = self.senet(embs)\n",
        "        bi = self.bilinear_interaction(embs)  # [B*G, D]\n",
        "\n",
        "        # Deep part\n",
        "        x_num_flat = x_num.view(B * G, -1)\n",
        "        deep_input = torch.cat([bi, x_num_flat], dim=1)\n",
        "        deep_out = self.mlp(deep_input)\n",
        "        scores = self.output(deep_out).view(B, G)\n",
        "\n",
        "        return scores + linear_out  # final output\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "def listmle_loss(scores, labels, lengths):\n",
        "    batch_size = scores.size(0)\n",
        "    total_loss = torch.tensor(0.0, device=scores.device, requires_grad=True)\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "\n",
        "        _, idx = torch.sort(y, descending=True)\n",
        "        s_sorted = s[idx]\n",
        "\n",
        "        parts = (\n",
        "            torch.logsumexp(s_sorted.unsqueeze(0).expand(l, -1).triu(diagonal=0), dim=1)\n",
        "            - s_sorted\n",
        "        )\n",
        "\n",
        "        total_loss = total_loss + parts.sum()\n",
        "\n",
        "    return total_loss / batch_size\n",
        "\"\"\"\n",
        "\n",
        "def hitrate_at_k(scores, labels, lengths, k=3, min_group_size=10):\n",
        "    batch_size = scores.size(0)\n",
        "    hits = 0\n",
        "    valid_count = 0\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        if l < min_group_size:\n",
        "            continue\n",
        "        length = min(l, k)\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "        _, topk_idx = torch.topk(s, length)\n",
        "        topk_labels = y[topk_idx]\n",
        "        hits += (topk_labels > 0).any().float()\n",
        "        valid_count += 1\n",
        "    return hits / valid_count if valid_count > 0 else torch.tensor(0.0, device=scores.device)\n",
        "\n",
        "\n",
        "def ndcg_at_k(scores, labels, lengths, k=3, min_group_size=10):\n",
        "    batch_size = scores.size(0)\n",
        "    total_ndcg = 0.0\n",
        "    valid_count = 0\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        if l < min_group_size:\n",
        "            continue\n",
        "\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "\n",
        "        _, idx_pred = torch.topk(s, min(k, l))\n",
        "        _, idx_ideal = torch.topk(y, min(k, l))\n",
        "\n",
        "        dcg = (y[idx_pred] / torch.log2(torch.arange(2, 2 + len(idx_pred), device=y.device).float())).sum()\n",
        "        idcg = (y[idx_ideal] / torch.log2(torch.arange(2, 2 + len(idx_ideal), device=y.device).float())).sum()\n",
        "\n",
        "        ndcg = dcg / idcg if idcg > 0 else 0.0\n",
        "        total_ndcg += ndcg\n",
        "        valid_count += 1\n",
        "\n",
        "    return total_ndcg / valid_count if valid_count > 0 else torch.tensor(0.0, device=scores.device)\n",
        "\n",
        "\n",
        "def map_at_k(scores, labels, lengths, k=3, min_group_size=10):\n",
        "    batch_size = scores.size(0)\n",
        "    total_ap = 0.0\n",
        "    valid_count = 0\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        if l < min_group_size:\n",
        "            continue\n",
        "\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "\n",
        "        _, idx_pred = torch.topk(s, min(k, l))\n",
        "        y_true = y[idx_pred] > 0\n",
        "\n",
        "        if y_true.sum() == 0:\n",
        "            continue\n",
        "\n",
        "        precisions = [(y_true[:j+1].float().sum() / (j+1)) for j in range(len(y_true)) if y_true[j]]\n",
        "        ap = torch.stack(precisions).mean()\n",
        "        total_ap += ap\n",
        "        valid_count += 1\n",
        "\n",
        "    return total_ap / valid_count if valid_count > 0 else torch.tensor(0.0, device=scores.device)\n",
        "\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "def listnet_loss(scores, labels, lengths):\n",
        "    batch_size = scores.size(0)\n",
        "    total_loss = 0.0\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "\n",
        "        s_softmax = torch.nn.functional.log_softmax(s, dim=0)\n",
        "        y_softmax = torch.nn.functional.softmax(y, dim=0)\n",
        "\n",
        "        loss = -torch.sum(y_softmax * s_softmax)\n",
        "        total_loss += loss\n",
        "\n",
        "    return total_loss / batch_size\n",
        "\"\"\"\n",
        "\n",
        "def ranknet_loss(scores, labels, lengths):\n",
        "    batch_size = scores.size(0)\n",
        "    total_loss = 0.0\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "\n",
        "        diff_scores = s.unsqueeze(1) - s.unsqueeze(0)\n",
        "        rel = y.unsqueeze(1) > y.unsqueeze(0)\n",
        "        label_diff = rel.float()\n",
        "\n",
        "        log_sigmoid = torch.nn.functional.logsigmoid(diff_scores)\n",
        "        pair_loss = -label_diff * log_sigmoid\n",
        "\n",
        "        total_loss += pair_loss.sum()\n",
        "\n",
        "    return total_loss / batch_size\n",
        "\n",
        "def xranknet_loss(scores, labels, lengths, temperature=1.0, margin=0.2, focus_topk=3):\n",
        "    \"\"\"\n",
        "    xRankNet with emphasis on top-K items (based on labels, not scores).\n",
        "    \"\"\"\n",
        "    batch_size = scores.size(0)\n",
        "    total_loss = 0.0\n",
        "    total_pairs = 0\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        if l < 2:\n",
        "            continue\n",
        "\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "\n",
        "        # Top-K mask based on ground truth labels\n",
        "        topk = min(focus_topk, l)\n",
        "        _, topk_idx = torch.topk(y, topk)\n",
        "        topk_mask = torch.zeros_like(y, dtype=torch.bool)\n",
        "        topk_mask[topk_idx] = True\n",
        "\n",
        "        # Create pairwise difference matrices\n",
        "        score_diff = s.unsqueeze(1) - s.unsqueeze(0)\n",
        "        label_diff = y.unsqueeze(1) - y.unsqueeze(0)\n",
        "\n",
        "        # valid pair: y_i > y_j and at least one of i, j is in top-K\n",
        "        valid_pairs = (label_diff > 0) & (\n",
        "            topk_mask.unsqueeze(1) | topk_mask.unsqueeze(0)\n",
        "        )\n",
        "\n",
        "        if valid_pairs.sum() == 0:\n",
        "            continue\n",
        "\n",
        "        importance = (label_diff.abs() * valid_pairs).float()\n",
        "\n",
        "        if margin > 0.0:\n",
        "            score_diff = score_diff - margin\n",
        "\n",
        "        score_diff = score_diff / temperature\n",
        "        pairwise_loss = -F_torch.logsigmoid(score_diff) * importance\n",
        "\n",
        "        total_loss += pairwise_loss.sum()\n",
        "        total_pairs += importance.sum()\n",
        "\n",
        "    if total_pairs == 0:\n",
        "        return torch.tensor(0.0, device=scores.device, requires_grad=True)\n",
        "\n",
        "    return total_loss / total_pairs\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "def bpr_loss(scores, labels, lengths):\n",
        "    batch_size = scores.size(0)\n",
        "    total_loss = 0.0\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "\n",
        "        pos_mask = y > 0\n",
        "        neg_mask = y <= 0\n",
        "\n",
        "        pos_scores = s[pos_mask]\n",
        "        neg_scores = s[neg_mask]\n",
        "\n",
        "        if len(pos_scores) == 0 or len(neg_scores) == 0:\n",
        "            continue\n",
        "\n",
        "        pair_diff = pos_scores.unsqueeze(1) - neg_scores.unsqueeze(0)\n",
        "        loss = -F.logsigmoid(pair_diff).mean()\n",
        "        total_loss += loss\n",
        "\n",
        "    return total_loss / batch_size\n",
        "\"\"\"\n",
        "\n",
        "\"\"\"\n",
        "def lambdarank_loss(scores, labels, lengths, eps=1e-10):\n",
        "    batch_size = scores.size(0)\n",
        "    total_loss = 0.0\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "\n",
        "        if l < 2:\n",
        "            continue\n",
        "\n",
        "        _, rank_order = torch.sort(s, descending=True)\n",
        "        ideal_order = torch.sort(y, descending=True).indices\n",
        "\n",
        "        gain = 2 ** y - 1\n",
        "        discount = torch.log2(torch.arange(2, l + 2, device=y.device).float())\n",
        "\n",
        "        ideal_dcg = (gain[ideal_order] / discount).sum()\n",
        "        if ideal_dcg < eps:\n",
        "            continue\n",
        "\n",
        "        delta_ndcg = torch.zeros((l, l), device=y.device)\n",
        "\n",
        "        for i_idx in range(l):\n",
        "            for j_idx in range(l):\n",
        "                if y[i_idx] > y[j_idx]:\n",
        "                    change = (\n",
        "                        (1.0 / torch.log2(rank_order[i_idx] + 2.0))\n",
        "                        - (1.0 / torch.log2(rank_order[j_idx] + 2.0))\n",
        "                    ).abs()\n",
        "                    delta = (2 ** y[i_idx] - 2 ** y[j_idx]).abs() * change\n",
        "                    delta_ndcg[i_idx, j_idx] = delta / ideal_dcg\n",
        "\n",
        "        score_diffs = s.unsqueeze(1) - s.unsqueeze(0)\n",
        "        lambdas = -F.logsigmoid(score_diffs) * delta_ndcg\n",
        "        total_loss += lambdas.sum()\n",
        "\n",
        "    return total_loss / batch_size\n",
        "\"\"\"\n",
        "\n",
        "def train_one_epoch(model, loader, optimizer, device, scheduler):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "    valid_batches = 0\n",
        "\n",
        "    for batch in tqdm(loader, desc=\"Training\", leave=False):\n",
        "        if batch is None:\n",
        "            continue\n",
        "\n",
        "        x_cat, x_num, y, lengths = batch\n",
        "\n",
        "        x_num, y = x_num.to(device), y.to(device)\n",
        "        lengths = lengths.to(device)\n",
        "        x_cat = {k: v.to(device) for k, v in x_cat.items()}\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        scores = model(x_cat, x_num)\n",
        "        loss = xranknet_loss(scores, y, lengths, temperature=1.0, margin=0.2, focus_topk=3)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        valid_batches += 1\n",
        "\n",
        "    return total_loss / valid_batches if valid_batches > 0 else float(\"inf\")\n",
        "\n",
        "\n",
        "\n",
        "def validate(model, loader, device, min_group_size=10):\n",
        "    model.eval()\n",
        "    total_hitrate = 0\n",
        "    total_ndcg = 0\n",
        "    total_map = 0\n",
        "    total_loss = 0\n",
        "    count = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for x_cat, x_num, y, lengths in tqdm(loader, desc=\"Validating\", leave=False):\n",
        "            x_num, y = x_num.to(device), y.to(device)\n",
        "            lengths = torch.tensor(lengths).to(device)\n",
        "            x_cat = {k: v.to(device) for k, v in x_cat.items()}\n",
        "\n",
        "            scores = model(x_cat, x_num)\n",
        "\n",
        "            hitrate = hitrate_at_k(scores, y, lengths, k=3, min_group_size=min_group_size)\n",
        "            ndcg = ndcg_at_k(scores, y, lengths, k=3, min_group_size=min_group_size)\n",
        "            map3 = map_at_k(scores, y, lengths, k=3, min_group_size=min_group_size)\n",
        "            loss = xranknet_loss(scores, y, lengths, temperature=1.0, margin=0.2, focus_topk=3)\n",
        "\n",
        "            batch_size = scores.size(0)\n",
        "            total_hitrate += hitrate * batch_size\n",
        "            total_ndcg += ndcg * batch_size\n",
        "            total_map += map3 * batch_size\n",
        "            total_loss += loss.item() * batch_size\n",
        "            count += batch_size\n",
        "\n",
        "    return total_loss / count, total_hitrate / count, total_ndcg / count, total_map / count\n",
        "\n",
        "\n",
        "def build_cat_dims(X, cat_features):\n",
        "    cat_dims = {}\n",
        "    for c in cat_features:\n",
        "        max_val = X[c].max()\n",
        "        if max_val < 0:\n",
        "            max_val = 0\n",
        "        cat_dims[c] = max_val + 1\n",
        "    return cat_dims\n",
        "\n",
        "\n",
        "def normalize_numeric_features(X, numeric_features, train_mask):\n",
        "    for col in numeric_features:\n",
        "        values = X[col].to_numpy()\n",
        "        train_vals = values[train_mask]\n",
        "        mean = train_vals.mean()\n",
        "        std = train_vals.std() if train_vals.std() > 0 else 1.0\n",
        "        norm_vals = (values - mean) / std\n",
        "        X = X.with_columns(pl.Series(col, norm_vals).alias(col))\n",
        "    return X\n",
        "\n",
        "\n",
        "def load_or_prepare_data(\n",
        "    data_dir,\n",
        "    train_file=\"train.parquet\",\n",
        "    test_file=\"test.parquet\",\n",
        "    cache_file=\"feature_engineered_val.parquet\",\n",
        "):\n",
        "    cache_path = os.path.join(data_dir, cache_file)\n",
        "\n",
        "    if os.path.exists(cache_path):\n",
        "        print(f\"Loading cached feature-engineered data from {cache_path} ...\")\n",
        "        df = pl.read_parquet(cache_path)\n",
        "\n",
        "        test = pl.read_parquet(os.path.join(data_dir, test_file)).drop(\"__index_level_0__\")\n",
        "        test_ids = test[\"Id\"]\n",
        "        test_rankers = test[\"ranker_id\"]\n",
        "    else:\n",
        "        print(\"Cached file not found, processing raw data ...\")\n",
        "\n",
        "        train = pl.read_parquet(os.path.join(data_dir, train_file)).drop(\"__index_level_0__\")\n",
        "        test = (\n",
        "            pl.read_parquet(os.path.join(data_dir, test_file))\n",
        "            .drop(\"__index_level_0__\")\n",
        "            .with_columns(pl.lit(0, dtype=pl.Int64).alias(\"selected\"))\n",
        "        )\n",
        "\n",
        "        test_ids = test[\"Id\"]\n",
        "        test_rankers = test[\"ranker_id\"]\n",
        "\n",
        "        df = pl.concat((train, test))\n",
        "        df = feature_engineering(df, full=True)\n",
        "\n",
        "        df = df.with_columns(\n",
        "            [pl.col(c).fill_null(0) for c in df.select(pl.selectors.numeric()).columns] +\n",
        "            [pl.col(c).fill_null(\"missing\") for c in df.select(pl.selectors.string()).columns]\n",
        "        )\n",
        "\n",
        "        os.makedirs(data_dir, exist_ok=True)\n",
        "        df.write_parquet(cache_path)\n",
        "        print(f\"Saved feature-engineered data to {cache_path}\")\n",
        "\n",
        "    return df, test_ids, test_rankers\n",
        "\n",
        "\n",
        "def prepare_data(data_dir):\n",
        "    df, test_ids, test_rankers = load_or_prepare_data(data_dir)\n",
        "\n",
        "    id_column = df[\"Id\"]\n",
        "    X, y, groups, cat_features, num_features = feature_selection(df)\n",
        "\n",
        "    X = X.with_columns(pl.Series(\"Id\", id_column[:X.shape[0]]))\n",
        "\n",
        "    X = X.with_columns(\n",
        "        [\n",
        "            (pl.col(c).rank(\"dense\") - 1).fill_null(-1).cast(pl.Int32)\n",
        "            for c in cat_features\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    train_size = 18145372\n",
        "    train_mask = np.arange(X.height) < train_size\n",
        "    X = normalize_numeric_features(X, num_features, train_mask)\n",
        "\n",
        "    return X, y, groups, cat_features, num_features, train_size, test_ids, test_rankers\n",
        "\n",
        "\n",
        "class EarlyStopping:\n",
        "    def __init__(self, patience=3, min_delta=0.00005):\n",
        "        self.patience = patience\n",
        "        self.min_delta = min_delta\n",
        "        self.best = float(\"-inf\")\n",
        "        self.counter = 0\n",
        "\n",
        "    def step(self, metric):\n",
        "        if metric > self.best + self.min_delta:\n",
        "            self.best = metric\n",
        "            self.counter = 0\n",
        "        else:\n",
        "            self.counter += 1\n",
        "        return self.counter >= self.patience\n",
        "\n",
        "\n",
        "def plot_group_size_distribution(dataset, save_path=None):\n",
        "    group_sizes = [len(v) for v in dataset.group_to_indices.values()]\n",
        "    plt.figure()\n",
        "    plt.hist(group_sizes, bins=100, log=True)\n",
        "    plt.xlabel(\"Group size (number of items per ranker_id)\")\n",
        "    plt.ylabel(\"Frequency (log scale)\")\n",
        "    plt.title(\"Distribution of Group Sizes\")\n",
        "    plt.grid(True)\n",
        "    if save_path:\n",
        "        plt.savefig(save_path)\n",
        "    else:\n",
        "        plt.show()\n",
        "    plt.close()\n",
        "\n",
        "\n",
        "def main():\n",
        "    DATA_DIR = \"./data\"\n",
        "    SUBMIT_DIR = \"submission\"\n",
        "    os.makedirs(SUBMIT_DIR, exist_ok=True)\n",
        "\n",
        "    learning_rates_to_try = [7e-4, 5e-4, 3e-4]\n",
        "\n",
        "    for lr in learning_rates_to_try:\n",
        "        run_name = f\"lr_{lr:.0e}\".replace(\"-\", \"\")\n",
        "        MODEL_DIR = f\"model_{run_name}\"\n",
        "        os.makedirs(MODEL_DIR, exist_ok=True)\n",
        "\n",
        "        print(f\"\\n\\nüöÄ Starting training with learning rate = {lr}\\nSaved to: {MODEL_DIR}\")\n",
        "\n",
        "        best_val_loss = float(\"inf\")\n",
        "        best_hitrate = 0.0\n",
        "        model_path = os.path.join(MODEL_DIR, \"best_dl_ranker.pt\")\n",
        "\n",
        "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "        train_losses = []\n",
        "        val_losses = []\n",
        "        val_hitrates = []\n",
        "        val_ndcgs = []\n",
        "        val_maps = []\n",
        "        learning_rates = []\n",
        "\n",
        "        os.makedirs(MODEL_DIR, exist_ok=True)\n",
        "        os.makedirs(SUBMIT_DIR, exist_ok=True)\n",
        "\n",
        "        early_stopper = EarlyStopping(patience=3, min_delta=0.00005)\n",
        "\n",
        "        X, y, groups, cat_features, num_features, train_size, test_ids, test_rankers = prepare_data(DATA_DIR)\n",
        "\n",
        "        # Fill missing values\n",
        "        float_cols = [c for c, t in zip(X.columns, X.dtypes) if t == pl.Float64]\n",
        "        for col in float_cols:\n",
        "            X = X.with_columns(\n",
        "                pl.when(pl.col(col).is_nan()).then(0).otherwise(pl.col(col)).alias(col)\n",
        "            )\n",
        "\n",
        "        n1 = 16487352\n",
        "        # n1 = 17487300\n",
        "        n2 = train_size\n",
        "\n",
        "        X_tr, X_va, X_te = X[:n1], X[n1:n2], X[n2:]\n",
        "        y_tr, y_va, y_te = y[:n1], y[n1:n2], y[n2:]\n",
        "        groups_tr, groups_va, groups_te = groups[:n1], groups[n1:n2], groups[n2:]\n",
        "\n",
        "        # Inspect group sizes in validation set\n",
        "        val_rankers = groups_va[\"ranker_id\"].to_numpy()\n",
        "        val_group_counts = Counter(val_rankers)\n",
        "\n",
        "        print(\"\\nüìã Validation group statistics:\")\n",
        "        # Save detailed group info to file\n",
        "        group_info_path = os.path.join(MODEL_DIR, \"validation_groups_info.txt\")\n",
        "        with open(group_info_path, \"w\") as f:\n",
        "            f.write(f\"Total groups: {len(val_group_counts)}\\n\\n\")\n",
        "            f.write(\"GroupID\\tSize\\tStartIdx\\tEndIdx\\n\")\n",
        "\n",
        "            group_to_rows = defaultdict(list)\n",
        "            for i, g in enumerate(val_rankers):\n",
        "                group_to_rows[g].append(i)\n",
        "\n",
        "            for group_id, indices in sorted(group_to_rows.items()):\n",
        "                start_idx = indices[0]\n",
        "                end_idx = indices[-1]\n",
        "                size = len(indices)\n",
        "                f.write(f\"{group_id}\\t{size}\\t{start_idx}\\t{end_idx}\\n\")\n",
        "\n",
        "        print(f\"üìÅ Saved validation group info to {group_info_path}\")\n",
        "\n",
        "\n",
        "        cat_dims = build_cat_dims(X, cat_features)\n",
        "        num_numeric_feats = len(num_features)\n",
        "\n",
        "        train_dataset = RankDataset(X_tr, y_tr, groups_tr, cat_features, num_features)\n",
        "        val_dataset = RankDataset(X_va, y_va, groups_va, cat_features, num_features)\n",
        "        test_dataset = RankDataset(X_te, y_te, groups_te, cat_features, num_features)\n",
        "\n",
        "        plot_group_size_distribution(train_dataset, save_path=os.path.join(MODEL_DIR, \"group_sizes.png\"))\n",
        "        print(\"üìä Group size distribution saved.\")\n",
        "\n",
        "        train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True, collate_fn=collate_fn)\n",
        "        val_loader = DataLoader(val_dataset, batch_size=4, shuffle=False, collate_fn=collate_fn)\n",
        "        test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False, collate_fn=collate_fn)\n",
        "\n",
        "        print(\"‚úÖ Data loaders created.\")\n",
        "\n",
        "        num_epochs = 10\n",
        "        num_training_steps = num_epochs * len(train_loader)\n",
        "        num_warmup_steps = int(0.1 * num_training_steps)\n",
        "\n",
        "        model = FiBiDLRanker(\n",
        "            cat_dims=cat_dims,\n",
        "            num_numeric_feats=num_numeric_feats,\n",
        "            emb_dim=64,\n",
        "            hidden=[512, 256, 128, 64]\n",
        "        ).to(device)\n",
        "\n",
        "        optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=0.01)\n",
        "\n",
        "        scheduler = get_scheduler(\n",
        "            \"linear\",\n",
        "            optimizer=optimizer,\n",
        "            num_warmup_steps=num_warmup_steps,\n",
        "            num_training_steps=num_training_steps\n",
        "        )\n",
        "\n",
        "        best_hitrate = 0\n",
        "        for epoch in range(num_epochs):\n",
        "            print(f\"\\n--- Epoch {epoch+1}/{num_epochs} ---\")\n",
        "            start_time = time.time()\n",
        "\n",
        "            train_loss = train_one_epoch(model, train_loader, optimizer, device, scheduler)\n",
        "            val_loss, val_hitrate, val_ndcg, val_map = validate(model, val_loader, device, min_group_size=10)\n",
        "\n",
        "            train_losses.append(train_loss)\n",
        "            val_losses.append(val_loss)\n",
        "            val_hitrates.append(val_hitrate.item())\n",
        "            val_ndcgs.append(val_ndcg.item())\n",
        "            val_maps.append(val_map.item())\n",
        "\n",
        "            current_lr = scheduler.get_last_lr()\n",
        "            learning_rates.append(current_lr[0])\n",
        "\n",
        "            elapsed = time.time() - start_time\n",
        "            print(\n",
        "                f\"Epoch {epoch+1}: \"\n",
        "                f\"Train Loss={train_loss:.4f}, \"\n",
        "                f\"Val Loss={val_loss:.4f}, \"\n",
        "                f\"HitRate@3={val_hitrate:.4f}, \"\n",
        "                f\"NDCG@3={val_ndcg:.4f}, \"\n",
        "                f\"MAP@3={val_map:.4f}, \"\n",
        "                f\"LR={current_lr[0]:.6f} \"\n",
        "                f\"({elapsed:.1f}s)\"\n",
        "            )\n",
        "\n",
        "\n",
        "            if val_loss < best_val_loss and val_hitrate > best_hitrate:\n",
        "                best_val_loss = val_loss\n",
        "                best_hitrate = val_hitrate\n",
        "                torch.save(model.state_dict(), model_path)\n",
        "                print(\"üíæ Model improved (loss ‚Üì and hitrate ‚Üë), saved.\")\n",
        "\n",
        "            if early_stopper.step(-val_loss):\n",
        "                print(\"‚õî Early stopping triggered.\")\n",
        "                break\n",
        "\n",
        "        # Plot metrics\n",
        "        epochs = list(range(1, len(train_losses) + 1))\n",
        "\n",
        "        # Plot Loss Curve\n",
        "        plt.figure()\n",
        "        plt.plot(epochs, train_losses, label=\"Train Loss\")\n",
        "        plt.plot(epochs, val_losses, label=\"Val Loss\")\n",
        "        plt.xlabel(\"Epoch\")\n",
        "        plt.ylabel(\"Loss\")\n",
        "        plt.title(\"Training & Validation Loss\")\n",
        "        plt.legend()\n",
        "        plt.grid(True)\n",
        "        plt.savefig(os.path.join(MODEL_DIR, \"loss_curve.png\"))\n",
        "        plt.close()\n",
        "\n",
        "        # Plot HitRate@3\n",
        "        plt.figure()\n",
        "        plt.plot(epochs, val_hitrates, label=\"Val HitRate@3\", color=\"green\")\n",
        "        plt.xlabel(\"Epoch\")\n",
        "        plt.ylabel(\"HitRate@3\")\n",
        "        plt.title(\"Validation HitRate@3\")\n",
        "        plt.legend()\n",
        "        plt.grid(True)\n",
        "        plt.savefig(os.path.join(MODEL_DIR, \"hitrate_curve.png\"))\n",
        "        plt.close()\n",
        "\n",
        "        # Plot Learning Rate\n",
        "        plt.figure()\n",
        "        plt.plot(epochs, learning_rates, label=\"Learning Rate\", color=\"orange\")\n",
        "        plt.xlabel(\"Epoch\")\n",
        "        plt.ylabel(\"LR\")\n",
        "        plt.title(\"Learning Rate Schedule\")\n",
        "        plt.legend()\n",
        "        plt.grid(True)\n",
        "        plt.savefig(os.path.join(MODEL_DIR, \"lr_curve.png\"))\n",
        "        plt.close()\n",
        "\n",
        "        # Plot NDCG@3\n",
        "        plt.figure()\n",
        "        plt.plot(epochs, val_ndcgs, label=\"Val NDCG@3\", color=\"purple\")\n",
        "        plt.xlabel(\"Epoch\")\n",
        "        plt.ylabel(\"NDCG@3\")\n",
        "        plt.title(\"Validation NDCG@3\")\n",
        "        plt.legend()\n",
        "        plt.grid(True)\n",
        "        plt.savefig(os.path.join(MODEL_DIR, \"ndcg_curve.png\"))\n",
        "        plt.close()\n",
        "\n",
        "        # Plot MAP@3\n",
        "        plt.figure()\n",
        "        plt.plot(epochs, val_maps, label=\"Val MAP@3\", color=\"red\")\n",
        "        plt.xlabel(\"Epoch\")\n",
        "        plt.ylabel(\"MAP@3\")\n",
        "        plt.title(\"Validation MAP@3\")\n",
        "        plt.legend()\n",
        "        plt.grid(True)\n",
        "        plt.savefig(os.path.join(MODEL_DIR, \"map_curve.png\"))\n",
        "        plt.close()\n",
        "\n",
        "        print(\"üìä Saved metric plots to model/\")\n",
        "\n",
        "        # Predict test set\n",
        "        model.load_state_dict(torch.load(model_path))\n",
        "        model.eval()\n",
        "\n",
        "        val_ids = X_va[\"Id\"]\n",
        "        val_rankers = groups_va[\"ranker_id\"]\n",
        "        val_labels = y_va\n",
        "\n",
        "        all_val_scores = []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for x_cat, x_num, _, lengths in tqdm(val_loader, desc=\"Predicting validation set\"):\n",
        "                x_num = x_num.to(device)\n",
        "                x_cat = {k: v.to(device) for k, v in x_cat.items()}\n",
        "                scores = model(x_cat, x_num)\n",
        "\n",
        "                for i in range(scores.size(0)):\n",
        "                    l = lengths[i]\n",
        "                    all_val_scores.append(scores[i, :l].cpu().numpy())\n",
        "\n",
        "        all_val_scores = np.concatenate(all_val_scores)\n",
        "\n",
        "        assert len(all_val_scores) == X_va.shape[0], \\\n",
        "            f\"Mismatch: {len(all_val_scores)} scores vs {X_va.shape[0]} rows\"\n",
        "\n",
        "        val_df = X_va.with_columns([\n",
        "            pl.Series(\"Id\", val_ids),\n",
        "            pl.Series(\"ranker_id\", val_rankers),\n",
        "            pl.Series(\"score\", all_val_scores),\n",
        "            pl.Series(\"label\", val_labels)\n",
        "        ])\n",
        "\n",
        "        val_df = val_df.with_columns(\n",
        "            pl.col(\"score\")\n",
        "            .rank(method=\"ordinal\", descending=True)\n",
        "            .over(\"ranker_id\")\n",
        "            .cast(pl.Int32)\n",
        "            .alias(\"selected\")\n",
        "        )\n",
        "\n",
        "        val_save_path = os.path.join(MODEL_DIR, \"validation_preds_dl_full.csv\")\n",
        "        val_df.write_csv(val_save_path)\n",
        "        print(f\"‚úÖ Saved full validation predictions (with features) to {val_save_path}\")\n",
        "\n",
        "        all_scores = []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for x_cat, x_num, _, lengths in tqdm(test_loader, desc=\"Predicting test set\"):\n",
        "                x_num = x_num.to(device)\n",
        "                x_cat = {k: v.to(device) for k, v in x_cat.items()}\n",
        "                scores = model(x_cat, x_num)\n",
        "\n",
        "                for i in range(scores.size(0)):\n",
        "                    l = lengths[i]\n",
        "                    all_scores.append(scores[i, :l].cpu().numpy())\n",
        "\n",
        "        all_scores = np.concatenate(all_scores)\n",
        "\n",
        "        assert len(all_scores) == X_te.shape[0], \\\n",
        "            f\"Mismatch: {len(all_scores)} scores vs {X_te.shape[0]} rows in X_te\"\n",
        "\n",
        "        submission_df = pl.DataFrame({\n",
        "            \"Id\": test_ids,\n",
        "            \"ranker_id\": test_rankers,\n",
        "            \"score\": all_scores\n",
        "        })\n",
        "\n",
        "        submission = (\n",
        "            submission_df\n",
        "            .with_columns(\n",
        "                pl.col(\"score\")\n",
        "                .rank(method=\"ordinal\", descending=True)\n",
        "                .over(\"ranker_id\")\n",
        "                .cast(pl.Int32)\n",
        "                .alias(\"selected\")\n",
        "            )\n",
        "            .select([\"Id\", \"ranker_id\", \"score\", \"selected\"])\n",
        "        )\n",
        "\n",
        "        submission_path = os.path.join(SUBMIT_DIR, \"submission_dl_ranker.csv\")\n",
        "        submission.write_csv(submission_path)\n",
        "        print(f\"‚úÖ Submission saved to {submission_path}\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YYC3t2RCKzZO",
        "outputId": "9962e2ee-32ff-44d7-8f82-23dcb413a4ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting deeprec_validate.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "lr = 7e-4, emb_dim=64, hidden=[512, 256, 128]"
      ],
      "metadata": {
        "id": "YmvOF9KNHyJN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "--- Epoch 1/10 ---\n",
        "Validating:   0%|          | 0/2636 [00:00<?, ?it/s]/home/ionut/test_whisper/test2/deeprec_validate.py:477: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
        "  lengths = torch.tensor(lengths).to(device)\n",
        "Epoch 1: Train Loss=0.3929, Val Loss=0.3008, HitRate@3=0.4760, NDCG@3=0.3810, MAP@3=0.6308, LR=0.000700 (734.3s)\n",
        "üíæ Model improved (loss ‚Üì and hitrate ‚Üë), saved.\n",
        "\n",
        "--- Epoch 2/10 ---\n",
        "Epoch 2: Train Loss=0.2802, Val Loss=0.2804, HitRate@3=0.4886, NDCG@3=0.3959, MAP@3=0.6438, LR=0.000622 (735.4s)\n",
        "üíæ Model improved (loss ‚Üì and hitrate ‚Üë), saved.\n",
        "\n",
        "--- Epoch 3/10 ---\n",
        "Epoch 3: Train Loss=0.2565, Val Loss=0.2692, HitRate@3=0.5046, NDCG@3=0.4088, MAP@3=0.6580, LR=0.000544 (734.8s)\n",
        "üíæ Model improved (loss ‚Üì and hitrate ‚Üë), saved.\n",
        "\n",
        "--- Epoch 4/10 ---\n",
        "Epoch 4: Train Loss=0.2436, Val Loss=0.2642, HitRate@3=0.5121, NDCG@3=0.4132, MAP@3=0.6552, LR=0.000467 (734.4s)\n",
        "üíæ Model improved (loss ‚Üì and hitrate ‚Üë), saved.\n",
        "\n",
        "--- Epoch 5/10 ---\n",
        "Epoch 5: Train Loss=0.2308, Val Loss=0.2568, HitRate@3=0.5065, NDCG@3=0.4089, MAP@3=0.6576, LR=0.000389 (734.8s)\n",
        "\n",
        "--- Epoch 6/10 ---\n",
        "Epoch 6: Train Loss=0.2172, Val Loss=0.2580, HitRate@3=0.5116, NDCG@3=0.4140, MAP@3=0.6602, LR=0.000311 (735.1s)\n",
        "\n",
        "--- Epoch 7/10 ---\n",
        "Epoch 7: Train Loss=0.2031, Val Loss=0.2569, HitRate@3=0.5158, NDCG@3=0.4193, MAP@3=0.6657, LR=0.000233 (734.9s)\n",
        "üíæ Model improved (loss ‚Üì and hitrate ‚Üë), saved.\n",
        "\n",
        "--- Epoch 8/10 ---\n",
        "Epoch 8: Train Loss=0.1898, Val Loss=0.2544, HitRate@3=0.5179, NDCG@3=0.4227, MAP@3=0.6722, LR=0.000156 (735.6s)\n",
        "üíæ Model improved (loss ‚Üì and hitrate ‚Üë), saved.\n",
        "\n",
        "--- Epoch 9/10 ---\n",
        "Epoch 9: Train Loss=0.1732, Val Loss=0.2569, HitRate@3=0.5188, NDCG@3=0.4229, MAP@3=0.6711, LR=0.000078 (735.9s)\n",
        "\n",
        "--- Epoch 10/10 ---\n",
        "Epoch 10: Train Loss=0.1575, Val Loss=0.2608, HitRate@3=0.5182, NDCG@3=0.4219, MAP@3=0.6718, LR=0.000000 (734.3s)"
      ],
      "metadata": {
        "id": "o4wb3vr3Hw_Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile deeprec_validate.py\n",
        "import os\n",
        "import time\n",
        "import random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F_torch\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import defaultdict\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "import polars as pl\n",
        "from tqdm import tqdm\n",
        "from src.feature import feature_engineering, feature_selection\n",
        "from transformers import get_scheduler\n",
        "from collections import Counter\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "class RankDataset(Dataset):\n",
        "    def __init__(\n",
        "        self,\n",
        "        X: pl.DataFrame,\n",
        "        y: pl.Series,\n",
        "        groups: pl.DataFrame,\n",
        "        cat_features: list[str],\n",
        "        num_features: list[str],\n",
        "    ):\n",
        "        self.cat_features = cat_features\n",
        "        self.num_features = num_features\n",
        "        self.X_cat = {c: X[c].to_numpy() for c in cat_features}\n",
        "        self.X_num = X[self.num_features].to_numpy()\n",
        "        self.y = y.to_numpy()\n",
        "        self.groups = groups[\"ranker_id\"].to_numpy()\n",
        "\n",
        "        self.group_to_indices = defaultdict(list)\n",
        "        for i, g in enumerate(self.groups):\n",
        "            self.group_to_indices[g].append(i)\n",
        "        self.group_keys = list(self.group_to_indices.keys())\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.group_keys)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        g = self.group_keys[idx]\n",
        "        inds = self.group_to_indices[g]\n",
        "        length = len(inds)\n",
        "\n",
        "        x_cat = {\n",
        "            c: torch.LongTensor([\n",
        "                self.X_cat[c][i] if self.X_cat[c][i] >= 0 else 0 for i in inds\n",
        "            ])\n",
        "            for c in self.cat_features\n",
        "        }\n",
        "\n",
        "        x_num = torch.FloatTensor(self.X_num[inds])\n",
        "        y = torch.FloatTensor(self.y[inds]).reshape(-1)\n",
        "\n",
        "        return x_cat, x_num, y, length\n",
        "\n",
        "def collate_fn(batch):\n",
        "    batch = [b for b in batch if b[3] >= 2]\n",
        "    if len(batch) == 0:\n",
        "        return None\n",
        "\n",
        "    batch_size = len(batch)\n",
        "    lengths = [b[3] for b in batch]\n",
        "    max_len = max(lengths)\n",
        "\n",
        "    padded_x_cat = {key: [] for key in batch[0][0].keys()}\n",
        "    padded_x_num = []\n",
        "    padded_y = []\n",
        "\n",
        "    num_dim = batch[0][1].shape[1]\n",
        "\n",
        "    for x_cat, x_num, y, length in batch:\n",
        "        pad_len = max_len - length\n",
        "\n",
        "        for key in padded_x_cat:\n",
        "            val = x_cat[key]\n",
        "            if pad_len > 0:\n",
        "                val = torch.cat([val, torch.zeros(pad_len, dtype=torch.long)])\n",
        "            padded_x_cat[key].append(val)\n",
        "\n",
        "        if pad_len > 0:\n",
        "            x_num = torch.cat([x_num, torch.zeros(pad_len, num_dim)])\n",
        "            y = torch.cat([y, torch.zeros(pad_len)])\n",
        "\n",
        "        padded_x_num.append(x_num)\n",
        "        padded_y.append(y)\n",
        "\n",
        "    padded_x_cat = {k: torch.stack(v) for k, v in padded_x_cat.items()}\n",
        "    padded_x_num = torch.stack(padded_x_num)\n",
        "    padded_y = torch.stack(padded_y)\n",
        "    lengths = torch.tensor(lengths, dtype=torch.long)\n",
        "\n",
        "    return padded_x_cat, padded_x_num, padded_y, lengths\n",
        "\n",
        "\n",
        "class FiBiDLRanker(nn.Module):\n",
        "    def __init__(self, cat_dims, num_numeric_feats, emb_dim=64, hidden=[512, 256, 128, 64], reduction=4, use_senet=True):\n",
        "        super().__init__()\n",
        "        self.cat_fields = list(cat_dims.keys())\n",
        "        self.emb_dim = emb_dim\n",
        "        self.num_fields = len(self.cat_fields)\n",
        "        self.use_senet = use_senet\n",
        "\n",
        "        # Embedding layers\n",
        "        self.embeddings = nn.ModuleDict({\n",
        "            f: nn.Embedding(cat_dims[f], emb_dim, padding_idx=0) for f in self.cat_fields\n",
        "        })\n",
        "        self.linear_cat = nn.ModuleDict({\n",
        "            f: nn.Embedding(cat_dims[f], 1, padding_idx=0) for f in self.cat_fields\n",
        "        })\n",
        "        self.linear_num = nn.Linear(num_numeric_feats, 1)\n",
        "\n",
        "        for emb in list(self.embeddings.values()) + list(self.linear_cat.values()):\n",
        "            nn.init.xavier_uniform_(emb.weight)\n",
        "        nn.init.xavier_uniform_(self.linear_num.weight)\n",
        "\n",
        "        # SENet (with LayerNorm)\n",
        "        if self.use_senet:\n",
        "            self.se_fc1 = nn.Linear(self.num_fields * emb_dim, self.num_fields * emb_dim // reduction)\n",
        "            self.se_ln1 = nn.LayerNorm(self.num_fields * emb_dim // reduction)\n",
        "            self.se_dropout = nn.Dropout(0.1)\n",
        "            self.se_fc2 = nn.Linear(self.num_fields * emb_dim // reduction, self.num_fields * emb_dim)\n",
        "\n",
        "        # Bilinear layer (shared)\n",
        "        self.bilinear = nn.Linear(emb_dim, emb_dim, bias=False)\n",
        "\n",
        "        # MLP (using LayerNorm instead of BatchNorm)\n",
        "        input_dim = emb_dim + num_numeric_feats\n",
        "        layers = []\n",
        "        for h in hidden:\n",
        "            layers.append(nn.Linear(input_dim, h))\n",
        "            layers.append(nn.LayerNorm(h))     # replaced BatchNorm1d with LayerNorm\n",
        "            layers.append(nn.ReLU())\n",
        "            layers.append(nn.Dropout(0.2))\n",
        "            input_dim = h\n",
        "        self.mlp = nn.Sequential(*layers)\n",
        "        self.output = nn.Linear(input_dim, 1)\n",
        "\n",
        "    def senet(self, embs):\n",
        "        B, F, D = embs.shape\n",
        "        z = embs.view(B, -1)  # Flatten [B, F*D]\n",
        "        a = self.se_fc1(z)    # Linear\n",
        "        a = self.se_ln1(a)    # LayerNorm instead of BatchNorm\n",
        "        a = F_torch.relu(a)\n",
        "        a = self.se_dropout(a)\n",
        "        s = torch.sigmoid(self.se_fc2(a)).view(B, F, D)\n",
        "        return embs * s\n",
        "\n",
        "    def bilinear_interaction(self, embs):\n",
        "        transformed = self.bilinear(embs)\n",
        "        interaction = (embs * transformed).mean(dim=1)\n",
        "        return interaction\n",
        "\n",
        "    def forward(self, x_cat, x_num):\n",
        "        B, G = x_num.shape[:2]\n",
        "        F, D = self.num_fields, self.emb_dim\n",
        "\n",
        "        # Embeddings [B, G, F, D]\n",
        "        embs = torch.stack([self.embeddings[f](x_cat[f]) for f in self.cat_fields], dim=2)\n",
        "\n",
        "        # Linear output\n",
        "        linear_cat_sum = torch.stack([\n",
        "            self.linear_cat[f](x_cat[f]).squeeze(-1) for f in self.cat_fields\n",
        "        ], dim=0).sum(dim=0)\n",
        "        linear_num_out = self.linear_num(x_num).squeeze(-1)\n",
        "        linear_out = linear_cat_sum + linear_num_out  # [B, G]\n",
        "\n",
        "        # Feature interactions\n",
        "        embs = embs.view(B * G, F, D)\n",
        "        if self.use_senet:\n",
        "            embs = self.senet(embs)\n",
        "        bi = self.bilinear_interaction(embs)  # [B*G, D]\n",
        "\n",
        "        # Deep part\n",
        "        x_num_flat = x_num.view(B * G, -1)\n",
        "        deep_input = torch.cat([bi, x_num_flat], dim=1)\n",
        "        deep_out = self.mlp(deep_input)\n",
        "        scores = self.output(deep_out).view(B, G)\n",
        "\n",
        "        return scores + linear_out  # final output\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "def listmle_loss(scores, labels, lengths):\n",
        "    batch_size = scores.size(0)\n",
        "    total_loss = torch.tensor(0.0, device=scores.device, requires_grad=True)\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "\n",
        "        _, idx = torch.sort(y, descending=True)\n",
        "        s_sorted = s[idx]\n",
        "\n",
        "        parts = (\n",
        "            torch.logsumexp(s_sorted.unsqueeze(0).expand(l, -1).triu(diagonal=0), dim=1)\n",
        "            - s_sorted\n",
        "        )\n",
        "\n",
        "        total_loss = total_loss + parts.sum()\n",
        "\n",
        "    return total_loss / batch_size\n",
        "\"\"\"\n",
        "\n",
        "def hitrate_at_k(scores, labels, lengths, k=3, min_group_size=10):\n",
        "    batch_size = scores.size(0)\n",
        "    hits = 0\n",
        "    valid_count = 0\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        if l < min_group_size:\n",
        "            continue\n",
        "        length = min(l, k)\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "        _, topk_idx = torch.topk(s, length)\n",
        "        topk_labels = y[topk_idx]\n",
        "        hits += (topk_labels > 0).any().float()\n",
        "        valid_count += 1\n",
        "    return hits / valid_count if valid_count > 0 else torch.tensor(0.0, device=scores.device)\n",
        "\n",
        "\n",
        "def ndcg_at_k(scores, labels, lengths, k=3, min_group_size=10):\n",
        "    batch_size = scores.size(0)\n",
        "    total_ndcg = 0.0\n",
        "    valid_count = 0\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        if l < min_group_size:\n",
        "            continue\n",
        "\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "\n",
        "        _, idx_pred = torch.topk(s, min(k, l))\n",
        "        _, idx_ideal = torch.topk(y, min(k, l))\n",
        "\n",
        "        dcg = (y[idx_pred] / torch.log2(torch.arange(2, 2 + len(idx_pred), device=y.device).float())).sum()\n",
        "        idcg = (y[idx_ideal] / torch.log2(torch.arange(2, 2 + len(idx_ideal), device=y.device).float())).sum()\n",
        "\n",
        "        ndcg = dcg / idcg if idcg > 0 else 0.0\n",
        "        total_ndcg += ndcg\n",
        "        valid_count += 1\n",
        "\n",
        "    return total_ndcg / valid_count if valid_count > 0 else torch.tensor(0.0, device=scores.device)\n",
        "\n",
        "\n",
        "def map_at_k(scores, labels, lengths, k=3, min_group_size=10):\n",
        "    batch_size = scores.size(0)\n",
        "    total_ap = 0.0\n",
        "    valid_count = 0\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        if l < min_group_size:\n",
        "            continue\n",
        "\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "\n",
        "        _, idx_pred = torch.topk(s, min(k, l))\n",
        "        y_true = y[idx_pred] > 0\n",
        "\n",
        "        if y_true.sum() == 0:\n",
        "            continue\n",
        "\n",
        "        precisions = [(y_true[:j+1].float().sum() / (j+1)) for j in range(len(y_true)) if y_true[j]]\n",
        "        ap = torch.stack(precisions).mean()\n",
        "        total_ap += ap\n",
        "        valid_count += 1\n",
        "\n",
        "    return total_ap / valid_count if valid_count > 0 else torch.tensor(0.0, device=scores.device)\n",
        "\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "def listnet_loss(scores, labels, lengths):\n",
        "    batch_size = scores.size(0)\n",
        "    total_loss = 0.0\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "\n",
        "        s_softmax = torch.nn.functional.log_softmax(s, dim=0)\n",
        "        y_softmax = torch.nn.functional.softmax(y, dim=0)\n",
        "\n",
        "        loss = -torch.sum(y_softmax * s_softmax)\n",
        "        total_loss += loss\n",
        "\n",
        "    return total_loss / batch_size\n",
        "\"\"\"\n",
        "\n",
        "def ranknet_loss(scores, labels, lengths):\n",
        "    batch_size = scores.size(0)\n",
        "    total_loss = 0.0\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "\n",
        "        diff_scores = s.unsqueeze(1) - s.unsqueeze(0)\n",
        "        rel = y.unsqueeze(1) > y.unsqueeze(0)\n",
        "        label_diff = rel.float()\n",
        "\n",
        "        log_sigmoid = torch.nn.functional.logsigmoid(diff_scores)\n",
        "        pair_loss = -label_diff * log_sigmoid\n",
        "\n",
        "        total_loss += pair_loss.sum()\n",
        "\n",
        "    return total_loss / batch_size\n",
        "\n",
        "def xranknet_loss(scores, labels, lengths, temperature=1.0, margin=0.2, focus_topk=3):\n",
        "    \"\"\"\n",
        "    xRankNet with emphasis on top-K items (based on labels, not scores).\n",
        "    \"\"\"\n",
        "    batch_size = scores.size(0)\n",
        "    total_loss = 0.0\n",
        "    total_pairs = 0\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        if l < 2:\n",
        "            continue\n",
        "\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "\n",
        "        # Top-K mask based on ground truth labels\n",
        "        topk = min(focus_topk, l)\n",
        "        _, topk_idx = torch.topk(y, topk)\n",
        "        topk_mask = torch.zeros_like(y, dtype=torch.bool)\n",
        "        topk_mask[topk_idx] = True\n",
        "\n",
        "        # Create pairwise difference matrices\n",
        "        score_diff = s.unsqueeze(1) - s.unsqueeze(0)\n",
        "        label_diff = y.unsqueeze(1) - y.unsqueeze(0)\n",
        "\n",
        "        # valid pair: y_i > y_j and at least one of i, j is in top-K\n",
        "        valid_pairs = (label_diff > 0) & (\n",
        "            topk_mask.unsqueeze(1) | topk_mask.unsqueeze(0)\n",
        "        )\n",
        "\n",
        "        if valid_pairs.sum() == 0:\n",
        "            continue\n",
        "\n",
        "        importance = (label_diff.abs() * valid_pairs).float()\n",
        "\n",
        "        if margin > 0.0:\n",
        "            score_diff = score_diff - margin\n",
        "\n",
        "        score_diff = score_diff / temperature\n",
        "        pairwise_loss = -F_torch.logsigmoid(score_diff) * importance\n",
        "\n",
        "        total_loss += pairwise_loss.sum()\n",
        "        total_pairs += importance.sum()\n",
        "\n",
        "    if total_pairs == 0:\n",
        "        return torch.tensor(0.0, device=scores.device, requires_grad=True)\n",
        "\n",
        "    return total_loss / total_pairs\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "def bpr_loss(scores, labels, lengths):\n",
        "    batch_size = scores.size(0)\n",
        "    total_loss = 0.0\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "\n",
        "        pos_mask = y > 0\n",
        "        neg_mask = y <= 0\n",
        "\n",
        "        pos_scores = s[pos_mask]\n",
        "        neg_scores = s[neg_mask]\n",
        "\n",
        "        if len(pos_scores) == 0 or len(neg_scores) == 0:\n",
        "            continue\n",
        "\n",
        "        pair_diff = pos_scores.unsqueeze(1) - neg_scores.unsqueeze(0)\n",
        "        loss = -F.logsigmoid(pair_diff).mean()\n",
        "        total_loss += loss\n",
        "\n",
        "    return total_loss / batch_size\n",
        "\"\"\"\n",
        "\n",
        "\"\"\"\n",
        "def lambdarank_loss(scores, labels, lengths, eps=1e-10):\n",
        "    batch_size = scores.size(0)\n",
        "    total_loss = 0.0\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "\n",
        "        if l < 2:\n",
        "            continue\n",
        "\n",
        "        _, rank_order = torch.sort(s, descending=True)\n",
        "        ideal_order = torch.sort(y, descending=True).indices\n",
        "\n",
        "        gain = 2 ** y - 1\n",
        "        discount = torch.log2(torch.arange(2, l + 2, device=y.device).float())\n",
        "\n",
        "        ideal_dcg = (gain[ideal_order] / discount).sum()\n",
        "        if ideal_dcg < eps:\n",
        "            continue\n",
        "\n",
        "        delta_ndcg = torch.zeros((l, l), device=y.device)\n",
        "\n",
        "        for i_idx in range(l):\n",
        "            for j_idx in range(l):\n",
        "                if y[i_idx] > y[j_idx]:\n",
        "                    change = (\n",
        "                        (1.0 / torch.log2(rank_order[i_idx] + 2.0))\n",
        "                        - (1.0 / torch.log2(rank_order[j_idx] + 2.0))\n",
        "                    ).abs()\n",
        "                    delta = (2 ** y[i_idx] - 2 ** y[j_idx]).abs() * change\n",
        "                    delta_ndcg[i_idx, j_idx] = delta / ideal_dcg\n",
        "\n",
        "        score_diffs = s.unsqueeze(1) - s.unsqueeze(0)\n",
        "        lambdas = -F.logsigmoid(score_diffs) * delta_ndcg\n",
        "        total_loss += lambdas.sum()\n",
        "\n",
        "    return total_loss / batch_size\n",
        "\"\"\"\n",
        "\n",
        "def train_one_epoch(model, loader, optimizer, device, scheduler):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "    valid_batches = 0\n",
        "\n",
        "    for batch in tqdm(loader, desc=\"Training\", leave=False):\n",
        "        if batch is None:\n",
        "            continue\n",
        "\n",
        "        x_cat, x_num, y, lengths = batch\n",
        "\n",
        "        x_num, y = x_num.to(device), y.to(device)\n",
        "        lengths = lengths.to(device)\n",
        "        x_cat = {k: v.to(device) for k, v in x_cat.items()}\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        scores = model(x_cat, x_num)\n",
        "        loss = xranknet_loss(scores, y, lengths, temperature=1.0, margin=0.2, focus_topk=3)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        valid_batches += 1\n",
        "\n",
        "    return total_loss / valid_batches if valid_batches > 0 else float(\"inf\")\n",
        "\n",
        "\n",
        "\n",
        "def validate(model, loader, device, min_group_size=10):\n",
        "    model.eval()\n",
        "    total_hitrate = 0\n",
        "    total_ndcg = 0\n",
        "    total_map = 0\n",
        "    total_loss = 0\n",
        "    count = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for x_cat, x_num, y, lengths in tqdm(loader, desc=\"Validating\", leave=False):\n",
        "            x_num, y = x_num.to(device), y.to(device)\n",
        "            lengths = torch.tensor(lengths).to(device)\n",
        "            x_cat = {k: v.to(device) for k, v in x_cat.items()}\n",
        "\n",
        "            scores = model(x_cat, x_num)\n",
        "\n",
        "            hitrate = hitrate_at_k(scores, y, lengths, k=3, min_group_size=min_group_size)\n",
        "            ndcg = ndcg_at_k(scores, y, lengths, k=3, min_group_size=min_group_size)\n",
        "            map3 = map_at_k(scores, y, lengths, k=3, min_group_size=min_group_size)\n",
        "            loss = xranknet_loss(scores, y, lengths, temperature=1.0, margin=0.2, focus_topk=3)\n",
        "\n",
        "            batch_size = scores.size(0)\n",
        "            total_hitrate += hitrate * batch_size\n",
        "            total_ndcg += ndcg * batch_size\n",
        "            total_map += map3 * batch_size\n",
        "            total_loss += loss.item() * batch_size\n",
        "            count += batch_size\n",
        "\n",
        "    return total_loss / count, total_hitrate / count, total_ndcg / count, total_map / count\n",
        "\n",
        "\n",
        "def build_cat_dims(X, cat_features):\n",
        "    cat_dims = {}\n",
        "    for c in cat_features:\n",
        "        max_val = X[c].max()\n",
        "        if max_val < 0:\n",
        "            max_val = 0\n",
        "        cat_dims[c] = max_val + 1\n",
        "    return cat_dims\n",
        "\n",
        "\n",
        "def normalize_numeric_features(X, numeric_features, train_mask):\n",
        "    for col in numeric_features:\n",
        "        values = X[col].to_numpy()\n",
        "        train_vals = values[train_mask]\n",
        "        mean = train_vals.mean()\n",
        "        std = train_vals.std() if train_vals.std() > 0 else 1.0\n",
        "        norm_vals = (values - mean) / std\n",
        "        X = X.with_columns(pl.Series(col, norm_vals).alias(col))\n",
        "    return X\n",
        "\n",
        "def apply_pca(X, numeric_features, train_mask, explained_variance=0.975):\n",
        "    train_data = X[numeric_features].to_numpy()[train_mask]\n",
        "    full_data = X[numeric_features].to_numpy()\n",
        "\n",
        "    pca = PCA(n_components=explained_variance, svd_solver='full')\n",
        "    pca.fit(train_data)\n",
        "    transformed = pca.transform(full_data)\n",
        "\n",
        "    print(f\"üìê PCA: {len(numeric_features)} features ‚Üí {transformed.shape[1]} components (explained variance ‚â• {explained_variance})\")\n",
        "\n",
        "    pca_feature_names = [f'pca_{i}' for i in range(transformed.shape[1])]\n",
        "    X_pca = pl.DataFrame(transformed, schema=pca_feature_names)\n",
        "\n",
        "    X = X.drop(numeric_features)\n",
        "    X = pl.concat([X, X_pca], how=\"horizontal\")\n",
        "\n",
        "    return X, pca_feature_names\n",
        "\n",
        "def load_or_prepare_data(\n",
        "    data_dir,\n",
        "    train_file=\"train.parquet\",\n",
        "    test_file=\"test.parquet\",\n",
        "    cache_file=\"feature_engineered_val.parquet\",\n",
        "):\n",
        "    cache_path = os.path.join(data_dir, cache_file)\n",
        "\n",
        "    if os.path.exists(cache_path):\n",
        "        print(f\"Loading cached feature-engineered data from {cache_path} ...\")\n",
        "        df = pl.read_parquet(cache_path)\n",
        "\n",
        "        test = pl.read_parquet(os.path.join(data_dir, test_file)).drop(\"__index_level_0__\")\n",
        "        test_ids = test[\"Id\"]\n",
        "        test_rankers = test[\"ranker_id\"]\n",
        "    else:\n",
        "        print(\"Cached file not found, processing raw data ...\")\n",
        "\n",
        "        train = pl.read_parquet(os.path.join(data_dir, train_file)).drop(\"__index_level_0__\")\n",
        "        test = (\n",
        "            pl.read_parquet(os.path.join(data_dir, test_file))\n",
        "            .drop(\"__index_level_0__\")\n",
        "            .with_columns(pl.lit(0, dtype=pl.Int64).alias(\"selected\"))\n",
        "        )\n",
        "\n",
        "        test_ids = test[\"Id\"]\n",
        "        test_rankers = test[\"ranker_id\"]\n",
        "\n",
        "        df = pl.concat((train, test))\n",
        "        df = feature_engineering(df, full=True)\n",
        "\n",
        "        df = df.with_columns(\n",
        "            [pl.col(c).fill_null(0) for c in df.select(pl.selectors.numeric()).columns] +\n",
        "            [pl.col(c).fill_null(\"missing\") for c in df.select(pl.selectors.string()).columns]\n",
        "        )\n",
        "\n",
        "        os.makedirs(data_dir, exist_ok=True)\n",
        "        df.write_parquet(cache_path)\n",
        "        print(f\"Saved feature-engineered data to {cache_path}\")\n",
        "\n",
        "    return df, test_ids, test_rankers\n",
        "\n",
        "\n",
        "def prepare_data(data_dir):\n",
        "    df, test_ids, test_rankers = load_or_prepare_data(data_dir)\n",
        "\n",
        "    id_column = df[\"Id\"]\n",
        "    X, y, groups, cat_features, num_features = feature_selection(df)\n",
        "\n",
        "    X = X.with_columns(pl.Series(\"Id\", id_column[:X.shape[0]]))\n",
        "\n",
        "    X = X.with_columns(\n",
        "        [\n",
        "            (pl.col(c).rank(\"dense\") - 1).fill_null(-1).cast(pl.Int32)\n",
        "            for c in cat_features\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    train_size = 18145372\n",
        "    train_mask = np.arange(X.height) < train_size\n",
        "\n",
        "    for col in num_features:\n",
        "        nans = X.select(pl.col(col).is_nan().sum()).item()\n",
        "        if nans > 0:\n",
        "            print(f\"‚ö†Ô∏è Found {nans} NaNs in column '{col}', filling with 0.\")\n",
        "            X = X.with_columns(\n",
        "                pl.when(pl.col(col).is_nan()).then(0).otherwise(pl.col(col)).alias(col)\n",
        "            )\n",
        "\n",
        "    X = normalize_numeric_features(X, num_features, train_mask)\n",
        "    X, pca_features = apply_pca(X, num_features, train_mask, explained_variance=0.975)\n",
        "    num_features = pca_features\n",
        "\n",
        "    return X, y, groups, cat_features, num_features, train_size, test_ids, test_rankers\n",
        "\n",
        "\n",
        "\n",
        "class EarlyStopping:\n",
        "    def __init__(self, patience=3, min_delta=0.00005):\n",
        "        self.patience = patience\n",
        "        self.min_delta = min_delta\n",
        "        self.best = float(\"-inf\")\n",
        "        self.counter = 0\n",
        "\n",
        "    def step(self, metric):\n",
        "        if metric > self.best + self.min_delta:\n",
        "            self.best = metric\n",
        "            self.counter = 0\n",
        "        else:\n",
        "            self.counter += 1\n",
        "        return self.counter >= self.patience\n",
        "\n",
        "\n",
        "def plot_group_size_distribution(dataset, save_path=None):\n",
        "    group_sizes = [len(v) for v in dataset.group_to_indices.values()]\n",
        "    plt.figure()\n",
        "    plt.hist(group_sizes, bins=100, log=True)\n",
        "    plt.xlabel(\"Group size (number of items per ranker_id)\")\n",
        "    plt.ylabel(\"Frequency (log scale)\")\n",
        "    plt.title(\"Distribution of Group Sizes\")\n",
        "    plt.grid(True)\n",
        "    if save_path:\n",
        "        plt.savefig(save_path)\n",
        "    else:\n",
        "        plt.show()\n",
        "    plt.close()\n",
        "\n",
        "\n",
        "def main():\n",
        "    DATA_DIR = \"./data\"\n",
        "    SUBMIT_DIR = \"submission\"\n",
        "    os.makedirs(SUBMIT_DIR, exist_ok=True)\n",
        "\n",
        "    learning_rates_to_try = [1e-3, 7e-4, 5e-4]\n",
        "\n",
        "    for lr in learning_rates_to_try:\n",
        "        run_name = f\"lr_{lr:.0e}\".replace(\"-\", \"\")\n",
        "        MODEL_DIR = f\"model_{run_name}\"\n",
        "        os.makedirs(MODEL_DIR, exist_ok=True)\n",
        "\n",
        "        print(f\"\\n\\nüöÄ Starting training with learning rate = {lr}\\nSaved to: {MODEL_DIR}\")\n",
        "\n",
        "        best_val_loss = float(\"inf\")\n",
        "        best_hitrate = 0.0\n",
        "        model_path = os.path.join(MODEL_DIR, \"best_dl_ranker.pt\")\n",
        "\n",
        "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "        train_losses = []\n",
        "        val_losses = []\n",
        "        val_hitrates = []\n",
        "        val_ndcgs = []\n",
        "        val_maps = []\n",
        "        learning_rates = []\n",
        "\n",
        "        os.makedirs(MODEL_DIR, exist_ok=True)\n",
        "        os.makedirs(SUBMIT_DIR, exist_ok=True)\n",
        "\n",
        "        early_stopper = EarlyStopping(patience=3, min_delta=0.00005)\n",
        "\n",
        "        X, y, groups, cat_features, num_features, train_size, test_ids, test_rankers = prepare_data(DATA_DIR)\n",
        "\n",
        "        # Fill missing values\n",
        "        float_cols = [c for c, t in zip(X.columns, X.dtypes) if t == pl.Float64]\n",
        "        for col in float_cols:\n",
        "            X = X.with_columns(\n",
        "                pl.when(pl.col(col).is_nan()).then(0).otherwise(pl.col(col)).alias(col)\n",
        "            )\n",
        "\n",
        "        n1 = 16487352\n",
        "        # n1 = 17487300\n",
        "        n2 = train_size\n",
        "\n",
        "        X_tr, X_va, X_te = X[:n1], X[n1:n2], X[n2:]\n",
        "        y_tr, y_va, y_te = y[:n1], y[n1:n2], y[n2:]\n",
        "        groups_tr, groups_va, groups_te = groups[:n1], groups[n1:n2], groups[n2:]\n",
        "\n",
        "        # Inspect group sizes in validation set\n",
        "        val_rankers = groups_va[\"ranker_id\"].to_numpy()\n",
        "        val_group_counts = Counter(val_rankers)\n",
        "\n",
        "        print(\"\\nüìã Validation group statistics:\")\n",
        "        # Save detailed group info to file\n",
        "        group_info_path = os.path.join(MODEL_DIR, \"validation_groups_info.txt\")\n",
        "        with open(group_info_path, \"w\") as f:\n",
        "            f.write(f\"Total groups: {len(val_group_counts)}\\n\\n\")\n",
        "            f.write(\"GroupID\\tSize\\tStartIdx\\tEndIdx\\n\")\n",
        "\n",
        "            group_to_rows = defaultdict(list)\n",
        "            for i, g in enumerate(val_rankers):\n",
        "                group_to_rows[g].append(i)\n",
        "\n",
        "            for group_id, indices in sorted(group_to_rows.items()):\n",
        "                start_idx = indices[0]\n",
        "                end_idx = indices[-1]\n",
        "                size = len(indices)\n",
        "                f.write(f\"{group_id}\\t{size}\\t{start_idx}\\t{end_idx}\\n\")\n",
        "\n",
        "        print(f\"üìÅ Saved validation group info to {group_info_path}\")\n",
        "\n",
        "\n",
        "        cat_dims = build_cat_dims(X, cat_features)\n",
        "        num_numeric_feats = len(num_features)\n",
        "\n",
        "        train_dataset = RankDataset(X_tr, y_tr, groups_tr, cat_features, num_features)\n",
        "        val_dataset = RankDataset(X_va, y_va, groups_va, cat_features, num_features)\n",
        "        test_dataset = RankDataset(X_te, y_te, groups_te, cat_features, num_features)\n",
        "\n",
        "        plot_group_size_distribution(train_dataset, save_path=os.path.join(MODEL_DIR, \"group_sizes.png\"))\n",
        "        print(\"üìä Group size distribution saved.\")\n",
        "\n",
        "        train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True, collate_fn=collate_fn)\n",
        "        val_loader = DataLoader(val_dataset, batch_size=4, shuffle=False, collate_fn=collate_fn)\n",
        "        test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False, collate_fn=collate_fn)\n",
        "\n",
        "        print(\"‚úÖ Data loaders created.\")\n",
        "\n",
        "        num_epochs = 10\n",
        "        num_training_steps = num_epochs * len(train_loader)\n",
        "        num_warmup_steps = int(0.1 * num_training_steps)\n",
        "\n",
        "        model = FiBiDLRanker(\n",
        "            cat_dims=cat_dims,\n",
        "            num_numeric_feats=num_numeric_feats,\n",
        "            emb_dim=32,\n",
        "            hidden=[512, 256, 128, 64]\n",
        "        ).to(device)\n",
        "\n",
        "        optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=0.01)\n",
        "\n",
        "        scheduler = get_scheduler(\n",
        "            \"linear\",\n",
        "            optimizer=optimizer,\n",
        "            num_warmup_steps=num_warmup_steps,\n",
        "            num_training_steps=num_training_steps\n",
        "        )\n",
        "\n",
        "        best_hitrate = 0\n",
        "        for epoch in range(num_epochs):\n",
        "            print(f\"\\n--- Epoch {epoch+1}/{num_epochs} ---\")\n",
        "            start_time = time.time()\n",
        "\n",
        "            train_loss = train_one_epoch(model, train_loader, optimizer, device, scheduler)\n",
        "            val_loss, val_hitrate, val_ndcg, val_map = validate(model, val_loader, device, min_group_size=10)\n",
        "\n",
        "            train_losses.append(train_loss)\n",
        "            val_losses.append(val_loss)\n",
        "            val_hitrates.append(val_hitrate.item())\n",
        "            val_ndcgs.append(val_ndcg.item())\n",
        "            val_maps.append(val_map.item())\n",
        "\n",
        "            current_lr = scheduler.get_last_lr()\n",
        "            learning_rates.append(current_lr[0])\n",
        "\n",
        "            elapsed = time.time() - start_time\n",
        "            print(\n",
        "                f\"Epoch {epoch+1}: \"\n",
        "                f\"Train Loss={train_loss:.4f}, \"\n",
        "                f\"Val Loss={val_loss:.4f}, \"\n",
        "                f\"HitRate@3={val_hitrate:.4f}, \"\n",
        "                f\"NDCG@3={val_ndcg:.4f}, \"\n",
        "                f\"MAP@3={val_map:.4f}, \"\n",
        "                f\"LR={current_lr[0]:.6f} \"\n",
        "                f\"({elapsed:.1f}s)\"\n",
        "            )\n",
        "\n",
        "\n",
        "            if val_loss < best_val_loss and val_hitrate > best_hitrate:\n",
        "                best_val_loss = val_loss\n",
        "                best_hitrate = val_hitrate\n",
        "                torch.save(model.state_dict(), model_path)\n",
        "                print(\"üíæ Model improved (loss ‚Üì and hitrate ‚Üë), saved.\")\n",
        "\n",
        "            if early_stopper.step(-val_loss):\n",
        "                print(\"‚õî Early stopping triggered.\")\n",
        "                break\n",
        "\n",
        "        # Plot metrics\n",
        "        epochs = list(range(1, len(train_losses) + 1))\n",
        "\n",
        "        # Plot Loss Curve\n",
        "        plt.figure()\n",
        "        plt.plot(epochs, train_losses, label=\"Train Loss\")\n",
        "        plt.plot(epochs, val_losses, label=\"Val Loss\")\n",
        "        plt.xlabel(\"Epoch\")\n",
        "        plt.ylabel(\"Loss\")\n",
        "        plt.title(\"Training & Validation Loss\")\n",
        "        plt.legend()\n",
        "        plt.grid(True)\n",
        "        plt.savefig(os.path.join(MODEL_DIR, \"loss_curve.png\"))\n",
        "        plt.close()\n",
        "\n",
        "        # Plot HitRate@3\n",
        "        plt.figure()\n",
        "        plt.plot(epochs, val_hitrates, label=\"Val HitRate@3\", color=\"green\")\n",
        "        plt.xlabel(\"Epoch\")\n",
        "        plt.ylabel(\"HitRate@3\")\n",
        "        plt.title(\"Validation HitRate@3\")\n",
        "        plt.legend()\n",
        "        plt.grid(True)\n",
        "        plt.savefig(os.path.join(MODEL_DIR, \"hitrate_curve.png\"))\n",
        "        plt.close()\n",
        "\n",
        "        # Plot Learning Rate\n",
        "        plt.figure()\n",
        "        plt.plot(epochs, learning_rates, label=\"Learning Rate\", color=\"orange\")\n",
        "        plt.xlabel(\"Epoch\")\n",
        "        plt.ylabel(\"LR\")\n",
        "        plt.title(\"Learning Rate Schedule\")\n",
        "        plt.legend()\n",
        "        plt.grid(True)\n",
        "        plt.savefig(os.path.join(MODEL_DIR, \"lr_curve.png\"))\n",
        "        plt.close()\n",
        "\n",
        "        # Plot NDCG@3\n",
        "        plt.figure()\n",
        "        plt.plot(epochs, val_ndcgs, label=\"Val NDCG@3\", color=\"purple\")\n",
        "        plt.xlabel(\"Epoch\")\n",
        "        plt.ylabel(\"NDCG@3\")\n",
        "        plt.title(\"Validation NDCG@3\")\n",
        "        plt.legend()\n",
        "        plt.grid(True)\n",
        "        plt.savefig(os.path.join(MODEL_DIR, \"ndcg_curve.png\"))\n",
        "        plt.close()\n",
        "\n",
        "        # Plot MAP@3\n",
        "        plt.figure()\n",
        "        plt.plot(epochs, val_maps, label=\"Val MAP@3\", color=\"red\")\n",
        "        plt.xlabel(\"Epoch\")\n",
        "        plt.ylabel(\"MAP@3\")\n",
        "        plt.title(\"Validation MAP@3\")\n",
        "        plt.legend()\n",
        "        plt.grid(True)\n",
        "        plt.savefig(os.path.join(MODEL_DIR, \"map_curve.png\"))\n",
        "        plt.close()\n",
        "\n",
        "        print(\"üìä Saved metric plots to model/\")\n",
        "\n",
        "        # Predict test set\n",
        "        model.load_state_dict(torch.load(model_path))\n",
        "        model.eval()\n",
        "\n",
        "        val_ids = X_va[\"Id\"]\n",
        "        val_rankers = groups_va[\"ranker_id\"]\n",
        "        val_labels = y_va\n",
        "\n",
        "        all_val_scores = []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for x_cat, x_num, _, lengths in tqdm(val_loader, desc=\"Predicting validation set\"):\n",
        "                x_num = x_num.to(device)\n",
        "                x_cat = {k: v.to(device) for k, v in x_cat.items()}\n",
        "                scores = model(x_cat, x_num)\n",
        "\n",
        "                for i in range(scores.size(0)):\n",
        "                    l = lengths[i]\n",
        "                    all_val_scores.append(scores[i, :l].cpu().numpy())\n",
        "\n",
        "        all_val_scores = np.concatenate(all_val_scores)\n",
        "\n",
        "        assert len(all_val_scores) == X_va.shape[0], \\\n",
        "            f\"Mismatch: {len(all_val_scores)} scores vs {X_va.shape[0]} rows\"\n",
        "\n",
        "        val_df = X_va.with_columns([\n",
        "            pl.Series(\"Id\", val_ids),\n",
        "            pl.Series(\"ranker_id\", val_rankers),\n",
        "            pl.Series(\"score\", all_val_scores),\n",
        "            pl.Series(\"label\", val_labels)\n",
        "        ])\n",
        "\n",
        "        val_df = val_df.with_columns(\n",
        "            pl.col(\"score\")\n",
        "            .rank(method=\"ordinal\", descending=True)\n",
        "            .over(\"ranker_id\")\n",
        "            .cast(pl.Int32)\n",
        "            .alias(\"selected\")\n",
        "        )\n",
        "\n",
        "        val_save_path = os.path.join(MODEL_DIR, \"validation_preds_dl_full.csv\")\n",
        "        val_df.write_csv(val_save_path)\n",
        "        print(f\"‚úÖ Saved full validation predictions (with features) to {val_save_path}\")\n",
        "\n",
        "        all_scores = []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for x_cat, x_num, _, lengths in tqdm(test_loader, desc=\"Predicting test set\"):\n",
        "                x_num = x_num.to(device)\n",
        "                x_cat = {k: v.to(device) for k, v in x_cat.items()}\n",
        "                scores = model(x_cat, x_num)\n",
        "\n",
        "                for i in range(scores.size(0)):\n",
        "                    l = lengths[i]\n",
        "                    all_scores.append(scores[i, :l].cpu().numpy())\n",
        "\n",
        "        all_scores = np.concatenate(all_scores)\n",
        "\n",
        "        assert len(all_scores) == X_te.shape[0], \\\n",
        "            f\"Mismatch: {len(all_scores)} scores vs {X_te.shape[0]} rows in X_te\"\n",
        "\n",
        "        submission_df = pl.DataFrame({\n",
        "            \"Id\": test_ids,\n",
        "            \"ranker_id\": test_rankers,\n",
        "            \"score\": all_scores\n",
        "        })\n",
        "\n",
        "        submission = (\n",
        "            submission_df\n",
        "            .with_columns(\n",
        "                pl.col(\"score\")\n",
        "                .rank(method=\"ordinal\", descending=True)\n",
        "                .over(\"ranker_id\")\n",
        "                .cast(pl.Int32)\n",
        "                .alias(\"selected\")\n",
        "            )\n",
        "            .select([\"Id\", \"ranker_id\", \"score\", \"selected\"])\n",
        "        )\n",
        "\n",
        "        submission_path = os.path.join(SUBMIT_DIR, \"submission_dl_ranker.csv\")\n",
        "        submission.write_csv(submission_path)\n",
        "        print(f\"‚úÖ Submission saved to {submission_path}\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HFb4wEyp20xJ",
        "outputId": "baf408cb-5e73-47cf-aa32-b34c54cabf51"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting deeprec_validate.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "--- Epoch 1/10 ---\n",
        "Validating:   0%|          | 0/2636 [00:00<?, ?it/s]/home/ionut/test_whisper/test2/deeprec_validate.py:477: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
        "  lengths = torch.tensor(lengths).to(device)\n",
        "Epoch 1: Train Loss=0.3914, Val Loss=0.3045, HitRate@3=0.4658, NDCG@3=0.3745, MAP@3=0.6268, LR=0.001000 (676.1s)\n",
        "üíæ Model improved (loss ‚Üì and hitrate ‚Üë), saved.\n",
        "\n",
        "--- Epoch 2/10 ---\n",
        "Epoch 2: Train Loss=0.2728, Val Loss=0.2828, HitRate@3=0.4873, NDCG@3=0.3919, MAP@3=0.6403, LR=0.000889 (677.7s)\n",
        "üíæ Model improved (loss ‚Üì and hitrate ‚Üë), saved.\n",
        "\n",
        "--- Epoch 3/10 ---\n",
        "Epoch 3: Train Loss=0.2507, Val Loss=0.2729, HitRate@3=0.4975, NDCG@3=0.3989, MAP@3=0.6378, LR=0.000778 (678.2s)\n",
        "üíæ Model improved (loss ‚Üì and hitrate ‚Üë), saved.\n",
        "\n",
        "--- Epoch 4/10 ---\n",
        "Epoch 4: Train Loss=0.2382, Val Loss=0.2738, HitRate@3=0.4914, NDCG@3=0.3931, MAP@3=0.6366, LR=0.000667 (678.7s)\n",
        "\n",
        "--- Epoch 5/10 ---\n",
        "Epoch 5: Train Loss=0.2266, Val Loss=0.2711, HitRate@3=0.5003, NDCG@3=0.4040, MAP@3=0.6473, LR=0.000556 (677.3s)\n",
        "üíæ Model improved (loss ‚Üì and hitrate ‚Üë), saved.\n",
        "\n",
        "--- Epoch 6/10 ---\n",
        "Epoch 6: Train Loss=0.2158, Val Loss=0.2698, HitRate@3=0.5047, NDCG@3=0.4069, MAP@3=0.6491, LR=0.000444 (677.0s)\n",
        "üíæ Model improved (loss ‚Üì and hitrate ‚Üë), saved.\n",
        "\n",
        "--- Epoch 7/10 ---\n",
        "Epoch 7: Train Loss=0.2054, Val Loss=0.2748, HitRate@3=0.5084, NDCG@3=0.4101, MAP@3=0.6543, LR=0.000333 (677.3s)\n",
        "\n",
        "--- Epoch 8/10 ---\n",
        "Epoch 8: Train Loss=0.1920, Val Loss=0.2720, HitRate@3=0.5144, NDCG@3=0.4137, MAP@3=0.6528, LR=0.000222 (675.0s)\n",
        "\n",
        "--- Epoch 9/10 ---\n",
        "Epoch 9: Train Loss=0.1792, Val Loss=0.2725, HitRate@3=0.5120, NDCG@3=0.4133, MAP@3=0.6567, LR=0.000111 (674.7s)\n",
        "‚õî Early stopping triggered."
      ],
      "metadata": {
        "id": "ssc_URqXdBWz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile deeprec_validate.py\n",
        "import os\n",
        "import time\n",
        "import random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F_torch\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import defaultdict\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "import polars as pl\n",
        "from tqdm import tqdm\n",
        "from src.feature import feature_engineering, feature_selection\n",
        "from transformers import get_scheduler\n",
        "from collections import Counter\n",
        "\n",
        "class RankDataset(Dataset):\n",
        "    def __init__(\n",
        "        self,\n",
        "        X: pl.DataFrame,\n",
        "        y: pl.Series,\n",
        "        groups: pl.DataFrame,\n",
        "        cat_features: list[str],\n",
        "        num_features: list[str],\n",
        "    ):\n",
        "        self.cat_features = cat_features\n",
        "        self.num_features = num_features\n",
        "        self.X_cat = {c: X[c].to_numpy() for c in cat_features}\n",
        "        self.X_num = X[self.num_features].to_numpy()\n",
        "        self.y = y.to_numpy()\n",
        "        self.groups = groups[\"ranker_id\"].to_numpy()\n",
        "\n",
        "        self.group_to_indices = defaultdict(list)\n",
        "        for i, g in enumerate(self.groups):\n",
        "            self.group_to_indices[g].append(i)\n",
        "        self.group_keys = list(self.group_to_indices.keys())\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.group_keys)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        g = self.group_keys[idx]\n",
        "        inds = self.group_to_indices[g]\n",
        "        length = len(inds)\n",
        "\n",
        "        x_cat = {\n",
        "            c: torch.LongTensor([\n",
        "                self.X_cat[c][i] if self.X_cat[c][i] >= 0 else 0 for i in inds\n",
        "            ])\n",
        "            for c in self.cat_features\n",
        "        }\n",
        "\n",
        "        x_num = torch.FloatTensor(self.X_num[inds])\n",
        "        y = torch.FloatTensor(self.y[inds]).reshape(-1)\n",
        "\n",
        "        return x_cat, x_num, y, length\n",
        "\n",
        "def collate_fn(batch):\n",
        "    batch = [b for b in batch if b[3] >= 2]\n",
        "    if len(batch) == 0:\n",
        "        return None\n",
        "\n",
        "    batch_size = len(batch)\n",
        "    lengths = [b[3] for b in batch]\n",
        "    max_len = max(lengths)\n",
        "\n",
        "    padded_x_cat = {key: [] for key in batch[0][0].keys()}\n",
        "    padded_x_num = []\n",
        "    padded_y = []\n",
        "\n",
        "    num_dim = batch[0][1].shape[1]\n",
        "\n",
        "    for x_cat, x_num, y, length in batch:\n",
        "        pad_len = max_len - length\n",
        "\n",
        "        for key in padded_x_cat:\n",
        "            val = x_cat[key]\n",
        "            if pad_len > 0:\n",
        "                val = torch.cat([val, torch.zeros(pad_len, dtype=torch.long)])\n",
        "            padded_x_cat[key].append(val)\n",
        "\n",
        "        if pad_len > 0:\n",
        "            x_num = torch.cat([x_num, torch.zeros(pad_len, num_dim)])\n",
        "            y = torch.cat([y, torch.zeros(pad_len)])\n",
        "\n",
        "        padded_x_num.append(x_num)\n",
        "        padded_y.append(y)\n",
        "\n",
        "    padded_x_cat = {k: torch.stack(v) for k, v in padded_x_cat.items()}\n",
        "    padded_x_num = torch.stack(padded_x_num)\n",
        "    padded_y = torch.stack(padded_y)\n",
        "    lengths = torch.tensor(lengths, dtype=torch.long)\n",
        "\n",
        "    return padded_x_cat, padded_x_num, padded_y, lengths\n",
        "\n",
        "\n",
        "class FiBiDLRanker(nn.Module):\n",
        "    def __init__(self, cat_dims, num_numeric_feats, emb_dim=64, hidden=[512, 256, 128, 64], reduction=4, use_senet=True):\n",
        "        super().__init__()\n",
        "        self.cat_fields = list(cat_dims.keys())\n",
        "        self.emb_dim = emb_dim\n",
        "        self.num_fields = len(self.cat_fields)\n",
        "        self.use_senet = use_senet\n",
        "\n",
        "        # Embedding layers\n",
        "        self.embeddings = nn.ModuleDict({\n",
        "            f: nn.Embedding(cat_dims[f], emb_dim, padding_idx=0) for f in self.cat_fields\n",
        "        })\n",
        "        self.linear_cat = nn.ModuleDict({\n",
        "            f: nn.Embedding(cat_dims[f], 1, padding_idx=0) for f in self.cat_fields\n",
        "        })\n",
        "        self.linear_num = nn.Linear(num_numeric_feats, 1)\n",
        "\n",
        "        for emb in list(self.embeddings.values()) + list(self.linear_cat.values()):\n",
        "            nn.init.xavier_uniform_(emb.weight)\n",
        "        nn.init.xavier_uniform_(self.linear_num.weight)\n",
        "\n",
        "        # SENet (with LayerNorm)\n",
        "        if self.use_senet:\n",
        "            self.se_fc1 = nn.Linear(self.num_fields * emb_dim, self.num_fields * emb_dim // reduction)\n",
        "            self.se_ln1 = nn.LayerNorm(self.num_fields * emb_dim // reduction)\n",
        "            self.se_dropout = nn.Dropout(0.1)\n",
        "            self.se_fc2 = nn.Linear(self.num_fields * emb_dim // reduction, self.num_fields * emb_dim)\n",
        "\n",
        "        # Bilinear layer (shared)\n",
        "        self.bilinear = nn.Linear(emb_dim, emb_dim, bias=False)\n",
        "\n",
        "        # MLP (using LayerNorm instead of BatchNorm)\n",
        "        input_dim = emb_dim + num_numeric_feats\n",
        "        layers = []\n",
        "        for h in hidden:\n",
        "            layers.append(nn.Linear(input_dim, h))\n",
        "            layers.append(nn.LayerNorm(h))     # replaced BatchNorm1d with LayerNorm\n",
        "            layers.append(nn.ReLU())\n",
        "            layers.append(nn.Dropout(0.2))\n",
        "            input_dim = h\n",
        "        self.mlp = nn.Sequential(*layers)\n",
        "        self.output = nn.Linear(input_dim, 1)\n",
        "\n",
        "    def senet(self, embs):\n",
        "        B, F, D = embs.shape\n",
        "        z = embs.view(B, -1)  # Flatten [B, F*D]\n",
        "        a = self.se_fc1(z)    # Linear\n",
        "        a = self.se_ln1(a)    # LayerNorm instead of BatchNorm\n",
        "        a = F_torch.relu(a)\n",
        "        a = self.se_dropout(a)\n",
        "        s = torch.sigmoid(self.se_fc2(a)).view(B, F, D)\n",
        "        return embs * s\n",
        "\n",
        "    def bilinear_interaction(self, embs):\n",
        "        transformed = self.bilinear(embs)\n",
        "        interaction = (embs * transformed).mean(dim=1)\n",
        "        return interaction\n",
        "\n",
        "    def forward(self, x_cat, x_num):\n",
        "        B, G = x_num.shape[:2]\n",
        "        F, D = self.num_fields, self.emb_dim\n",
        "\n",
        "        # Embeddings [B, G, F, D]\n",
        "        embs = torch.stack([self.embeddings[f](x_cat[f]) for f in self.cat_fields], dim=2)\n",
        "\n",
        "        # Linear output\n",
        "        linear_cat_sum = torch.stack([\n",
        "            self.linear_cat[f](x_cat[f]).squeeze(-1) for f in self.cat_fields\n",
        "        ], dim=0).sum(dim=0)\n",
        "        linear_num_out = self.linear_num(x_num).squeeze(-1)\n",
        "        linear_out = linear_cat_sum + linear_num_out  # [B, G]\n",
        "\n",
        "        # Feature interactions\n",
        "        embs = embs.view(B * G, F, D)\n",
        "        if self.use_senet:\n",
        "            embs = self.senet(embs)\n",
        "        bi = self.bilinear_interaction(embs)  # [B*G, D]\n",
        "\n",
        "        # Deep part\n",
        "        x_num_flat = x_num.view(B * G, -1)\n",
        "        deep_input = torch.cat([bi, x_num_flat], dim=1)\n",
        "        deep_out = self.mlp(deep_input)\n",
        "        scores = self.output(deep_out).view(B, G)\n",
        "\n",
        "        return scores + linear_out  # final output\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "def listmle_loss(scores, labels, lengths):\n",
        "    batch_size = scores.size(0)\n",
        "    total_loss = torch.tensor(0.0, device=scores.device, requires_grad=True)\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "\n",
        "        _, idx = torch.sort(y, descending=True)\n",
        "        s_sorted = s[idx]\n",
        "\n",
        "        parts = (\n",
        "            torch.logsumexp(s_sorted.unsqueeze(0).expand(l, -1).triu(diagonal=0), dim=1)\n",
        "            - s_sorted\n",
        "        )\n",
        "\n",
        "        total_loss = total_loss + parts.sum()\n",
        "\n",
        "    return total_loss / batch_size\n",
        "\"\"\"\n",
        "\n",
        "def hitrate_at_k(scores, labels, lengths, k=3, min_group_size=10):\n",
        "    batch_size = scores.size(0)\n",
        "    hits = 0\n",
        "    valid_count = 0\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        if l < min_group_size:\n",
        "            continue\n",
        "        length = min(l, k)\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "        _, topk_idx = torch.topk(s, length)\n",
        "        topk_labels = y[topk_idx]\n",
        "        hits += (topk_labels > 0).any().float()\n",
        "        valid_count += 1\n",
        "    return hits / valid_count if valid_count > 0 else torch.tensor(0.0, device=scores.device)\n",
        "\n",
        "\n",
        "def ndcg_at_k(scores, labels, lengths, k=3, min_group_size=10):\n",
        "    batch_size = scores.size(0)\n",
        "    total_ndcg = 0.0\n",
        "    valid_count = 0\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        if l < min_group_size:\n",
        "            continue\n",
        "\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "\n",
        "        _, idx_pred = torch.topk(s, min(k, l))\n",
        "        _, idx_ideal = torch.topk(y, min(k, l))\n",
        "\n",
        "        dcg = (y[idx_pred] / torch.log2(torch.arange(2, 2 + len(idx_pred), device=y.device).float())).sum()\n",
        "        idcg = (y[idx_ideal] / torch.log2(torch.arange(2, 2 + len(idx_ideal), device=y.device).float())).sum()\n",
        "\n",
        "        ndcg = dcg / idcg if idcg > 0 else 0.0\n",
        "        total_ndcg += ndcg\n",
        "        valid_count += 1\n",
        "\n",
        "    return total_ndcg / valid_count if valid_count > 0 else torch.tensor(0.0, device=scores.device)\n",
        "\n",
        "\n",
        "def map_at_k(scores, labels, lengths, k=3, min_group_size=10):\n",
        "    batch_size = scores.size(0)\n",
        "    total_ap = 0.0\n",
        "    valid_count = 0\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        if l < min_group_size:\n",
        "            continue\n",
        "\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "\n",
        "        _, idx_pred = torch.topk(s, min(k, l))\n",
        "        y_true = y[idx_pred] > 0\n",
        "\n",
        "        if y_true.sum() == 0:\n",
        "            continue\n",
        "\n",
        "        precisions = [(y_true[:j+1].float().sum() / (j+1)) for j in range(len(y_true)) if y_true[j]]\n",
        "        ap = torch.stack(precisions).mean()\n",
        "        total_ap += ap\n",
        "        valid_count += 1\n",
        "\n",
        "    return total_ap / valid_count if valid_count > 0 else torch.tensor(0.0, device=scores.device)\n",
        "\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "def listnet_loss(scores, labels, lengths):\n",
        "    batch_size = scores.size(0)\n",
        "    total_loss = 0.0\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "\n",
        "        s_softmax = torch.nn.functional.log_softmax(s, dim=0)\n",
        "        y_softmax = torch.nn.functional.softmax(y, dim=0)\n",
        "\n",
        "        loss = -torch.sum(y_softmax * s_softmax)\n",
        "        total_loss += loss\n",
        "\n",
        "    return total_loss / batch_size\n",
        "\"\"\"\n",
        "\n",
        "def ranknet_loss(scores, labels, lengths):\n",
        "    batch_size = scores.size(0)\n",
        "    total_loss = 0.0\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "\n",
        "        diff_scores = s.unsqueeze(1) - s.unsqueeze(0)\n",
        "        rel = y.unsqueeze(1) > y.unsqueeze(0)\n",
        "        label_diff = rel.float()\n",
        "\n",
        "        log_sigmoid = torch.nn.functional.logsigmoid(diff_scores)\n",
        "        pair_loss = -label_diff * log_sigmoid\n",
        "\n",
        "        total_loss += pair_loss.sum()\n",
        "\n",
        "    return total_loss / batch_size\n",
        "\n",
        "def xranknet_loss(scores, labels, lengths, temperature=1.0, margin=0.2, focus_topk=3):\n",
        "    \"\"\"\n",
        "    xRankNet with emphasis on top-K items (based on labels, not scores).\n",
        "    \"\"\"\n",
        "    batch_size = scores.size(0)\n",
        "    total_loss = 0.0\n",
        "    total_pairs = 0\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        if l < 2:\n",
        "            continue\n",
        "\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "\n",
        "        # Top-K mask based on ground truth labels\n",
        "        topk = min(focus_topk, l)\n",
        "        _, topk_idx = torch.topk(y, topk)\n",
        "        topk_mask = torch.zeros_like(y, dtype=torch.bool)\n",
        "        topk_mask[topk_idx] = True\n",
        "\n",
        "        # Create pairwise difference matrices\n",
        "        score_diff = s.unsqueeze(1) - s.unsqueeze(0)\n",
        "        label_diff = y.unsqueeze(1) - y.unsqueeze(0)\n",
        "\n",
        "        # valid pair: y_i > y_j and at least one of i, j is in top-K\n",
        "        valid_pairs = (label_diff > 0) & (\n",
        "            topk_mask.unsqueeze(1) | topk_mask.unsqueeze(0)\n",
        "        )\n",
        "\n",
        "        if valid_pairs.sum() == 0:\n",
        "            continue\n",
        "\n",
        "        importance = (label_diff.abs() * valid_pairs).float()\n",
        "\n",
        "        if margin > 0.0:\n",
        "            score_diff = score_diff - margin\n",
        "\n",
        "        score_diff = score_diff / temperature\n",
        "        pairwise_loss = -F_torch.logsigmoid(score_diff) * importance\n",
        "\n",
        "        total_loss += pairwise_loss.sum()\n",
        "        total_pairs += importance.sum()\n",
        "\n",
        "    if total_pairs == 0:\n",
        "        return torch.tensor(0.0, device=scores.device, requires_grad=True)\n",
        "\n",
        "    return total_loss / total_pairs\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "def bpr_loss(scores, labels, lengths):\n",
        "    batch_size = scores.size(0)\n",
        "    total_loss = 0.0\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "\n",
        "        pos_mask = y > 0\n",
        "        neg_mask = y <= 0\n",
        "\n",
        "        pos_scores = s[pos_mask]\n",
        "        neg_scores = s[neg_mask]\n",
        "\n",
        "        if len(pos_scores) == 0 or len(neg_scores) == 0:\n",
        "            continue\n",
        "\n",
        "        pair_diff = pos_scores.unsqueeze(1) - neg_scores.unsqueeze(0)\n",
        "        loss = -F.logsigmoid(pair_diff).mean()\n",
        "        total_loss += loss\n",
        "\n",
        "    return total_loss / batch_size\n",
        "\"\"\"\n",
        "\n",
        "\"\"\"\n",
        "def lambdarank_loss(scores, labels, lengths, eps=1e-10):\n",
        "    batch_size = scores.size(0)\n",
        "    total_loss = 0.0\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "\n",
        "        if l < 2:\n",
        "            continue\n",
        "\n",
        "        _, rank_order = torch.sort(s, descending=True)\n",
        "        ideal_order = torch.sort(y, descending=True).indices\n",
        "\n",
        "        gain = 2 ** y - 1\n",
        "        discount = torch.log2(torch.arange(2, l + 2, device=y.device).float())\n",
        "\n",
        "        ideal_dcg = (gain[ideal_order] / discount).sum()\n",
        "        if ideal_dcg < eps:\n",
        "            continue\n",
        "\n",
        "        delta_ndcg = torch.zeros((l, l), device=y.device)\n",
        "\n",
        "        for i_idx in range(l):\n",
        "            for j_idx in range(l):\n",
        "                if y[i_idx] > y[j_idx]:\n",
        "                    change = (\n",
        "                        (1.0 / torch.log2(rank_order[i_idx] + 2.0))\n",
        "                        - (1.0 / torch.log2(rank_order[j_idx] + 2.0))\n",
        "                    ).abs()\n",
        "                    delta = (2 ** y[i_idx] - 2 ** y[j_idx]).abs() * change\n",
        "                    delta_ndcg[i_idx, j_idx] = delta / ideal_dcg\n",
        "\n",
        "        score_diffs = s.unsqueeze(1) - s.unsqueeze(0)\n",
        "        lambdas = -F.logsigmoid(score_diffs) * delta_ndcg\n",
        "        total_loss += lambdas.sum()\n",
        "\n",
        "    return total_loss / batch_size\n",
        "\"\"\"\n",
        "\n",
        "def train_one_epoch(model, loader, optimizer, device, scheduler):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "    valid_batches = 0\n",
        "\n",
        "    for batch in tqdm(loader, desc=\"Training\", leave=False):\n",
        "        if batch is None:\n",
        "            continue\n",
        "\n",
        "        x_cat, x_num, y, lengths = batch\n",
        "\n",
        "        x_num, y = x_num.to(device), y.to(device)\n",
        "        lengths = lengths.to(device)\n",
        "        x_cat = {k: v.to(device) for k, v in x_cat.items()}\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        scores = model(x_cat, x_num)\n",
        "        loss = xranknet_loss(scores, y, lengths, temperature=1.0, margin=0.2, focus_topk=3)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        valid_batches += 1\n",
        "\n",
        "    return total_loss / valid_batches if valid_batches > 0 else float(\"inf\")\n",
        "\n",
        "\n",
        "\n",
        "def validate(model, loader, device, min_group_size=10):\n",
        "    model.eval()\n",
        "    total_hitrate = 0\n",
        "    total_ndcg = 0\n",
        "    total_map = 0\n",
        "    total_loss = 0\n",
        "    count = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for x_cat, x_num, y, lengths in tqdm(loader, desc=\"Validating\", leave=False):\n",
        "            x_num, y = x_num.to(device), y.to(device)\n",
        "            lengths = torch.tensor(lengths).to(device)\n",
        "            x_cat = {k: v.to(device) for k, v in x_cat.items()}\n",
        "\n",
        "            scores = model(x_cat, x_num)\n",
        "\n",
        "            hitrate = hitrate_at_k(scores, y, lengths, k=3, min_group_size=min_group_size)\n",
        "            ndcg = ndcg_at_k(scores, y, lengths, k=3, min_group_size=min_group_size)\n",
        "            map3 = map_at_k(scores, y, lengths, k=3, min_group_size=min_group_size)\n",
        "            loss = xranknet_loss(scores, y, lengths, temperature=1.0, margin=0.2, focus_topk=3)\n",
        "\n",
        "            batch_size = scores.size(0)\n",
        "            total_hitrate += hitrate * batch_size\n",
        "            total_ndcg += ndcg * batch_size\n",
        "            total_map += map3 * batch_size\n",
        "            total_loss += loss.item() * batch_size\n",
        "            count += batch_size\n",
        "\n",
        "    return total_loss / count, total_hitrate / count, total_ndcg / count, total_map / count\n",
        "\n",
        "\n",
        "def build_cat_dims(X, cat_features):\n",
        "    cat_dims = {}\n",
        "    for c in cat_features:\n",
        "        max_val = X[c].max()\n",
        "        if max_val < 0:\n",
        "            max_val = 0\n",
        "        cat_dims[c] = max_val + 1\n",
        "    return cat_dims\n",
        "\n",
        "\n",
        "def normalize_numeric_features(X, numeric_features, train_mask):\n",
        "    for col in numeric_features:\n",
        "        values = X[col].to_numpy()\n",
        "        train_vals = values[train_mask]\n",
        "        mean = train_vals.mean()\n",
        "        std = train_vals.std() if train_vals.std() > 0 else 1.0\n",
        "        norm_vals = (values - mean) / std\n",
        "        X = X.with_columns(pl.Series(col, norm_vals).alias(col))\n",
        "    return X\n",
        "\n",
        "\n",
        "def load_or_prepare_data(\n",
        "    data_dir,\n",
        "    train_file=\"train.parquet\",\n",
        "    test_file=\"test.parquet\",\n",
        "    cache_file=\"feature_engineered_val.parquet\",\n",
        "):\n",
        "    cache_path = os.path.join(data_dir, cache_file)\n",
        "\n",
        "    if os.path.exists(cache_path):\n",
        "        print(f\"Loading cached feature-engineered data from {cache_path} ...\")\n",
        "        df = pl.read_parquet(cache_path)\n",
        "\n",
        "        test = pl.read_parquet(os.path.join(data_dir, test_file)).drop(\"__index_level_0__\")\n",
        "        test_ids = test[\"Id\"]\n",
        "        test_rankers = test[\"ranker_id\"]\n",
        "    else:\n",
        "        print(\"Cached file not found, processing raw data ...\")\n",
        "\n",
        "        train = pl.read_parquet(os.path.join(data_dir, train_file)).drop(\"__index_level_0__\")\n",
        "        test = (\n",
        "            pl.read_parquet(os.path.join(data_dir, test_file))\n",
        "            .drop(\"__index_level_0__\")\n",
        "            .with_columns(pl.lit(0, dtype=pl.Int64).alias(\"selected\"))\n",
        "        )\n",
        "\n",
        "        test_ids = test[\"Id\"]\n",
        "        test_rankers = test[\"ranker_id\"]\n",
        "\n",
        "        df = pl.concat((train, test))\n",
        "        df = feature_engineering(df, full=True)\n",
        "\n",
        "        df = df.with_columns(\n",
        "            [pl.col(c).fill_null(0) for c in df.select(pl.selectors.numeric()).columns] +\n",
        "            [pl.col(c).fill_null(\"missing\") for c in df.select(pl.selectors.string()).columns]\n",
        "        )\n",
        "\n",
        "        os.makedirs(data_dir, exist_ok=True)\n",
        "        df.write_parquet(cache_path)\n",
        "        print(f\"Saved feature-engineered data to {cache_path}\")\n",
        "\n",
        "    return df, test_ids, test_rankers\n",
        "\n",
        "\n",
        "def prepare_data(data_dir):\n",
        "    df, test_ids, test_rankers = load_or_prepare_data(data_dir)\n",
        "\n",
        "    id_column = df[\"Id\"]\n",
        "    X, y, groups, cat_features, num_features = feature_selection(df)\n",
        "\n",
        "    X = X.with_columns(pl.Series(\"Id\", id_column[:X.shape[0]]))\n",
        "\n",
        "    X = X.with_columns(\n",
        "        [\n",
        "            (pl.col(c).rank(\"dense\") - 1).fill_null(-1).cast(pl.Int32)\n",
        "            for c in cat_features\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    train_size = 18145372\n",
        "    train_mask = np.arange(X.height) < train_size\n",
        "    X = normalize_numeric_features(X, num_features, train_mask)\n",
        "\n",
        "    return X, y, groups, cat_features, num_features, train_size, test_ids, test_rankers\n",
        "\n",
        "\n",
        "class EarlyStopping:\n",
        "    def __init__(self, patience=3, min_delta=0.00005):\n",
        "        self.patience = patience\n",
        "        self.min_delta = min_delta\n",
        "        self.best = float(\"-inf\")\n",
        "        self.counter = 0\n",
        "\n",
        "    def step(self, metric):\n",
        "        if metric > self.best + self.min_delta:\n",
        "            self.best = metric\n",
        "            self.counter = 0\n",
        "        else:\n",
        "            self.counter += 1\n",
        "        return self.counter >= self.patience\n",
        "\n",
        "\n",
        "def plot_group_size_distribution(dataset, save_path=None):\n",
        "    group_sizes = [len(v) for v in dataset.group_to_indices.values()]\n",
        "    plt.figure()\n",
        "    plt.hist(group_sizes, bins=100, log=True)\n",
        "    plt.xlabel(\"Group size (number of items per ranker_id)\")\n",
        "    plt.ylabel(\"Frequency (log scale)\")\n",
        "    plt.title(\"Distribution of Group Sizes\")\n",
        "    plt.grid(True)\n",
        "    if save_path:\n",
        "        plt.savefig(save_path)\n",
        "    else:\n",
        "        plt.show()\n",
        "    plt.close()\n",
        "\n",
        "\n",
        "def main():\n",
        "    DATA_DIR = \"./data\"\n",
        "    SUBMIT_DIR = \"submission\"\n",
        "    os.makedirs(SUBMIT_DIR, exist_ok=True)\n",
        "\n",
        "    learning_rates_to_try = [1e-3, 7e-4, 5e-4]\n",
        "\n",
        "    for lr in learning_rates_to_try:\n",
        "        run_name = f\"lr_{lr:.0e}\".replace(\"-\", \"\")\n",
        "        MODEL_DIR = f\"model_{run_name}\"\n",
        "        os.makedirs(MODEL_DIR, exist_ok=True)\n",
        "\n",
        "        print(f\"\\n\\nüöÄ Starting training with learning rate = {lr}\\nSaved to: {MODEL_DIR}\")\n",
        "\n",
        "        best_val_loss = float(\"inf\")\n",
        "        best_hitrate = 0.0\n",
        "        model_path = os.path.join(MODEL_DIR, \"best_dl_ranker.pt\")\n",
        "\n",
        "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "        train_losses = []\n",
        "        val_losses = []\n",
        "        val_hitrates = []\n",
        "        val_ndcgs = []\n",
        "        val_maps = []\n",
        "        learning_rates = []\n",
        "\n",
        "        os.makedirs(MODEL_DIR, exist_ok=True)\n",
        "        os.makedirs(SUBMIT_DIR, exist_ok=True)\n",
        "\n",
        "        early_stopper = EarlyStopping(patience=3, min_delta=0.00005)\n",
        "\n",
        "        X, y, groups, cat_features, num_features, train_size, test_ids, test_rankers = prepare_data(DATA_DIR)\n",
        "\n",
        "        # Fill missing values\n",
        "        float_cols = [c for c, t in zip(X.columns, X.dtypes) if t == pl.Float64]\n",
        "        for col in float_cols:\n",
        "            X = X.with_columns(\n",
        "                pl.when(pl.col(col).is_nan()).then(0).otherwise(pl.col(col)).alias(col)\n",
        "            )\n",
        "\n",
        "        n1 = 16487352\n",
        "        # n1 = 17487300\n",
        "        n2 = train_size\n",
        "\n",
        "        X_tr, X_va, X_te = X[:n1], X[n1:n2], X[n2:]\n",
        "        y_tr, y_va, y_te = y[:n1], y[n1:n2], y[n2:]\n",
        "        groups_tr, groups_va, groups_te = groups[:n1], groups[n1:n2], groups[n2:]\n",
        "\n",
        "        # Inspect group sizes in validation set\n",
        "        val_rankers = groups_va[\"ranker_id\"].to_numpy()\n",
        "        val_group_counts = Counter(val_rankers)\n",
        "\n",
        "        print(\"\\nüìã Validation group statistics:\")\n",
        "        # Save detailed group info to file\n",
        "        group_info_path = os.path.join(MODEL_DIR, \"validation_groups_info.txt\")\n",
        "        with open(group_info_path, \"w\") as f:\n",
        "            f.write(f\"Total groups: {len(val_group_counts)}\\n\\n\")\n",
        "            f.write(\"GroupID\\tSize\\tStartIdx\\tEndIdx\\n\")\n",
        "\n",
        "            group_to_rows = defaultdict(list)\n",
        "            for i, g in enumerate(val_rankers):\n",
        "                group_to_rows[g].append(i)\n",
        "\n",
        "            for group_id, indices in sorted(group_to_rows.items()):\n",
        "                start_idx = indices[0]\n",
        "                end_idx = indices[-1]\n",
        "                size = len(indices)\n",
        "                f.write(f\"{group_id}\\t{size}\\t{start_idx}\\t{end_idx}\\n\")\n",
        "\n",
        "        print(f\"üìÅ Saved validation group info to {group_info_path}\")\n",
        "\n",
        "\n",
        "        cat_dims = build_cat_dims(X, cat_features)\n",
        "        num_numeric_feats = len(num_features)\n",
        "\n",
        "        train_dataset = RankDataset(X_tr, y_tr, groups_tr, cat_features, num_features)\n",
        "        val_dataset = RankDataset(X_va, y_va, groups_va, cat_features, num_features)\n",
        "        test_dataset = RankDataset(X_te, y_te, groups_te, cat_features, num_features)\n",
        "\n",
        "        plot_group_size_distribution(train_dataset, save_path=os.path.join(MODEL_DIR, \"group_sizes.png\"))\n",
        "        print(\"üìä Group size distribution saved.\")\n",
        "\n",
        "        train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True, collate_fn=collate_fn)\n",
        "        val_loader = DataLoader(val_dataset, batch_size=4, shuffle=False, collate_fn=collate_fn)\n",
        "        test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False, collate_fn=collate_fn)\n",
        "\n",
        "        print(\"‚úÖ Data loaders created.\")\n",
        "\n",
        "        num_epochs = 10\n",
        "        num_training_steps = num_epochs * len(train_loader)\n",
        "        num_warmup_steps = int(0.1 * num_training_steps)\n",
        "\n",
        "        model = FiBiDLRanker(\n",
        "            cat_dims=cat_dims,\n",
        "            num_numeric_feats=num_numeric_feats,\n",
        "            emb_dim=32,\n",
        "            hidden=[512, 256, 128, 64]\n",
        "        ).to(device)\n",
        "\n",
        "        optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=0.01)\n",
        "\n",
        "        scheduler = get_scheduler(\n",
        "            \"linear\",\n",
        "            optimizer=optimizer,\n",
        "            num_warmup_steps=num_warmup_steps,\n",
        "            num_training_steps=num_training_steps\n",
        "        )\n",
        "\n",
        "        best_hitrate = 0\n",
        "        for epoch in range(num_epochs):\n",
        "            print(f\"\\n--- Epoch {epoch+1}/{num_epochs} ---\")\n",
        "            start_time = time.time()\n",
        "\n",
        "            train_loss = train_one_epoch(model, train_loader, optimizer, device, scheduler)\n",
        "            val_loss, val_hitrate, val_ndcg, val_map = validate(model, val_loader, device, min_group_size=10)\n",
        "\n",
        "            train_losses.append(train_loss)\n",
        "            val_losses.append(val_loss)\n",
        "            val_hitrates.append(val_hitrate.item())\n",
        "            val_ndcgs.append(val_ndcg.item())\n",
        "            val_maps.append(val_map.item())\n",
        "\n",
        "            current_lr = scheduler.get_last_lr()\n",
        "            learning_rates.append(current_lr[0])\n",
        "\n",
        "            elapsed = time.time() - start_time\n",
        "            print(\n",
        "                f\"Epoch {epoch+1}: \"\n",
        "                f\"Train Loss={train_loss:.4f}, \"\n",
        "                f\"Val Loss={val_loss:.4f}, \"\n",
        "                f\"HitRate@3={val_hitrate:.4f}, \"\n",
        "                f\"NDCG@3={val_ndcg:.4f}, \"\n",
        "                f\"MAP@3={val_map:.4f}, \"\n",
        "                f\"LR={current_lr[0]:.6f} \"\n",
        "                f\"({elapsed:.1f}s)\"\n",
        "            )\n",
        "\n",
        "\n",
        "            if val_loss < best_val_loss and val_hitrate > best_hitrate:\n",
        "                best_val_loss = val_loss\n",
        "                best_hitrate = val_hitrate\n",
        "                torch.save(model.state_dict(), model_path)\n",
        "                print(\"üíæ Model improved (loss ‚Üì and hitrate ‚Üë), saved.\")\n",
        "\n",
        "            if early_stopper.step(-val_loss):\n",
        "                print(\"‚õî Early stopping triggered.\")\n",
        "                break\n",
        "\n",
        "        # Plot metrics\n",
        "        epochs = list(range(1, len(train_losses) + 1))\n",
        "\n",
        "        # Plot Loss Curve\n",
        "        plt.figure()\n",
        "        plt.plot(epochs, train_losses, label=\"Train Loss\")\n",
        "        plt.plot(epochs, val_losses, label=\"Val Loss\")\n",
        "        plt.xlabel(\"Epoch\")\n",
        "        plt.ylabel(\"Loss\")\n",
        "        plt.title(\"Training & Validation Loss\")\n",
        "        plt.legend()\n",
        "        plt.grid(True)\n",
        "        plt.savefig(os.path.join(MODEL_DIR, \"loss_curve.png\"))\n",
        "        plt.close()\n",
        "\n",
        "        # Plot HitRate@3\n",
        "        plt.figure()\n",
        "        plt.plot(epochs, val_hitrates, label=\"Val HitRate@3\", color=\"green\")\n",
        "        plt.xlabel(\"Epoch\")\n",
        "        plt.ylabel(\"HitRate@3\")\n",
        "        plt.title(\"Validation HitRate@3\")\n",
        "        plt.legend()\n",
        "        plt.grid(True)\n",
        "        plt.savefig(os.path.join(MODEL_DIR, \"hitrate_curve.png\"))\n",
        "        plt.close()\n",
        "\n",
        "        # Plot Learning Rate\n",
        "        plt.figure()\n",
        "        plt.plot(epochs, learning_rates, label=\"Learning Rate\", color=\"orange\")\n",
        "        plt.xlabel(\"Epoch\")\n",
        "        plt.ylabel(\"LR\")\n",
        "        plt.title(\"Learning Rate Schedule\")\n",
        "        plt.legend()\n",
        "        plt.grid(True)\n",
        "        plt.savefig(os.path.join(MODEL_DIR, \"lr_curve.png\"))\n",
        "        plt.close()\n",
        "\n",
        "        # Plot NDCG@3\n",
        "        plt.figure()\n",
        "        plt.plot(epochs, val_ndcgs, label=\"Val NDCG@3\", color=\"purple\")\n",
        "        plt.xlabel(\"Epoch\")\n",
        "        plt.ylabel(\"NDCG@3\")\n",
        "        plt.title(\"Validation NDCG@3\")\n",
        "        plt.legend()\n",
        "        plt.grid(True)\n",
        "        plt.savefig(os.path.join(MODEL_DIR, \"ndcg_curve.png\"))\n",
        "        plt.close()\n",
        "\n",
        "        # Plot MAP@3\n",
        "        plt.figure()\n",
        "        plt.plot(epochs, val_maps, label=\"Val MAP@3\", color=\"red\")\n",
        "        plt.xlabel(\"Epoch\")\n",
        "        plt.ylabel(\"MAP@3\")\n",
        "        plt.title(\"Validation MAP@3\")\n",
        "        plt.legend()\n",
        "        plt.grid(True)\n",
        "        plt.savefig(os.path.join(MODEL_DIR, \"map_curve.png\"))\n",
        "        plt.close()\n",
        "\n",
        "        print(\"üìä Saved metric plots to model/\")\n",
        "\n",
        "        # Predict test set\n",
        "        model.load_state_dict(torch.load(model_path))\n",
        "        model.eval()\n",
        "\n",
        "        val_ids = X_va[\"Id\"]\n",
        "        val_rankers = groups_va[\"ranker_id\"]\n",
        "        val_labels = y_va\n",
        "\n",
        "        all_val_scores = []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for x_cat, x_num, _, lengths in tqdm(val_loader, desc=\"Predicting validation set\"):\n",
        "                x_num = x_num.to(device)\n",
        "                x_cat = {k: v.to(device) for k, v in x_cat.items()}\n",
        "                scores = model(x_cat, x_num)\n",
        "\n",
        "                for i in range(scores.size(0)):\n",
        "                    l = lengths[i]\n",
        "                    all_val_scores.append(scores[i, :l].cpu().numpy())\n",
        "\n",
        "        all_val_scores = np.concatenate(all_val_scores)\n",
        "\n",
        "        assert len(all_val_scores) == X_va.shape[0], \\\n",
        "            f\"Mismatch: {len(all_val_scores)} scores vs {X_va.shape[0]} rows\"\n",
        "\n",
        "        val_df = X_va.with_columns([\n",
        "            pl.Series(\"Id\", val_ids),\n",
        "            pl.Series(\"ranker_id\", val_rankers),\n",
        "            pl.Series(\"score\", all_val_scores),\n",
        "            pl.Series(\"label\", val_labels)\n",
        "        ])\n",
        "\n",
        "        val_df = val_df.with_columns(\n",
        "            pl.col(\"score\")\n",
        "            .rank(method=\"ordinal\", descending=True)\n",
        "            .over(\"ranker_id\")\n",
        "            .cast(pl.Int32)\n",
        "            .alias(\"selected\")\n",
        "        )\n",
        "\n",
        "        val_save_path = os.path.join(MODEL_DIR, \"validation_preds_dl_full.csv\")\n",
        "        val_df.write_csv(val_save_path)\n",
        "        print(f\"‚úÖ Saved full validation predictions (with features) to {val_save_path}\")\n",
        "\n",
        "        all_scores = []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for x_cat, x_num, _, lengths in tqdm(test_loader, desc=\"Predicting test set\"):\n",
        "                x_num = x_num.to(device)\n",
        "                x_cat = {k: v.to(device) for k, v in x_cat.items()}\n",
        "                scores = model(x_cat, x_num)\n",
        "\n",
        "                for i in range(scores.size(0)):\n",
        "                    l = lengths[i]\n",
        "                    all_scores.append(scores[i, :l].cpu().numpy())\n",
        "\n",
        "        all_scores = np.concatenate(all_scores)\n",
        "\n",
        "        assert len(all_scores) == X_te.shape[0], \\\n",
        "            f\"Mismatch: {len(all_scores)} scores vs {X_te.shape[0]} rows in X_te\"\n",
        "\n",
        "        submission_df = pl.DataFrame({\n",
        "            \"Id\": test_ids,\n",
        "            \"ranker_id\": test_rankers,\n",
        "            \"score\": all_scores\n",
        "        })\n",
        "\n",
        "        submission = (\n",
        "            submission_df\n",
        "            .with_columns(\n",
        "                pl.col(\"score\")\n",
        "                .rank(method=\"ordinal\", descending=True)\n",
        "                .over(\"ranker_id\")\n",
        "                .cast(pl.Int32)\n",
        "                .alias(\"selected\")\n",
        "            )\n",
        "            .select([\"Id\", \"ranker_id\", \"score\", \"selected\"])\n",
        "        )\n",
        "\n",
        "        submission_path = os.path.join(SUBMIT_DIR, \"submission_dl_ranker.csv\")\n",
        "        submission.write_csv(submission_path)\n",
        "        print(f\"‚úÖ Submission saved to {submission_path}\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c79VbffVdEoI",
        "outputId": "5f54c7c1-cc91-433f-d66a-08b99217f974"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting deeprec_validate.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "--- Epoch 1/10 ---\n",
        "Validating:   0%|          | 0/2636 [00:00<?, ?it/s]/home/ionut/test_whisper/test2/deeprec_validate.py:476: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
        "  lengths = torch.tensor(lengths).to(device)\n",
        "Epoch 1: Train Loss=0.4424, Val Loss=0.3009, HitRate@3=0.4628, NDCG@3=0.3676, MAP@3=0.6147, LR=0.001000 (677.8s)\n",
        "üíæ Model improved (loss ‚Üì and hitrate ‚Üë), saved.\n",
        "\n",
        "--- Epoch 2/10 ---\n",
        "Epoch 2: Train Loss=0.2698, Val Loss=0.2787, HitRate@3=0.4965, NDCG@3=0.3992, MAP@3=0.6466, LR=0.000889 (675.4s)\n",
        "üíæ Model improved (loss ‚Üì and hitrate ‚Üë), saved.\n",
        "\n",
        "--- Epoch 3/10 ---\n",
        "Epoch 3: Train Loss=0.2496, Val Loss=0.2811, HitRate@3=0.4974, NDCG@3=0.4020, MAP@3=0.6474, LR=0.000778 (677.2s)\n",
        "\n",
        "--- Epoch 4/10 ---\n",
        "Epoch 4: Train Loss=0.2372, Val Loss=0.2765, HitRate@3=0.4972, NDCG@3=0.3997, MAP@3=0.6492, LR=0.000667 (676.6s)\n",
        "üíæ Model improved (loss ‚Üì and hitrate ‚Üë), saved.\n",
        "\n",
        "--- Epoch 5/10 ---\n",
        "Epoch 5: Train Loss=0.2285, Val Loss=0.2752, HitRate@3=0.5032, NDCG@3=0.4051, MAP@3=0.6495, LR=0.000556 (679.4s)\n",
        "üíæ Model improved (loss ‚Üì and hitrate ‚Üë), saved.\n",
        "\n",
        "--- Epoch 6/10 ---\n",
        "Epoch 6: Train Loss=0.2158, Val Loss=0.2673, HitRate@3=0.5006, NDCG@3=0.4048, MAP@3=0.6558, LR=0.000444 (677.1s)\n",
        "\n",
        "--- Epoch 7/10 ---\n",
        "Epoch 7: Train Loss=0.2041, Val Loss=0.2659, HitRate@3=0.5060, NDCG@3=0.4099, MAP@3=0.6584, LR=0.000333 (677.9s)\n",
        "üíæ Model improved (loss ‚Üì and hitrate ‚Üë), saved.\n",
        "\n",
        "--- Epoch 8/10 ---\n",
        "Epoch 8: Train Loss=0.1934, Val Loss=0.2687, HitRate@3=0.5033, NDCG@3=0.4066, MAP@3=0.6519, LR=0.000222 (682.1s)\n",
        "\n",
        "--- Epoch 9/10 ---\n",
        "Epoch 9: Train Loss=0.1804, Val Loss=0.2782, HitRate@3=0.5061, NDCG@3=0.4094, MAP@3=0.6585, LR=0.000111 (682.8s)\n",
        "\n",
        "--- Epoch 10/10 ---\n",
        "Epoch 10: Train Loss=0.1679, Val Loss=0.2728, HitRate@3=0.5081, NDCG@3=0.4104, MAP@3=0.6588, LR=0.000000 (677.5s)\n",
        "‚õî Early stopping triggered."
      ],
      "metadata": {
        "id": "Fga2PTgB9q0e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile deeprec_validate.py\n",
        "import os\n",
        "import time\n",
        "import random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F_torch\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import defaultdict\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "import polars as pl\n",
        "from tqdm import tqdm\n",
        "from src.feature import feature_engineering, feature_selection\n",
        "from transformers import get_scheduler\n",
        "from collections import Counter\n",
        "\n",
        "class RankDataset(Dataset):\n",
        "    def __init__(\n",
        "        self,\n",
        "        X: pl.DataFrame,\n",
        "        y: pl.Series,\n",
        "        groups: pl.DataFrame,\n",
        "        cat_features: list[str],\n",
        "        num_features: list[str],\n",
        "    ):\n",
        "        self.cat_features = cat_features\n",
        "        self.num_features = num_features\n",
        "        self.X_cat = {c: X[c].to_numpy() for c in cat_features}\n",
        "        self.X_num = X[self.num_features].to_numpy()\n",
        "        self.y = y.to_numpy()\n",
        "        self.groups = groups[\"ranker_id\"].to_numpy()\n",
        "\n",
        "        self.group_to_indices = defaultdict(list)\n",
        "        for i, g in enumerate(self.groups):\n",
        "            self.group_to_indices[g].append(i)\n",
        "        self.group_keys = list(self.group_to_indices.keys())\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.group_keys)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        g = self.group_keys[idx]\n",
        "        inds = self.group_to_indices[g]\n",
        "        length = len(inds)\n",
        "\n",
        "        x_cat = {\n",
        "            c: torch.LongTensor([\n",
        "                self.X_cat[c][i] if self.X_cat[c][i] >= 0 else 0 for i in inds\n",
        "            ])\n",
        "            for c in self.cat_features\n",
        "        }\n",
        "\n",
        "        x_num = torch.FloatTensor(self.X_num[inds])\n",
        "        y = torch.FloatTensor(self.y[inds]).reshape(-1)\n",
        "\n",
        "        return x_cat, x_num, y, length\n",
        "\n",
        "def collate_fn(batch):\n",
        "    batch = [b for b in batch if b[3] >= 2]\n",
        "    if len(batch) == 0:\n",
        "        return None\n",
        "\n",
        "    batch_size = len(batch)\n",
        "    lengths = [b[3] for b in batch]\n",
        "    max_len = max(lengths)\n",
        "\n",
        "    padded_x_cat = {key: [] for key in batch[0][0].keys()}\n",
        "    padded_x_num = []\n",
        "    padded_y = []\n",
        "\n",
        "    num_dim = batch[0][1].shape[1]\n",
        "\n",
        "    for x_cat, x_num, y, length in batch:\n",
        "        pad_len = max_len - length\n",
        "\n",
        "        for key in padded_x_cat:\n",
        "            val = x_cat[key]\n",
        "            if pad_len > 0:\n",
        "                val = torch.cat([val, torch.zeros(pad_len, dtype=torch.long)])\n",
        "            padded_x_cat[key].append(val)\n",
        "\n",
        "        if pad_len > 0:\n",
        "            x_num = torch.cat([x_num, torch.zeros(pad_len, num_dim)])\n",
        "            y = torch.cat([y, torch.zeros(pad_len)])\n",
        "\n",
        "        padded_x_num.append(x_num)\n",
        "        padded_y.append(y)\n",
        "\n",
        "    padded_x_cat = {k: torch.stack(v) for k, v in padded_x_cat.items()}\n",
        "    padded_x_num = torch.stack(padded_x_num)\n",
        "    padded_y = torch.stack(padded_y)\n",
        "    lengths = torch.tensor(lengths, dtype=torch.long)\n",
        "\n",
        "    return padded_x_cat, padded_x_num, padded_y, lengths\n",
        "\n",
        "\n",
        "class FiBiDLRanker(nn.Module):\n",
        "    def __init__(self, cat_dims, num_numeric_feats, emb_dim=64, hidden=[512, 256, 128, 64], reduction=4, use_senet=True):\n",
        "        super().__init__()\n",
        "        self.cat_fields = list(cat_dims.keys())\n",
        "        self.emb_dim = emb_dim\n",
        "        self.num_fields = len(self.cat_fields)\n",
        "        self.use_senet = use_senet\n",
        "\n",
        "        # Embedding layers\n",
        "        self.embeddings = nn.ModuleDict({\n",
        "            f: nn.Embedding(cat_dims[f], emb_dim, padding_idx=0) for f in self.cat_fields\n",
        "        })\n",
        "        self.linear_cat = nn.ModuleDict({\n",
        "            f: nn.Embedding(cat_dims[f], 1, padding_idx=0) for f in self.cat_fields\n",
        "        })\n",
        "        self.linear_num = nn.Linear(num_numeric_feats, 1)\n",
        "\n",
        "        for emb in list(self.embeddings.values()) + list(self.linear_cat.values()):\n",
        "            nn.init.xavier_uniform_(emb.weight)\n",
        "        nn.init.xavier_uniform_(self.linear_num.weight)\n",
        "\n",
        "        # SENet (with LayerNorm)\n",
        "        if self.use_senet:\n",
        "            self.se_fc1 = nn.Linear(self.num_fields * emb_dim, self.num_fields * emb_dim // reduction)\n",
        "            self.se_ln1 = nn.LayerNorm(self.num_fields * emb_dim // reduction)\n",
        "            self.se_dropout = nn.Dropout(0.1)\n",
        "            self.se_fc2 = nn.Linear(self.num_fields * emb_dim // reduction, self.num_fields * emb_dim)\n",
        "\n",
        "        # Bilinear layer (shared)\n",
        "        self.bilinear = nn.Linear(emb_dim, emb_dim, bias=False)\n",
        "\n",
        "        # MLP (using LayerNorm instead of BatchNorm)\n",
        "        input_dim = emb_dim + num_numeric_feats\n",
        "        layers = []\n",
        "        for h in hidden:\n",
        "            layers.append(nn.Linear(input_dim, h))\n",
        "            layers.append(nn.LayerNorm(h))     # replaced BatchNorm1d with LayerNorm\n",
        "            layers.append(nn.ReLU())\n",
        "            layers.append(nn.Dropout(0.2))\n",
        "            input_dim = h\n",
        "        self.mlp = nn.Sequential(*layers)\n",
        "        self.output = nn.Linear(input_dim, 1)\n",
        "\n",
        "    def senet(self, embs):\n",
        "        B, F, D = embs.shape\n",
        "        z = embs.view(B, -1)  # Flatten [B, F*D]\n",
        "        a = self.se_fc1(z)    # Linear\n",
        "        a = self.se_ln1(a)    # LayerNorm instead of BatchNorm\n",
        "        a = F_torch.relu(a)\n",
        "        a = self.se_dropout(a)\n",
        "        s = torch.sigmoid(self.se_fc2(a)).view(B, F, D)\n",
        "        return embs * s\n",
        "\n",
        "    def bilinear_interaction(self, embs):\n",
        "        transformed = self.bilinear(embs)\n",
        "        interaction = (embs * transformed).mean(dim=1)\n",
        "        return interaction\n",
        "\n",
        "    def forward(self, x_cat, x_num):\n",
        "        B, G = x_num.shape[:2]\n",
        "        F, D = self.num_fields, self.emb_dim\n",
        "\n",
        "        # Embeddings [B, G, F, D]\n",
        "        embs = torch.stack([self.embeddings[f](x_cat[f]) for f in self.cat_fields], dim=2)\n",
        "\n",
        "        # Linear output\n",
        "        linear_cat_sum = torch.stack([\n",
        "            self.linear_cat[f](x_cat[f]).squeeze(-1) for f in self.cat_fields\n",
        "        ], dim=0).sum(dim=0)\n",
        "        linear_num_out = self.linear_num(x_num).squeeze(-1)\n",
        "        linear_out = linear_cat_sum + linear_num_out  # [B, G]\n",
        "\n",
        "        # Feature interactions\n",
        "        embs = embs.view(B * G, F, D)\n",
        "        if self.use_senet:\n",
        "            embs = self.senet(embs)\n",
        "        bi = self.bilinear_interaction(embs)  # [B*G, D]\n",
        "\n",
        "        # Deep part\n",
        "        x_num_flat = x_num.view(B * G, -1)\n",
        "        deep_input = torch.cat([bi, x_num_flat], dim=1)\n",
        "        deep_out = self.mlp(deep_input)\n",
        "        scores = self.output(deep_out).view(B, G)\n",
        "\n",
        "        return scores + linear_out  # final output\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "def listmle_loss(scores, labels, lengths):\n",
        "    batch_size = scores.size(0)\n",
        "    total_loss = torch.tensor(0.0, device=scores.device, requires_grad=True)\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "\n",
        "        _, idx = torch.sort(y, descending=True)\n",
        "        s_sorted = s[idx]\n",
        "\n",
        "        parts = (\n",
        "            torch.logsumexp(s_sorted.unsqueeze(0).expand(l, -1).triu(diagonal=0), dim=1)\n",
        "            - s_sorted\n",
        "        )\n",
        "\n",
        "        total_loss = total_loss + parts.sum()\n",
        "\n",
        "    return total_loss / batch_size\n",
        "\"\"\"\n",
        "\n",
        "def hitrate_at_k(scores, labels, lengths, k=3, min_group_size=10):\n",
        "    batch_size = scores.size(0)\n",
        "    hits = 0\n",
        "    valid_count = 0\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        if l < min_group_size:\n",
        "            continue\n",
        "        length = min(l, k)\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "        _, topk_idx = torch.topk(s, length)\n",
        "        topk_labels = y[topk_idx]\n",
        "        hits += (topk_labels > 0).any().float()\n",
        "        valid_count += 1\n",
        "    return hits / valid_count if valid_count > 0 else torch.tensor(0.0, device=scores.device)\n",
        "\n",
        "\n",
        "def ndcg_at_k(scores, labels, lengths, k=3, min_group_size=10):\n",
        "    batch_size = scores.size(0)\n",
        "    total_ndcg = 0.0\n",
        "    valid_count = 0\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        if l < min_group_size:\n",
        "            continue\n",
        "\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "\n",
        "        _, idx_pred = torch.topk(s, min(k, l))\n",
        "        _, idx_ideal = torch.topk(y, min(k, l))\n",
        "\n",
        "        dcg = (y[idx_pred] / torch.log2(torch.arange(2, 2 + len(idx_pred), device=y.device).float())).sum()\n",
        "        idcg = (y[idx_ideal] / torch.log2(torch.arange(2, 2 + len(idx_ideal), device=y.device).float())).sum()\n",
        "\n",
        "        ndcg = dcg / idcg if idcg > 0 else 0.0\n",
        "        total_ndcg += ndcg\n",
        "        valid_count += 1\n",
        "\n",
        "    return total_ndcg / valid_count if valid_count > 0 else torch.tensor(0.0, device=scores.device)\n",
        "\n",
        "\n",
        "def map_at_k(scores, labels, lengths, k=3, min_group_size=10):\n",
        "    batch_size = scores.size(0)\n",
        "    total_ap = 0.0\n",
        "    valid_count = 0\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        if l < min_group_size:\n",
        "            continue\n",
        "\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "\n",
        "        _, idx_pred = torch.topk(s, min(k, l))\n",
        "        y_true = y[idx_pred] > 0\n",
        "\n",
        "        if y_true.sum() == 0:\n",
        "            continue\n",
        "\n",
        "        precisions = [(y_true[:j+1].float().sum() / (j+1)) for j in range(len(y_true)) if y_true[j]]\n",
        "        ap = torch.stack(precisions).mean()\n",
        "        total_ap += ap\n",
        "        valid_count += 1\n",
        "\n",
        "    return total_ap / valid_count if valid_count > 0 else torch.tensor(0.0, device=scores.device)\n",
        "\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "def listnet_loss(scores, labels, lengths):\n",
        "    batch_size = scores.size(0)\n",
        "    total_loss = 0.0\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "\n",
        "        s_softmax = torch.nn.functional.log_softmax(s, dim=0)\n",
        "        y_softmax = torch.nn.functional.softmax(y, dim=0)\n",
        "\n",
        "        loss = -torch.sum(y_softmax * s_softmax)\n",
        "        total_loss += loss\n",
        "\n",
        "    return total_loss / batch_size\n",
        "\"\"\"\n",
        "\n",
        "def ranknet_loss(scores, labels, lengths):\n",
        "    batch_size = scores.size(0)\n",
        "    total_loss = 0.0\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "\n",
        "        diff_scores = s.unsqueeze(1) - s.unsqueeze(0)\n",
        "        rel = y.unsqueeze(1) > y.unsqueeze(0)\n",
        "        label_diff = rel.float()\n",
        "\n",
        "        log_sigmoid = torch.nn.functional.logsigmoid(diff_scores)\n",
        "        pair_loss = -label_diff * log_sigmoid\n",
        "\n",
        "        total_loss += pair_loss.sum()\n",
        "\n",
        "    return total_loss / batch_size\n",
        "\n",
        "def xranknet_loss(scores, labels, lengths, temperature=1.0, margin=0.2, focus_topk=3):\n",
        "    \"\"\"\n",
        "    xRankNet with emphasis on top-K items (based on labels, not scores).\n",
        "    \"\"\"\n",
        "    batch_size = scores.size(0)\n",
        "    total_loss = 0.0\n",
        "    total_pairs = 0\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        if l < 2:\n",
        "            continue\n",
        "\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "\n",
        "        # Top-K mask based on ground truth labels\n",
        "        topk = min(focus_topk, l)\n",
        "        _, topk_idx = torch.topk(y, topk)\n",
        "        topk_mask = torch.zeros_like(y, dtype=torch.bool)\n",
        "        topk_mask[topk_idx] = True\n",
        "\n",
        "        # Create pairwise difference matrices\n",
        "        score_diff = s.unsqueeze(1) - s.unsqueeze(0)\n",
        "        label_diff = y.unsqueeze(1) - y.unsqueeze(0)\n",
        "\n",
        "        # valid pair: y_i > y_j and at least one of i, j is in top-K\n",
        "        valid_pairs = (label_diff > 0) & (\n",
        "            topk_mask.unsqueeze(1) | topk_mask.unsqueeze(0)\n",
        "        )\n",
        "\n",
        "        if valid_pairs.sum() == 0:\n",
        "            continue\n",
        "\n",
        "        importance = (label_diff.abs() * valid_pairs).float()\n",
        "\n",
        "        if margin > 0.0:\n",
        "            score_diff = score_diff - margin\n",
        "\n",
        "        score_diff = score_diff / temperature\n",
        "        pairwise_loss = -F_torch.logsigmoid(score_diff) * importance\n",
        "\n",
        "        total_loss += pairwise_loss.sum()\n",
        "        total_pairs += importance.sum()\n",
        "\n",
        "    if total_pairs == 0:\n",
        "        return torch.tensor(0.0, device=scores.device, requires_grad=True)\n",
        "\n",
        "    return total_loss / total_pairs\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "def bpr_loss(scores, labels, lengths):\n",
        "    batch_size = scores.size(0)\n",
        "    total_loss = 0.0\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "\n",
        "        pos_mask = y > 0\n",
        "        neg_mask = y <= 0\n",
        "\n",
        "        pos_scores = s[pos_mask]\n",
        "        neg_scores = s[neg_mask]\n",
        "\n",
        "        if len(pos_scores) == 0 or len(neg_scores) == 0:\n",
        "            continue\n",
        "\n",
        "        pair_diff = pos_scores.unsqueeze(1) - neg_scores.unsqueeze(0)\n",
        "        loss = -F.logsigmoid(pair_diff).mean()\n",
        "        total_loss += loss\n",
        "\n",
        "    return total_loss / batch_size\n",
        "\"\"\"\n",
        "\n",
        "\"\"\"\n",
        "def lambdarank_loss(scores, labels, lengths, eps=1e-10):\n",
        "    batch_size = scores.size(0)\n",
        "    total_loss = 0.0\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "\n",
        "        if l < 2:\n",
        "            continue\n",
        "\n",
        "        _, rank_order = torch.sort(s, descending=True)\n",
        "        ideal_order = torch.sort(y, descending=True).indices\n",
        "\n",
        "        gain = 2 ** y - 1\n",
        "        discount = torch.log2(torch.arange(2, l + 2, device=y.device).float())\n",
        "\n",
        "        ideal_dcg = (gain[ideal_order] / discount).sum()\n",
        "        if ideal_dcg < eps:\n",
        "            continue\n",
        "\n",
        "        delta_ndcg = torch.zeros((l, l), device=y.device)\n",
        "\n",
        "        for i_idx in range(l):\n",
        "            for j_idx in range(l):\n",
        "                if y[i_idx] > y[j_idx]:\n",
        "                    change = (\n",
        "                        (1.0 / torch.log2(rank_order[i_idx] + 2.0))\n",
        "                        - (1.0 / torch.log2(rank_order[j_idx] + 2.0))\n",
        "                    ).abs()\n",
        "                    delta = (2 ** y[i_idx] - 2 ** y[j_idx]).abs() * change\n",
        "                    delta_ndcg[i_idx, j_idx] = delta / ideal_dcg\n",
        "\n",
        "        score_diffs = s.unsqueeze(1) - s.unsqueeze(0)\n",
        "        lambdas = -F.logsigmoid(score_diffs) * delta_ndcg\n",
        "        total_loss += lambdas.sum()\n",
        "\n",
        "    return total_loss / batch_size\n",
        "\"\"\"\n",
        "\n",
        "def train_one_epoch(model, loader, optimizer, device, scheduler):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "    valid_batches = 0\n",
        "\n",
        "    for batch in tqdm(loader, desc=\"Training\", leave=False):\n",
        "        if batch is None:\n",
        "            continue\n",
        "\n",
        "        x_cat, x_num, y, lengths = batch\n",
        "\n",
        "        x_num, y = x_num.to(device), y.to(device)\n",
        "        lengths = lengths.to(device)\n",
        "        x_cat = {k: v.to(device) for k, v in x_cat.items()}\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        scores = model(x_cat, x_num)\n",
        "        loss = xranknet_loss(scores, y, lengths, temperature=1.0, margin=0.2, focus_topk=3)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        valid_batches += 1\n",
        "\n",
        "    return total_loss / valid_batches if valid_batches > 0 else float(\"inf\")\n",
        "\n",
        "\n",
        "\n",
        "def validate(model, loader, device, min_group_size=10):\n",
        "    model.eval()\n",
        "    total_hitrate = 0\n",
        "    total_ndcg = 0\n",
        "    total_map = 0\n",
        "    total_loss = 0\n",
        "    count = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for x_cat, x_num, y, lengths in tqdm(loader, desc=\"Validating\", leave=False):\n",
        "            x_num, y = x_num.to(device), y.to(device)\n",
        "            lengths = torch.tensor(lengths).to(device)\n",
        "            x_cat = {k: v.to(device) for k, v in x_cat.items()}\n",
        "\n",
        "            scores = model(x_cat, x_num)\n",
        "\n",
        "            hitrate = hitrate_at_k(scores, y, lengths, k=3, min_group_size=min_group_size)\n",
        "            ndcg = ndcg_at_k(scores, y, lengths, k=3, min_group_size=min_group_size)\n",
        "            map3 = map_at_k(scores, y, lengths, k=3, min_group_size=min_group_size)\n",
        "            loss = xranknet_loss(scores, y, lengths, temperature=1.0, margin=0.2, focus_topk=3)\n",
        "\n",
        "            batch_size = scores.size(0)\n",
        "            total_hitrate += hitrate * batch_size\n",
        "            total_ndcg += ndcg * batch_size\n",
        "            total_map += map3 * batch_size\n",
        "            total_loss += loss.item() * batch_size\n",
        "            count += batch_size\n",
        "\n",
        "    return total_loss / count, total_hitrate / count, total_ndcg / count, total_map / count\n",
        "\n",
        "\n",
        "def build_cat_dims(X, cat_features):\n",
        "    cat_dims = {}\n",
        "    for c in cat_features:\n",
        "        max_val = X[c].max()\n",
        "        if max_val < 0:\n",
        "            max_val = 0\n",
        "        cat_dims[c] = max_val + 1\n",
        "    return cat_dims\n",
        "\n",
        "\n",
        "def normalize_numeric_features(X, numeric_features, train_mask):\n",
        "    for col in numeric_features:\n",
        "        values = X[col].to_numpy()\n",
        "        train_vals = values[train_mask]\n",
        "        mean = train_vals.mean()\n",
        "        std = train_vals.std() if train_vals.std() > 0 else 1.0\n",
        "        norm_vals = (values - mean) / std\n",
        "        X = X.with_columns(pl.Series(col, norm_vals).alias(col))\n",
        "    return X\n",
        "\n",
        "\n",
        "def load_or_prepare_data(\n",
        "    data_dir,\n",
        "    train_file=\"train.parquet\",\n",
        "    test_file=\"test.parquet\",\n",
        "    cache_file=\"feature_engineered_val.parquet\",\n",
        "):\n",
        "    cache_path = os.path.join(data_dir, cache_file)\n",
        "\n",
        "    if os.path.exists(cache_path):\n",
        "        print(f\"Loading cached feature-engineered data from {cache_path} ...\")\n",
        "        df = pl.read_parquet(cache_path)\n",
        "\n",
        "        test = pl.read_parquet(os.path.join(data_dir, test_file)).drop(\"__index_level_0__\")\n",
        "        test_ids = test[\"Id\"]\n",
        "        test_rankers = test[\"ranker_id\"]\n",
        "    else:\n",
        "        print(\"Cached file not found, processing raw data ...\")\n",
        "\n",
        "        train = pl.read_parquet(os.path.join(data_dir, train_file)).drop(\"__index_level_0__\")\n",
        "        test = (\n",
        "            pl.read_parquet(os.path.join(data_dir, test_file))\n",
        "            .drop(\"__index_level_0__\")\n",
        "            .with_columns(pl.lit(0, dtype=pl.Int64).alias(\"selected\"))\n",
        "        )\n",
        "\n",
        "        test_ids = test[\"Id\"]\n",
        "        test_rankers = test[\"ranker_id\"]\n",
        "\n",
        "        df = pl.concat((train, test))\n",
        "        df = feature_engineering(df, full=True)\n",
        "\n",
        "        df = df.with_columns(\n",
        "            [pl.col(c).fill_null(0) for c in df.select(pl.selectors.numeric()).columns] +\n",
        "            [pl.col(c).fill_null(\"missing\") for c in df.select(pl.selectors.string()).columns]\n",
        "        )\n",
        "\n",
        "        os.makedirs(data_dir, exist_ok=True)\n",
        "        df.write_parquet(cache_path)\n",
        "        print(f\"Saved feature-engineered data to {cache_path}\")\n",
        "\n",
        "    return df, test_ids, test_rankers\n",
        "\n",
        "\n",
        "def prepare_data(data_dir):\n",
        "    df, test_ids, test_rankers = load_or_prepare_data(data_dir)\n",
        "\n",
        "    id_column = df[\"Id\"]\n",
        "    X, y, groups, cat_features, num_features = feature_selection(df)\n",
        "\n",
        "    X = X.with_columns(pl.Series(\"Id\", id_column[:X.shape[0]]))\n",
        "\n",
        "    X = X.with_columns(\n",
        "        [\n",
        "            (pl.col(c).rank(\"dense\") - 1).fill_null(-1).cast(pl.Int32)\n",
        "            for c in cat_features\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    train_size = 18145372\n",
        "    train_mask = np.arange(X.height) < train_size\n",
        "    X = normalize_numeric_features(X, num_features, train_mask)\n",
        "\n",
        "    return X, y, groups, cat_features, num_features, train_size, test_ids, test_rankers\n",
        "\n",
        "\n",
        "class EarlyStopping:\n",
        "    def __init__(self, patience=3, min_delta=0.00005):\n",
        "        self.patience = patience\n",
        "        self.min_delta = min_delta\n",
        "        self.best = float(\"-inf\")\n",
        "        self.counter = 0\n",
        "\n",
        "    def step(self, metric):\n",
        "        if metric > self.best + self.min_delta:\n",
        "            self.best = metric\n",
        "            self.counter = 0\n",
        "        else:\n",
        "            self.counter += 1\n",
        "        return self.counter >= self.patience\n",
        "\n",
        "\n",
        "def plot_group_size_distribution(dataset, save_path=None):\n",
        "    group_sizes = [len(v) for v in dataset.group_to_indices.values()]\n",
        "    plt.figure()\n",
        "    plt.hist(group_sizes, bins=100, log=True)\n",
        "    plt.xlabel(\"Group size (number of items per ranker_id)\")\n",
        "    plt.ylabel(\"Frequency (log scale)\")\n",
        "    plt.title(\"Distribution of Group Sizes\")\n",
        "    plt.grid(True)\n",
        "    if save_path:\n",
        "        plt.savefig(save_path)\n",
        "    else:\n",
        "        plt.show()\n",
        "    plt.close()\n",
        "\n",
        "\n",
        "def main():\n",
        "    DATA_DIR = \"./data\"\n",
        "    SUBMIT_DIR = \"submission\"\n",
        "    os.makedirs(SUBMIT_DIR, exist_ok=True)\n",
        "\n",
        "    learning_rates_to_try = [7e-4, 5e-4]\n",
        "\n",
        "    for lr in learning_rates_to_try:\n",
        "        run_name = f\"lr_{lr:.0e}\".replace(\"-\", \"\")\n",
        "        MODEL_DIR = f\"model_{run_name}\"\n",
        "        os.makedirs(MODEL_DIR, exist_ok=True)\n",
        "\n",
        "        print(f\"\\n\\nüöÄ Starting training with learning rate = {lr}\\nSaved to: {MODEL_DIR}\")\n",
        "\n",
        "        best_val_loss = float(\"inf\")\n",
        "        best_hitrate = 0.0\n",
        "        model_path = os.path.join(MODEL_DIR, \"best_dl_ranker.pt\")\n",
        "\n",
        "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "        train_losses = []\n",
        "        val_losses = []\n",
        "        val_hitrates = []\n",
        "        val_ndcgs = []\n",
        "        val_maps = []\n",
        "        learning_rates = []\n",
        "\n",
        "        os.makedirs(MODEL_DIR, exist_ok=True)\n",
        "        os.makedirs(SUBMIT_DIR, exist_ok=True)\n",
        "\n",
        "        early_stopper = EarlyStopping(patience=3, min_delta=0.00005)\n",
        "\n",
        "        X, y, groups, cat_features, num_features, train_size, test_ids, test_rankers = prepare_data(DATA_DIR)\n",
        "\n",
        "        # Fill missing values\n",
        "        float_cols = [c for c, t in zip(X.columns, X.dtypes) if t == pl.Float64]\n",
        "        for col in float_cols:\n",
        "            X = X.with_columns(\n",
        "                pl.when(pl.col(col).is_nan()).then(0).otherwise(pl.col(col)).alias(col)\n",
        "            )\n",
        "\n",
        "        n1 = 16487352\n",
        "        # n1 = 17487300\n",
        "        n2 = train_size\n",
        "\n",
        "        X_tr, X_va, X_te = X[:n1], X[n1:n2], X[n2:]\n",
        "        y_tr, y_va, y_te = y[:n1], y[n1:n2], y[n2:]\n",
        "        groups_tr, groups_va, groups_te = groups[:n1], groups[n1:n2], groups[n2:]\n",
        "\n",
        "        # Inspect group sizes in validation set\n",
        "        val_rankers = groups_va[\"ranker_id\"].to_numpy()\n",
        "        val_group_counts = Counter(val_rankers)\n",
        "\n",
        "        print(\"\\nüìã Validation group statistics:\")\n",
        "        # Save detailed group info to file\n",
        "        group_info_path = os.path.join(MODEL_DIR, \"validation_groups_info.txt\")\n",
        "        with open(group_info_path, \"w\") as f:\n",
        "            f.write(f\"Total groups: {len(val_group_counts)}\\n\\n\")\n",
        "            f.write(\"GroupID\\tSize\\tStartIdx\\tEndIdx\\n\")\n",
        "\n",
        "            group_to_rows = defaultdict(list)\n",
        "            for i, g in enumerate(val_rankers):\n",
        "                group_to_rows[g].append(i)\n",
        "\n",
        "            for group_id, indices in sorted(group_to_rows.items()):\n",
        "                start_idx = indices[0]\n",
        "                end_idx = indices[-1]\n",
        "                size = len(indices)\n",
        "                f.write(f\"{group_id}\\t{size}\\t{start_idx}\\t{end_idx}\\n\")\n",
        "\n",
        "        print(f\"üìÅ Saved validation group info to {group_info_path}\")\n",
        "\n",
        "\n",
        "        cat_dims = build_cat_dims(X, cat_features)\n",
        "        num_numeric_feats = len(num_features)\n",
        "\n",
        "        train_dataset = RankDataset(X_tr, y_tr, groups_tr, cat_features, num_features)\n",
        "        val_dataset = RankDataset(X_va, y_va, groups_va, cat_features, num_features)\n",
        "        test_dataset = RankDataset(X_te, y_te, groups_te, cat_features, num_features)\n",
        "\n",
        "        plot_group_size_distribution(train_dataset, save_path=os.path.join(MODEL_DIR, \"group_sizes.png\"))\n",
        "        print(\"üìä Group size distribution saved.\")\n",
        "\n",
        "        train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True, collate_fn=collate_fn)\n",
        "        val_loader = DataLoader(val_dataset, batch_size=4, shuffle=False, collate_fn=collate_fn)\n",
        "        test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False, collate_fn=collate_fn)\n",
        "\n",
        "        print(\"‚úÖ Data loaders created.\")\n",
        "\n",
        "        num_epochs = 10\n",
        "        num_training_steps = num_epochs * len(train_loader)\n",
        "        num_warmup_steps = int(0.1 * num_training_steps)\n",
        "\n",
        "        model = FiBiDLRanker(\n",
        "            cat_dims=cat_dims,\n",
        "            num_numeric_feats=num_numeric_feats,\n",
        "            emb_dim=48,\n",
        "            hidden=[1024, 512, 256, 128, 64]\n",
        "        ).to(device)\n",
        "\n",
        "        optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=0.01)\n",
        "\n",
        "        scheduler = get_scheduler(\n",
        "            \"linear\",\n",
        "            optimizer=optimizer,\n",
        "            num_warmup_steps=num_warmup_steps,\n",
        "            num_training_steps=num_training_steps\n",
        "        )\n",
        "\n",
        "        best_hitrate = 0\n",
        "        for epoch in range(num_epochs):\n",
        "            print(f\"\\n--- Epoch {epoch+1}/{num_epochs} ---\")\n",
        "            start_time = time.time()\n",
        "\n",
        "            train_loss = train_one_epoch(model, train_loader, optimizer, device, scheduler)\n",
        "            val_loss, val_hitrate, val_ndcg, val_map = validate(model, val_loader, device, min_group_size=10)\n",
        "\n",
        "            train_losses.append(train_loss)\n",
        "            val_losses.append(val_loss)\n",
        "            val_hitrates.append(val_hitrate.item())\n",
        "            val_ndcgs.append(val_ndcg.item())\n",
        "            val_maps.append(val_map.item())\n",
        "\n",
        "            current_lr = scheduler.get_last_lr()\n",
        "            learning_rates.append(current_lr[0])\n",
        "\n",
        "            elapsed = time.time() - start_time\n",
        "            print(\n",
        "                f\"Epoch {epoch+1}: \"\n",
        "                f\"Train Loss={train_loss:.4f}, \"\n",
        "                f\"Val Loss={val_loss:.4f}, \"\n",
        "                f\"HitRate@3={val_hitrate:.4f}, \"\n",
        "                f\"NDCG@3={val_ndcg:.4f}, \"\n",
        "                f\"MAP@3={val_map:.4f}, \"\n",
        "                f\"LR={current_lr[0]:.6f} \"\n",
        "                f\"({elapsed:.1f}s)\"\n",
        "            )\n",
        "\n",
        "\n",
        "            if val_loss < best_val_loss and val_hitrate > best_hitrate:\n",
        "                best_val_loss = val_loss\n",
        "                best_hitrate = val_hitrate\n",
        "                torch.save(model.state_dict(), model_path)\n",
        "                print(\"üíæ Model improved (loss ‚Üì and hitrate ‚Üë), saved.\")\n",
        "\n",
        "            if early_stopper.step(-val_loss):\n",
        "                print(\"‚õî Early stopping triggered.\")\n",
        "                break\n",
        "\n",
        "        # Plot metrics\n",
        "        epochs = list(range(1, len(train_losses) + 1))\n",
        "\n",
        "        # Plot Loss Curve\n",
        "        plt.figure()\n",
        "        plt.plot(epochs, train_losses, label=\"Train Loss\")\n",
        "        plt.plot(epochs, val_losses, label=\"Val Loss\")\n",
        "        plt.xlabel(\"Epoch\")\n",
        "        plt.ylabel(\"Loss\")\n",
        "        plt.title(\"Training & Validation Loss\")\n",
        "        plt.legend()\n",
        "        plt.grid(True)\n",
        "        plt.savefig(os.path.join(MODEL_DIR, \"loss_curve.png\"))\n",
        "        plt.close()\n",
        "\n",
        "        # Plot HitRate@3\n",
        "        plt.figure()\n",
        "        plt.plot(epochs, val_hitrates, label=\"Val HitRate@3\", color=\"green\")\n",
        "        plt.xlabel(\"Epoch\")\n",
        "        plt.ylabel(\"HitRate@3\")\n",
        "        plt.title(\"Validation HitRate@3\")\n",
        "        plt.legend()\n",
        "        plt.grid(True)\n",
        "        plt.savefig(os.path.join(MODEL_DIR, \"hitrate_curve.png\"))\n",
        "        plt.close()\n",
        "\n",
        "        # Plot Learning Rate\n",
        "        plt.figure()\n",
        "        plt.plot(epochs, learning_rates, label=\"Learning Rate\", color=\"orange\")\n",
        "        plt.xlabel(\"Epoch\")\n",
        "        plt.ylabel(\"LR\")\n",
        "        plt.title(\"Learning Rate Schedule\")\n",
        "        plt.legend()\n",
        "        plt.grid(True)\n",
        "        plt.savefig(os.path.join(MODEL_DIR, \"lr_curve.png\"))\n",
        "        plt.close()\n",
        "\n",
        "        # Plot NDCG@3\n",
        "        plt.figure()\n",
        "        plt.plot(epochs, val_ndcgs, label=\"Val NDCG@3\", color=\"purple\")\n",
        "        plt.xlabel(\"Epoch\")\n",
        "        plt.ylabel(\"NDCG@3\")\n",
        "        plt.title(\"Validation NDCG@3\")\n",
        "        plt.legend()\n",
        "        plt.grid(True)\n",
        "        plt.savefig(os.path.join(MODEL_DIR, \"ndcg_curve.png\"))\n",
        "        plt.close()\n",
        "\n",
        "        # Plot MAP@3\n",
        "        plt.figure()\n",
        "        plt.plot(epochs, val_maps, label=\"Val MAP@3\", color=\"red\")\n",
        "        plt.xlabel(\"Epoch\")\n",
        "        plt.ylabel(\"MAP@3\")\n",
        "        plt.title(\"Validation MAP@3\")\n",
        "        plt.legend()\n",
        "        plt.grid(True)\n",
        "        plt.savefig(os.path.join(MODEL_DIR, \"map_curve.png\"))\n",
        "        plt.close()\n",
        "\n",
        "        print(\"üìä Saved metric plots to model/\")\n",
        "\n",
        "        # Predict test set\n",
        "        model.load_state_dict(torch.load(model_path))\n",
        "        model.eval()\n",
        "\n",
        "        val_ids = X_va[\"Id\"]\n",
        "        val_rankers = groups_va[\"ranker_id\"]\n",
        "        val_labels = y_va\n",
        "\n",
        "        all_val_scores = []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for x_cat, x_num, _, lengths in tqdm(val_loader, desc=\"Predicting validation set\"):\n",
        "                x_num = x_num.to(device)\n",
        "                x_cat = {k: v.to(device) for k, v in x_cat.items()}\n",
        "                scores = model(x_cat, x_num)\n",
        "\n",
        "                for i in range(scores.size(0)):\n",
        "                    l = lengths[i]\n",
        "                    all_val_scores.append(scores[i, :l].cpu().numpy())\n",
        "\n",
        "        all_val_scores = np.concatenate(all_val_scores)\n",
        "\n",
        "        assert len(all_val_scores) == X_va.shape[0], \\\n",
        "            f\"Mismatch: {len(all_val_scores)} scores vs {X_va.shape[0]} rows\"\n",
        "\n",
        "        val_df = X_va.with_columns([\n",
        "            pl.Series(\"Id\", val_ids),\n",
        "            pl.Series(\"ranker_id\", val_rankers),\n",
        "            pl.Series(\"score\", all_val_scores),\n",
        "            pl.Series(\"label\", val_labels)\n",
        "        ])\n",
        "\n",
        "        val_df = val_df.with_columns(\n",
        "            pl.col(\"score\")\n",
        "            .rank(method=\"ordinal\", descending=True)\n",
        "            .over(\"ranker_id\")\n",
        "            .cast(pl.Int32)\n",
        "            .alias(\"selected\")\n",
        "        )\n",
        "\n",
        "        val_save_path = os.path.join(MODEL_DIR, \"validation_preds_dl_full.csv\")\n",
        "        val_df.write_csv(val_save_path)\n",
        "        print(f\"‚úÖ Saved full validation predictions (with features) to {val_save_path}\")\n",
        "\n",
        "        all_scores = []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for x_cat, x_num, _, lengths in tqdm(test_loader, desc=\"Predicting test set\"):\n",
        "                x_num = x_num.to(device)\n",
        "                x_cat = {k: v.to(device) for k, v in x_cat.items()}\n",
        "                scores = model(x_cat, x_num)\n",
        "\n",
        "                for i in range(scores.size(0)):\n",
        "                    l = lengths[i]\n",
        "                    all_scores.append(scores[i, :l].cpu().numpy())\n",
        "\n",
        "        all_scores = np.concatenate(all_scores)\n",
        "\n",
        "        assert len(all_scores) == X_te.shape[0], \\\n",
        "            f\"Mismatch: {len(all_scores)} scores vs {X_te.shape[0]} rows in X_te\"\n",
        "\n",
        "        submission_df = pl.DataFrame({\n",
        "            \"Id\": test_ids,\n",
        "            \"ranker_id\": test_rankers,\n",
        "            \"score\": all_scores\n",
        "        })\n",
        "\n",
        "        submission = (\n",
        "            submission_df\n",
        "            .with_columns(\n",
        "                pl.col(\"score\")\n",
        "                .rank(method=\"ordinal\", descending=True)\n",
        "                .over(\"ranker_id\")\n",
        "                .cast(pl.Int32)\n",
        "                .alias(\"selected\")\n",
        "            )\n",
        "            .select([\"Id\", \"ranker_id\", \"score\", \"selected\"])\n",
        "        )\n",
        "\n",
        "        submission_path = os.path.join(SUBMIT_DIR, \"submission_dl_ranker.csv\")\n",
        "        submission.write_csv(submission_path)\n",
        "        print(f\"‚úÖ Submission saved to {submission_path}\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2YCbYP1AZg2p",
        "outputId": "43de5519-620e-423d-da63-372744e251b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting deeprec_validate.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile deeprec_validate.py\n",
        "import os\n",
        "import time\n",
        "import random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F_torch\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import defaultdict\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "import polars as pl\n",
        "from tqdm import tqdm\n",
        "from src.feature import feature_engineering, feature_selection\n",
        "from transformers import get_scheduler\n",
        "from collections import Counter\n",
        "\n",
        "class RankDataset(Dataset):\n",
        "    def __init__(\n",
        "        self,\n",
        "        X: pl.DataFrame,\n",
        "        y: pl.Series,\n",
        "        groups: pl.DataFrame,\n",
        "        cat_features: list[str],\n",
        "        num_features: list[str],\n",
        "    ):\n",
        "        self.cat_features = cat_features\n",
        "        self.num_features = num_features\n",
        "        self.X_cat = {c: X[c].to_numpy() for c in cat_features}\n",
        "        self.X_num = X[self.num_features].to_numpy()\n",
        "        self.y = y.to_numpy()\n",
        "        self.groups = groups[\"ranker_id\"].to_numpy()\n",
        "\n",
        "        self.group_to_indices = defaultdict(list)\n",
        "        for i, g in enumerate(self.groups):\n",
        "            self.group_to_indices[g].append(i)\n",
        "        self.group_keys = list(self.group_to_indices.keys())\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.group_keys)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        g = self.group_keys[idx]\n",
        "        inds = self.group_to_indices[g]\n",
        "        length = len(inds)\n",
        "\n",
        "        x_cat = {\n",
        "            c: torch.LongTensor([\n",
        "                self.X_cat[c][i] if self.X_cat[c][i] >= 0 else 0 for i in inds\n",
        "            ])\n",
        "            for c in self.cat_features\n",
        "        }\n",
        "\n",
        "        x_num = torch.FloatTensor(self.X_num[inds])\n",
        "        y = torch.FloatTensor(self.y[inds]).reshape(-1)\n",
        "\n",
        "        return x_cat, x_num, y, length\n",
        "\n",
        "def collate_fn(batch):\n",
        "    batch = [b for b in batch if b[3] >= 2]\n",
        "    if len(batch) == 0:\n",
        "        return None\n",
        "\n",
        "    batch_size = len(batch)\n",
        "    lengths = [b[3] for b in batch]\n",
        "    max_len = max(lengths)\n",
        "\n",
        "    padded_x_cat = {key: [] for key in batch[0][0].keys()}\n",
        "    padded_x_num = []\n",
        "    padded_y = []\n",
        "\n",
        "    num_dim = batch[0][1].shape[1]\n",
        "\n",
        "    for x_cat, x_num, y, length in batch:\n",
        "        pad_len = max_len - length\n",
        "\n",
        "        for key in padded_x_cat:\n",
        "            val = x_cat[key]\n",
        "            if pad_len > 0:\n",
        "                val = torch.cat([val, torch.zeros(pad_len, dtype=torch.long)])\n",
        "            padded_x_cat[key].append(val)\n",
        "\n",
        "        if pad_len > 0:\n",
        "            x_num = torch.cat([x_num, torch.zeros(pad_len, num_dim)])\n",
        "            y = torch.cat([y, torch.zeros(pad_len)])\n",
        "\n",
        "        padded_x_num.append(x_num)\n",
        "        padded_y.append(y)\n",
        "\n",
        "    padded_x_cat = {k: torch.stack(v) for k, v in padded_x_cat.items()}\n",
        "    padded_x_num = torch.stack(padded_x_num)\n",
        "    padded_y = torch.stack(padded_y)\n",
        "    lengths = torch.tensor(lengths, dtype=torch.long)\n",
        "\n",
        "    return padded_x_cat, padded_x_num, padded_y, lengths\n",
        "\n",
        "\n",
        "class SelfAttentionLayer(nn.Module):\n",
        "    def __init__(self, emb_dim, n_heads=4):\n",
        "        super().__init__()\n",
        "        self.attention = nn.MultiheadAttention(embed_dim=emb_dim, num_heads=n_heads, batch_first=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: [B, F, D]\n",
        "        attn_output, _ = self.attention(x, x, x)\n",
        "        return attn_output.mean(dim=1)  # [B, D]\n",
        "\n",
        "\n",
        "class FiBiDLRanker(nn.Module):\n",
        "    def __init__(self, cat_dims, num_numeric_feats, emb_dim=64, hidden=[512, 256, 128, 64], use_senet=True):\n",
        "        super().__init__()\n",
        "        self.cat_fields = list(cat_dims.keys())\n",
        "        self.emb_dim = emb_dim\n",
        "        self.num_fields = len(self.cat_fields)\n",
        "        self.use_senet = use_senet\n",
        "\n",
        "        # Embedding layers\n",
        "        self.embeddings = nn.ModuleDict({\n",
        "            f: nn.Embedding(cat_dims[f], emb_dim, padding_idx=0) for f in self.cat_fields\n",
        "        })\n",
        "        self.linear_cat = nn.ModuleDict({\n",
        "            f: nn.Embedding(cat_dims[f], 1, padding_idx=0) for f in self.cat_fields\n",
        "        })\n",
        "        self.linear_num = nn.Linear(num_numeric_feats, 1)\n",
        "\n",
        "        # Init weights\n",
        "        for emb in list(self.embeddings.values()) + list(self.linear_cat.values()):\n",
        "            nn.init.xavier_uniform_(emb.weight)\n",
        "        nn.init.xavier_uniform_(self.linear_num.weight)\n",
        "\n",
        "        # SENet (op»õional)\n",
        "        if self.use_senet:\n",
        "            self.se_fc1 = nn.Linear(self.num_fields * emb_dim, self.num_fields * emb_dim // 4)\n",
        "            self.se_ln1 = nn.LayerNorm(self.num_fields * emb_dim // 4)\n",
        "            self.se_dropout = nn.Dropout(0.1)\n",
        "            self.se_fc2 = nn.Linear(self.num_fields * emb_dim // 4, self.num_fields * emb_dim)\n",
        "\n",
        "        # üîÅ Self-Attention layer\n",
        "        self.attention = SelfAttentionLayer(emb_dim, n_heads=4)\n",
        "\n",
        "        # MLP\n",
        "        input_dim = emb_dim + num_numeric_feats\n",
        "        layers = []\n",
        "        for h in hidden:\n",
        "            layers.append(nn.Linear(input_dim, h))\n",
        "            layers.append(nn.LayerNorm(h))\n",
        "            layers.append(nn.ReLU())\n",
        "            layers.append(nn.Dropout(0.2))\n",
        "            input_dim = h\n",
        "        self.mlp = nn.Sequential(*layers)\n",
        "        self.output = nn.Linear(input_dim, 1)\n",
        "\n",
        "    def senet(self, embs):\n",
        "        B, F, D = embs.shape\n",
        "        z = embs.view(B, -1)\n",
        "        a = self.se_fc1(z)\n",
        "        a = self.se_ln1(a)\n",
        "        a = F_torch.relu(a)\n",
        "        a = self.se_dropout(a)\n",
        "        s = torch.sigmoid(self.se_fc2(a)).view(B, F, D)\n",
        "        return embs * s\n",
        "\n",
        "    def forward(self, x_cat, x_num):\n",
        "        B, G = x_num.shape[:2]\n",
        "        F, D = self.num_fields, self.emb_dim\n",
        "\n",
        "        embs = torch.stack([self.embeddings[f](x_cat[f]) for f in self.cat_fields], dim=2)  # [B, G, F, D]\n",
        "        linear_cat_sum = torch.stack([\n",
        "            self.linear_cat[f](x_cat[f]).squeeze(-1) for f in self.cat_fields\n",
        "        ], dim=0).sum(dim=0)  # [B, G]\n",
        "        linear_num_out = self.linear_num(x_num).squeeze(-1)\n",
        "        linear_out = linear_cat_sum + linear_num_out\n",
        "\n",
        "        embs = embs.view(B * G, F, D)\n",
        "        if self.use_senet:\n",
        "            embs = self.senet(embs)\n",
        "\n",
        "        bi = self.attention(embs)  # [B*G, D]\n",
        "        x_num_flat = x_num.view(B * G, -1)\n",
        "        deep_input = torch.cat([bi, x_num_flat], dim=1)\n",
        "        deep_out = self.mlp(deep_input)\n",
        "        scores = self.output(deep_out).view(B, G)\n",
        "\n",
        "        return scores + linear_out\n",
        "\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "def listmle_loss(scores, labels, lengths):\n",
        "    batch_size = scores.size(0)\n",
        "    total_loss = torch.tensor(0.0, device=scores.device, requires_grad=True)\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "\n",
        "        _, idx = torch.sort(y, descending=True)\n",
        "        s_sorted = s[idx]\n",
        "\n",
        "        parts = (\n",
        "            torch.logsumexp(s_sorted.unsqueeze(0).expand(l, -1).triu(diagonal=0), dim=1)\n",
        "            - s_sorted\n",
        "        )\n",
        "\n",
        "        total_loss = total_loss + parts.sum()\n",
        "\n",
        "    return total_loss / batch_size\n",
        "\"\"\"\n",
        "\n",
        "def hitrate_at_k(scores, labels, lengths, k=3, min_group_size=10):\n",
        "    batch_size = scores.size(0)\n",
        "    hits = 0\n",
        "    valid_count = 0\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        if l < min_group_size:\n",
        "            continue\n",
        "        length = min(l, k)\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "        _, topk_idx = torch.topk(s, length)\n",
        "        topk_labels = y[topk_idx]\n",
        "        hits += (topk_labels > 0).any().float()\n",
        "        valid_count += 1\n",
        "    return hits / valid_count if valid_count > 0 else torch.tensor(0.0, device=scores.device)\n",
        "\n",
        "\n",
        "def ndcg_at_k(scores, labels, lengths, k=3, min_group_size=10):\n",
        "    batch_size = scores.size(0)\n",
        "    total_ndcg = 0.0\n",
        "    valid_count = 0\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        if l < min_group_size:\n",
        "            continue\n",
        "\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "\n",
        "        _, idx_pred = torch.topk(s, min(k, l))\n",
        "        _, idx_ideal = torch.topk(y, min(k, l))\n",
        "\n",
        "        dcg = (y[idx_pred] / torch.log2(torch.arange(2, 2 + len(idx_pred), device=y.device).float())).sum()\n",
        "        idcg = (y[idx_ideal] / torch.log2(torch.arange(2, 2 + len(idx_ideal), device=y.device).float())).sum()\n",
        "\n",
        "        ndcg = dcg / idcg if idcg > 0 else 0.0\n",
        "        total_ndcg += ndcg\n",
        "        valid_count += 1\n",
        "\n",
        "    return total_ndcg / valid_count if valid_count > 0 else torch.tensor(0.0, device=scores.device)\n",
        "\n",
        "\n",
        "def map_at_k(scores, labels, lengths, k=3, min_group_size=10):\n",
        "    batch_size = scores.size(0)\n",
        "    total_ap = 0.0\n",
        "    valid_count = 0\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        if l < min_group_size:\n",
        "            continue\n",
        "\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "\n",
        "        _, idx_pred = torch.topk(s, min(k, l))\n",
        "        y_true = y[idx_pred] > 0\n",
        "\n",
        "        if y_true.sum() == 0:\n",
        "            continue\n",
        "\n",
        "        precisions = [(y_true[:j+1].float().sum() / (j+1)) for j in range(len(y_true)) if y_true[j]]\n",
        "        ap = torch.stack(precisions).mean()\n",
        "        total_ap += ap\n",
        "        valid_count += 1\n",
        "\n",
        "    return total_ap / valid_count if valid_count > 0 else torch.tensor(0.0, device=scores.device)\n",
        "\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "def listnet_loss(scores, labels, lengths):\n",
        "    batch_size = scores.size(0)\n",
        "    total_loss = 0.0\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "\n",
        "        s_softmax = torch.nn.functional.log_softmax(s, dim=0)\n",
        "        y_softmax = torch.nn.functional.softmax(y, dim=0)\n",
        "\n",
        "        loss = -torch.sum(y_softmax * s_softmax)\n",
        "        total_loss += loss\n",
        "\n",
        "    return total_loss / batch_size\n",
        "\"\"\"\n",
        "\n",
        "def ranknet_loss(scores, labels, lengths):\n",
        "    batch_size = scores.size(0)\n",
        "    total_loss = 0.0\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "\n",
        "        diff_scores = s.unsqueeze(1) - s.unsqueeze(0)\n",
        "        rel = y.unsqueeze(1) > y.unsqueeze(0)\n",
        "        label_diff = rel.float()\n",
        "\n",
        "        log_sigmoid = torch.nn.functional.logsigmoid(diff_scores)\n",
        "        pair_loss = -label_diff * log_sigmoid\n",
        "\n",
        "        total_loss += pair_loss.sum()\n",
        "\n",
        "    return total_loss / batch_size\n",
        "\n",
        "def xranknet_loss(scores, labels, lengths, temperature=1.0, margin=0.2, focus_topk=3):\n",
        "    \"\"\"\n",
        "    xRankNet with emphasis on top-K items (based on labels, not scores).\n",
        "    \"\"\"\n",
        "    batch_size = scores.size(0)\n",
        "    total_loss = 0.0\n",
        "    total_pairs = 0\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        if l < 2:\n",
        "            continue\n",
        "\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "\n",
        "        # Top-K mask based on ground truth labels\n",
        "        topk = min(focus_topk, l)\n",
        "        _, topk_idx = torch.topk(y, topk)\n",
        "        topk_mask = torch.zeros_like(y, dtype=torch.bool)\n",
        "        topk_mask[topk_idx] = True\n",
        "\n",
        "        # Create pairwise difference matrices\n",
        "        score_diff = s.unsqueeze(1) - s.unsqueeze(0)\n",
        "        label_diff = y.unsqueeze(1) - y.unsqueeze(0)\n",
        "\n",
        "        # valid pair: y_i > y_j and at least one of i, j is in top-K\n",
        "        valid_pairs = (label_diff > 0) & (\n",
        "            topk_mask.unsqueeze(1) | topk_mask.unsqueeze(0)\n",
        "        )\n",
        "\n",
        "        if valid_pairs.sum() == 0:\n",
        "            continue\n",
        "\n",
        "        importance = (label_diff.abs() * valid_pairs).float()\n",
        "\n",
        "        if margin > 0.0:\n",
        "            score_diff = score_diff - margin\n",
        "\n",
        "        score_diff = score_diff / temperature\n",
        "        pairwise_loss = -F_torch.logsigmoid(score_diff) * importance\n",
        "\n",
        "        total_loss += pairwise_loss.sum()\n",
        "        total_pairs += importance.sum()\n",
        "\n",
        "    if total_pairs == 0:\n",
        "        return torch.tensor(0.0, device=scores.device, requires_grad=True)\n",
        "\n",
        "    return total_loss / total_pairs\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "def bpr_loss(scores, labels, lengths):\n",
        "    batch_size = scores.size(0)\n",
        "    total_loss = 0.0\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "\n",
        "        pos_mask = y > 0\n",
        "        neg_mask = y <= 0\n",
        "\n",
        "        pos_scores = s[pos_mask]\n",
        "        neg_scores = s[neg_mask]\n",
        "\n",
        "        if len(pos_scores) == 0 or len(neg_scores) == 0:\n",
        "            continue\n",
        "\n",
        "        pair_diff = pos_scores.unsqueeze(1) - neg_scores.unsqueeze(0)\n",
        "        loss = -F.logsigmoid(pair_diff).mean()\n",
        "        total_loss += loss\n",
        "\n",
        "    return total_loss / batch_size\n",
        "\"\"\"\n",
        "\n",
        "\"\"\"\n",
        "def lambdarank_loss(scores, labels, lengths, eps=1e-10):\n",
        "    batch_size = scores.size(0)\n",
        "    total_loss = 0.0\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "\n",
        "        if l < 2:\n",
        "            continue\n",
        "\n",
        "        _, rank_order = torch.sort(s, descending=True)\n",
        "        ideal_order = torch.sort(y, descending=True).indices\n",
        "\n",
        "        gain = 2 ** y - 1\n",
        "        discount = torch.log2(torch.arange(2, l + 2, device=y.device).float())\n",
        "\n",
        "        ideal_dcg = (gain[ideal_order] / discount).sum()\n",
        "        if ideal_dcg < eps:\n",
        "            continue\n",
        "\n",
        "        delta_ndcg = torch.zeros((l, l), device=y.device)\n",
        "\n",
        "        for i_idx in range(l):\n",
        "            for j_idx in range(l):\n",
        "                if y[i_idx] > y[j_idx]:\n",
        "                    change = (\n",
        "                        (1.0 / torch.log2(rank_order[i_idx] + 2.0))\n",
        "                        - (1.0 / torch.log2(rank_order[j_idx] + 2.0))\n",
        "                    ).abs()\n",
        "                    delta = (2 ** y[i_idx] - 2 ** y[j_idx]).abs() * change\n",
        "                    delta_ndcg[i_idx, j_idx] = delta / ideal_dcg\n",
        "\n",
        "        score_diffs = s.unsqueeze(1) - s.unsqueeze(0)\n",
        "        lambdas = -F.logsigmoid(score_diffs) * delta_ndcg\n",
        "        total_loss += lambdas.sum()\n",
        "\n",
        "    return total_loss / batch_size\n",
        "\"\"\"\n",
        "\n",
        "def train_one_epoch(model, loader, optimizer, device, scheduler):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "    valid_batches = 0\n",
        "\n",
        "    for batch in tqdm(loader, desc=\"Training\", leave=False):\n",
        "        if batch is None:\n",
        "            continue\n",
        "\n",
        "        x_cat, x_num, y, lengths = batch\n",
        "\n",
        "        x_num, y = x_num.to(device), y.to(device)\n",
        "        lengths = lengths.to(device)\n",
        "        x_cat = {k: v.to(device) for k, v in x_cat.items()}\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        scores = model(x_cat, x_num)\n",
        "        loss = xranknet_loss(scores, y, lengths, temperature=1.0, margin=0.2, focus_topk=3)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        valid_batches += 1\n",
        "\n",
        "    return total_loss / valid_batches if valid_batches > 0 else float(\"inf\")\n",
        "\n",
        "\n",
        "\n",
        "def validate(model, loader, device, min_group_size=10):\n",
        "    model.eval()\n",
        "    total_hitrate = 0\n",
        "    total_ndcg = 0\n",
        "    total_map = 0\n",
        "    total_loss = 0\n",
        "    count = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for x_cat, x_num, y, lengths in tqdm(loader, desc=\"Validating\", leave=False):\n",
        "            x_num, y = x_num.to(device), y.to(device)\n",
        "            lengths = torch.tensor(lengths).to(device)\n",
        "            x_cat = {k: v.to(device) for k, v in x_cat.items()}\n",
        "\n",
        "            scores = model(x_cat, x_num)\n",
        "\n",
        "            hitrate = hitrate_at_k(scores, y, lengths, k=3, min_group_size=min_group_size)\n",
        "            ndcg = ndcg_at_k(scores, y, lengths, k=3, min_group_size=min_group_size)\n",
        "            map3 = map_at_k(scores, y, lengths, k=3, min_group_size=min_group_size)\n",
        "            loss = xranknet_loss(scores, y, lengths, temperature=1.0, margin=0.2, focus_topk=3)\n",
        "\n",
        "            batch_size = scores.size(0)\n",
        "            total_hitrate += hitrate * batch_size\n",
        "            total_ndcg += ndcg * batch_size\n",
        "            total_map += map3 * batch_size\n",
        "            total_loss += loss.item() * batch_size\n",
        "            count += batch_size\n",
        "\n",
        "    return total_loss / count, total_hitrate / count, total_ndcg / count, total_map / count\n",
        "\n",
        "\n",
        "def build_cat_dims(X, cat_features):\n",
        "    cat_dims = {}\n",
        "    for c in cat_features:\n",
        "        max_val = X[c].max()\n",
        "        if max_val < 0:\n",
        "            max_val = 0\n",
        "        cat_dims[c] = max_val + 1\n",
        "    return cat_dims\n",
        "\n",
        "\n",
        "def normalize_numeric_features(X, numeric_features, train_mask):\n",
        "    for col in numeric_features:\n",
        "        values = X[col].to_numpy()\n",
        "        train_vals = values[train_mask]\n",
        "        mean = train_vals.mean()\n",
        "        std = train_vals.std() if train_vals.std() > 0 else 1.0\n",
        "        norm_vals = (values - mean) / std\n",
        "        X = X.with_columns(pl.Series(col, norm_vals).alias(col))\n",
        "    return X\n",
        "\n",
        "\n",
        "def load_or_prepare_data(\n",
        "    data_dir,\n",
        "    train_file=\"train.parquet\",\n",
        "    test_file=\"test.parquet\",\n",
        "    cache_file=\"feature_engineered_val.parquet\",\n",
        "):\n",
        "    cache_path = os.path.join(data_dir, cache_file)\n",
        "\n",
        "    if os.path.exists(cache_path):\n",
        "        print(f\"Loading cached feature-engineered data from {cache_path} ...\")\n",
        "        df = pl.read_parquet(cache_path)\n",
        "\n",
        "        test = pl.read_parquet(os.path.join(data_dir, test_file)).drop(\"__index_level_0__\")\n",
        "        test_ids = test[\"Id\"]\n",
        "        test_rankers = test[\"ranker_id\"]\n",
        "    else:\n",
        "        print(\"Cached file not found, processing raw data ...\")\n",
        "\n",
        "        train = pl.read_parquet(os.path.join(data_dir, train_file)).drop(\"__index_level_0__\")\n",
        "        test = (\n",
        "            pl.read_parquet(os.path.join(data_dir, test_file))\n",
        "            .drop(\"__index_level_0__\")\n",
        "            .with_columns(pl.lit(0, dtype=pl.Int64).alias(\"selected\"))\n",
        "        )\n",
        "\n",
        "        test_ids = test[\"Id\"]\n",
        "        test_rankers = test[\"ranker_id\"]\n",
        "\n",
        "        df = pl.concat((train, test))\n",
        "        df = feature_engineering(df, full=True)\n",
        "\n",
        "        df = df.with_columns(\n",
        "            [pl.col(c).fill_null(0) for c in df.select(pl.selectors.numeric()).columns] +\n",
        "            [pl.col(c).fill_null(\"missing\") for c in df.select(pl.selectors.string()).columns]\n",
        "        )\n",
        "\n",
        "        os.makedirs(data_dir, exist_ok=True)\n",
        "        df.write_parquet(cache_path)\n",
        "        print(f\"Saved feature-engineered data to {cache_path}\")\n",
        "\n",
        "    return df, test_ids, test_rankers\n",
        "\n",
        "\n",
        "def prepare_data(data_dir):\n",
        "    df, test_ids, test_rankers = load_or_prepare_data(data_dir)\n",
        "\n",
        "    id_column = df[\"Id\"]\n",
        "    X, y, groups, cat_features, num_features = feature_selection(df)\n",
        "\n",
        "    X = X.with_columns(pl.Series(\"Id\", id_column[:X.shape[0]]))\n",
        "\n",
        "    X = X.with_columns(\n",
        "        [\n",
        "            (pl.col(c).rank(\"dense\") - 1).fill_null(-1).cast(pl.Int32)\n",
        "            for c in cat_features\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    train_size = 18145372\n",
        "    train_mask = np.arange(X.height) < train_size\n",
        "    X = normalize_numeric_features(X, num_features, train_mask)\n",
        "\n",
        "    return X, y, groups, cat_features, num_features, train_size, test_ids, test_rankers\n",
        "\n",
        "\n",
        "class EarlyStopping:\n",
        "    def __init__(self, patience=3, min_delta=0.00005):\n",
        "        self.patience = patience\n",
        "        self.min_delta = min_delta\n",
        "        self.best = float(\"-inf\")\n",
        "        self.counter = 0\n",
        "\n",
        "    def step(self, metric):\n",
        "        if metric > self.best + self.min_delta:\n",
        "            self.best = metric\n",
        "            self.counter = 0\n",
        "        else:\n",
        "            self.counter += 1\n",
        "        return self.counter >= self.patience\n",
        "\n",
        "\n",
        "def plot_group_size_distribution(dataset, save_path=None):\n",
        "    group_sizes = [len(v) for v in dataset.group_to_indices.values()]\n",
        "    plt.figure()\n",
        "    plt.hist(group_sizes, bins=100, log=True)\n",
        "    plt.xlabel(\"Group size (number of items per ranker_id)\")\n",
        "    plt.ylabel(\"Frequency (log scale)\")\n",
        "    plt.title(\"Distribution of Group Sizes\")\n",
        "    plt.grid(True)\n",
        "    if save_path:\n",
        "        plt.savefig(save_path)\n",
        "    else:\n",
        "        plt.show()\n",
        "    plt.close()\n",
        "\n",
        "\n",
        "def main():\n",
        "    DATA_DIR = \"./data\"\n",
        "    SUBMIT_DIR = \"submission\"\n",
        "    os.makedirs(SUBMIT_DIR, exist_ok=True)\n",
        "\n",
        "    learning_rates_to_try = [1e-3, 7e-4]\n",
        "\n",
        "    for lr in learning_rates_to_try:\n",
        "        run_name = f\"lr_{lr:.0e}\".replace(\"-\", \"\")\n",
        "        MODEL_DIR = f\"model_{run_name}\"\n",
        "        os.makedirs(MODEL_DIR, exist_ok=True)\n",
        "\n",
        "        print(f\"\\n\\nüöÄ Starting training with learning rate = {lr}\\nSaved to: {MODEL_DIR}\")\n",
        "\n",
        "        best_val_loss = float(\"inf\")\n",
        "        best_hitrate = 0.0\n",
        "        model_path = os.path.join(MODEL_DIR, \"best_dl_ranker.pt\")\n",
        "\n",
        "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "        train_losses = []\n",
        "        val_losses = []\n",
        "        val_hitrates = []\n",
        "        val_ndcgs = []\n",
        "        val_maps = []\n",
        "        learning_rates = []\n",
        "\n",
        "        os.makedirs(MODEL_DIR, exist_ok=True)\n",
        "        os.makedirs(SUBMIT_DIR, exist_ok=True)\n",
        "\n",
        "        early_stopper = EarlyStopping(patience=3, min_delta=0.00005)\n",
        "\n",
        "        X, y, groups, cat_features, num_features, train_size, test_ids, test_rankers = prepare_data(DATA_DIR)\n",
        "\n",
        "        # Fill missing values\n",
        "        float_cols = [c for c, t in zip(X.columns, X.dtypes) if t == pl.Float64]\n",
        "        for col in float_cols:\n",
        "            X = X.with_columns(\n",
        "                pl.when(pl.col(col).is_nan()).then(0).otherwise(pl.col(col)).alias(col)\n",
        "            )\n",
        "\n",
        "        n1 = 16487352\n",
        "        # n1 = 17487300\n",
        "        n2 = train_size\n",
        "\n",
        "        X_tr, X_va, X_te = X[:n1], X[n1:n2], X[n2:]\n",
        "        y_tr, y_va, y_te = y[:n1], y[n1:n2], y[n2:]\n",
        "        groups_tr, groups_va, groups_te = groups[:n1], groups[n1:n2], groups[n2:]\n",
        "\n",
        "        # Inspect group sizes in validation set\n",
        "        val_rankers = groups_va[\"ranker_id\"].to_numpy()\n",
        "        val_group_counts = Counter(val_rankers)\n",
        "\n",
        "        print(\"\\nüìã Validation group statistics:\")\n",
        "        # Save detailed group info to file\n",
        "        group_info_path = os.path.join(MODEL_DIR, \"validation_groups_info.txt\")\n",
        "        with open(group_info_path, \"w\") as f:\n",
        "            f.write(f\"Total groups: {len(val_group_counts)}\\n\\n\")\n",
        "            f.write(\"GroupID\\tSize\\tStartIdx\\tEndIdx\\n\")\n",
        "\n",
        "            group_to_rows = defaultdict(list)\n",
        "            for i, g in enumerate(val_rankers):\n",
        "                group_to_rows[g].append(i)\n",
        "\n",
        "            for group_id, indices in sorted(group_to_rows.items()):\n",
        "                start_idx = indices[0]\n",
        "                end_idx = indices[-1]\n",
        "                size = len(indices)\n",
        "                f.write(f\"{group_id}\\t{size}\\t{start_idx}\\t{end_idx}\\n\")\n",
        "\n",
        "        print(f\"üìÅ Saved validation group info to {group_info_path}\")\n",
        "\n",
        "\n",
        "        cat_dims = build_cat_dims(X, cat_features)\n",
        "        num_numeric_feats = len(num_features)\n",
        "\n",
        "        train_dataset = RankDataset(X_tr, y_tr, groups_tr, cat_features, num_features)\n",
        "        val_dataset = RankDataset(X_va, y_va, groups_va, cat_features, num_features)\n",
        "        test_dataset = RankDataset(X_te, y_te, groups_te, cat_features, num_features)\n",
        "\n",
        "        plot_group_size_distribution(train_dataset, save_path=os.path.join(MODEL_DIR, \"group_sizes.png\"))\n",
        "        print(\"üìä Group size distribution saved.\")\n",
        "\n",
        "        train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True, collate_fn=collate_fn)\n",
        "        val_loader = DataLoader(val_dataset, batch_size=4, shuffle=False, collate_fn=collate_fn)\n",
        "        test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False, collate_fn=collate_fn)\n",
        "\n",
        "        print(\"‚úÖ Data loaders created.\")\n",
        "\n",
        "        num_epochs = 10\n",
        "        num_training_steps = num_epochs * len(train_loader)\n",
        "        num_warmup_steps = int(0.1 * num_training_steps)\n",
        "\n",
        "        model = FiBiDLRanker(\n",
        "            cat_dims=cat_dims,\n",
        "            num_numeric_feats=num_numeric_feats,\n",
        "            emb_dim=16,\n",
        "            hidden=[256, 128]\n",
        "        ).to(device)\n",
        "\n",
        "        optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=0.01)\n",
        "\n",
        "        scheduler = get_scheduler(\n",
        "            \"linear\",\n",
        "            optimizer=optimizer,\n",
        "            num_warmup_steps=num_warmup_steps,\n",
        "            num_training_steps=num_training_steps\n",
        "        )\n",
        "\n",
        "        best_hitrate = 0\n",
        "        for epoch in range(num_epochs):\n",
        "            print(f\"\\n--- Epoch {epoch+1}/{num_epochs} ---\")\n",
        "            start_time = time.time()\n",
        "\n",
        "            train_loss = train_one_epoch(model, train_loader, optimizer, device, scheduler)\n",
        "            val_loss, val_hitrate, val_ndcg, val_map = validate(model, val_loader, device, min_group_size=10)\n",
        "\n",
        "            train_losses.append(train_loss)\n",
        "            val_losses.append(val_loss)\n",
        "            val_hitrates.append(val_hitrate.item())\n",
        "            val_ndcgs.append(val_ndcg.item())\n",
        "            val_maps.append(val_map.item())\n",
        "\n",
        "            current_lr = scheduler.get_last_lr()\n",
        "            learning_rates.append(current_lr[0])\n",
        "\n",
        "            elapsed = time.time() - start_time\n",
        "            print(\n",
        "                f\"Epoch {epoch+1}: \"\n",
        "                f\"Train Loss={train_loss:.4f}, \"\n",
        "                f\"Val Loss={val_loss:.4f}, \"\n",
        "                f\"HitRate@3={val_hitrate:.4f}, \"\n",
        "                f\"NDCG@3={val_ndcg:.4f}, \"\n",
        "                f\"MAP@3={val_map:.4f}, \"\n",
        "                f\"LR={current_lr[0]:.6f} \"\n",
        "                f\"({elapsed:.1f}s)\"\n",
        "            )\n",
        "\n",
        "\n",
        "            if val_loss < best_val_loss and val_hitrate > best_hitrate:\n",
        "                best_val_loss = val_loss\n",
        "                best_hitrate = val_hitrate\n",
        "                torch.save(model.state_dict(), model_path)\n",
        "                print(\"üíæ Model improved (loss ‚Üì and hitrate ‚Üë), saved.\")\n",
        "\n",
        "            if early_stopper.step(-val_loss):\n",
        "                print(\"‚õî Early stopping triggered.\")\n",
        "                break\n",
        "\n",
        "        # Plot metrics\n",
        "        epochs = list(range(1, len(train_losses) + 1))\n",
        "\n",
        "        # Plot Loss Curve\n",
        "        plt.figure()\n",
        "        plt.plot(epochs, train_losses, label=\"Train Loss\")\n",
        "        plt.plot(epochs, val_losses, label=\"Val Loss\")\n",
        "        plt.xlabel(\"Epoch\")\n",
        "        plt.ylabel(\"Loss\")\n",
        "        plt.title(\"Training & Validation Loss\")\n",
        "        plt.legend()\n",
        "        plt.grid(True)\n",
        "        plt.savefig(os.path.join(MODEL_DIR, \"loss_curve.png\"))\n",
        "        plt.close()\n",
        "\n",
        "        # Plot HitRate@3\n",
        "        plt.figure()\n",
        "        plt.plot(epochs, val_hitrates, label=\"Val HitRate@3\", color=\"green\")\n",
        "        plt.xlabel(\"Epoch\")\n",
        "        plt.ylabel(\"HitRate@3\")\n",
        "        plt.title(\"Validation HitRate@3\")\n",
        "        plt.legend()\n",
        "        plt.grid(True)\n",
        "        plt.savefig(os.path.join(MODEL_DIR, \"hitrate_curve.png\"))\n",
        "        plt.close()\n",
        "\n",
        "        # Plot Learning Rate\n",
        "        plt.figure()\n",
        "        plt.plot(epochs, learning_rates, label=\"Learning Rate\", color=\"orange\")\n",
        "        plt.xlabel(\"Epoch\")\n",
        "        plt.ylabel(\"LR\")\n",
        "        plt.title(\"Learning Rate Schedule\")\n",
        "        plt.legend()\n",
        "        plt.grid(True)\n",
        "        plt.savefig(os.path.join(MODEL_DIR, \"lr_curve.png\"))\n",
        "        plt.close()\n",
        "\n",
        "        # Plot NDCG@3\n",
        "        plt.figure()\n",
        "        plt.plot(epochs, val_ndcgs, label=\"Val NDCG@3\", color=\"purple\")\n",
        "        plt.xlabel(\"Epoch\")\n",
        "        plt.ylabel(\"NDCG@3\")\n",
        "        plt.title(\"Validation NDCG@3\")\n",
        "        plt.legend()\n",
        "        plt.grid(True)\n",
        "        plt.savefig(os.path.join(MODEL_DIR, \"ndcg_curve.png\"))\n",
        "        plt.close()\n",
        "\n",
        "        # Plot MAP@3\n",
        "        plt.figure()\n",
        "        plt.plot(epochs, val_maps, label=\"Val MAP@3\", color=\"red\")\n",
        "        plt.xlabel(\"Epoch\")\n",
        "        plt.ylabel(\"MAP@3\")\n",
        "        plt.title(\"Validation MAP@3\")\n",
        "        plt.legend()\n",
        "        plt.grid(True)\n",
        "        plt.savefig(os.path.join(MODEL_DIR, \"map_curve.png\"))\n",
        "        plt.close()\n",
        "\n",
        "        print(\"üìä Saved metric plots to model/\")\n",
        "\n",
        "        # Predict test set\n",
        "        model.load_state_dict(torch.load(model_path))\n",
        "        model.eval()\n",
        "\n",
        "        val_ids = X_va[\"Id\"]\n",
        "        val_rankers = groups_va[\"ranker_id\"]\n",
        "        val_labels = y_va\n",
        "\n",
        "        all_val_scores = []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for x_cat, x_num, _, lengths in tqdm(val_loader, desc=\"Predicting validation set\"):\n",
        "                x_num = x_num.to(device)\n",
        "                x_cat = {k: v.to(device) for k, v in x_cat.items()}\n",
        "                scores = model(x_cat, x_num)\n",
        "\n",
        "                for i in range(scores.size(0)):\n",
        "                    l = lengths[i]\n",
        "                    all_val_scores.append(scores[i, :l].cpu().numpy())\n",
        "\n",
        "        all_val_scores = np.concatenate(all_val_scores)\n",
        "\n",
        "        assert len(all_val_scores) == X_va.shape[0], \\\n",
        "            f\"Mismatch: {len(all_val_scores)} scores vs {X_va.shape[0]} rows\"\n",
        "\n",
        "        val_df = X_va.with_columns([\n",
        "            pl.Series(\"Id\", val_ids),\n",
        "            pl.Series(\"ranker_id\", val_rankers),\n",
        "            pl.Series(\"score\", all_val_scores),\n",
        "            pl.Series(\"label\", val_labels)\n",
        "        ])\n",
        "\n",
        "        val_df = val_df.with_columns(\n",
        "            pl.col(\"score\")\n",
        "            .rank(method=\"ordinal\", descending=True)\n",
        "            .over(\"ranker_id\")\n",
        "            .cast(pl.Int32)\n",
        "            .alias(\"selected\")\n",
        "        )\n",
        "\n",
        "        val_save_path = os.path.join(MODEL_DIR, \"validation_preds_dl_full.csv\")\n",
        "        val_df.write_csv(val_save_path)\n",
        "        print(f\"‚úÖ Saved full validation predictions (with features) to {val_save_path}\")\n",
        "\n",
        "        all_scores = []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for x_cat, x_num, _, lengths in tqdm(test_loader, desc=\"Predicting test set\"):\n",
        "                x_num = x_num.to(device)\n",
        "                x_cat = {k: v.to(device) for k, v in x_cat.items()}\n",
        "                scores = model(x_cat, x_num)\n",
        "\n",
        "                for i in range(scores.size(0)):\n",
        "                    l = lengths[i]\n",
        "                    all_scores.append(scores[i, :l].cpu().numpy())\n",
        "\n",
        "        all_scores = np.concatenate(all_scores)\n",
        "\n",
        "        assert len(all_scores) == X_te.shape[0], \\\n",
        "            f\"Mismatch: {len(all_scores)} scores vs {X_te.shape[0]} rows in X_te\"\n",
        "\n",
        "        submission_df = pl.DataFrame({\n",
        "            \"Id\": test_ids,\n",
        "            \"ranker_id\": test_rankers,\n",
        "            \"score\": all_scores\n",
        "        })\n",
        "\n",
        "        submission = (\n",
        "            submission_df\n",
        "            .with_columns(\n",
        "                pl.col(\"score\")\n",
        "                .rank(method=\"ordinal\", descending=True)\n",
        "                .over(\"ranker_id\")\n",
        "                .cast(pl.Int32)\n",
        "                .alias(\"selected\")\n",
        "            )\n",
        "            .select([\"Id\", \"ranker_id\", \"score\", \"selected\"])\n",
        "        )\n",
        "\n",
        "        submission_path = os.path.join(SUBMIT_DIR, \"submission_dl_ranker.csv\")\n",
        "        submission.write_csv(submission_path)\n",
        "        print(f\"‚úÖ Submission saved to {submission_path}\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nXEo-ATWUHEV",
        "outputId": "f5a1b424-742b-433b-8804-8607c030009f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting deeprec_validate.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **New Model**"
      ],
      "metadata": {
        "id": "QyWQ3D2YZ3VP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile deeprec_validate.py\n",
        "import os\n",
        "import time\n",
        "import random\n",
        "import torch\n",
        "import math\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import defaultdict\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "import polars as pl\n",
        "from tqdm import tqdm\n",
        "from src.feature import feature_engineering, feature_selection\n",
        "from transformers import get_scheduler\n",
        "from collections import Counter\n",
        "\n",
        "class RankDataset(Dataset):\n",
        "    def __init__(\n",
        "        self,\n",
        "        X: pl.DataFrame,\n",
        "        y: pl.Series,\n",
        "        groups: pl.DataFrame,\n",
        "        cat_features: list[str],\n",
        "        num_features: list[str],\n",
        "    ):\n",
        "        self.cat_features = cat_features\n",
        "        self.num_features = num_features\n",
        "        self.X_cat = {c: X[c].to_numpy() for c in cat_features}\n",
        "        self.X_num = X[self.num_features].to_numpy()\n",
        "        self.y = y.to_numpy()\n",
        "        self.groups = groups[\"ranker_id\"].to_numpy()\n",
        "\n",
        "        self.group_to_indices = defaultdict(list)\n",
        "        for i, g in enumerate(self.groups):\n",
        "            self.group_to_indices[g].append(i)\n",
        "        self.group_keys = list(self.group_to_indices.keys())\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.group_keys)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        g = self.group_keys[idx]\n",
        "        inds = self.group_to_indices[g]\n",
        "        length = len(inds)\n",
        "\n",
        "        x_cat = {\n",
        "            c: torch.LongTensor([\n",
        "                self.X_cat[c][i] if self.X_cat[c][i] >= 0 else 0 for i in inds\n",
        "            ])\n",
        "            for c in self.cat_features\n",
        "        }\n",
        "\n",
        "        x_num = torch.FloatTensor(self.X_num[inds])\n",
        "        y = torch.FloatTensor(self.y[inds]).reshape(-1)\n",
        "\n",
        "        return x_cat, x_num, y, length\n",
        "\n",
        "def collate_fn(batch):\n",
        "    batch_size = len(batch)\n",
        "    lengths = [b[3] for b in batch]\n",
        "    max_len = max(lengths)\n",
        "\n",
        "    padded_x_cat = {key: [] for key in batch[0][0].keys()}\n",
        "    padded_x_num = []\n",
        "    padded_y = []\n",
        "\n",
        "    num_dim = batch[0][1].shape[1]\n",
        "\n",
        "    for x_cat, x_num, y, length in batch:\n",
        "        pad_len = max_len - length\n",
        "\n",
        "        for key in padded_x_cat:\n",
        "            val = x_cat[key]\n",
        "            if pad_len > 0:\n",
        "                val = torch.cat([val, torch.zeros(pad_len, dtype=torch.long)])\n",
        "            padded_x_cat[key].append(val)\n",
        "\n",
        "        if pad_len > 0:\n",
        "            x_num = torch.cat([x_num, torch.zeros(pad_len, num_dim)])\n",
        "            y = torch.cat([y, torch.zeros(pad_len)])\n",
        "\n",
        "        padded_x_num.append(x_num)\n",
        "        padded_y.append(y)\n",
        "\n",
        "    padded_x_cat = {k: torch.stack(v) for k, v in padded_x_cat.items()}\n",
        "    padded_x_num = torch.stack(padded_x_num)\n",
        "    padded_y = torch.stack(padded_y)\n",
        "    lengths = torch.tensor(lengths, dtype=torch.long)\n",
        "\n",
        "    return padded_x_cat, padded_x_num, padded_y, lengths\n",
        "\n",
        "class SEModule(nn.Module):\n",
        "    def __init__(self, channel, reduction=4):\n",
        "        super().__init__()\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(channel, channel // reduction),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(channel // reduction, channel),\n",
        "            nn.Sigmoid(),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: [B, N, C]\n",
        "        w = self.fc(x.mean(dim=1))\n",
        "        w = w.unsqueeze(1)  # [B, 1, C]\n",
        "        return x * w\n",
        "\n",
        "\n",
        "class DLRankerAttention(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        cat_dims,\n",
        "        num_numeric_feats,\n",
        "        emb_dropout=0.1,\n",
        "        dropout=0.1,\n",
        "        num_heads=4,\n",
        "        num_layers=2,\n",
        "        dim_feedforward=128,\n",
        "        proj_dim=64,\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "        self.emb_dims = {\n",
        "            f: min(50, max(4, round(6 * math.log2(cat_dims[f] + 1)))) for f in cat_dims\n",
        "        }\n",
        "        self.embeddings = nn.ModuleDict(\n",
        "            {\n",
        "                f: nn.Embedding(cat_dims[f], self.emb_dims[f], padding_idx=0)\n",
        "                for f in cat_dims\n",
        "            }\n",
        "        )\n",
        "        self.emb_dropout = nn.Dropout(emb_dropout)\n",
        "\n",
        "        total_emb_dim = sum(self.emb_dims.values())\n",
        "        print(\n",
        "            f\"Categorial emb dim sum: {total_emb_dim}, Numerical dim: {num_numeric_feats}\"\n",
        "        )\n",
        "\n",
        "        self.cat_proj = nn.Linear(total_emb_dim, proj_dim)\n",
        "        self.cat_transformer = nn.TransformerEncoder(\n",
        "            nn.TransformerEncoderLayer(\n",
        "                d_model=proj_dim,\n",
        "                nhead=4,\n",
        "                dim_feedforward=dim_feedforward,\n",
        "                dropout=dropout,\n",
        "                batch_first=True,\n",
        "            ),\n",
        "            num_layers=1,\n",
        "        )\n",
        "\n",
        "\n",
        "        self.num_proj_in = nn.Linear(num_numeric_feats, proj_dim)\n",
        "        self.num_transformer = nn.TransformerEncoder(\n",
        "            nn.TransformerEncoderLayer(\n",
        "                d_model=proj_dim,\n",
        "                nhead=4,\n",
        "                dim_feedforward=dim_feedforward,\n",
        "                dropout=dropout,\n",
        "                batch_first=True,\n",
        "            ),\n",
        "            num_layers=1,\n",
        "        )\n",
        "        self.num_se = SEModule(proj_dim)\n",
        "        self.num_proj_out = nn.Sequential(\n",
        "            nn.Linear(proj_dim, proj_dim),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(dropout),\n",
        "        )\n",
        "\n",
        "        self.transformer_layers = nn.ModuleList(\n",
        "            [\n",
        "                nn.TransformerEncoderLayer(\n",
        "                    d_model=2 * proj_dim,\n",
        "                    nhead=num_heads,\n",
        "                    dim_feedforward=dim_feedforward,\n",
        "                    dropout=dropout,\n",
        "                    batch_first=True,\n",
        "                )\n",
        "                for _ in range(num_layers)\n",
        "            ]\n",
        "        )\n",
        "\n",
        "        self.mlp = nn.Sequential(\n",
        "            nn.Linear(2 * proj_dim, 128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(128, 64),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(64, 1),\n",
        "        )\n",
        "\n",
        "    def forward(self, x_cat: dict, x_num: torch.Tensor, attn_mask=None):\n",
        "        B, N, _ = x_num.shape  # x_num: [B, N, F_num]\n",
        "\n",
        "        cat_emb_list = []\n",
        "        for f, emb_layer in self.embeddings.items():\n",
        "            emb = emb_layer(x_cat[f])  # [B, N]\n",
        "            cat_emb_list.append(emb)\n",
        "        cat_embs = torch.cat(cat_emb_list, dim=-1)  # [B, N, total_emb_dim]\n",
        "        cat_embs = self.emb_dropout(cat_embs)\n",
        "        cat_feat = self.cat_proj(cat_embs)  # [B, N, proj_dim]\n",
        "        cat_feat = self.cat_transformer(cat_feat)  # [B, N, proj_dim]\n",
        "\n",
        "        num_feat = self.num_proj_in(x_num)  # [B, N, proj_dim]\n",
        "        num_feat = self.num_transformer(num_feat)  # [B, N, proj_dim]\n",
        "        num_feat = self.num_se(num_feat)  # [B, N, proj_dim]\n",
        "        num_feat = self.num_proj_out(num_feat)  # [B, N, proj_dim]\n",
        "\n",
        "        x = torch.cat([cat_feat, num_feat], dim=-1)  # [B, N, 2*proj_dim]\n",
        "\n",
        "        for layer in self.transformer_layers:\n",
        "            x = layer(x, src_key_padding_mask=attn_mask)\n",
        "\n",
        "        scores = self.mlp(x).squeeze(-1)  # [B, N]\n",
        "\n",
        "        return scores\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "def listmle_loss(scores, labels, lengths):\n",
        "    batch_size = scores.size(0)\n",
        "    total_loss = torch.tensor(0.0, device=scores.device, requires_grad=True)\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "\n",
        "        _, idx = torch.sort(y, descending=True)\n",
        "        s_sorted = s[idx]\n",
        "\n",
        "        parts = (\n",
        "            torch.logsumexp(s_sorted.unsqueeze(0).expand(l, -1).triu(diagonal=0), dim=1)\n",
        "            - s_sorted\n",
        "        )\n",
        "\n",
        "        total_loss = total_loss + parts.sum()\n",
        "\n",
        "    return total_loss / batch_size\n",
        "\"\"\"\n",
        "\n",
        "def hitrate_at_k(scores, labels, lengths, k=3, min_group_size=10):\n",
        "    batch_size = scores.size(0)\n",
        "    hits = 0\n",
        "    valid_count = 0\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        if l < min_group_size:\n",
        "            continue\n",
        "        length = min(l, k)\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "        _, topk_idx = torch.topk(s, length)\n",
        "        topk_labels = y[topk_idx]\n",
        "        hits += (topk_labels > 0).any().float()\n",
        "        valid_count += 1\n",
        "    return hits / valid_count if valid_count > 0 else torch.tensor(0.0, device=scores.device)\n",
        "\n",
        "\n",
        "def ndcg_at_k(scores, labels, lengths, k=3, min_group_size=10):\n",
        "    batch_size = scores.size(0)\n",
        "    total_ndcg = 0.0\n",
        "    valid_count = 0\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        if l < min_group_size:\n",
        "            continue\n",
        "\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "\n",
        "        _, idx_pred = torch.topk(s, min(k, l))\n",
        "        _, idx_ideal = torch.topk(y, min(k, l))\n",
        "\n",
        "        dcg = (y[idx_pred] / torch.log2(torch.arange(2, 2 + len(idx_pred), device=y.device).float())).sum()\n",
        "        idcg = (y[idx_ideal] / torch.log2(torch.arange(2, 2 + len(idx_ideal), device=y.device).float())).sum()\n",
        "\n",
        "        ndcg = dcg / idcg if idcg > 0 else 0.0\n",
        "        total_ndcg += ndcg\n",
        "        valid_count += 1\n",
        "\n",
        "    return total_ndcg / valid_count if valid_count > 0 else torch.tensor(0.0, device=scores.device)\n",
        "\n",
        "\n",
        "def map_at_k(scores, labels, lengths, k=3, min_group_size=10):\n",
        "    batch_size = scores.size(0)\n",
        "    total_ap = 0.0\n",
        "    valid_count = 0\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        if l < min_group_size:\n",
        "            continue\n",
        "\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "\n",
        "        _, idx_pred = torch.topk(s, min(k, l))\n",
        "        y_true = y[idx_pred] > 0\n",
        "\n",
        "        if y_true.sum() == 0:\n",
        "            continue\n",
        "\n",
        "        precisions = [(y_true[:j+1].float().sum() / (j+1)) for j in range(len(y_true)) if y_true[j]]\n",
        "        ap = torch.stack(precisions).mean()\n",
        "        total_ap += ap\n",
        "        valid_count += 1\n",
        "\n",
        "    return total_ap / valid_count if valid_count > 0 else torch.tensor(0.0, device=scores.device)\n",
        "\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "def listnet_loss(scores, labels, lengths):\n",
        "    batch_size = scores.size(0)\n",
        "    total_loss = 0.0\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "\n",
        "        s_softmax = torch.nn.functional.log_softmax(s, dim=0)\n",
        "        y_softmax = torch.nn.functional.softmax(y, dim=0)\n",
        "\n",
        "        loss = -torch.sum(y_softmax * s_softmax)\n",
        "        total_loss += loss\n",
        "\n",
        "    return total_loss / batch_size\n",
        "\"\"\"\n",
        "\n",
        "def ranknet_loss(scores, labels, lengths):\n",
        "    batch_size = scores.size(0)\n",
        "    total_loss = 0.0\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "\n",
        "        diff_scores = s.unsqueeze(1) - s.unsqueeze(0)\n",
        "        rel = y.unsqueeze(1) > y.unsqueeze(0)\n",
        "        label_diff = rel.float()\n",
        "\n",
        "        log_sigmoid = torch.nn.functional.logsigmoid(diff_scores)\n",
        "        pair_loss = -label_diff * log_sigmoid\n",
        "\n",
        "        total_loss += pair_loss.sum()\n",
        "\n",
        "    return total_loss / batch_size\n",
        "\n",
        "def xranknet_loss(scores, labels, lengths, temperature=1.0, margin=0.2, focus_topk=3):\n",
        "    \"\"\"\n",
        "    xRankNet with emphasis on top-K items (based on labels, not scores).\n",
        "    \"\"\"\n",
        "    batch_size = scores.size(0)\n",
        "    total_loss = 0.0\n",
        "    total_pairs = 0\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        if l < 2:\n",
        "            continue\n",
        "\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "\n",
        "        # Top-K mask based on ground truth labels\n",
        "        topk = min(focus_topk, l)\n",
        "        _, topk_idx = torch.topk(y, topk)\n",
        "        topk_mask = torch.zeros_like(y, dtype=torch.bool)\n",
        "        topk_mask[topk_idx] = True\n",
        "\n",
        "        # Create pairwise difference matrices\n",
        "        score_diff = s.unsqueeze(1) - s.unsqueeze(0)\n",
        "        label_diff = y.unsqueeze(1) - y.unsqueeze(0)\n",
        "\n",
        "        # valid pair: y_i > y_j and at least one of i, j is in top-K\n",
        "        valid_pairs = (label_diff > 0) & (\n",
        "            topk_mask.unsqueeze(1) | topk_mask.unsqueeze(0)\n",
        "        )\n",
        "\n",
        "        if valid_pairs.sum() == 0:\n",
        "            continue\n",
        "\n",
        "        importance = (label_diff.abs() * valid_pairs).float()\n",
        "\n",
        "        if margin > 0.0:\n",
        "            score_diff = score_diff - margin\n",
        "\n",
        "        score_diff = score_diff / temperature\n",
        "        pairwise_loss = -F.logsigmoid(score_diff) * importance\n",
        "\n",
        "        total_loss += pairwise_loss.sum()\n",
        "        total_pairs += importance.sum()\n",
        "\n",
        "    if total_pairs == 0:\n",
        "        return torch.tensor(0.0, device=scores.device, requires_grad=True)\n",
        "\n",
        "    return total_loss / total_pairs\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "def bpr_loss(scores, labels, lengths):\n",
        "    batch_size = scores.size(0)\n",
        "    total_loss = 0.0\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "\n",
        "        pos_mask = y > 0\n",
        "        neg_mask = y <= 0\n",
        "\n",
        "        pos_scores = s[pos_mask]\n",
        "        neg_scores = s[neg_mask]\n",
        "\n",
        "        if len(pos_scores) == 0 or len(neg_scores) == 0:\n",
        "            continue\n",
        "\n",
        "        pair_diff = pos_scores.unsqueeze(1) - neg_scores.unsqueeze(0)\n",
        "        loss = -F.logsigmoid(pair_diff).mean()\n",
        "        total_loss += loss\n",
        "\n",
        "    return total_loss / batch_size\n",
        "\"\"\"\n",
        "\n",
        "\"\"\"\n",
        "def lambdarank_loss(scores, labels, lengths, eps=1e-10):\n",
        "    batch_size = scores.size(0)\n",
        "    total_loss = 0.0\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "\n",
        "        if l < 2:\n",
        "            continue\n",
        "\n",
        "        _, rank_order = torch.sort(s, descending=True)\n",
        "        ideal_order = torch.sort(y, descending=True).indices\n",
        "\n",
        "        gain = 2 ** y - 1\n",
        "        discount = torch.log2(torch.arange(2, l + 2, device=y.device).float())\n",
        "\n",
        "        ideal_dcg = (gain[ideal_order] / discount).sum()\n",
        "        if ideal_dcg < eps:\n",
        "            continue\n",
        "\n",
        "        delta_ndcg = torch.zeros((l, l), device=y.device)\n",
        "\n",
        "        for i_idx in range(l):\n",
        "            for j_idx in range(l):\n",
        "                if y[i_idx] > y[j_idx]:\n",
        "                    change = (\n",
        "                        (1.0 / torch.log2(rank_order[i_idx] + 2.0))\n",
        "                        - (1.0 / torch.log2(rank_order[j_idx] + 2.0))\n",
        "                    ).abs()\n",
        "                    delta = (2 ** y[i_idx] - 2 ** y[j_idx]).abs() * change\n",
        "                    delta_ndcg[i_idx, j_idx] = delta / ideal_dcg\n",
        "\n",
        "        score_diffs = s.unsqueeze(1) - s.unsqueeze(0)\n",
        "        lambdas = -F.logsigmoid(score_diffs) * delta_ndcg\n",
        "        total_loss += lambdas.sum()\n",
        "\n",
        "    return total_loss / batch_size\n",
        "\"\"\"\n",
        "\n",
        "def train_one_epoch(model, loader, optimizer, device, scheduler):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "\n",
        "    for x_cat, x_num, y, lengths in tqdm(loader, desc=\"Training\", leave=False):\n",
        "        x_num, y = x_num.to(device), y.to(device)\n",
        "        if not isinstance(lengths, torch.Tensor):\n",
        "            lengths = torch.tensor(lengths)\n",
        "        lengths = lengths.detach().clone().to(device)\n",
        "        x_cat = {k: v.to(device) for k, v in x_cat.items()}\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        scores = model(x_cat, x_num)\n",
        "        loss = xranknet_loss(scores, y, lengths, temperature=1.0, margin=0.2, focus_topk=3)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    return total_loss / len(loader)\n",
        "\n",
        "\n",
        "def validate(model, loader, device, min_group_size=10):\n",
        "    model.eval()\n",
        "    total_hitrate = 0\n",
        "    total_ndcg = 0\n",
        "    total_map = 0\n",
        "    total_loss = 0\n",
        "    count = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for x_cat, x_num, y, lengths in tqdm(loader, desc=\"Validating\", leave=False):\n",
        "            x_num, y = x_num.to(device), y.to(device)\n",
        "            lengths = torch.tensor(lengths).to(device)\n",
        "            x_cat = {k: v.to(device) for k, v in x_cat.items()}\n",
        "\n",
        "            scores = model(x_cat, x_num)\n",
        "\n",
        "            hitrate = hitrate_at_k(scores, y, lengths, k=3, min_group_size=min_group_size)\n",
        "            ndcg = ndcg_at_k(scores, y, lengths, k=3, min_group_size=min_group_size)\n",
        "            map3 = map_at_k(scores, y, lengths, k=3, min_group_size=min_group_size)\n",
        "            loss = xranknet_loss(scores, y, lengths, temperature=1.0, margin=0.2, focus_topk=3)\n",
        "\n",
        "            batch_size = scores.size(0)\n",
        "            total_hitrate += hitrate * batch_size\n",
        "            total_ndcg += ndcg * batch_size\n",
        "            total_map += map3 * batch_size\n",
        "            total_loss += loss.item() * batch_size\n",
        "            count += batch_size\n",
        "\n",
        "    return total_loss / count, total_hitrate / count, total_ndcg / count, total_map / count\n",
        "\n",
        "\n",
        "def build_cat_dims(X, cat_features):\n",
        "    cat_dims = {}\n",
        "    for c in cat_features:\n",
        "        max_val = X[c].max()\n",
        "        if max_val < 0:\n",
        "            max_val = 0\n",
        "        cat_dims[c] = max_val + 1\n",
        "    return cat_dims\n",
        "\n",
        "\n",
        "def normalize_numeric_features(X, numeric_features, train_mask):\n",
        "    for col in numeric_features:\n",
        "        values = X[col].to_numpy()\n",
        "        train_vals = values[train_mask]\n",
        "        mean = train_vals.mean()\n",
        "        std = train_vals.std() if train_vals.std() > 0 else 1.0\n",
        "        norm_vals = (values - mean) / std\n",
        "        X = X.with_columns(pl.Series(col, norm_vals).alias(col))\n",
        "    return X\n",
        "\n",
        "\n",
        "def load_or_prepare_data(\n",
        "    data_dir,\n",
        "    train_file=\"train.parquet\",\n",
        "    test_file=\"test.parquet\",\n",
        "    cache_file=\"feature_engineered_val.parquet\",\n",
        "):\n",
        "    cache_path = os.path.join(data_dir, cache_file)\n",
        "\n",
        "    if os.path.exists(cache_path):\n",
        "        print(f\"Loading cached feature-engineered data from {cache_path} ...\")\n",
        "        df = pl.read_parquet(cache_path)\n",
        "\n",
        "        test = pl.read_parquet(os.path.join(data_dir, test_file)).drop(\"__index_level_0__\")\n",
        "        test_ids = test[\"Id\"]\n",
        "        test_rankers = test[\"ranker_id\"]\n",
        "    else:\n",
        "        print(\"Cached file not found, processing raw data ...\")\n",
        "\n",
        "        train = pl.read_parquet(os.path.join(data_dir, train_file)).drop(\"__index_level_0__\")\n",
        "        test = (\n",
        "            pl.read_parquet(os.path.join(data_dir, test_file))\n",
        "            .drop(\"__index_level_0__\")\n",
        "            .with_columns(pl.lit(0, dtype=pl.Int64).alias(\"selected\"))\n",
        "        )\n",
        "\n",
        "        test_ids = test[\"Id\"]\n",
        "        test_rankers = test[\"ranker_id\"]\n",
        "\n",
        "        df = pl.concat((train, test))\n",
        "        df = feature_engineering(df, full=True)\n",
        "\n",
        "        df = df.with_columns(\n",
        "            [pl.col(c).fill_null(0) for c in df.select(pl.selectors.numeric()).columns] +\n",
        "            [pl.col(c).fill_null(\"missing\") for c in df.select(pl.selectors.string()).columns]\n",
        "        )\n",
        "\n",
        "        os.makedirs(data_dir, exist_ok=True)\n",
        "        df.write_parquet(cache_path)\n",
        "        print(f\"Saved feature-engineered data to {cache_path}\")\n",
        "\n",
        "    return df, test_ids, test_rankers\n",
        "\n",
        "\n",
        "def prepare_data(data_dir):\n",
        "    df, test_ids, test_rankers = load_or_prepare_data(data_dir)\n",
        "\n",
        "    id_column = df[\"Id\"]\n",
        "    X, y, groups, cat_features, num_features = feature_selection(df)\n",
        "\n",
        "    X = X.with_columns(pl.Series(\"Id\", id_column[:X.shape[0]]))\n",
        "\n",
        "    X = X.with_columns(\n",
        "        [\n",
        "            (pl.col(c).rank(\"dense\") - 1).fill_null(-1).cast(pl.Int32)\n",
        "            for c in cat_features\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    train_size = 18145372\n",
        "    train_mask = np.arange(X.height) < train_size\n",
        "    X = normalize_numeric_features(X, num_features, train_mask)\n",
        "\n",
        "    return X, y, groups, cat_features, num_features, train_size, test_ids, test_rankers\n",
        "\n",
        "\n",
        "class EarlyStopping:\n",
        "    def __init__(self, patience=3, min_delta=0.00005):\n",
        "        self.patience = patience\n",
        "        self.min_delta = min_delta\n",
        "        self.best = float(\"-inf\")\n",
        "        self.counter = 0\n",
        "\n",
        "    def step(self, metric):\n",
        "        if metric > self.best + self.min_delta:\n",
        "            self.best = metric\n",
        "            self.counter = 0\n",
        "        else:\n",
        "            self.counter += 1\n",
        "        return self.counter >= self.patience\n",
        "\n",
        "\n",
        "def plot_group_size_distribution(dataset, save_path=None):\n",
        "    group_sizes = [len(v) for v in dataset.group_to_indices.values()]\n",
        "    plt.figure()\n",
        "    plt.hist(group_sizes, bins=100, log=True)\n",
        "    plt.xlabel(\"Group size (number of items per ranker_id)\")\n",
        "    plt.ylabel(\"Frequency (log scale)\")\n",
        "    plt.title(\"Distribution of Group Sizes\")\n",
        "    plt.grid(True)\n",
        "    if save_path:\n",
        "        plt.savefig(save_path)\n",
        "    else:\n",
        "        plt.show()\n",
        "    plt.close()\n",
        "\n",
        "\n",
        "def main():\n",
        "    DATA_DIR = \"./data\"\n",
        "    MODEL_DIR = \"model\"\n",
        "    SUBMIT_DIR = \"submission\"\n",
        "\n",
        "    best_val_loss = float(\"inf\")\n",
        "    best_hitrate = 0.0\n",
        "    model_path = os.path.join(MODEL_DIR, \"best_dl_ranker.pt\")\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "    val_hitrates = []\n",
        "    val_ndcgs = []\n",
        "    val_maps = []\n",
        "    learning_rates = []\n",
        "\n",
        "    os.makedirs(MODEL_DIR, exist_ok=True)\n",
        "    os.makedirs(SUBMIT_DIR, exist_ok=True)\n",
        "\n",
        "    early_stopper = EarlyStopping(patience=3, min_delta=0.001)\n",
        "\n",
        "    X, y, groups, cat_features, num_features, train_size, test_ids, test_rankers = prepare_data(DATA_DIR)\n",
        "\n",
        "    # Fill missing values\n",
        "    float_cols = [c for c, t in zip(X.columns, X.dtypes) if t == pl.Float64]\n",
        "    for col in float_cols:\n",
        "        X = X.with_columns(\n",
        "            pl.when(pl.col(col).is_nan()).then(0).otherwise(pl.col(col)).alias(col)\n",
        "        )\n",
        "\n",
        "    n1 = 16487352\n",
        "    # n1 = 17487300\n",
        "    n2 = train_size\n",
        "\n",
        "    X_tr, X_va, X_te = X[:n1], X[n1:n2], X[n2:]\n",
        "    y_tr, y_va, y_te = y[:n1], y[n1:n2], y[n2:]\n",
        "    groups_tr, groups_va, groups_te = groups[:n1], groups[n1:n2], groups[n2:]\n",
        "\n",
        "    # Inspect group sizes in validation set\n",
        "    val_rankers = groups_va[\"ranker_id\"].to_numpy()\n",
        "    val_group_counts = Counter(val_rankers)\n",
        "\n",
        "    print(\"\\nüìã Validation group statistics:\")\n",
        "    # Save detailed group info to file\n",
        "    group_info_path = os.path.join(MODEL_DIR, \"validation_groups_info.txt\")\n",
        "    with open(group_info_path, \"w\") as f:\n",
        "        f.write(f\"Total groups: {len(val_group_counts)}\\n\\n\")\n",
        "        f.write(\"GroupID\\tSize\\tStartIdx\\tEndIdx\\n\")\n",
        "\n",
        "        group_to_rows = defaultdict(list)\n",
        "        for i, g in enumerate(val_rankers):\n",
        "            group_to_rows[g].append(i)\n",
        "\n",
        "        for group_id, indices in sorted(group_to_rows.items()):\n",
        "            start_idx = indices[0]\n",
        "            end_idx = indices[-1]\n",
        "            size = len(indices)\n",
        "            f.write(f\"{group_id}\\t{size}\\t{start_idx}\\t{end_idx}\\n\")\n",
        "\n",
        "    print(f\"üìÅ Saved validation group info to {group_info_path}\")\n",
        "\n",
        "\n",
        "    cat_dims = build_cat_dims(X, cat_features)\n",
        "    num_numeric_feats = len(num_features)\n",
        "\n",
        "    train_dataset = RankDataset(X_tr, y_tr, groups_tr, cat_features, num_features)\n",
        "    val_dataset = RankDataset(X_va, y_va, groups_va, cat_features, num_features)\n",
        "    test_dataset = RankDataset(X_te, y_te, groups_te, cat_features, num_features)\n",
        "\n",
        "    plot_group_size_distribution(train_dataset, save_path=os.path.join(MODEL_DIR, \"group_sizes.png\"))\n",
        "    print(\"üìä Group size distribution saved.\")\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True, collate_fn=collate_fn)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=4, shuffle=False, collate_fn=collate_fn)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False, collate_fn=collate_fn)\n",
        "\n",
        "    print(\"‚úÖ Data loaders created.\")\n",
        "\n",
        "    num_epochs = 10\n",
        "    num_training_steps = num_epochs * len(train_loader)\n",
        "    num_warmup_steps = int(0.1 * num_training_steps)\n",
        "\n",
        "    learning_rate = 1e-4\n",
        "\n",
        "    model = DLRankerAttention(\n",
        "        cat_dims=cat_dims,\n",
        "        num_numeric_feats=num_numeric_feats,\n",
        "        emb_dropout=0.1,\n",
        "        dropout=0.1,\n",
        "        num_heads=4,\n",
        "        num_layers=2,\n",
        "        dim_feedforward=128,\n",
        "        proj_dim=64\n",
        "    ).to(device)\n",
        "\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=0.01)\n",
        "\n",
        "    scheduler = get_scheduler(\n",
        "        \"linear\",\n",
        "        optimizer=optimizer,\n",
        "        num_warmup_steps=num_warmup_steps,\n",
        "        num_training_steps=num_training_steps\n",
        "    )\n",
        "\n",
        "    best_hitrate = 0\n",
        "    for epoch in range(num_epochs):\n",
        "        print(f\"\\n--- Epoch {epoch+1}/{num_epochs} ---\")\n",
        "        start_time = time.time()\n",
        "\n",
        "        train_loss = train_one_epoch(model, train_loader, optimizer, device, scheduler)\n",
        "        val_loss, val_hitrate, val_ndcg, val_map = validate(model, val_loader, device, min_group_size=10)\n",
        "\n",
        "        train_losses.append(train_loss)\n",
        "        val_losses.append(val_loss)\n",
        "        val_hitrates.append(val_hitrate.item())\n",
        "        val_ndcgs.append(val_ndcg.item())\n",
        "        val_maps.append(val_map.item())\n",
        "\n",
        "        current_lr = scheduler.get_last_lr()\n",
        "        learning_rates.append(current_lr[0])\n",
        "\n",
        "        elapsed = time.time() - start_time\n",
        "        print(\n",
        "            f\"Epoch {epoch+1}: \"\n",
        "            f\"Train Loss={train_loss:.4f}, \"\n",
        "            f\"Val Loss={val_loss:.4f}, \"\n",
        "            f\"HitRate@3={val_hitrate:.4f}, \"\n",
        "            f\"NDCG@3={val_ndcg:.4f}, \"\n",
        "            f\"MAP@3={val_map:.4f}, \"\n",
        "            f\"LR={current_lr[0]:.6f} \"\n",
        "            f\"({elapsed:.1f}s)\"\n",
        "        )\n",
        "\n",
        "\n",
        "        if val_loss < best_val_loss and val_hitrate > best_hitrate:\n",
        "            best_val_loss = val_loss\n",
        "            best_hitrate = val_hitrate\n",
        "            torch.save(model.state_dict(), model_path)\n",
        "            print(\"üíæ Model improved (loss ‚Üì and hitrate ‚Üë), saved.\")\n",
        "\n",
        "        if early_stopper.step(-val_loss):\n",
        "            print(\"‚õî Early stopping triggered.\")\n",
        "            break\n",
        "\n",
        "    # Plot metrics\n",
        "    epochs = list(range(1, len(train_losses) + 1))\n",
        "\n",
        "    # Plot Loss Curve\n",
        "    plt.figure()\n",
        "    plt.plot(epochs, train_losses, label=\"Train Loss\")\n",
        "    plt.plot(epochs, val_losses, label=\"Val Loss\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.title(\"Training & Validation Loss\")\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.savefig(os.path.join(MODEL_DIR, \"loss_curve.png\"))\n",
        "    plt.close()\n",
        "\n",
        "    # Plot HitRate@3\n",
        "    plt.figure()\n",
        "    plt.plot(epochs, val_hitrates, label=\"Val HitRate@3\", color=\"green\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"HitRate@3\")\n",
        "    plt.title(\"Validation HitRate@3\")\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.savefig(os.path.join(MODEL_DIR, \"hitrate_curve.png\"))\n",
        "    plt.close()\n",
        "\n",
        "    # Plot Learning Rate\n",
        "    plt.figure()\n",
        "    plt.plot(epochs, learning_rates, label=\"Learning Rate\", color=\"orange\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"LR\")\n",
        "    plt.title(\"Learning Rate Schedule\")\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.savefig(os.path.join(MODEL_DIR, \"lr_curve.png\"))\n",
        "    plt.close()\n",
        "\n",
        "    # Plot NDCG@3\n",
        "    plt.figure()\n",
        "    plt.plot(epochs, val_ndcgs, label=\"Val NDCG@3\", color=\"purple\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"NDCG@3\")\n",
        "    plt.title(\"Validation NDCG@3\")\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.savefig(os.path.join(MODEL_DIR, \"ndcg_curve.png\"))\n",
        "    plt.close()\n",
        "\n",
        "    # Plot MAP@3\n",
        "    plt.figure()\n",
        "    plt.plot(epochs, val_maps, label=\"Val MAP@3\", color=\"red\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"MAP@3\")\n",
        "    plt.title(\"Validation MAP@3\")\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.savefig(os.path.join(MODEL_DIR, \"map_curve.png\"))\n",
        "    plt.close()\n",
        "\n",
        "    print(\"üìä Saved metric plots to model/\")\n",
        "\n",
        "    # Predict test set\n",
        "    model.load_state_dict(torch.load(model_path))\n",
        "    model.eval()\n",
        "\n",
        "    val_ids = X_va[\"Id\"]\n",
        "    val_rankers = groups_va[\"ranker_id\"]\n",
        "    val_labels = y_va\n",
        "\n",
        "    all_val_scores = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for x_cat, x_num, _, lengths in tqdm(val_loader, desc=\"Predicting validation set\"):\n",
        "            x_num = x_num.to(device)\n",
        "            x_cat = {k: v.to(device) for k, v in x_cat.items()}\n",
        "            scores = model(x_cat, x_num)\n",
        "\n",
        "            for i in range(scores.size(0)):\n",
        "                l = lengths[i]\n",
        "                all_val_scores.append(scores[i, :l].cpu().numpy())\n",
        "\n",
        "    all_val_scores = np.concatenate(all_val_scores)\n",
        "\n",
        "    assert len(all_val_scores) == X_va.shape[0], \\\n",
        "        f\"Mismatch: {len(all_val_scores)} scores vs {X_va.shape[0]} rows\"\n",
        "\n",
        "    val_df = X_va.with_columns([\n",
        "        pl.Series(\"Id\", val_ids),\n",
        "        pl.Series(\"ranker_id\", val_rankers),\n",
        "        pl.Series(\"score\", all_val_scores),\n",
        "        pl.Series(\"label\", val_labels)\n",
        "    ])\n",
        "\n",
        "    val_df = val_df.with_columns(\n",
        "        pl.col(\"score\")\n",
        "        .rank(method=\"ordinal\", descending=True)\n",
        "        .over(\"ranker_id\")\n",
        "        .cast(pl.Int32)\n",
        "        .alias(\"selected\")\n",
        "    )\n",
        "\n",
        "    val_save_path = os.path.join(MODEL_DIR, \"validation_preds_dl_full.csv\")\n",
        "    val_df.write_csv(val_save_path)\n",
        "    print(f\"‚úÖ Saved full validation predictions (with features) to {val_save_path}\")\n",
        "\n",
        "    all_scores = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for x_cat, x_num, _, lengths in tqdm(test_loader, desc=\"Predicting test set\"):\n",
        "            x_num = x_num.to(device)\n",
        "            x_cat = {k: v.to(device) for k, v in x_cat.items()}\n",
        "            scores = model(x_cat, x_num)\n",
        "\n",
        "            for i in range(scores.size(0)):\n",
        "                l = lengths[i]\n",
        "                all_scores.append(scores[i, :l].cpu().numpy())\n",
        "\n",
        "    all_scores = np.concatenate(all_scores)\n",
        "\n",
        "    assert len(all_scores) == X_te.shape[0], \\\n",
        "        f\"Mismatch: {len(all_scores)} scores vs {X_te.shape[0]} rows in X_te\"\n",
        "\n",
        "    submission_df = pl.DataFrame({\n",
        "        \"Id\": test_ids,\n",
        "        \"ranker_id\": test_rankers,\n",
        "        \"score\": all_scores\n",
        "    })\n",
        "\n",
        "    submission = (\n",
        "        submission_df\n",
        "        .with_columns(\n",
        "            pl.col(\"score\")\n",
        "            .rank(method=\"ordinal\", descending=True)\n",
        "            .over(\"ranker_id\")\n",
        "            .cast(pl.Int32)\n",
        "            .alias(\"selected\")\n",
        "        )\n",
        "        .select([\"Id\", \"ranker_id\", \"score\", \"selected\"])\n",
        "    )\n",
        "\n",
        "    submission_path = os.path.join(SUBMIT_DIR, \"submission_dl_ranker.csv\")\n",
        "    submission.write_csv(submission_path)\n",
        "    print(f\"‚úÖ Submission saved to {submission_path}\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VY2P7hFRZ7iY",
        "outputId": "3118e42a-c6a9-4b38-889f-16a53ab15094"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing deeprec_validate.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "--- Epoch 1/10 ---\n",
        "Validating:   0%|          | 0/2636 [00:00<?, ?it/s]/home/ionut/test_whisper/test2/deeprec_validate.py:507: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
        "  lengths = torch.tensor(lengths).to(device)\n",
        "Epoch 1: Train Loss=0.3812, Val Loss=0.2907, HitRate@3=0.4687, NDCG@3=0.3718, MAP@3=0.6123, LR=0.000100 (600.4s)\n",
        "üíæ Model improved (loss ‚Üì and hitrate ‚Üë), saved.\n",
        "\n",
        "--- Epoch 2/10 ---\n",
        "Epoch 2: Train Loss=0.2850, Val Loss=0.2799, HitRate@3=0.4891, NDCG@3=0.3904, MAP@3=0.6328, LR=0.000089 (601.3s)\n",
        "üíæ Model improved (loss ‚Üì and hitrate ‚Üë), saved.\n",
        "\n",
        "--- Epoch 3/10 ---\n",
        "Epoch 3: Train Loss=0.2639, Val Loss=0.2602, HitRate@3=0.5026, NDCG@3=0.4052, MAP@3=0.6515, LR=0.000078 (602.0s)\n",
        "üíæ Model improved (loss ‚Üì and hitrate ‚Üë), saved.\n",
        "\n",
        "--- Epoch 4/10 ---\n",
        "Epoch 4: Train Loss=0.2495, Val Loss=0.2569, HitRate@3=0.5059, NDCG@3=0.4057, MAP@3=0.6464, LR=0.000067 (602.4s)\n",
        "üíæ Model improved (loss ‚Üì and hitrate ‚Üë), saved.\n",
        "\n",
        "--- Epoch 5/10 ---\n",
        "Epoch 5: Train Loss=0.2383, Val Loss=0.2471, HitRate@3=0.5104, NDCG@3=0.4107, MAP@3=0.6527, LR=0.000056 (602.1s)\n",
        "üíæ Model improved (loss ‚Üì and hitrate ‚Üë), saved.\n",
        "\n",
        "--- Epoch 6/10 ---\n",
        "Epoch 6: Train Loss=0.2275, Val Loss=0.2495, HitRate@3=0.5132, NDCG@3=0.4138, MAP@3=0.6553, LR=0.000044 (602.8s)\n",
        "\n",
        "--- Epoch 7/10 ---\n",
        "Epoch 7: Train Loss=0.2204, Val Loss=0.2442, HitRate@3=0.5157, NDCG@3=0.4142, MAP@3=0.6537, LR=0.000033 (602.4s)\n",
        "üíæ Model improved (loss ‚Üì and hitrate ‚Üë), saved.\n",
        "\n",
        "--- Epoch 8/10 ---\n",
        "Epoch 8: Train Loss=0.2116, Val Loss=0.2445, HitRate@3=0.5193, NDCG@3=0.4168, MAP@3=0.6530, LR=0.000022 (603.0s)\n",
        "\n",
        "--- Epoch 9/10 ---\n",
        "Epoch 9: Train Loss=0.2049, Val Loss=0.2437, HitRate@3=0.5210, NDCG@3=0.4191, MAP@3=0.6604, LR=0.000011 (603.7s)\n",
        "üíæ Model improved (loss ‚Üì and hitrate ‚Üë), saved.\n",
        "\n",
        "--- Epoch 10/10 ---\n",
        "Epoch 10: Train Loss=0.1996, Val Loss=0.2446, HitRate@3=0.5203, NDCG@3=0.4186, MAP@3=0.6592, LR=0.000000 (603.8s)"
      ],
      "metadata": {
        "id": "kG3pIAHK1teI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile deeprec_validate.py\n",
        "import os\n",
        "import time\n",
        "import random\n",
        "import torch\n",
        "import math\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import defaultdict\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "import polars as pl\n",
        "from tqdm import tqdm\n",
        "from src.feature import feature_engineering, feature_selection\n",
        "from transformers import get_scheduler\n",
        "from collections import Counter\n",
        "\n",
        "class RankDataset(Dataset):\n",
        "    def __init__(\n",
        "        self,\n",
        "        X: pl.DataFrame,\n",
        "        y: pl.Series,\n",
        "        groups: pl.DataFrame,\n",
        "        cat_features: list[str],\n",
        "        num_features: list[str],\n",
        "    ):\n",
        "        self.cat_features = cat_features\n",
        "        self.num_features = num_features\n",
        "        self.X_cat = {c: X[c].to_numpy() for c in cat_features}\n",
        "        self.X_num = X[self.num_features].to_numpy()\n",
        "        self.y = y.to_numpy()\n",
        "        self.groups = groups[\"ranker_id\"].to_numpy()\n",
        "\n",
        "        self.group_to_indices = defaultdict(list)\n",
        "        for i, g in enumerate(self.groups):\n",
        "            self.group_to_indices[g].append(i)\n",
        "        self.group_keys = list(self.group_to_indices.keys())\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.group_keys)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        g = self.group_keys[idx]\n",
        "        inds = self.group_to_indices[g]\n",
        "        length = len(inds)\n",
        "\n",
        "        x_cat = {\n",
        "            c: torch.LongTensor([\n",
        "                self.X_cat[c][i] if self.X_cat[c][i] >= 0 else 0 for i in inds\n",
        "            ])\n",
        "            for c in self.cat_features\n",
        "        }\n",
        "\n",
        "        x_num = torch.FloatTensor(self.X_num[inds])\n",
        "        y = torch.FloatTensor(self.y[inds]).reshape(-1)\n",
        "\n",
        "        return x_cat, x_num, y, length\n",
        "\n",
        "def collate_fn(batch):\n",
        "    batch_size = len(batch)\n",
        "    lengths = [b[3] for b in batch]\n",
        "    max_len = max(lengths)\n",
        "\n",
        "    padded_x_cat = {key: [] for key in batch[0][0].keys()}\n",
        "    padded_x_num = []\n",
        "    padded_y = []\n",
        "\n",
        "    num_dim = batch[0][1].shape[1]\n",
        "\n",
        "    for x_cat, x_num, y, length in batch:\n",
        "        pad_len = max_len - length\n",
        "\n",
        "        for key in padded_x_cat:\n",
        "            val = x_cat[key]\n",
        "            if pad_len > 0:\n",
        "                val = torch.cat([val, torch.zeros(pad_len, dtype=torch.long)])\n",
        "            padded_x_cat[key].append(val)\n",
        "\n",
        "        if pad_len > 0:\n",
        "            x_num = torch.cat([x_num, torch.zeros(pad_len, num_dim)])\n",
        "            y = torch.cat([y, torch.zeros(pad_len)])\n",
        "\n",
        "        padded_x_num.append(x_num)\n",
        "        padded_y.append(y)\n",
        "\n",
        "    padded_x_cat = {k: torch.stack(v) for k, v in padded_x_cat.items()}\n",
        "    padded_x_num = torch.stack(padded_x_num)\n",
        "    padded_y = torch.stack(padded_y)\n",
        "    lengths = torch.tensor(lengths, dtype=torch.long)\n",
        "\n",
        "    return padded_x_cat, padded_x_num, padded_y, lengths\n",
        "\n",
        "class SEModule(nn.Module):\n",
        "    def __init__(self, channel, reduction=4):\n",
        "        super().__init__()\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(channel, channel // reduction),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(channel // reduction, channel),\n",
        "            nn.Sigmoid(),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: [B, N, C]\n",
        "        w = self.fc(x.mean(dim=1))\n",
        "        w = w.unsqueeze(1)  # [B, 1, C]\n",
        "        return x * w\n",
        "\n",
        "\n",
        "class DLRankerAttention(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        cat_dims,\n",
        "        num_numeric_feats,\n",
        "        emb_dropout=0.1,\n",
        "        dropout=0.1,\n",
        "        num_heads=4,\n",
        "        num_layers=2,\n",
        "        dim_feedforward=128,\n",
        "        proj_dim=64,\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "        self.emb_dims = {\n",
        "            f: min(50, max(4, round(6 * math.log2(cat_dims[f] + 1)))) for f in cat_dims\n",
        "        }\n",
        "        self.embeddings = nn.ModuleDict(\n",
        "            {\n",
        "                f: nn.Embedding(cat_dims[f], self.emb_dims[f], padding_idx=0)\n",
        "                for f in cat_dims\n",
        "            }\n",
        "        )\n",
        "        self.emb_dropout = nn.Dropout(emb_dropout)\n",
        "\n",
        "        total_emb_dim = sum(self.emb_dims.values())\n",
        "        print(\n",
        "            f\"Categorial emb dim sum: {total_emb_dim}, Numerical dim: {num_numeric_feats}\"\n",
        "        )\n",
        "\n",
        "        self.cat_proj = nn.Linear(total_emb_dim, proj_dim)\n",
        "        self.cat_transformer = nn.TransformerEncoder(\n",
        "            nn.TransformerEncoderLayer(\n",
        "                d_model=proj_dim,\n",
        "                nhead=4,\n",
        "                dim_feedforward=dim_feedforward,\n",
        "                dropout=dropout,\n",
        "                batch_first=True,\n",
        "            ),\n",
        "            num_layers=1,\n",
        "        )\n",
        "\n",
        "\n",
        "        self.num_proj_in = nn.Linear(num_numeric_feats, proj_dim)\n",
        "        self.num_transformer = nn.TransformerEncoder(\n",
        "            nn.TransformerEncoderLayer(\n",
        "                d_model=proj_dim,\n",
        "                nhead=4,\n",
        "                dim_feedforward=dim_feedforward,\n",
        "                dropout=dropout,\n",
        "                batch_first=True,\n",
        "            ),\n",
        "            num_layers=1,\n",
        "        )\n",
        "        self.num_se = SEModule(proj_dim)\n",
        "        self.num_proj_out = nn.Sequential(\n",
        "            nn.Linear(proj_dim, proj_dim),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(dropout),\n",
        "        )\n",
        "\n",
        "        self.transformer_layers = nn.ModuleList(\n",
        "            [\n",
        "                nn.TransformerEncoderLayer(\n",
        "                    d_model=2 * proj_dim,\n",
        "                    nhead=num_heads,\n",
        "                    dim_feedforward=dim_feedforward,\n",
        "                    dropout=dropout,\n",
        "                    batch_first=True,\n",
        "                )\n",
        "                for _ in range(num_layers)\n",
        "            ]\n",
        "        )\n",
        "\n",
        "        self.mlp = nn.Sequential(\n",
        "            nn.Linear(2 * proj_dim, 128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(128, 64),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(64, 1),\n",
        "        )\n",
        "\n",
        "    def forward(self, x_cat: dict, x_num: torch.Tensor, attn_mask=None):\n",
        "        B, N, _ = x_num.shape  # x_num: [B, N, F_num]\n",
        "\n",
        "        cat_emb_list = []\n",
        "        for f, emb_layer in self.embeddings.items():\n",
        "            emb = emb_layer(x_cat[f])  # [B, N]\n",
        "            cat_emb_list.append(emb)\n",
        "        cat_embs = torch.cat(cat_emb_list, dim=-1)  # [B, N, total_emb_dim]\n",
        "        cat_embs = self.emb_dropout(cat_embs)\n",
        "        cat_feat = self.cat_proj(cat_embs)  # [B, N, proj_dim]\n",
        "        cat_feat = self.cat_transformer(cat_feat)  # [B, N, proj_dim]\n",
        "\n",
        "        num_feat = self.num_proj_in(x_num)  # [B, N, proj_dim]\n",
        "        num_feat = self.num_transformer(num_feat)  # [B, N, proj_dim]\n",
        "        num_feat = self.num_se(num_feat)  # [B, N, proj_dim]\n",
        "        num_feat = self.num_proj_out(num_feat)  # [B, N, proj_dim]\n",
        "\n",
        "        x = torch.cat([cat_feat, num_feat], dim=-1)  # [B, N, 2*proj_dim]\n",
        "\n",
        "        for layer in self.transformer_layers:\n",
        "            x = layer(x, src_key_padding_mask=attn_mask)\n",
        "\n",
        "        scores = self.mlp(x).squeeze(-1)  # [B, N]\n",
        "\n",
        "        return scores\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "def listmle_loss(scores, labels, lengths):\n",
        "    batch_size = scores.size(0)\n",
        "    total_loss = torch.tensor(0.0, device=scores.device, requires_grad=True)\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "\n",
        "        _, idx = torch.sort(y, descending=True)\n",
        "        s_sorted = s[idx]\n",
        "\n",
        "        parts = (\n",
        "            torch.logsumexp(s_sorted.unsqueeze(0).expand(l, -1).triu(diagonal=0), dim=1)\n",
        "            - s_sorted\n",
        "        )\n",
        "\n",
        "        total_loss = total_loss + parts.sum()\n",
        "\n",
        "    return total_loss / batch_size\n",
        "\"\"\"\n",
        "\n",
        "def hitrate_at_k(scores, labels, lengths, k=3, min_group_size=10):\n",
        "    batch_size = scores.size(0)\n",
        "    hits = 0\n",
        "    valid_count = 0\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        if l < min_group_size:\n",
        "            continue\n",
        "        length = min(l, k)\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "        _, topk_idx = torch.topk(s, length)\n",
        "        topk_labels = y[topk_idx]\n",
        "        hits += (topk_labels > 0).any().float()\n",
        "        valid_count += 1\n",
        "    return hits / valid_count if valid_count > 0 else torch.tensor(0.0, device=scores.device)\n",
        "\n",
        "\n",
        "def ndcg_at_k(scores, labels, lengths, k=3, min_group_size=10):\n",
        "    batch_size = scores.size(0)\n",
        "    total_ndcg = 0.0\n",
        "    valid_count = 0\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        if l < min_group_size:\n",
        "            continue\n",
        "\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "\n",
        "        _, idx_pred = torch.topk(s, min(k, l))\n",
        "        _, idx_ideal = torch.topk(y, min(k, l))\n",
        "\n",
        "        dcg = (y[idx_pred] / torch.log2(torch.arange(2, 2 + len(idx_pred), device=y.device).float())).sum()\n",
        "        idcg = (y[idx_ideal] / torch.log2(torch.arange(2, 2 + len(idx_ideal), device=y.device).float())).sum()\n",
        "\n",
        "        ndcg = dcg / idcg if idcg > 0 else 0.0\n",
        "        total_ndcg += ndcg\n",
        "        valid_count += 1\n",
        "\n",
        "    return total_ndcg / valid_count if valid_count > 0 else torch.tensor(0.0, device=scores.device)\n",
        "\n",
        "\n",
        "def map_at_k(scores, labels, lengths, k=3, min_group_size=10):\n",
        "    batch_size = scores.size(0)\n",
        "    total_ap = 0.0\n",
        "    valid_count = 0\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        if l < min_group_size:\n",
        "            continue\n",
        "\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "\n",
        "        _, idx_pred = torch.topk(s, min(k, l))\n",
        "        y_true = y[idx_pred] > 0\n",
        "\n",
        "        if y_true.sum() == 0:\n",
        "            continue\n",
        "\n",
        "        precisions = [(y_true[:j+1].float().sum() / (j+1)) for j in range(len(y_true)) if y_true[j]]\n",
        "        ap = torch.stack(precisions).mean()\n",
        "        total_ap += ap\n",
        "        valid_count += 1\n",
        "\n",
        "    return total_ap / valid_count if valid_count > 0 else torch.tensor(0.0, device=scores.device)\n",
        "\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "def listnet_loss(scores, labels, lengths):\n",
        "    batch_size = scores.size(0)\n",
        "    total_loss = 0.0\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "\n",
        "        s_softmax = torch.nn.functional.log_softmax(s, dim=0)\n",
        "        y_softmax = torch.nn.functional.softmax(y, dim=0)\n",
        "\n",
        "        loss = -torch.sum(y_softmax * s_softmax)\n",
        "        total_loss += loss\n",
        "\n",
        "    return total_loss / batch_size\n",
        "\"\"\"\n",
        "\n",
        "def ranknet_loss(scores, labels, lengths):\n",
        "    batch_size = scores.size(0)\n",
        "    total_loss = 0.0\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "\n",
        "        diff_scores = s.unsqueeze(1) - s.unsqueeze(0)\n",
        "        rel = y.unsqueeze(1) > y.unsqueeze(0)\n",
        "        label_diff = rel.float()\n",
        "\n",
        "        log_sigmoid = torch.nn.functional.logsigmoid(diff_scores)\n",
        "        pair_loss = -label_diff * log_sigmoid\n",
        "\n",
        "        total_loss += pair_loss.sum()\n",
        "\n",
        "    return total_loss / batch_size\n",
        "\n",
        "def xranknet_loss(scores, labels, lengths, temperature=1.0, margin=0.2, focus_topk=3):\n",
        "    \"\"\"\n",
        "    xRankNet with emphasis on top-K items (based on labels, not scores).\n",
        "    \"\"\"\n",
        "    batch_size = scores.size(0)\n",
        "    total_loss = 0.0\n",
        "    total_pairs = 0\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        if l < 2:\n",
        "            continue\n",
        "\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "\n",
        "        # Top-K mask based on ground truth labels\n",
        "        topk = min(focus_topk, l)\n",
        "        _, topk_idx = torch.topk(y, topk)\n",
        "        topk_mask = torch.zeros_like(y, dtype=torch.bool)\n",
        "        topk_mask[topk_idx] = True\n",
        "\n",
        "        # Create pairwise difference matrices\n",
        "        score_diff = s.unsqueeze(1) - s.unsqueeze(0)\n",
        "        label_diff = y.unsqueeze(1) - y.unsqueeze(0)\n",
        "\n",
        "        # valid pair: y_i > y_j and at least one of i, j is in top-K\n",
        "        valid_pairs = (label_diff > 0) & (\n",
        "            topk_mask.unsqueeze(1) | topk_mask.unsqueeze(0)\n",
        "        )\n",
        "\n",
        "        if valid_pairs.sum() == 0:\n",
        "            continue\n",
        "\n",
        "        importance = (label_diff.abs() * valid_pairs).float()\n",
        "\n",
        "        if margin > 0.0:\n",
        "            score_diff = score_diff - margin\n",
        "\n",
        "        score_diff = score_diff / temperature\n",
        "        pairwise_loss = -F.logsigmoid(score_diff) * importance\n",
        "\n",
        "        total_loss += pairwise_loss.sum()\n",
        "        total_pairs += importance.sum()\n",
        "\n",
        "    if total_pairs == 0:\n",
        "        return torch.tensor(0.0, device=scores.device, requires_grad=True)\n",
        "\n",
        "    return total_loss / total_pairs\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "def bpr_loss(scores, labels, lengths):\n",
        "    batch_size = scores.size(0)\n",
        "    total_loss = 0.0\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "\n",
        "        pos_mask = y > 0\n",
        "        neg_mask = y <= 0\n",
        "\n",
        "        pos_scores = s[pos_mask]\n",
        "        neg_scores = s[neg_mask]\n",
        "\n",
        "        if len(pos_scores) == 0 or len(neg_scores) == 0:\n",
        "            continue\n",
        "\n",
        "        pair_diff = pos_scores.unsqueeze(1) - neg_scores.unsqueeze(0)\n",
        "        loss = -F.logsigmoid(pair_diff).mean()\n",
        "        total_loss += loss\n",
        "\n",
        "    return total_loss / batch_size\n",
        "\"\"\"\n",
        "\n",
        "\"\"\"\n",
        "def lambdarank_loss(scores, labels, lengths, eps=1e-10):\n",
        "    batch_size = scores.size(0)\n",
        "    total_loss = 0.0\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "\n",
        "        if l < 2:\n",
        "            continue\n",
        "\n",
        "        _, rank_order = torch.sort(s, descending=True)\n",
        "        ideal_order = torch.sort(y, descending=True).indices\n",
        "\n",
        "        gain = 2 ** y - 1\n",
        "        discount = torch.log2(torch.arange(2, l + 2, device=y.device).float())\n",
        "\n",
        "        ideal_dcg = (gain[ideal_order] / discount).sum()\n",
        "        if ideal_dcg < eps:\n",
        "            continue\n",
        "\n",
        "        delta_ndcg = torch.zeros((l, l), device=y.device)\n",
        "\n",
        "        for i_idx in range(l):\n",
        "            for j_idx in range(l):\n",
        "                if y[i_idx] > y[j_idx]:\n",
        "                    change = (\n",
        "                        (1.0 / torch.log2(rank_order[i_idx] + 2.0))\n",
        "                        - (1.0 / torch.log2(rank_order[j_idx] + 2.0))\n",
        "                    ).abs()\n",
        "                    delta = (2 ** y[i_idx] - 2 ** y[j_idx]).abs() * change\n",
        "                    delta_ndcg[i_idx, j_idx] = delta / ideal_dcg\n",
        "\n",
        "        score_diffs = s.unsqueeze(1) - s.unsqueeze(0)\n",
        "        lambdas = -F.logsigmoid(score_diffs) * delta_ndcg\n",
        "        total_loss += lambdas.sum()\n",
        "\n",
        "    return total_loss / batch_size\n",
        "\"\"\"\n",
        "\n",
        "def train_one_epoch(model, loader, optimizer, device, scheduler):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "\n",
        "    for x_cat, x_num, y, lengths in tqdm(loader, desc=\"Training\", leave=False):\n",
        "        x_num, y = x_num.to(device), y.to(device)\n",
        "        if not isinstance(lengths, torch.Tensor):\n",
        "            lengths = torch.tensor(lengths)\n",
        "        lengths = lengths.detach().clone().to(device)\n",
        "        x_cat = {k: v.to(device) for k, v in x_cat.items()}\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        scores = model(x_cat, x_num)\n",
        "        loss = xranknet_loss(scores, y, lengths, temperature=1.0, margin=0.2, focus_topk=3)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    return total_loss / len(loader)\n",
        "\n",
        "\n",
        "def validate(model, loader, device, min_group_size=10):\n",
        "    model.eval()\n",
        "    total_hitrate = 0\n",
        "    total_ndcg = 0\n",
        "    total_map = 0\n",
        "    total_loss = 0\n",
        "    count = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for x_cat, x_num, y, lengths in tqdm(loader, desc=\"Validating\", leave=False):\n",
        "            x_num, y = x_num.to(device), y.to(device)\n",
        "            lengths = torch.tensor(lengths).to(device)\n",
        "            x_cat = {k: v.to(device) for k, v in x_cat.items()}\n",
        "\n",
        "            scores = model(x_cat, x_num)\n",
        "\n",
        "            hitrate = hitrate_at_k(scores, y, lengths, k=3, min_group_size=min_group_size)\n",
        "            ndcg = ndcg_at_k(scores, y, lengths, k=3, min_group_size=min_group_size)\n",
        "            map3 = map_at_k(scores, y, lengths, k=3, min_group_size=min_group_size)\n",
        "            loss = xranknet_loss(scores, y, lengths, temperature=1.0, margin=0.2, focus_topk=3)\n",
        "\n",
        "            batch_size = scores.size(0)\n",
        "            total_hitrate += hitrate * batch_size\n",
        "            total_ndcg += ndcg * batch_size\n",
        "            total_map += map3 * batch_size\n",
        "            total_loss += loss.item() * batch_size\n",
        "            count += batch_size\n",
        "\n",
        "    return total_loss / count, total_hitrate / count, total_ndcg / count, total_map / count\n",
        "\n",
        "\n",
        "def build_cat_dims(X, cat_features):\n",
        "    cat_dims = {}\n",
        "    for c in cat_features:\n",
        "        max_val = X[c].max()\n",
        "        if max_val < 0:\n",
        "            max_val = 0\n",
        "        cat_dims[c] = max_val + 1\n",
        "    return cat_dims\n",
        "\n",
        "\n",
        "def normalize_numeric_features(X, numeric_features, train_mask):\n",
        "    for col in numeric_features:\n",
        "        values = X[col].to_numpy()\n",
        "        train_vals = values[train_mask]\n",
        "        mean = train_vals.mean()\n",
        "        std = train_vals.std() if train_vals.std() > 0 else 1.0\n",
        "        norm_vals = (values - mean) / std\n",
        "        X = X.with_columns(pl.Series(col, norm_vals).alias(col))\n",
        "    return X\n",
        "\n",
        "\n",
        "def load_or_prepare_data(\n",
        "    data_dir,\n",
        "    train_file=\"train.parquet\",\n",
        "    test_file=\"test.parquet\",\n",
        "    cache_file=\"feature_engineered_val.parquet\",\n",
        "):\n",
        "    cache_path = os.path.join(data_dir, cache_file)\n",
        "\n",
        "    if os.path.exists(cache_path):\n",
        "        print(f\"Loading cached feature-engineered data from {cache_path} ...\")\n",
        "        df = pl.read_parquet(cache_path)\n",
        "\n",
        "        test = pl.read_parquet(os.path.join(data_dir, test_file)).drop(\"__index_level_0__\")\n",
        "        test_ids = test[\"Id\"]\n",
        "        test_rankers = test[\"ranker_id\"]\n",
        "    else:\n",
        "        print(\"Cached file not found, processing raw data ...\")\n",
        "\n",
        "        train = pl.read_parquet(os.path.join(data_dir, train_file)).drop(\"__index_level_0__\")\n",
        "        test = (\n",
        "            pl.read_parquet(os.path.join(data_dir, test_file))\n",
        "            .drop(\"__index_level_0__\")\n",
        "            .with_columns(pl.lit(0, dtype=pl.Int64).alias(\"selected\"))\n",
        "        )\n",
        "\n",
        "        test_ids = test[\"Id\"]\n",
        "        test_rankers = test[\"ranker_id\"]\n",
        "\n",
        "        df = pl.concat((train, test))\n",
        "        df = feature_engineering(df, full=True)\n",
        "\n",
        "        df = df.with_columns(\n",
        "            [pl.col(c).fill_null(0) for c in df.select(pl.selectors.numeric()).columns] +\n",
        "            [pl.col(c).fill_null(\"missing\") for c in df.select(pl.selectors.string()).columns]\n",
        "        )\n",
        "\n",
        "        os.makedirs(data_dir, exist_ok=True)\n",
        "        df.write_parquet(cache_path)\n",
        "        print(f\"Saved feature-engineered data to {cache_path}\")\n",
        "\n",
        "    return df, test_ids, test_rankers\n",
        "\n",
        "\n",
        "def prepare_data(data_dir):\n",
        "    df, test_ids, test_rankers = load_or_prepare_data(data_dir)\n",
        "\n",
        "    id_column = df[\"Id\"]\n",
        "    X, y, groups, cat_features, num_features = feature_selection(df)\n",
        "\n",
        "    X = X.with_columns(pl.Series(\"Id\", id_column[:X.shape[0]]))\n",
        "\n",
        "    X = X.with_columns(\n",
        "        [\n",
        "            (pl.col(c).rank(\"dense\") - 1).fill_null(-1).cast(pl.Int32)\n",
        "            for c in cat_features\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    train_size = 18145372\n",
        "    train_mask = np.arange(X.height) < train_size\n",
        "    X = normalize_numeric_features(X, num_features, train_mask)\n",
        "\n",
        "    return X, y, groups, cat_features, num_features, train_size, test_ids, test_rankers\n",
        "\n",
        "\n",
        "class EarlyStopping:\n",
        "    def __init__(self, patience=3, min_delta=0.00005):\n",
        "        self.patience = patience\n",
        "        self.min_delta = min_delta\n",
        "        self.best = float(\"-inf\")\n",
        "        self.counter = 0\n",
        "\n",
        "    def step(self, metric):\n",
        "        if metric > self.best + self.min_delta:\n",
        "            self.best = metric\n",
        "            self.counter = 0\n",
        "        else:\n",
        "            self.counter += 1\n",
        "        return self.counter >= self.patience\n",
        "\n",
        "\n",
        "def plot_group_size_distribution(dataset, save_path=None):\n",
        "    group_sizes = [len(v) for v in dataset.group_to_indices.values()]\n",
        "    plt.figure()\n",
        "    plt.hist(group_sizes, bins=100, log=True)\n",
        "    plt.xlabel(\"Group size (number of items per ranker_id)\")\n",
        "    plt.ylabel(\"Frequency (log scale)\")\n",
        "    plt.title(\"Distribution of Group Sizes\")\n",
        "    plt.grid(True)\n",
        "    if save_path:\n",
        "        plt.savefig(save_path)\n",
        "    else:\n",
        "        plt.show()\n",
        "    plt.close()\n",
        "\n",
        "\n",
        "def main():\n",
        "    DATA_DIR = \"./data\"\n",
        "    MODEL_DIR = \"model\"\n",
        "    SUBMIT_DIR = \"submission\"\n",
        "\n",
        "    best_val_loss = float(\"inf\")\n",
        "    best_hitrate = 0.0\n",
        "    model_path = os.path.join(MODEL_DIR, \"best_dl_ranker.pt\")\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "    val_hitrates = []\n",
        "    val_ndcgs = []\n",
        "    val_maps = []\n",
        "    learning_rates = []\n",
        "\n",
        "    os.makedirs(MODEL_DIR, exist_ok=True)\n",
        "    os.makedirs(SUBMIT_DIR, exist_ok=True)\n",
        "\n",
        "    early_stopper = EarlyStopping(patience=3, min_delta=0.001)\n",
        "\n",
        "    X, y, groups, cat_features, num_features, train_size, test_ids, test_rankers = prepare_data(DATA_DIR)\n",
        "\n",
        "    # Fill missing values\n",
        "    float_cols = [c for c, t in zip(X.columns, X.dtypes) if t == pl.Float64]\n",
        "    for col in float_cols:\n",
        "        X = X.with_columns(\n",
        "            pl.when(pl.col(col).is_nan()).then(0).otherwise(pl.col(col)).alias(col)\n",
        "        )\n",
        "\n",
        "    n1 = 16487352\n",
        "    # n1 = 17487300\n",
        "    n2 = train_size\n",
        "\n",
        "    X_tr, X_va, X_te = X[:n1], X[n1:n2], X[n2:]\n",
        "    y_tr, y_va, y_te = y[:n1], y[n1:n2], y[n2:]\n",
        "    groups_tr, groups_va, groups_te = groups[:n1], groups[n1:n2], groups[n2:]\n",
        "\n",
        "    # Inspect group sizes in validation set\n",
        "    val_rankers = groups_va[\"ranker_id\"].to_numpy()\n",
        "    val_group_counts = Counter(val_rankers)\n",
        "\n",
        "    print(\"\\nüìã Validation group statistics:\")\n",
        "    # Save detailed group info to file\n",
        "    group_info_path = os.path.join(MODEL_DIR, \"validation_groups_info.txt\")\n",
        "    with open(group_info_path, \"w\") as f:\n",
        "        f.write(f\"Total groups: {len(val_group_counts)}\\n\\n\")\n",
        "        f.write(\"GroupID\\tSize\\tStartIdx\\tEndIdx\\n\")\n",
        "\n",
        "        group_to_rows = defaultdict(list)\n",
        "        for i, g in enumerate(val_rankers):\n",
        "            group_to_rows[g].append(i)\n",
        "\n",
        "        for group_id, indices in sorted(group_to_rows.items()):\n",
        "            start_idx = indices[0]\n",
        "            end_idx = indices[-1]\n",
        "            size = len(indices)\n",
        "            f.write(f\"{group_id}\\t{size}\\t{start_idx}\\t{end_idx}\\n\")\n",
        "\n",
        "    print(f\"üìÅ Saved validation group info to {group_info_path}\")\n",
        "\n",
        "\n",
        "    cat_dims = build_cat_dims(X, cat_features)\n",
        "    num_numeric_feats = len(num_features)\n",
        "\n",
        "    train_dataset = RankDataset(X_tr, y_tr, groups_tr, cat_features, num_features)\n",
        "    val_dataset = RankDataset(X_va, y_va, groups_va, cat_features, num_features)\n",
        "    test_dataset = RankDataset(X_te, y_te, groups_te, cat_features, num_features)\n",
        "\n",
        "    plot_group_size_distribution(train_dataset, save_path=os.path.join(MODEL_DIR, \"group_sizes.png\"))\n",
        "    print(\"üìä Group size distribution saved.\")\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True, collate_fn=collate_fn)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=4, shuffle=False, collate_fn=collate_fn)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False, collate_fn=collate_fn)\n",
        "\n",
        "    print(\"‚úÖ Data loaders created.\")\n",
        "\n",
        "    num_epochs = 10\n",
        "    num_training_steps = num_epochs * len(train_loader)\n",
        "    num_warmup_steps = int(0.1 * num_training_steps)\n",
        "\n",
        "    learning_rate = 1e-4\n",
        "\n",
        "    model = DLRankerAttention(\n",
        "        cat_dims=cat_dims,\n",
        "        num_numeric_feats=num_numeric_feats,\n",
        "        emb_dropout=0.2,\n",
        "        dropout=0.2,\n",
        "        num_heads=8,\n",
        "        num_layers=3,\n",
        "        dim_feedforward=256,\n",
        "        proj_dim=64\n",
        "    ).to(device)\n",
        "\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=0.01)\n",
        "\n",
        "    scheduler = get_scheduler(\n",
        "        \"linear\",\n",
        "        optimizer=optimizer,\n",
        "        num_warmup_steps=num_warmup_steps,\n",
        "        num_training_steps=num_training_steps\n",
        "    )\n",
        "\n",
        "    best_hitrate = 0\n",
        "    for epoch in range(num_epochs):\n",
        "        print(f\"\\n--- Epoch {epoch+1}/{num_epochs} ---\")\n",
        "        start_time = time.time()\n",
        "\n",
        "        train_loss = train_one_epoch(model, train_loader, optimizer, device, scheduler)\n",
        "        val_loss, val_hitrate, val_ndcg, val_map = validate(model, val_loader, device, min_group_size=10)\n",
        "\n",
        "        train_losses.append(train_loss)\n",
        "        val_losses.append(val_loss)\n",
        "        val_hitrates.append(val_hitrate.item())\n",
        "        val_ndcgs.append(val_ndcg.item())\n",
        "        val_maps.append(val_map.item())\n",
        "\n",
        "        current_lr = scheduler.get_last_lr()\n",
        "        learning_rates.append(current_lr[0])\n",
        "\n",
        "        elapsed = time.time() - start_time\n",
        "        print(\n",
        "            f\"Epoch {epoch+1}: \"\n",
        "            f\"Train Loss={train_loss:.4f}, \"\n",
        "            f\"Val Loss={val_loss:.4f}, \"\n",
        "            f\"HitRate@3={val_hitrate:.4f}, \"\n",
        "            f\"NDCG@3={val_ndcg:.4f}, \"\n",
        "            f\"MAP@3={val_map:.4f}, \"\n",
        "            f\"LR={current_lr[0]:.6f} \"\n",
        "            f\"({elapsed:.1f}s)\"\n",
        "        )\n",
        "\n",
        "\n",
        "        if val_loss < best_val_loss and val_hitrate > best_hitrate:\n",
        "            best_val_loss = val_loss\n",
        "            best_hitrate = val_hitrate\n",
        "            torch.save(model.state_dict(), model_path)\n",
        "            print(\"üíæ Model improved (loss ‚Üì and hitrate ‚Üë), saved.\")\n",
        "\n",
        "        if early_stopper.step(-val_loss):\n",
        "            print(\"‚õî Early stopping triggered.\")\n",
        "            break\n",
        "\n",
        "    # Plot metrics\n",
        "    epochs = list(range(1, len(train_losses) + 1))\n",
        "\n",
        "    # Plot Loss Curve\n",
        "    plt.figure()\n",
        "    plt.plot(epochs, train_losses, label=\"Train Loss\")\n",
        "    plt.plot(epochs, val_losses, label=\"Val Loss\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.title(\"Training & Validation Loss\")\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.savefig(os.path.join(MODEL_DIR, \"loss_curve.png\"))\n",
        "    plt.close()\n",
        "\n",
        "    # Plot HitRate@3\n",
        "    plt.figure()\n",
        "    plt.plot(epochs, val_hitrates, label=\"Val HitRate@3\", color=\"green\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"HitRate@3\")\n",
        "    plt.title(\"Validation HitRate@3\")\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.savefig(os.path.join(MODEL_DIR, \"hitrate_curve.png\"))\n",
        "    plt.close()\n",
        "\n",
        "    # Plot Learning Rate\n",
        "    plt.figure()\n",
        "    plt.plot(epochs, learning_rates, label=\"Learning Rate\", color=\"orange\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"LR\")\n",
        "    plt.title(\"Learning Rate Schedule\")\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.savefig(os.path.join(MODEL_DIR, \"lr_curve.png\"))\n",
        "    plt.close()\n",
        "\n",
        "    # Plot NDCG@3\n",
        "    plt.figure()\n",
        "    plt.plot(epochs, val_ndcgs, label=\"Val NDCG@3\", color=\"purple\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"NDCG@3\")\n",
        "    plt.title(\"Validation NDCG@3\")\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.savefig(os.path.join(MODEL_DIR, \"ndcg_curve.png\"))\n",
        "    plt.close()\n",
        "\n",
        "    # Plot MAP@3\n",
        "    plt.figure()\n",
        "    plt.plot(epochs, val_maps, label=\"Val MAP@3\", color=\"red\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"MAP@3\")\n",
        "    plt.title(\"Validation MAP@3\")\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.savefig(os.path.join(MODEL_DIR, \"map_curve.png\"))\n",
        "    plt.close()\n",
        "\n",
        "    print(\"üìä Saved metric plots to model/\")\n",
        "\n",
        "    # Predict test set\n",
        "    model.load_state_dict(torch.load(model_path))\n",
        "    model.eval()\n",
        "\n",
        "    val_ids = X_va[\"Id\"]\n",
        "    val_rankers = groups_va[\"ranker_id\"]\n",
        "    val_labels = y_va\n",
        "\n",
        "    all_val_scores = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for x_cat, x_num, _, lengths in tqdm(val_loader, desc=\"Predicting validation set\"):\n",
        "            x_num = x_num.to(device)\n",
        "            x_cat = {k: v.to(device) for k, v in x_cat.items()}\n",
        "            scores = model(x_cat, x_num)\n",
        "\n",
        "            for i in range(scores.size(0)):\n",
        "                l = lengths[i]\n",
        "                all_val_scores.append(scores[i, :l].cpu().numpy())\n",
        "\n",
        "    all_val_scores = np.concatenate(all_val_scores)\n",
        "\n",
        "    assert len(all_val_scores) == X_va.shape[0], \\\n",
        "        f\"Mismatch: {len(all_val_scores)} scores vs {X_va.shape[0]} rows\"\n",
        "\n",
        "    val_df = X_va.with_columns([\n",
        "        pl.Series(\"Id\", val_ids),\n",
        "        pl.Series(\"ranker_id\", val_rankers),\n",
        "        pl.Series(\"score\", all_val_scores),\n",
        "        pl.Series(\"label\", val_labels)\n",
        "    ])\n",
        "\n",
        "    val_df = val_df.with_columns(\n",
        "        pl.col(\"score\")\n",
        "        .rank(method=\"ordinal\", descending=True)\n",
        "        .over(\"ranker_id\")\n",
        "        .cast(pl.Int32)\n",
        "        .alias(\"selected\")\n",
        "    )\n",
        "\n",
        "    val_save_path = os.path.join(MODEL_DIR, \"validation_preds_dl_full.csv\")\n",
        "    val_df.write_csv(val_save_path)\n",
        "    print(f\"‚úÖ Saved full validation predictions (with features) to {val_save_path}\")\n",
        "\n",
        "    all_scores = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for x_cat, x_num, _, lengths in tqdm(test_loader, desc=\"Predicting test set\"):\n",
        "            x_num = x_num.to(device)\n",
        "            x_cat = {k: v.to(device) for k, v in x_cat.items()}\n",
        "            scores = model(x_cat, x_num)\n",
        "\n",
        "            for i in range(scores.size(0)):\n",
        "                l = lengths[i]\n",
        "                all_scores.append(scores[i, :l].cpu().numpy())\n",
        "\n",
        "    all_scores = np.concatenate(all_scores)\n",
        "\n",
        "    assert len(all_scores) == X_te.shape[0], \\\n",
        "        f\"Mismatch: {len(all_scores)} scores vs {X_te.shape[0]} rows in X_te\"\n",
        "\n",
        "    submission_df = pl.DataFrame({\n",
        "        \"Id\": test_ids,\n",
        "        \"ranker_id\": test_rankers,\n",
        "        \"score\": all_scores\n",
        "    })\n",
        "\n",
        "    submission = (\n",
        "        submission_df\n",
        "        .with_columns(\n",
        "            pl.col(\"score\")\n",
        "            .rank(method=\"ordinal\", descending=True)\n",
        "            .over(\"ranker_id\")\n",
        "            .cast(pl.Int32)\n",
        "            .alias(\"selected\")\n",
        "        )\n",
        "        .select([\"Id\", \"ranker_id\", \"score\", \"selected\"])\n",
        "    )\n",
        "\n",
        "    submission_path = os.path.join(SUBMIT_DIR, \"submission_dl_ranker.csv\")\n",
        "    submission.write_csv(submission_path)\n",
        "    print(f\"‚úÖ Submission saved to {submission_path}\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DaJyhnV92Mdh",
        "outputId": "0b098cb2-487a-477d-ebc0-a0b2d44a0610"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting deeprec_validate.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "--- Epoch 1/10 ---\n",
        "Validating:   0%|          | 0/2636 [00:00<?, ?it/s]/home/ionut/test_whisper/test2/deeprec_validate.py:507: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
        "  lengths = torch.tensor(lengths).to(device)\n",
        "Epoch 1: Train Loss=0.4052, Val Loss=0.3081, HitRate@3=0.4668, NDCG@3=0.3688, MAP@3=0.6106, LR=0.000100 (712.8s)\n",
        "üíæ Model improved (loss ‚Üì and hitrate ‚Üë), saved.\n",
        "\n",
        "--- Epoch 2/10 ---\n",
        "Epoch 2: Train Loss=0.2998, Val Loss=0.2927, HitRate@3=0.4705, NDCG@3=0.3740, MAP@3=0.6192, LR=0.000089 (713.7s)\n",
        "üíæ Model improved (loss ‚Üì and hitrate ‚Üë), saved.\n",
        "\n",
        "--- Epoch 3/10 ---\n",
        "Epoch 3: Train Loss=0.2819, Val Loss=0.2735, HitRate@3=0.4969, NDCG@3=0.3980, MAP@3=0.6364, LR=0.000078 (714.7s)\n",
        "üíæ Model improved (loss ‚Üì and hitrate ‚Üë), saved.\n",
        "\n",
        "--- Epoch 4/10 ---\n",
        "Epoch 4: Train Loss=0.2688, Val Loss=0.2676, HitRate@3=0.4995, NDCG@3=0.4034, MAP@3=0.6480, LR=0.000067 (713.3s)\n",
        "üíæ Model improved (loss ‚Üì and hitrate ‚Üë), saved.\n",
        "\n",
        "--- Epoch 5/10 ---\n",
        "Epoch 5: Train Loss=0.2604, Val Loss=0.2637, HitRate@3=0.4975, NDCG@3=0.3973, MAP@3=0.6355, LR=0.000056 (715.3s)\n",
        "\n",
        "--- Epoch 6/10 ---\n",
        "Epoch 6: Train Loss=0.2508, Val Loss=0.2598, HitRate@3=0.5024, NDCG@3=0.4057, MAP@3=0.6475, LR=0.000044 (716.7s)\n",
        "üíæ Model improved (loss ‚Üì and hitrate ‚Üë), saved.\n",
        "\n",
        "--- Epoch 7/10 ---\n",
        "Epoch 7: Train Loss=0.2424, Val Loss=0.2582, HitRate@3=0.5061, NDCG@3=0.4069, MAP@3=0.6486, LR=0.000033 (714.8s)\n",
        "üíæ Model improved (loss ‚Üì and hitrate ‚Üë), saved.\n",
        "\n",
        "--- Epoch 8/10 ---\n",
        "Epoch 8: Train Loss=0.2370, Val Loss=0.2533, HitRate@3=0.5108, NDCG@3=0.4109, MAP@3=0.6505, LR=0.000022 (714.3s)\n",
        "üíæ Model improved (loss ‚Üì and hitrate ‚Üë), saved.\n",
        "\n",
        "--- Epoch 9/10 ---\n",
        "Epoch 9: Train Loss=0.2311, Val Loss=0.2529, HitRate@3=0.5183, NDCG@3=0.4153, MAP@3=0.6502, LR=0.000011 (712.8s)\n",
        "üíæ Model improved (loss ‚Üì and hitrate ‚Üë), saved.\n",
        "\n",
        "--- Epoch 10/10 ---\n",
        "Epoch 10: Train Loss=0.2269, Val Loss=0.2518, HitRate@3=0.5139, NDCG@3=0.4138, MAP@3=0.6534, LR=0.000000 (716.0s)"
      ],
      "metadata": {
        "id": "v2Yf-79LaN4Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile deeprec_validate.py\n",
        "import os\n",
        "import time\n",
        "import random\n",
        "import torch\n",
        "import math\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import defaultdict\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "import polars as pl\n",
        "from tqdm import tqdm\n",
        "from src.feature import feature_engineering, feature_selection\n",
        "from transformers import get_scheduler\n",
        "from collections import Counter\n",
        "\n",
        "class RankDataset(Dataset):\n",
        "    def __init__(\n",
        "        self,\n",
        "        X: pl.DataFrame,\n",
        "        y: pl.Series,\n",
        "        groups: pl.DataFrame,\n",
        "        cat_features: list[str],\n",
        "        num_features: list[str],\n",
        "    ):\n",
        "        self.cat_features = cat_features\n",
        "        self.num_features = num_features\n",
        "        self.X_cat = {c: X[c].to_numpy() for c in cat_features}\n",
        "        self.X_num = X[self.num_features].to_numpy()\n",
        "        self.y = y.to_numpy()\n",
        "        self.groups = groups[\"ranker_id\"].to_numpy()\n",
        "\n",
        "        self.group_to_indices = defaultdict(list)\n",
        "        for i, g in enumerate(self.groups):\n",
        "            self.group_to_indices[g].append(i)\n",
        "        self.group_keys = list(self.group_to_indices.keys())\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.group_keys)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        g = self.group_keys[idx]\n",
        "        inds = self.group_to_indices[g]\n",
        "        length = len(inds)\n",
        "\n",
        "        x_cat = {\n",
        "            c: torch.LongTensor([\n",
        "                self.X_cat[c][i] if self.X_cat[c][i] >= 0 else 0 for i in inds\n",
        "            ])\n",
        "            for c in self.cat_features\n",
        "        }\n",
        "\n",
        "        x_num = torch.FloatTensor(self.X_num[inds])\n",
        "        y = torch.FloatTensor(self.y[inds]).reshape(-1)\n",
        "\n",
        "        return x_cat, x_num, y, length\n",
        "\n",
        "def collate_fn(batch):\n",
        "    batch_size = len(batch)\n",
        "    lengths = [b[3] for b in batch]\n",
        "    max_len = max(lengths)\n",
        "\n",
        "    padded_x_cat = {key: [] for key in batch[0][0].keys()}\n",
        "    padded_x_num = []\n",
        "    padded_y = []\n",
        "\n",
        "    num_dim = batch[0][1].shape[1]\n",
        "\n",
        "    for x_cat, x_num, y, length in batch:\n",
        "        pad_len = max_len - length\n",
        "\n",
        "        for key in padded_x_cat:\n",
        "            val = x_cat[key]\n",
        "            if pad_len > 0:\n",
        "                val = torch.cat([val, torch.zeros(pad_len, dtype=torch.long)])\n",
        "            padded_x_cat[key].append(val)\n",
        "\n",
        "        if pad_len > 0:\n",
        "            x_num = torch.cat([x_num, torch.zeros(pad_len, num_dim)])\n",
        "            y = torch.cat([y, torch.zeros(pad_len)])\n",
        "\n",
        "        padded_x_num.append(x_num)\n",
        "        padded_y.append(y)\n",
        "\n",
        "    padded_x_cat = {k: torch.stack(v) for k, v in padded_x_cat.items()}\n",
        "    padded_x_num = torch.stack(padded_x_num)\n",
        "    padded_y = torch.stack(padded_y)\n",
        "    lengths = torch.tensor(lengths, dtype=torch.long)\n",
        "\n",
        "    return padded_x_cat, padded_x_num, padded_y, lengths\n",
        "\n",
        "class SEModule(nn.Module):\n",
        "    def __init__(self, channel, reduction=4):\n",
        "        super().__init__()\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(channel, channel // reduction),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(channel // reduction, channel),\n",
        "            nn.Sigmoid(),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: [B, N, C]\n",
        "        w = self.fc(x.mean(dim=1))\n",
        "        w = w.unsqueeze(1)  # [B, 1, C]\n",
        "        return x * w\n",
        "\n",
        "\n",
        "class DLRankerAttention(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        cat_dims,\n",
        "        num_numeric_feats,\n",
        "        emb_dropout=0.1,\n",
        "        dropout=0.1,\n",
        "        num_heads=4,\n",
        "        num_layers=2,\n",
        "        dim_feedforward=128,\n",
        "        proj_dim=64,\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "        self.emb_dims = {\n",
        "            f: min(50, max(4, round(6 * math.log2(cat_dims[f] + 1)))) for f in cat_dims\n",
        "        }\n",
        "        self.embeddings = nn.ModuleDict(\n",
        "            {\n",
        "                f: nn.Embedding(cat_dims[f], self.emb_dims[f], padding_idx=0)\n",
        "                for f in cat_dims\n",
        "            }\n",
        "        )\n",
        "        self.emb_dropout = nn.Dropout(emb_dropout)\n",
        "\n",
        "        total_emb_dim = sum(self.emb_dims.values())\n",
        "        print(\n",
        "            f\"Categorial emb dim sum: {total_emb_dim}, Numerical dim: {num_numeric_feats}\"\n",
        "        )\n",
        "\n",
        "        self.cat_proj = nn.Linear(total_emb_dim, proj_dim)\n",
        "        self.cat_transformer = nn.TransformerEncoder(\n",
        "            nn.TransformerEncoderLayer(\n",
        "                d_model=proj_dim,\n",
        "                nhead=4,\n",
        "                dim_feedforward=dim_feedforward,\n",
        "                dropout=dropout,\n",
        "                batch_first=True,\n",
        "            ),\n",
        "            num_layers=1,\n",
        "        )\n",
        "\n",
        "\n",
        "        self.num_proj_in = nn.Linear(num_numeric_feats, proj_dim)\n",
        "        self.num_transformer = nn.TransformerEncoder(\n",
        "            nn.TransformerEncoderLayer(\n",
        "                d_model=proj_dim,\n",
        "                nhead=4,\n",
        "                dim_feedforward=dim_feedforward,\n",
        "                dropout=dropout,\n",
        "                batch_first=True,\n",
        "            ),\n",
        "            num_layers=1,\n",
        "        )\n",
        "        self.num_se = SEModule(proj_dim)\n",
        "        self.num_proj_out = nn.Sequential(\n",
        "            nn.Linear(proj_dim, proj_dim),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(dropout),\n",
        "        )\n",
        "\n",
        "        self.transformer_layers = nn.ModuleList(\n",
        "            [\n",
        "                nn.TransformerEncoderLayer(\n",
        "                    d_model=2 * proj_dim,\n",
        "                    nhead=num_heads,\n",
        "                    dim_feedforward=dim_feedforward,\n",
        "                    dropout=dropout,\n",
        "                    batch_first=True,\n",
        "                )\n",
        "                for _ in range(num_layers)\n",
        "            ]\n",
        "        )\n",
        "\n",
        "        self.mlp = nn.Sequential(\n",
        "            nn.Linear(2 * proj_dim, 128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(128, 64),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(64, 1),\n",
        "        )\n",
        "\n",
        "    def forward(self, x_cat: dict, x_num: torch.Tensor, attn_mask=None):\n",
        "        B, N, _ = x_num.shape  # x_num: [B, N, F_num]\n",
        "\n",
        "        cat_emb_list = []\n",
        "        for f, emb_layer in self.embeddings.items():\n",
        "            emb = emb_layer(x_cat[f])  # [B, N]\n",
        "            cat_emb_list.append(emb)\n",
        "        cat_embs = torch.cat(cat_emb_list, dim=-1)  # [B, N, total_emb_dim]\n",
        "        cat_embs = self.emb_dropout(cat_embs)\n",
        "        cat_feat = self.cat_proj(cat_embs)  # [B, N, proj_dim]\n",
        "        cat_feat = self.cat_transformer(cat_feat)  # [B, N, proj_dim]\n",
        "\n",
        "        num_feat = self.num_proj_in(x_num)  # [B, N, proj_dim]\n",
        "        num_feat = self.num_transformer(num_feat)  # [B, N, proj_dim]\n",
        "        num_feat = self.num_se(num_feat)  # [B, N, proj_dim]\n",
        "        num_feat = self.num_proj_out(num_feat)  # [B, N, proj_dim]\n",
        "\n",
        "        x = torch.cat([cat_feat, num_feat], dim=-1)  # [B, N, 2*proj_dim]\n",
        "\n",
        "        for layer in self.transformer_layers:\n",
        "            x = layer(x, src_key_padding_mask=attn_mask)\n",
        "\n",
        "        scores = self.mlp(x).squeeze(-1)  # [B, N]\n",
        "\n",
        "        return scores\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "def listmle_loss(scores, labels, lengths):\n",
        "    batch_size = scores.size(0)\n",
        "    total_loss = torch.tensor(0.0, device=scores.device, requires_grad=True)\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "\n",
        "        _, idx = torch.sort(y, descending=True)\n",
        "        s_sorted = s[idx]\n",
        "\n",
        "        parts = (\n",
        "            torch.logsumexp(s_sorted.unsqueeze(0).expand(l, -1).triu(diagonal=0), dim=1)\n",
        "            - s_sorted\n",
        "        )\n",
        "\n",
        "        total_loss = total_loss + parts.sum()\n",
        "\n",
        "    return total_loss / batch_size\n",
        "\"\"\"\n",
        "\n",
        "def hitrate_at_k(scores, labels, lengths, k=3, min_group_size=10):\n",
        "    batch_size = scores.size(0)\n",
        "    hits = 0\n",
        "    valid_count = 0\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        if l < min_group_size:\n",
        "            continue\n",
        "        length = min(l, k)\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "        _, topk_idx = torch.topk(s, length)\n",
        "        topk_labels = y[topk_idx]\n",
        "        hits += (topk_labels > 0).any().float()\n",
        "        valid_count += 1\n",
        "    return hits / valid_count if valid_count > 0 else torch.tensor(0.0, device=scores.device)\n",
        "\n",
        "\n",
        "def ndcg_at_k(scores, labels, lengths, k=3, min_group_size=10):\n",
        "    batch_size = scores.size(0)\n",
        "    total_ndcg = 0.0\n",
        "    valid_count = 0\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        if l < min_group_size:\n",
        "            continue\n",
        "\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "\n",
        "        _, idx_pred = torch.topk(s, min(k, l))\n",
        "        _, idx_ideal = torch.topk(y, min(k, l))\n",
        "\n",
        "        dcg = (y[idx_pred] / torch.log2(torch.arange(2, 2 + len(idx_pred), device=y.device).float())).sum()\n",
        "        idcg = (y[idx_ideal] / torch.log2(torch.arange(2, 2 + len(idx_ideal), device=y.device).float())).sum()\n",
        "\n",
        "        ndcg = dcg / idcg if idcg > 0 else 0.0\n",
        "        total_ndcg += ndcg\n",
        "        valid_count += 1\n",
        "\n",
        "    return total_ndcg / valid_count if valid_count > 0 else torch.tensor(0.0, device=scores.device)\n",
        "\n",
        "\n",
        "def map_at_k(scores, labels, lengths, k=3, min_group_size=10):\n",
        "    batch_size = scores.size(0)\n",
        "    total_ap = 0.0\n",
        "    valid_count = 0\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        if l < min_group_size:\n",
        "            continue\n",
        "\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "\n",
        "        _, idx_pred = torch.topk(s, min(k, l))\n",
        "        y_true = y[idx_pred] > 0\n",
        "\n",
        "        if y_true.sum() == 0:\n",
        "            continue\n",
        "\n",
        "        precisions = [(y_true[:j+1].float().sum() / (j+1)) for j in range(len(y_true)) if y_true[j]]\n",
        "        ap = torch.stack(precisions).mean()\n",
        "        total_ap += ap\n",
        "        valid_count += 1\n",
        "\n",
        "    return total_ap / valid_count if valid_count > 0 else torch.tensor(0.0, device=scores.device)\n",
        "\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "def listnet_loss(scores, labels, lengths):\n",
        "    batch_size = scores.size(0)\n",
        "    total_loss = 0.0\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "\n",
        "        s_softmax = torch.nn.functional.log_softmax(s, dim=0)\n",
        "        y_softmax = torch.nn.functional.softmax(y, dim=0)\n",
        "\n",
        "        loss = -torch.sum(y_softmax * s_softmax)\n",
        "        total_loss += loss\n",
        "\n",
        "    return total_loss / batch_size\n",
        "\"\"\"\n",
        "\n",
        "def ranknet_loss(scores, labels, lengths):\n",
        "    batch_size = scores.size(0)\n",
        "    total_loss = 0.0\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "\n",
        "        diff_scores = s.unsqueeze(1) - s.unsqueeze(0)\n",
        "        rel = y.unsqueeze(1) > y.unsqueeze(0)\n",
        "        label_diff = rel.float()\n",
        "\n",
        "        log_sigmoid = torch.nn.functional.logsigmoid(diff_scores)\n",
        "        pair_loss = -label_diff * log_sigmoid\n",
        "\n",
        "        total_loss += pair_loss.sum()\n",
        "\n",
        "    return total_loss / batch_size\n",
        "\n",
        "def xranknet_loss(scores, labels, lengths, temperature=1.0, margin=0.2, focus_topk=3):\n",
        "    \"\"\"\n",
        "    xRankNet with emphasis on top-K items (based on labels, not scores).\n",
        "    \"\"\"\n",
        "    batch_size = scores.size(0)\n",
        "    total_loss = 0.0\n",
        "    total_pairs = 0\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        if l < 2:\n",
        "            continue\n",
        "\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "\n",
        "        # Top-K mask based on ground truth labels\n",
        "        topk = min(focus_topk, l)\n",
        "        _, topk_idx = torch.topk(y, topk)\n",
        "        topk_mask = torch.zeros_like(y, dtype=torch.bool)\n",
        "        topk_mask[topk_idx] = True\n",
        "\n",
        "        # Create pairwise difference matrices\n",
        "        score_diff = s.unsqueeze(1) - s.unsqueeze(0)\n",
        "        label_diff = y.unsqueeze(1) - y.unsqueeze(0)\n",
        "\n",
        "        # valid pair: y_i > y_j and at least one of i, j is in top-K\n",
        "        valid_pairs = (label_diff > 0) & (\n",
        "            topk_mask.unsqueeze(1) | topk_mask.unsqueeze(0)\n",
        "        )\n",
        "\n",
        "        if valid_pairs.sum() == 0:\n",
        "            continue\n",
        "\n",
        "        importance = (label_diff.abs() * valid_pairs).float()\n",
        "\n",
        "        if margin > 0.0:\n",
        "            score_diff = score_diff - margin\n",
        "\n",
        "        score_diff = score_diff / temperature\n",
        "        pairwise_loss = -F.logsigmoid(score_diff) * importance\n",
        "\n",
        "        total_loss += pairwise_loss.sum()\n",
        "        total_pairs += importance.sum()\n",
        "\n",
        "    if total_pairs == 0:\n",
        "        return torch.tensor(0.0, device=scores.device, requires_grad=True)\n",
        "\n",
        "    return total_loss / total_pairs\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "def bpr_loss(scores, labels, lengths):\n",
        "    batch_size = scores.size(0)\n",
        "    total_loss = 0.0\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "\n",
        "        pos_mask = y > 0\n",
        "        neg_mask = y <= 0\n",
        "\n",
        "        pos_scores = s[pos_mask]\n",
        "        neg_scores = s[neg_mask]\n",
        "\n",
        "        if len(pos_scores) == 0 or len(neg_scores) == 0:\n",
        "            continue\n",
        "\n",
        "        pair_diff = pos_scores.unsqueeze(1) - neg_scores.unsqueeze(0)\n",
        "        loss = -F.logsigmoid(pair_diff).mean()\n",
        "        total_loss += loss\n",
        "\n",
        "    return total_loss / batch_size\n",
        "\"\"\"\n",
        "\n",
        "\"\"\"\n",
        "def lambdarank_loss(scores, labels, lengths, eps=1e-10):\n",
        "    batch_size = scores.size(0)\n",
        "    total_loss = 0.0\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "\n",
        "        if l < 2:\n",
        "            continue\n",
        "\n",
        "        _, rank_order = torch.sort(s, descending=True)\n",
        "        ideal_order = torch.sort(y, descending=True).indices\n",
        "\n",
        "        gain = 2 ** y - 1\n",
        "        discount = torch.log2(torch.arange(2, l + 2, device=y.device).float())\n",
        "\n",
        "        ideal_dcg = (gain[ideal_order] / discount).sum()\n",
        "        if ideal_dcg < eps:\n",
        "            continue\n",
        "\n",
        "        delta_ndcg = torch.zeros((l, l), device=y.device)\n",
        "\n",
        "        for i_idx in range(l):\n",
        "            for j_idx in range(l):\n",
        "                if y[i_idx] > y[j_idx]:\n",
        "                    change = (\n",
        "                        (1.0 / torch.log2(rank_order[i_idx] + 2.0))\n",
        "                        - (1.0 / torch.log2(rank_order[j_idx] + 2.0))\n",
        "                    ).abs()\n",
        "                    delta = (2 ** y[i_idx] - 2 ** y[j_idx]).abs() * change\n",
        "                    delta_ndcg[i_idx, j_idx] = delta / ideal_dcg\n",
        "\n",
        "        score_diffs = s.unsqueeze(1) - s.unsqueeze(0)\n",
        "        lambdas = -F.logsigmoid(score_diffs) * delta_ndcg\n",
        "        total_loss += lambdas.sum()\n",
        "\n",
        "    return total_loss / batch_size\n",
        "\"\"\"\n",
        "\n",
        "def train_one_epoch(model, loader, optimizer, device, scheduler):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "\n",
        "    for x_cat, x_num, y, lengths in tqdm(loader, desc=\"Training\", leave=False):\n",
        "        x_num, y = x_num.to(device), y.to(device)\n",
        "        if not isinstance(lengths, torch.Tensor):\n",
        "            lengths = torch.tensor(lengths)\n",
        "        lengths = lengths.detach().clone().to(device)\n",
        "        x_cat = {k: v.to(device) for k, v in x_cat.items()}\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        scores = model(x_cat, x_num)\n",
        "        loss = xranknet_loss(scores, y, lengths, temperature=1.0, margin=0.2, focus_topk=3)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    return total_loss / len(loader)\n",
        "\n",
        "\n",
        "def validate(model, loader, device, min_group_size=10):\n",
        "    model.eval()\n",
        "    total_hitrate = 0\n",
        "    total_ndcg = 0\n",
        "    total_map = 0\n",
        "    total_loss = 0\n",
        "    count = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for x_cat, x_num, y, lengths in tqdm(loader, desc=\"Validating\", leave=False):\n",
        "            x_num, y = x_num.to(device), y.to(device)\n",
        "            lengths = torch.tensor(lengths).to(device)\n",
        "            x_cat = {k: v.to(device) for k, v in x_cat.items()}\n",
        "\n",
        "            scores = model(x_cat, x_num)\n",
        "\n",
        "            hitrate = hitrate_at_k(scores, y, lengths, k=3, min_group_size=min_group_size)\n",
        "            ndcg = ndcg_at_k(scores, y, lengths, k=3, min_group_size=min_group_size)\n",
        "            map3 = map_at_k(scores, y, lengths, k=3, min_group_size=min_group_size)\n",
        "            loss = xranknet_loss(scores, y, lengths, temperature=1.0, margin=0.2, focus_topk=3)\n",
        "\n",
        "            batch_size = scores.size(0)\n",
        "            total_hitrate += hitrate * batch_size\n",
        "            total_ndcg += ndcg * batch_size\n",
        "            total_map += map3 * batch_size\n",
        "            total_loss += loss.item() * batch_size\n",
        "            count += batch_size\n",
        "\n",
        "    return total_loss / count, total_hitrate / count, total_ndcg / count, total_map / count\n",
        "\n",
        "\n",
        "def build_cat_dims(X, cat_features):\n",
        "    cat_dims = {}\n",
        "    for c in cat_features:\n",
        "        max_val = X[c].max()\n",
        "        if max_val < 0:\n",
        "            max_val = 0\n",
        "        cat_dims[c] = max_val + 1\n",
        "    return cat_dims\n",
        "\n",
        "\n",
        "def normalize_numeric_features(X, numeric_features, train_mask):\n",
        "    for col in numeric_features:\n",
        "        values = X[col].to_numpy()\n",
        "        train_vals = values[train_mask]\n",
        "        mean = train_vals.mean()\n",
        "        std = train_vals.std() if train_vals.std() > 0 else 1.0\n",
        "        norm_vals = (values - mean) / std\n",
        "        X = X.with_columns(pl.Series(col, norm_vals).alias(col))\n",
        "    return X\n",
        "\n",
        "\n",
        "def load_or_prepare_data(\n",
        "    data_dir,\n",
        "    train_file=\"train.parquet\",\n",
        "    test_file=\"test.parquet\",\n",
        "    cache_file=\"feature_engineered_val.parquet\",\n",
        "):\n",
        "    cache_path = os.path.join(data_dir, cache_file)\n",
        "\n",
        "    if os.path.exists(cache_path):\n",
        "        print(f\"Loading cached feature-engineered data from {cache_path} ...\")\n",
        "        df = pl.read_parquet(cache_path)\n",
        "\n",
        "        test = pl.read_parquet(os.path.join(data_dir, test_file)).drop(\"__index_level_0__\")\n",
        "        test_ids = test[\"Id\"]\n",
        "        test_rankers = test[\"ranker_id\"]\n",
        "    else:\n",
        "        print(\"Cached file not found, processing raw data ...\")\n",
        "\n",
        "        train = pl.read_parquet(os.path.join(data_dir, train_file)).drop(\"__index_level_0__\")\n",
        "        test = (\n",
        "            pl.read_parquet(os.path.join(data_dir, test_file))\n",
        "            .drop(\"__index_level_0__\")\n",
        "            .with_columns(pl.lit(0, dtype=pl.Int64).alias(\"selected\"))\n",
        "        )\n",
        "\n",
        "        test_ids = test[\"Id\"]\n",
        "        test_rankers = test[\"ranker_id\"]\n",
        "\n",
        "        df = pl.concat((train, test))\n",
        "        df = feature_engineering(df, full=True)\n",
        "\n",
        "        df = df.with_columns(\n",
        "            [pl.col(c).fill_null(0) for c in df.select(pl.selectors.numeric()).columns] +\n",
        "            [pl.col(c).fill_null(\"missing\") for c in df.select(pl.selectors.string()).columns]\n",
        "        )\n",
        "\n",
        "        os.makedirs(data_dir, exist_ok=True)\n",
        "        df.write_parquet(cache_path)\n",
        "        print(f\"Saved feature-engineered data to {cache_path}\")\n",
        "\n",
        "    return df, test_ids, test_rankers\n",
        "\n",
        "\n",
        "def prepare_data(data_dir):\n",
        "    df, test_ids, test_rankers = load_or_prepare_data(data_dir)\n",
        "\n",
        "    id_column = df[\"Id\"]\n",
        "    X, y, groups, cat_features, num_features = feature_selection(df)\n",
        "\n",
        "    X = X.with_columns(pl.Series(\"Id\", id_column[:X.shape[0]]))\n",
        "\n",
        "    X = X.with_columns(\n",
        "        [\n",
        "            (pl.col(c).rank(\"dense\") - 1).fill_null(-1).cast(pl.Int32)\n",
        "            for c in cat_features\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    train_size = 18145372\n",
        "    train_mask = np.arange(X.height) < train_size\n",
        "    X = normalize_numeric_features(X, num_features, train_mask)\n",
        "\n",
        "    return X, y, groups, cat_features, num_features, train_size, test_ids, test_rankers\n",
        "\n",
        "\n",
        "class EarlyStopping:\n",
        "    def __init__(self, patience=3, min_delta=0.00005):\n",
        "        self.patience = patience\n",
        "        self.min_delta = min_delta\n",
        "        self.best = float(\"-inf\")\n",
        "        self.counter = 0\n",
        "\n",
        "    def step(self, metric):\n",
        "        if metric > self.best + self.min_delta:\n",
        "            self.best = metric\n",
        "            self.counter = 0\n",
        "        else:\n",
        "            self.counter += 1\n",
        "        return self.counter >= self.patience\n",
        "\n",
        "\n",
        "def plot_group_size_distribution(dataset, save_path=None):\n",
        "    group_sizes = [len(v) for v in dataset.group_to_indices.values()]\n",
        "    plt.figure()\n",
        "    plt.hist(group_sizes, bins=100, log=True)\n",
        "    plt.xlabel(\"Group size (number of items per ranker_id)\")\n",
        "    plt.ylabel(\"Frequency (log scale)\")\n",
        "    plt.title(\"Distribution of Group Sizes\")\n",
        "    plt.grid(True)\n",
        "    if save_path:\n",
        "        plt.savefig(save_path)\n",
        "    else:\n",
        "        plt.show()\n",
        "    plt.close()\n",
        "\n",
        "\n",
        "def main():\n",
        "    DATA_DIR = \"./data\"\n",
        "    MODEL_DIR = \"model\"\n",
        "    SUBMIT_DIR = \"submission\"\n",
        "\n",
        "    best_val_loss = float(\"inf\")\n",
        "    best_hitrate = 0.0\n",
        "    model_path = os.path.join(MODEL_DIR, \"best_dl_ranker.pt\")\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "    val_hitrates = []\n",
        "    val_ndcgs = []\n",
        "    val_maps = []\n",
        "    learning_rates = []\n",
        "\n",
        "    os.makedirs(MODEL_DIR, exist_ok=True)\n",
        "    os.makedirs(SUBMIT_DIR, exist_ok=True)\n",
        "\n",
        "    early_stopper = EarlyStopping(patience=3, min_delta=0.001)\n",
        "\n",
        "    X, y, groups, cat_features, num_features, train_size, test_ids, test_rankers = prepare_data(DATA_DIR)\n",
        "\n",
        "    # Fill missing values\n",
        "    float_cols = [c for c, t in zip(X.columns, X.dtypes) if t == pl.Float64]\n",
        "    for col in float_cols:\n",
        "        X = X.with_columns(\n",
        "            pl.when(pl.col(col).is_nan()).then(0).otherwise(pl.col(col)).alias(col)\n",
        "        )\n",
        "\n",
        "    n1 = 16487352\n",
        "    # n1 = 17487300\n",
        "    n2 = train_size\n",
        "\n",
        "    X_tr, X_va, X_te = X[:n1], X[n1:n2], X[n2:]\n",
        "    y_tr, y_va, y_te = y[:n1], y[n1:n2], y[n2:]\n",
        "    groups_tr, groups_va, groups_te = groups[:n1], groups[n1:n2], groups[n2:]\n",
        "\n",
        "    # Inspect group sizes in validation set\n",
        "    val_rankers = groups_va[\"ranker_id\"].to_numpy()\n",
        "    val_group_counts = Counter(val_rankers)\n",
        "\n",
        "    print(\"\\nüìã Validation group statistics:\")\n",
        "    # Save detailed group info to file\n",
        "    group_info_path = os.path.join(MODEL_DIR, \"validation_groups_info.txt\")\n",
        "    with open(group_info_path, \"w\") as f:\n",
        "        f.write(f\"Total groups: {len(val_group_counts)}\\n\\n\")\n",
        "        f.write(\"GroupID\\tSize\\tStartIdx\\tEndIdx\\n\")\n",
        "\n",
        "        group_to_rows = defaultdict(list)\n",
        "        for i, g in enumerate(val_rankers):\n",
        "            group_to_rows[g].append(i)\n",
        "\n",
        "        for group_id, indices in sorted(group_to_rows.items()):\n",
        "            start_idx = indices[0]\n",
        "            end_idx = indices[-1]\n",
        "            size = len(indices)\n",
        "            f.write(f\"{group_id}\\t{size}\\t{start_idx}\\t{end_idx}\\n\")\n",
        "\n",
        "    print(f\"üìÅ Saved validation group info to {group_info_path}\")\n",
        "\n",
        "\n",
        "    cat_dims = build_cat_dims(X, cat_features)\n",
        "    num_numeric_feats = len(num_features)\n",
        "\n",
        "    train_dataset = RankDataset(X_tr, y_tr, groups_tr, cat_features, num_features)\n",
        "    val_dataset = RankDataset(X_va, y_va, groups_va, cat_features, num_features)\n",
        "    test_dataset = RankDataset(X_te, y_te, groups_te, cat_features, num_features)\n",
        "\n",
        "    plot_group_size_distribution(train_dataset, save_path=os.path.join(MODEL_DIR, \"group_sizes.png\"))\n",
        "    print(\"üìä Group size distribution saved.\")\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True, collate_fn=collate_fn)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=4, shuffle=False, collate_fn=collate_fn)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False, collate_fn=collate_fn)\n",
        "\n",
        "    print(\"‚úÖ Data loaders created.\")\n",
        "\n",
        "    num_epochs = 10\n",
        "    num_training_steps = num_epochs * len(train_loader)\n",
        "    num_warmup_steps = int(0.1 * num_training_steps)\n",
        "\n",
        "    learning_rate = 1e-4\n",
        "\n",
        "    model = DLRankerAttention(\n",
        "        cat_dims=cat_dims,\n",
        "        num_numeric_feats=num_numeric_feats,\n",
        "        emb_dropout=0.25,\n",
        "        dropout=0.25,\n",
        "        num_heads=8,\n",
        "        num_layers=4,\n",
        "        dim_feedforward=512,\n",
        "        proj_dim=128\n",
        "    ).to(device)\n",
        "\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=0.01)\n",
        "\n",
        "    scheduler = get_scheduler(\n",
        "        \"linear\",\n",
        "        optimizer=optimizer,\n",
        "        num_warmup_steps=num_warmup_steps,\n",
        "        num_training_steps=num_training_steps\n",
        "    )\n",
        "\n",
        "    best_hitrate = 0\n",
        "    for epoch in range(num_epochs):\n",
        "        print(f\"\\n--- Epoch {epoch+1}/{num_epochs} ---\")\n",
        "        start_time = time.time()\n",
        "\n",
        "        train_loss = train_one_epoch(model, train_loader, optimizer, device, scheduler)\n",
        "        val_loss, val_hitrate, val_ndcg, val_map = validate(model, val_loader, device, min_group_size=10)\n",
        "\n",
        "        train_losses.append(train_loss)\n",
        "        val_losses.append(val_loss)\n",
        "        val_hitrates.append(val_hitrate.item())\n",
        "        val_ndcgs.append(val_ndcg.item())\n",
        "        val_maps.append(val_map.item())\n",
        "\n",
        "        current_lr = scheduler.get_last_lr()\n",
        "        learning_rates.append(current_lr[0])\n",
        "\n",
        "        elapsed = time.time() - start_time\n",
        "        print(\n",
        "            f\"Epoch {epoch+1}: \"\n",
        "            f\"Train Loss={train_loss:.4f}, \"\n",
        "            f\"Val Loss={val_loss:.4f}, \"\n",
        "            f\"HitRate@3={val_hitrate:.4f}, \"\n",
        "            f\"NDCG@3={val_ndcg:.4f}, \"\n",
        "            f\"MAP@3={val_map:.4f}, \"\n",
        "            f\"LR={current_lr[0]:.6f} \"\n",
        "            f\"({elapsed:.1f}s)\"\n",
        "        )\n",
        "\n",
        "\n",
        "        if val_loss < best_val_loss and val_hitrate > best_hitrate:\n",
        "            best_val_loss = val_loss\n",
        "            best_hitrate = val_hitrate\n",
        "            torch.save(model.state_dict(), model_path)\n",
        "            print(\"üíæ Model improved (loss ‚Üì and hitrate ‚Üë), saved.\")\n",
        "\n",
        "        if early_stopper.step(-val_loss):\n",
        "            print(\"‚õî Early stopping triggered.\")\n",
        "            break\n",
        "\n",
        "    # Plot metrics\n",
        "    epochs = list(range(1, len(train_losses) + 1))\n",
        "\n",
        "    # Plot Loss Curve\n",
        "    plt.figure()\n",
        "    plt.plot(epochs, train_losses, label=\"Train Loss\")\n",
        "    plt.plot(epochs, val_losses, label=\"Val Loss\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.title(\"Training & Validation Loss\")\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.savefig(os.path.join(MODEL_DIR, \"loss_curve.png\"))\n",
        "    plt.close()\n",
        "\n",
        "    # Plot HitRate@3\n",
        "    plt.figure()\n",
        "    plt.plot(epochs, val_hitrates, label=\"Val HitRate@3\", color=\"green\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"HitRate@3\")\n",
        "    plt.title(\"Validation HitRate@3\")\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.savefig(os.path.join(MODEL_DIR, \"hitrate_curve.png\"))\n",
        "    plt.close()\n",
        "\n",
        "    # Plot Learning Rate\n",
        "    plt.figure()\n",
        "    plt.plot(epochs, learning_rates, label=\"Learning Rate\", color=\"orange\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"LR\")\n",
        "    plt.title(\"Learning Rate Schedule\")\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.savefig(os.path.join(MODEL_DIR, \"lr_curve.png\"))\n",
        "    plt.close()\n",
        "\n",
        "    # Plot NDCG@3\n",
        "    plt.figure()\n",
        "    plt.plot(epochs, val_ndcgs, label=\"Val NDCG@3\", color=\"purple\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"NDCG@3\")\n",
        "    plt.title(\"Validation NDCG@3\")\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.savefig(os.path.join(MODEL_DIR, \"ndcg_curve.png\"))\n",
        "    plt.close()\n",
        "\n",
        "    # Plot MAP@3\n",
        "    plt.figure()\n",
        "    plt.plot(epochs, val_maps, label=\"Val MAP@3\", color=\"red\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"MAP@3\")\n",
        "    plt.title(\"Validation MAP@3\")\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.savefig(os.path.join(MODEL_DIR, \"map_curve.png\"))\n",
        "    plt.close()\n",
        "\n",
        "    print(\"üìä Saved metric plots to model/\")\n",
        "\n",
        "    # Predict test set\n",
        "    model.load_state_dict(torch.load(model_path))\n",
        "    model.eval()\n",
        "\n",
        "    val_ids = X_va[\"Id\"]\n",
        "    val_rankers = groups_va[\"ranker_id\"]\n",
        "    val_labels = y_va\n",
        "\n",
        "    all_val_scores = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for x_cat, x_num, _, lengths in tqdm(val_loader, desc=\"Predicting validation set\"):\n",
        "            x_num = x_num.to(device)\n",
        "            x_cat = {k: v.to(device) for k, v in x_cat.items()}\n",
        "            scores = model(x_cat, x_num)\n",
        "\n",
        "            for i in range(scores.size(0)):\n",
        "                l = lengths[i]\n",
        "                all_val_scores.append(scores[i, :l].cpu().numpy())\n",
        "\n",
        "    all_val_scores = np.concatenate(all_val_scores)\n",
        "\n",
        "    assert len(all_val_scores) == X_va.shape[0], \\\n",
        "        f\"Mismatch: {len(all_val_scores)} scores vs {X_va.shape[0]} rows\"\n",
        "\n",
        "    val_df = X_va.with_columns([\n",
        "        pl.Series(\"Id\", val_ids),\n",
        "        pl.Series(\"ranker_id\", val_rankers),\n",
        "        pl.Series(\"score\", all_val_scores),\n",
        "        pl.Series(\"label\", val_labels)\n",
        "    ])\n",
        "\n",
        "    val_df = val_df.with_columns(\n",
        "        pl.col(\"score\")\n",
        "        .rank(method=\"ordinal\", descending=True)\n",
        "        .over(\"ranker_id\")\n",
        "        .cast(pl.Int32)\n",
        "        .alias(\"selected\")\n",
        "    )\n",
        "\n",
        "    val_save_path = os.path.join(MODEL_DIR, \"validation_preds_dl_full.csv\")\n",
        "    val_df.write_csv(val_save_path)\n",
        "    print(f\"‚úÖ Saved full validation predictions (with features) to {val_save_path}\")\n",
        "\n",
        "    all_scores = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for x_cat, x_num, _, lengths in tqdm(test_loader, desc=\"Predicting test set\"):\n",
        "            x_num = x_num.to(device)\n",
        "            x_cat = {k: v.to(device) for k, v in x_cat.items()}\n",
        "            scores = model(x_cat, x_num)\n",
        "\n",
        "            for i in range(scores.size(0)):\n",
        "                l = lengths[i]\n",
        "                all_scores.append(scores[i, :l].cpu().numpy())\n",
        "\n",
        "    all_scores = np.concatenate(all_scores)\n",
        "\n",
        "    assert len(all_scores) == X_te.shape[0], \\\n",
        "        f\"Mismatch: {len(all_scores)} scores vs {X_te.shape[0]} rows in X_te\"\n",
        "\n",
        "    submission_df = pl.DataFrame({\n",
        "        \"Id\": test_ids,\n",
        "        \"ranker_id\": test_rankers,\n",
        "        \"score\": all_scores\n",
        "    })\n",
        "\n",
        "    submission = (\n",
        "        submission_df\n",
        "        .with_columns(\n",
        "            pl.col(\"score\")\n",
        "            .rank(method=\"ordinal\", descending=True)\n",
        "            .over(\"ranker_id\")\n",
        "            .cast(pl.Int32)\n",
        "            .alias(\"selected\")\n",
        "        )\n",
        "        .select([\"Id\", \"ranker_id\", \"score\", \"selected\"])\n",
        "    )\n",
        "\n",
        "    submission_path = os.path.join(SUBMIT_DIR, \"submission_dl_ranker.csv\")\n",
        "    submission.write_csv(submission_path)\n",
        "    print(f\"‚úÖ Submission saved to {submission_path}\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FkrPYP5NaU-H",
        "outputId": "fb9720bc-a4ca-4219-c1f0-a40531ef89b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing deeprec_validate.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "--- Epoch 1/10 ---\n",
        "Validating:   0%|          | 0/2636 [00:00<?, ?it/s]/home/ionut/test_whisper/test2/deeprec_validate.py:507: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
        "  lengths = torch.tensor(lengths).to(device)\n",
        "Epoch 1: Train Loss=0.3997, Val Loss=0.3201, HitRate@3=0.4613, NDCG@3=0.3643, MAP@3=0.6071, LR=0.000100 (864.1s)\n",
        "üíæ Model improved (loss ‚Üì and hitrate ‚Üë), saved.\n",
        "\n",
        "--- Epoch 2/10 ---\n",
        "Epoch 2: Train Loss=0.3148, Val Loss=0.2894, HitRate@3=0.4814, NDCG@3=0.3850, MAP@3=0.6309, LR=0.000089 (862.7s)\n",
        "üíæ Model improved (loss ‚Üì and hitrate ‚Üë), saved.\n",
        "\n",
        "--- Epoch 3/10 ---\n",
        "Epoch 3: Train Loss=0.2954, Val Loss=0.2887, HitRate@3=0.4845, NDCG@3=0.3857, MAP@3=0.6258, LR=0.000078 (864.2s)\n",
        "üíæ Model improved (loss ‚Üì and hitrate ‚Üë), saved.\n",
        "\n",
        "--- Epoch 4/10 ---\n",
        "Epoch 4: Train Loss=0.2842, Val Loss=0.2762, HitRate@3=0.4923, NDCG@3=0.3928, MAP@3=0.6363, LR=0.000067 (865.1s)\n",
        "üíæ Model improved (loss ‚Üì and hitrate ‚Üë), saved.\n",
        "\n",
        "--- Epoch 5/10 ---\n",
        "Epoch 5: Train Loss=0.2741, Val Loss=0.2660, HitRate@3=0.4970, NDCG@3=0.3983, MAP@3=0.6404, LR=0.000056 (864.5s)\n",
        "üíæ Model improved (loss ‚Üì and hitrate ‚Üë), saved.\n",
        "\n",
        "--- Epoch 6/10 ---\n",
        "Epoch 6: Train Loss=0.2656, Val Loss=0.2749, HitRate@3=0.5043, NDCG@3=0.4017, MAP@3=0.6417, LR=0.000044 (864.4s)\n",
        "\n",
        "--- Epoch 7/10 ---\n",
        "Epoch 7: Train Loss=0.2557, Val Loss=0.2626, HitRate@3=0.5066, NDCG@3=0.4066, MAP@3=0.6499, LR=0.000033 (865.9s)\n",
        "üíæ Model improved (loss ‚Üì and hitrate ‚Üë), saved.\n",
        "\n",
        "--- Epoch 8/10 ---\n",
        "Epoch 8: Train Loss=0.2512, Val Loss=0.2622, HitRate@3=0.5017, NDCG@3=0.4032, MAP@3=0.6473, LR=0.000022 (865.0s)\n",
        "\n",
        "--- Epoch 9/10 ---\n",
        "Epoch 9: Train Loss=0.2433, Val Loss=0.2569, HitRate@3=0.5095, NDCG@3=0.4094, MAP@3=0.6544, LR=0.000011 (862.8s)\n",
        "üíæ Model improved (loss ‚Üì and hitrate ‚Üë), saved.\n",
        "\n",
        "--- Epoch 10/10 ---\n",
        "Epoch 10: Train Loss=0.2376, Val Loss=0.2574, HitRate@3=0.5089, NDCG@3=0.4087, MAP@3=0.6519, LR=0.000000 (865.3s)"
      ],
      "metadata": {
        "id": "dANc2AlvCdU_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile deeprec_validate.py\n",
        "import os\n",
        "import time\n",
        "import random\n",
        "import torch\n",
        "import math\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import defaultdict\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "import polars as pl\n",
        "from tqdm import tqdm\n",
        "from src.feature import feature_engineering, feature_selection\n",
        "from transformers import get_scheduler\n",
        "from collections import Counter\n",
        "from torch.optim.lr_scheduler import OneCycleLR\n",
        "\n",
        "class RankDataset(Dataset):\n",
        "    def __init__(\n",
        "        self,\n",
        "        X: pl.DataFrame,\n",
        "        y: pl.Series,\n",
        "        groups: pl.DataFrame,\n",
        "        cat_features: list[str],\n",
        "        num_features: list[str],\n",
        "    ):\n",
        "        self.cat_features = cat_features\n",
        "        self.num_features = num_features\n",
        "        self.X_cat = {c: X[c].to_numpy() for c in cat_features}\n",
        "        self.X_num = X[self.num_features].to_numpy()\n",
        "        self.y = y.to_numpy()\n",
        "        self.groups = groups[\"ranker_id\"].to_numpy()\n",
        "\n",
        "        self.group_to_indices = defaultdict(list)\n",
        "        for i, g in enumerate(self.groups):\n",
        "            self.group_to_indices[g].append(i)\n",
        "        self.group_keys = list(self.group_to_indices.keys())\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.group_keys)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        g = self.group_keys[idx]\n",
        "        inds = self.group_to_indices[g]\n",
        "        length = len(inds)\n",
        "\n",
        "        x_cat = {\n",
        "            c: torch.LongTensor([\n",
        "                self.X_cat[c][i] if self.X_cat[c][i] >= 0 else 0 for i in inds\n",
        "            ])\n",
        "            for c in self.cat_features\n",
        "        }\n",
        "\n",
        "        x_num = torch.FloatTensor(self.X_num[inds])\n",
        "        y = torch.FloatTensor(self.y[inds]).reshape(-1)\n",
        "\n",
        "        return x_cat, x_num, y, length\n",
        "\n",
        "def collate_fn(batch):\n",
        "    batch_size = len(batch)\n",
        "    lengths = [b[3] for b in batch]\n",
        "    max_len = max(lengths)\n",
        "\n",
        "    padded_x_cat = {key: [] for key in batch[0][0].keys()}\n",
        "    padded_x_num = []\n",
        "    padded_y = []\n",
        "\n",
        "    num_dim = batch[0][1].shape[1]\n",
        "\n",
        "    for x_cat, x_num, y, length in batch:\n",
        "        pad_len = max_len - length\n",
        "\n",
        "        for key in padded_x_cat:\n",
        "            val = x_cat[key]\n",
        "            if pad_len > 0:\n",
        "                val = torch.cat([val, torch.zeros(pad_len, dtype=torch.long)])\n",
        "            padded_x_cat[key].append(val)\n",
        "\n",
        "        if pad_len > 0:\n",
        "            x_num = torch.cat([x_num, torch.zeros(pad_len, num_dim)])\n",
        "            y = torch.cat([y, torch.zeros(pad_len)])\n",
        "\n",
        "        padded_x_num.append(x_num)\n",
        "        padded_y.append(y)\n",
        "\n",
        "    padded_x_cat = {k: torch.stack(v) for k, v in padded_x_cat.items()}\n",
        "    padded_x_num = torch.stack(padded_x_num)\n",
        "    padded_y = torch.stack(padded_y)\n",
        "    lengths = torch.tensor(lengths, dtype=torch.long)\n",
        "\n",
        "    return padded_x_cat, padded_x_num, padded_y, lengths\n",
        "\n",
        "class SEModule(nn.Module):\n",
        "    def __init__(self, channel, reduction=4):\n",
        "        super().__init__()\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(channel, channel // reduction),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(channel // reduction, channel),\n",
        "            nn.Sigmoid(),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: [B, N, C]\n",
        "        w = self.fc(x.mean(dim=1))\n",
        "        w = w.unsqueeze(1)  # [B, 1, C]\n",
        "        return x * w\n",
        "\n",
        "\n",
        "class DLRankerAttention(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        cat_dims,\n",
        "        num_numeric_feats,\n",
        "        emb_dropout=0.1,\n",
        "        dropout=0.1,\n",
        "        num_heads=4,\n",
        "        num_layers=2,\n",
        "        dim_feedforward=128,\n",
        "        proj_dim=64,\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "        self.emb_dims = {\n",
        "            f: min(50, max(4, round(6 * math.log2(cat_dims[f] + 1)))) for f in cat_dims\n",
        "        }\n",
        "        self.embeddings = nn.ModuleDict(\n",
        "            {\n",
        "                f: nn.Embedding(cat_dims[f], self.emb_dims[f], padding_idx=0)\n",
        "                for f in cat_dims\n",
        "            }\n",
        "        )\n",
        "        self.emb_dropout = nn.Dropout(emb_dropout)\n",
        "\n",
        "        total_emb_dim = sum(self.emb_dims.values())\n",
        "        print(\n",
        "            f\"Categorial emb dim sum: {total_emb_dim}, Numerical dim: {num_numeric_feats}\"\n",
        "        )\n",
        "\n",
        "        self.cat_proj = nn.Linear(total_emb_dim, proj_dim)\n",
        "        self.cat_transformer = nn.TransformerEncoder(\n",
        "            nn.TransformerEncoderLayer(\n",
        "                d_model=proj_dim,\n",
        "                nhead=4,\n",
        "                dim_feedforward=dim_feedforward,\n",
        "                dropout=dropout,\n",
        "                batch_first=True,\n",
        "            ),\n",
        "            num_layers=1,\n",
        "        )\n",
        "\n",
        "\n",
        "        self.num_proj_in = nn.Linear(num_numeric_feats, proj_dim)\n",
        "        self.num_transformer = nn.TransformerEncoder(\n",
        "            nn.TransformerEncoderLayer(\n",
        "                d_model=proj_dim,\n",
        "                nhead=4,\n",
        "                dim_feedforward=dim_feedforward,\n",
        "                dropout=dropout,\n",
        "                batch_first=True,\n",
        "            ),\n",
        "            num_layers=1,\n",
        "        )\n",
        "        self.num_se = SEModule(proj_dim)\n",
        "        self.num_proj_out = nn.Sequential(\n",
        "            nn.Linear(proj_dim, proj_dim),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(dropout),\n",
        "        )\n",
        "\n",
        "        self.transformer_layers = nn.ModuleList(\n",
        "            [\n",
        "                nn.TransformerEncoderLayer(\n",
        "                    d_model=2 * proj_dim,\n",
        "                    nhead=num_heads,\n",
        "                    dim_feedforward=dim_feedforward,\n",
        "                    dropout=dropout,\n",
        "                    batch_first=True,\n",
        "                )\n",
        "                for _ in range(num_layers)\n",
        "            ]\n",
        "        )\n",
        "\n",
        "        self.mlp = nn.Sequential(\n",
        "            nn.Linear(2 * proj_dim, 128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(128, 64),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(64, 1),\n",
        "        )\n",
        "\n",
        "    def forward(self, x_cat: dict, x_num: torch.Tensor, attn_mask=None):\n",
        "        B, N, _ = x_num.shape  # x_num: [B, N, F_num]\n",
        "\n",
        "        cat_emb_list = []\n",
        "        for f, emb_layer in self.embeddings.items():\n",
        "            emb = emb_layer(x_cat[f])  # [B, N]\n",
        "            cat_emb_list.append(emb)\n",
        "        cat_embs = torch.cat(cat_emb_list, dim=-1)  # [B, N, total_emb_dim]\n",
        "        cat_embs = self.emb_dropout(cat_embs)\n",
        "        cat_feat = self.cat_proj(cat_embs)  # [B, N, proj_dim]\n",
        "        cat_feat = self.cat_transformer(cat_feat)  # [B, N, proj_dim]\n",
        "\n",
        "        num_feat = self.num_proj_in(x_num)  # [B, N, proj_dim]\n",
        "        num_feat = self.num_transformer(num_feat)  # [B, N, proj_dim]\n",
        "        num_feat = self.num_se(num_feat)  # [B, N, proj_dim]\n",
        "        num_feat = self.num_proj_out(num_feat)  # [B, N, proj_dim]\n",
        "\n",
        "        x = torch.cat([cat_feat, num_feat], dim=-1)  # [B, N, 2*proj_dim]\n",
        "\n",
        "        for layer in self.transformer_layers:\n",
        "            x = layer(x, src_key_padding_mask=attn_mask)\n",
        "\n",
        "        scores = self.mlp(x).squeeze(-1)  # [B, N]\n",
        "\n",
        "        return scores\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "def listmle_loss(scores, labels, lengths):\n",
        "    batch_size = scores.size(0)\n",
        "    total_loss = torch.tensor(0.0, device=scores.device, requires_grad=True)\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "\n",
        "        _, idx = torch.sort(y, descending=True)\n",
        "        s_sorted = s[idx]\n",
        "\n",
        "        parts = (\n",
        "            torch.logsumexp(s_sorted.unsqueeze(0).expand(l, -1).triu(diagonal=0), dim=1)\n",
        "            - s_sorted\n",
        "        )\n",
        "\n",
        "        total_loss = total_loss + parts.sum()\n",
        "\n",
        "    return total_loss / batch_size\n",
        "\"\"\"\n",
        "\n",
        "def hitrate_at_k(scores, labels, lengths, k=3, min_group_size=10):\n",
        "    batch_size = scores.size(0)\n",
        "    hits = 0\n",
        "    valid_count = 0\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        if l < min_group_size:\n",
        "            continue\n",
        "        length = min(l, k)\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "        _, topk_idx = torch.topk(s, length)\n",
        "        topk_labels = y[topk_idx]\n",
        "        hits += (topk_labels > 0).any().float()\n",
        "        valid_count += 1\n",
        "    return hits / valid_count if valid_count > 0 else torch.tensor(0.0, device=scores.device)\n",
        "\n",
        "\n",
        "def ndcg_at_k(scores, labels, lengths, k=3, min_group_size=10):\n",
        "    batch_size = scores.size(0)\n",
        "    total_ndcg = 0.0\n",
        "    valid_count = 0\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        if l < min_group_size:\n",
        "            continue\n",
        "\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "\n",
        "        _, idx_pred = torch.topk(s, min(k, l))\n",
        "        _, idx_ideal = torch.topk(y, min(k, l))\n",
        "\n",
        "        dcg = (y[idx_pred] / torch.log2(torch.arange(2, 2 + len(idx_pred), device=y.device).float())).sum()\n",
        "        idcg = (y[idx_ideal] / torch.log2(torch.arange(2, 2 + len(idx_ideal), device=y.device).float())).sum()\n",
        "\n",
        "        ndcg = dcg / idcg if idcg > 0 else 0.0\n",
        "        total_ndcg += ndcg\n",
        "        valid_count += 1\n",
        "\n",
        "    return total_ndcg / valid_count if valid_count > 0 else torch.tensor(0.0, device=scores.device)\n",
        "\n",
        "\n",
        "def map_at_k(scores, labels, lengths, k=3, min_group_size=10):\n",
        "    batch_size = scores.size(0)\n",
        "    total_ap = 0.0\n",
        "    valid_count = 0\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        if l < min_group_size:\n",
        "            continue\n",
        "\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "\n",
        "        _, idx_pred = torch.topk(s, min(k, l))\n",
        "        y_true = y[idx_pred] > 0\n",
        "\n",
        "        if y_true.sum() == 0:\n",
        "            continue\n",
        "\n",
        "        precisions = [(y_true[:j+1].float().sum() / (j+1)) for j in range(len(y_true)) if y_true[j]]\n",
        "        ap = torch.stack(precisions).mean()\n",
        "        total_ap += ap\n",
        "        valid_count += 1\n",
        "\n",
        "    return total_ap / valid_count if valid_count > 0 else torch.tensor(0.0, device=scores.device)\n",
        "\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "def listnet_loss(scores, labels, lengths):\n",
        "    batch_size = scores.size(0)\n",
        "    total_loss = 0.0\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "\n",
        "        s_softmax = torch.nn.functional.log_softmax(s, dim=0)\n",
        "        y_softmax = torch.nn.functional.softmax(y, dim=0)\n",
        "\n",
        "        loss = -torch.sum(y_softmax * s_softmax)\n",
        "        total_loss += loss\n",
        "\n",
        "    return total_loss / batch_size\n",
        "\"\"\"\n",
        "\n",
        "def ranknet_loss(scores, labels, lengths):\n",
        "    batch_size = scores.size(0)\n",
        "    total_loss = 0.0\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "\n",
        "        diff_scores = s.unsqueeze(1) - s.unsqueeze(0)\n",
        "        rel = y.unsqueeze(1) > y.unsqueeze(0)\n",
        "        label_diff = rel.float()\n",
        "\n",
        "        log_sigmoid = torch.nn.functional.logsigmoid(diff_scores)\n",
        "        pair_loss = -label_diff * log_sigmoid\n",
        "\n",
        "        total_loss += pair_loss.sum()\n",
        "\n",
        "    return total_loss / batch_size\n",
        "\n",
        "def xranknet_loss(scores, labels, lengths, temperature=1.0, margin=0.2, focus_topk=3):\n",
        "    \"\"\"\n",
        "    xRankNet with emphasis on top-K items (based on labels, not scores).\n",
        "    \"\"\"\n",
        "    batch_size = scores.size(0)\n",
        "    total_loss = 0.0\n",
        "    total_pairs = 0\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        if l < 2:\n",
        "            continue\n",
        "\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "\n",
        "        # Top-K mask based on ground truth labels\n",
        "        topk = min(focus_topk, l)\n",
        "        _, topk_idx = torch.topk(y, topk)\n",
        "        topk_mask = torch.zeros_like(y, dtype=torch.bool)\n",
        "        topk_mask[topk_idx] = True\n",
        "\n",
        "        # Create pairwise difference matrices\n",
        "        score_diff = s.unsqueeze(1) - s.unsqueeze(0)\n",
        "        label_diff = y.unsqueeze(1) - y.unsqueeze(0)\n",
        "\n",
        "        # valid pair: y_i > y_j and at least one of i, j is in top-K\n",
        "        valid_pairs = (label_diff > 0) & (\n",
        "            topk_mask.unsqueeze(1) | topk_mask.unsqueeze(0)\n",
        "        )\n",
        "\n",
        "        if valid_pairs.sum() == 0:\n",
        "            continue\n",
        "\n",
        "        importance = (label_diff.abs() * valid_pairs).float()\n",
        "\n",
        "        if margin > 0.0:\n",
        "            score_diff = score_diff - margin\n",
        "\n",
        "        score_diff = score_diff / temperature\n",
        "        pairwise_loss = -F.logsigmoid(score_diff) * importance\n",
        "\n",
        "        total_loss += pairwise_loss.sum()\n",
        "        total_pairs += importance.sum()\n",
        "\n",
        "    if total_pairs == 0:\n",
        "        return torch.tensor(0.0, device=scores.device, requires_grad=True)\n",
        "\n",
        "    return total_loss / total_pairs\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "def bpr_loss(scores, labels, lengths):\n",
        "    batch_size = scores.size(0)\n",
        "    total_loss = 0.0\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "\n",
        "        pos_mask = y > 0\n",
        "        neg_mask = y <= 0\n",
        "\n",
        "        pos_scores = s[pos_mask]\n",
        "        neg_scores = s[neg_mask]\n",
        "\n",
        "        if len(pos_scores) == 0 or len(neg_scores) == 0:\n",
        "            continue\n",
        "\n",
        "        pair_diff = pos_scores.unsqueeze(1) - neg_scores.unsqueeze(0)\n",
        "        loss = -F.logsigmoid(pair_diff).mean()\n",
        "        total_loss += loss\n",
        "\n",
        "    return total_loss / batch_size\n",
        "\"\"\"\n",
        "\n",
        "\"\"\"\n",
        "def lambdarank_loss(scores, labels, lengths, eps=1e-10):\n",
        "    batch_size = scores.size(0)\n",
        "    total_loss = 0.0\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "\n",
        "        if l < 2:\n",
        "            continue\n",
        "\n",
        "        _, rank_order = torch.sort(s, descending=True)\n",
        "        ideal_order = torch.sort(y, descending=True).indices\n",
        "\n",
        "        gain = 2 ** y - 1\n",
        "        discount = torch.log2(torch.arange(2, l + 2, device=y.device).float())\n",
        "\n",
        "        ideal_dcg = (gain[ideal_order] / discount).sum()\n",
        "        if ideal_dcg < eps:\n",
        "            continue\n",
        "\n",
        "        delta_ndcg = torch.zeros((l, l), device=y.device)\n",
        "\n",
        "        for i_idx in range(l):\n",
        "            for j_idx in range(l):\n",
        "                if y[i_idx] > y[j_idx]:\n",
        "                    change = (\n",
        "                        (1.0 / torch.log2(rank_order[i_idx] + 2.0))\n",
        "                        - (1.0 / torch.log2(rank_order[j_idx] + 2.0))\n",
        "                    ).abs()\n",
        "                    delta = (2 ** y[i_idx] - 2 ** y[j_idx]).abs() * change\n",
        "                    delta_ndcg[i_idx, j_idx] = delta / ideal_dcg\n",
        "\n",
        "        score_diffs = s.unsqueeze(1) - s.unsqueeze(0)\n",
        "        lambdas = -F.logsigmoid(score_diffs) * delta_ndcg\n",
        "        total_loss += lambdas.sum()\n",
        "\n",
        "    return total_loss / batch_size\n",
        "\"\"\"\n",
        "\n",
        "def train_one_epoch(model, loader, optimizer, device, scheduler):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "\n",
        "    for x_cat, x_num, y, lengths in tqdm(loader, desc=\"Training\", leave=False):\n",
        "        x_num, y = x_num.to(device), y.to(device)\n",
        "        if not isinstance(lengths, torch.Tensor):\n",
        "            lengths = torch.tensor(lengths)\n",
        "        lengths = lengths.detach().clone().to(device)\n",
        "        x_cat = {k: v.to(device) for k, v in x_cat.items()}\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        scores = model(x_cat, x_num)\n",
        "        loss = xranknet_loss(scores, y, lengths, temperature=1.0, margin=0.2, focus_topk=3)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    return total_loss / len(loader)\n",
        "\n",
        "\n",
        "def validate(model, loader, device, min_group_size=10):\n",
        "    model.eval()\n",
        "    total_hitrate = 0\n",
        "    total_ndcg = 0\n",
        "    total_map = 0\n",
        "    total_loss = 0\n",
        "    count = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for x_cat, x_num, y, lengths in tqdm(loader, desc=\"Validating\", leave=False):\n",
        "            x_num, y = x_num.to(device), y.to(device)\n",
        "            lengths = torch.tensor(lengths).to(device)\n",
        "            x_cat = {k: v.to(device) for k, v in x_cat.items()}\n",
        "\n",
        "            scores = model(x_cat, x_num)\n",
        "\n",
        "            hitrate = hitrate_at_k(scores, y, lengths, k=3, min_group_size=min_group_size)\n",
        "            ndcg = ndcg_at_k(scores, y, lengths, k=3, min_group_size=min_group_size)\n",
        "            map3 = map_at_k(scores, y, lengths, k=3, min_group_size=min_group_size)\n",
        "            loss = xranknet_loss(scores, y, lengths, temperature=1.0, margin=0.2, focus_topk=3)\n",
        "\n",
        "            batch_size = scores.size(0)\n",
        "            total_hitrate += hitrate * batch_size\n",
        "            total_ndcg += ndcg * batch_size\n",
        "            total_map += map3 * batch_size\n",
        "            total_loss += loss.item() * batch_size\n",
        "            count += batch_size\n",
        "\n",
        "    return total_loss / count, total_hitrate / count, total_ndcg / count, total_map / count\n",
        "\n",
        "\n",
        "def build_cat_dims(X, cat_features):\n",
        "    cat_dims = {}\n",
        "    for c in cat_features:\n",
        "        max_val = X[c].max()\n",
        "        if max_val < 0:\n",
        "            max_val = 0\n",
        "        cat_dims[c] = max_val + 1\n",
        "    return cat_dims\n",
        "\n",
        "\n",
        "def normalize_numeric_features(X, numeric_features, train_mask):\n",
        "    for col in numeric_features:\n",
        "        values = X[col].to_numpy()\n",
        "        train_vals = values[train_mask]\n",
        "        mean = train_vals.mean()\n",
        "        std = train_vals.std() if train_vals.std() > 0 else 1.0\n",
        "        norm_vals = (values - mean) / std\n",
        "        X = X.with_columns(pl.Series(col, norm_vals).alias(col))\n",
        "    return X\n",
        "\n",
        "\n",
        "def load_or_prepare_data(\n",
        "    data_dir,\n",
        "    train_file=\"train.parquet\",\n",
        "    test_file=\"test.parquet\",\n",
        "    cache_file=\"feature_engineered_val.parquet\",\n",
        "):\n",
        "    cache_path = os.path.join(data_dir, cache_file)\n",
        "\n",
        "    if os.path.exists(cache_path):\n",
        "        print(f\"Loading cached feature-engineered data from {cache_path} ...\")\n",
        "        df = pl.read_parquet(cache_path)\n",
        "\n",
        "        test = pl.read_parquet(os.path.join(data_dir, test_file)).drop(\"__index_level_0__\")\n",
        "        test_ids = test[\"Id\"]\n",
        "        test_rankers = test[\"ranker_id\"]\n",
        "    else:\n",
        "        print(\"Cached file not found, processing raw data ...\")\n",
        "\n",
        "        train = pl.read_parquet(os.path.join(data_dir, train_file)).drop(\"__index_level_0__\")\n",
        "        test = (\n",
        "            pl.read_parquet(os.path.join(data_dir, test_file))\n",
        "            .drop(\"__index_level_0__\")\n",
        "            .with_columns(pl.lit(0, dtype=pl.Int64).alias(\"selected\"))\n",
        "        )\n",
        "\n",
        "        test_ids = test[\"Id\"]\n",
        "        test_rankers = test[\"ranker_id\"]\n",
        "\n",
        "        df = pl.concat((train, test))\n",
        "        df = feature_engineering(df, full=True)\n",
        "\n",
        "        df = df.with_columns(\n",
        "            [pl.col(c).fill_null(0) for c in df.select(pl.selectors.numeric()).columns] +\n",
        "            [pl.col(c).fill_null(\"missing\") for c in df.select(pl.selectors.string()).columns]\n",
        "        )\n",
        "\n",
        "        os.makedirs(data_dir, exist_ok=True)\n",
        "        df.write_parquet(cache_path)\n",
        "        print(f\"Saved feature-engineered data to {cache_path}\")\n",
        "\n",
        "    return df, test_ids, test_rankers\n",
        "\n",
        "\n",
        "def prepare_data(data_dir):\n",
        "    df, test_ids, test_rankers = load_or_prepare_data(data_dir)\n",
        "\n",
        "    id_column = df[\"Id\"]\n",
        "    X, y, groups, cat_features, num_features = feature_selection(df)\n",
        "\n",
        "    X = X.with_columns(pl.Series(\"Id\", id_column[:X.shape[0]]))\n",
        "\n",
        "    X = X.with_columns(\n",
        "        [\n",
        "            (pl.col(c).rank(\"dense\") - 1).fill_null(-1).cast(pl.Int32)\n",
        "            for c in cat_features\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    train_size = 18145372\n",
        "    train_mask = np.arange(X.height) < train_size\n",
        "    X = normalize_numeric_features(X, num_features, train_mask)\n",
        "\n",
        "    return X, y, groups, cat_features, num_features, train_size, test_ids, test_rankers\n",
        "\n",
        "\n",
        "class EarlyStopping:\n",
        "    def __init__(self, patience=3, min_delta=0.00005):\n",
        "        self.patience = patience\n",
        "        self.min_delta = min_delta\n",
        "        self.best = float(\"-inf\")\n",
        "        self.counter = 0\n",
        "\n",
        "    def step(self, metric):\n",
        "        if metric > self.best + self.min_delta:\n",
        "            self.best = metric\n",
        "            self.counter = 0\n",
        "        else:\n",
        "            self.counter += 1\n",
        "        return self.counter >= self.patience\n",
        "\n",
        "\n",
        "def plot_group_size_distribution(dataset, save_path=None):\n",
        "    group_sizes = [len(v) for v in dataset.group_to_indices.values()]\n",
        "    plt.figure()\n",
        "    plt.hist(group_sizes, bins=100, log=True)\n",
        "    plt.xlabel(\"Group size (number of items per ranker_id)\")\n",
        "    plt.ylabel(\"Frequency (log scale)\")\n",
        "    plt.title(\"Distribution of Group Sizes\")\n",
        "    plt.grid(True)\n",
        "    if save_path:\n",
        "        plt.savefig(save_path)\n",
        "    else:\n",
        "        plt.show()\n",
        "    plt.close()\n",
        "\n",
        "\n",
        "def main():\n",
        "    DATA_DIR = \"./data\"\n",
        "    MODEL_DIR = \"model\"\n",
        "    SUBMIT_DIR = \"submission\"\n",
        "\n",
        "    best_val_loss = float(\"inf\")\n",
        "    best_hitrate = 0.0\n",
        "    model_path = os.path.join(MODEL_DIR, \"best_dl_ranker.pt\")\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "    val_hitrates = []\n",
        "    val_ndcgs = []\n",
        "    val_maps = []\n",
        "    learning_rates = []\n",
        "\n",
        "    os.makedirs(MODEL_DIR, exist_ok=True)\n",
        "    os.makedirs(SUBMIT_DIR, exist_ok=True)\n",
        "\n",
        "    early_stopper = EarlyStopping(patience=3, min_delta=0.001)\n",
        "\n",
        "    X, y, groups, cat_features, num_features, train_size, test_ids, test_rankers = prepare_data(DATA_DIR)\n",
        "\n",
        "    # Fill missing values\n",
        "    float_cols = [c for c, t in zip(X.columns, X.dtypes) if t == pl.Float64]\n",
        "    for col in float_cols:\n",
        "        X = X.with_columns(\n",
        "            pl.when(pl.col(col).is_nan()).then(0).otherwise(pl.col(col)).alias(col)\n",
        "        )\n",
        "\n",
        "    n1 = 16487352\n",
        "    # n1 = 17487300\n",
        "    n2 = train_size\n",
        "\n",
        "    X_tr, X_va, X_te = X[:n1], X[n1:n2], X[n2:]\n",
        "    y_tr, y_va, y_te = y[:n1], y[n1:n2], y[n2:]\n",
        "    groups_tr, groups_va, groups_te = groups[:n1], groups[n1:n2], groups[n2:]\n",
        "\n",
        "    # Inspect group sizes in validation set\n",
        "    val_rankers = groups_va[\"ranker_id\"].to_numpy()\n",
        "    val_group_counts = Counter(val_rankers)\n",
        "\n",
        "    print(\"\\nüìã Validation group statistics:\")\n",
        "    # Save detailed group info to file\n",
        "    group_info_path = os.path.join(MODEL_DIR, \"validation_groups_info.txt\")\n",
        "    with open(group_info_path, \"w\") as f:\n",
        "        f.write(f\"Total groups: {len(val_group_counts)}\\n\\n\")\n",
        "        f.write(\"GroupID\\tSize\\tStartIdx\\tEndIdx\\n\")\n",
        "\n",
        "        group_to_rows = defaultdict(list)\n",
        "        for i, g in enumerate(val_rankers):\n",
        "            group_to_rows[g].append(i)\n",
        "\n",
        "        for group_id, indices in sorted(group_to_rows.items()):\n",
        "            start_idx = indices[0]\n",
        "            end_idx = indices[-1]\n",
        "            size = len(indices)\n",
        "            f.write(f\"{group_id}\\t{size}\\t{start_idx}\\t{end_idx}\\n\")\n",
        "\n",
        "    print(f\"üìÅ Saved validation group info to {group_info_path}\")\n",
        "\n",
        "\n",
        "    cat_dims = build_cat_dims(X, cat_features)\n",
        "    num_numeric_feats = len(num_features)\n",
        "\n",
        "    train_dataset = RankDataset(X_tr, y_tr, groups_tr, cat_features, num_features)\n",
        "    val_dataset = RankDataset(X_va, y_va, groups_va, cat_features, num_features)\n",
        "    test_dataset = RankDataset(X_te, y_te, groups_te, cat_features, num_features)\n",
        "\n",
        "    plot_group_size_distribution(train_dataset, save_path=os.path.join(MODEL_DIR, \"group_sizes.png\"))\n",
        "    print(\"üìä Group size distribution saved.\")\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True, collate_fn=collate_fn)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=4, shuffle=False, collate_fn=collate_fn)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False, collate_fn=collate_fn)\n",
        "\n",
        "    print(\"‚úÖ Data loaders created.\")\n",
        "\n",
        "    num_epochs = 10\n",
        "    num_training_steps = num_epochs * len(train_loader)\n",
        "    num_warmup_steps = int(0.1 * num_training_steps)\n",
        "\n",
        "    learning_rate = 3e-4\n",
        "\n",
        "    model = DLRankerAttention(\n",
        "        cat_dims=cat_dims,\n",
        "        num_numeric_feats=num_numeric_feats,\n",
        "        emb_dropout=0.1,\n",
        "        dropout=0.1,\n",
        "        num_heads=4,\n",
        "        num_layers=2,\n",
        "        dim_feedforward=128,\n",
        "        proj_dim=64\n",
        "    ).to(device)\n",
        "\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=0.01)\n",
        "\n",
        "    scheduler = OneCycleLR(\n",
        "        optimizer,\n",
        "        max_lr=learning_rate,\n",
        "        steps_per_epoch=len(train_loader),\n",
        "        epochs=num_epochs,\n",
        "        pct_start=0.3,\n",
        "    )\n",
        "\n",
        "    best_hitrate = 0\n",
        "    for epoch in range(num_epochs):\n",
        "        print(f\"\\n--- Epoch {epoch+1}/{num_epochs} ---\")\n",
        "        start_time = time.time()\n",
        "\n",
        "        train_loss = train_one_epoch(model, train_loader, optimizer, device, scheduler)\n",
        "        val_loss, val_hitrate, val_ndcg, val_map = validate(model, val_loader, device, min_group_size=10)\n",
        "\n",
        "        train_losses.append(train_loss)\n",
        "        val_losses.append(val_loss)\n",
        "        val_hitrates.append(val_hitrate.item())\n",
        "        val_ndcgs.append(val_ndcg.item())\n",
        "        val_maps.append(val_map.item())\n",
        "\n",
        "        current_lr = scheduler.get_last_lr()\n",
        "        learning_rates.append(current_lr[0])\n",
        "\n",
        "        elapsed = time.time() - start_time\n",
        "        print(\n",
        "            f\"Epoch {epoch+1}: \"\n",
        "            f\"Train Loss={train_loss:.4f}, \"\n",
        "            f\"Val Loss={val_loss:.4f}, \"\n",
        "            f\"HitRate@3={val_hitrate:.4f}, \"\n",
        "            f\"NDCG@3={val_ndcg:.4f}, \"\n",
        "            f\"MAP@3={val_map:.4f}, \"\n",
        "            f\"LR={current_lr[0]:.6f} \"\n",
        "            f\"({elapsed:.1f}s)\"\n",
        "        )\n",
        "\n",
        "\n",
        "        if val_loss < best_val_loss and val_hitrate > best_hitrate:\n",
        "            best_val_loss = val_loss\n",
        "            best_hitrate = val_hitrate\n",
        "            torch.save(model.state_dict(), model_path)\n",
        "            print(\"üíæ Model improved (loss ‚Üì and hitrate ‚Üë), saved.\")\n",
        "\n",
        "        if early_stopper.step(-val_loss):\n",
        "            print(\"‚õî Early stopping triggered.\")\n",
        "            break\n",
        "\n",
        "    # Plot metrics\n",
        "    epochs = list(range(1, len(train_losses) + 1))\n",
        "\n",
        "    # Plot Loss Curve\n",
        "    plt.figure()\n",
        "    plt.plot(epochs, train_losses, label=\"Train Loss\")\n",
        "    plt.plot(epochs, val_losses, label=\"Val Loss\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.title(\"Training & Validation Loss\")\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.savefig(os.path.join(MODEL_DIR, \"loss_curve.png\"))\n",
        "    plt.close()\n",
        "\n",
        "    # Plot HitRate@3\n",
        "    plt.figure()\n",
        "    plt.plot(epochs, val_hitrates, label=\"Val HitRate@3\", color=\"green\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"HitRate@3\")\n",
        "    plt.title(\"Validation HitRate@3\")\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.savefig(os.path.join(MODEL_DIR, \"hitrate_curve.png\"))\n",
        "    plt.close()\n",
        "\n",
        "    # Plot Learning Rate\n",
        "    plt.figure()\n",
        "    plt.plot(epochs, learning_rates, label=\"Learning Rate\", color=\"orange\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"LR\")\n",
        "    plt.title(\"Learning Rate Schedule\")\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.savefig(os.path.join(MODEL_DIR, \"lr_curve.png\"))\n",
        "    plt.close()\n",
        "\n",
        "    # Plot NDCG@3\n",
        "    plt.figure()\n",
        "    plt.plot(epochs, val_ndcgs, label=\"Val NDCG@3\", color=\"purple\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"NDCG@3\")\n",
        "    plt.title(\"Validation NDCG@3\")\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.savefig(os.path.join(MODEL_DIR, \"ndcg_curve.png\"))\n",
        "    plt.close()\n",
        "\n",
        "    # Plot MAP@3\n",
        "    plt.figure()\n",
        "    plt.plot(epochs, val_maps, label=\"Val MAP@3\", color=\"red\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"MAP@3\")\n",
        "    plt.title(\"Validation MAP@3\")\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.savefig(os.path.join(MODEL_DIR, \"map_curve.png\"))\n",
        "    plt.close()\n",
        "\n",
        "    print(\"üìä Saved metric plots to model/\")\n",
        "\n",
        "    # Predict test set\n",
        "    model.load_state_dict(torch.load(model_path))\n",
        "    model.eval()\n",
        "\n",
        "    val_ids = X_va[\"Id\"]\n",
        "    val_rankers = groups_va[\"ranker_id\"]\n",
        "    val_labels = y_va\n",
        "\n",
        "    all_val_scores = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for x_cat, x_num, _, lengths in tqdm(val_loader, desc=\"Predicting validation set\"):\n",
        "            x_num = x_num.to(device)\n",
        "            x_cat = {k: v.to(device) for k, v in x_cat.items()}\n",
        "            scores = model(x_cat, x_num)\n",
        "\n",
        "            for i in range(scores.size(0)):\n",
        "                l = lengths[i]\n",
        "                all_val_scores.append(scores[i, :l].cpu().numpy())\n",
        "\n",
        "    all_val_scores = np.concatenate(all_val_scores)\n",
        "\n",
        "    assert len(all_val_scores) == X_va.shape[0], \\\n",
        "        f\"Mismatch: {len(all_val_scores)} scores vs {X_va.shape[0]} rows\"\n",
        "\n",
        "    val_df = X_va.with_columns([\n",
        "        pl.Series(\"Id\", val_ids),\n",
        "        pl.Series(\"ranker_id\", val_rankers),\n",
        "        pl.Series(\"score\", all_val_scores),\n",
        "        pl.Series(\"label\", val_labels)\n",
        "    ])\n",
        "\n",
        "    val_df = val_df.with_columns(\n",
        "        pl.col(\"score\")\n",
        "        .rank(method=\"ordinal\", descending=True)\n",
        "        .over(\"ranker_id\")\n",
        "        .cast(pl.Int32)\n",
        "        .alias(\"selected\")\n",
        "    )\n",
        "\n",
        "    val_save_path = os.path.join(MODEL_DIR, \"validation_preds_dl_full.csv\")\n",
        "    val_df.write_csv(val_save_path)\n",
        "    print(f\"‚úÖ Saved full validation predictions (with features) to {val_save_path}\")\n",
        "\n",
        "    all_scores = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for x_cat, x_num, _, lengths in tqdm(test_loader, desc=\"Predicting test set\"):\n",
        "            x_num = x_num.to(device)\n",
        "            x_cat = {k: v.to(device) for k, v in x_cat.items()}\n",
        "            scores = model(x_cat, x_num)\n",
        "\n",
        "            for i in range(scores.size(0)):\n",
        "                l = lengths[i]\n",
        "                all_scores.append(scores[i, :l].cpu().numpy())\n",
        "\n",
        "    all_scores = np.concatenate(all_scores)\n",
        "\n",
        "    assert len(all_scores) == X_te.shape[0], \\\n",
        "        f\"Mismatch: {len(all_scores)} scores vs {X_te.shape[0]} rows in X_te\"\n",
        "\n",
        "    submission_df = pl.DataFrame({\n",
        "        \"Id\": test_ids,\n",
        "        \"ranker_id\": test_rankers,\n",
        "        \"score\": all_scores\n",
        "    })\n",
        "\n",
        "    submission = (\n",
        "        submission_df\n",
        "        .with_columns(\n",
        "            pl.col(\"score\")\n",
        "            .rank(method=\"ordinal\", descending=True)\n",
        "            .over(\"ranker_id\")\n",
        "            .cast(pl.Int32)\n",
        "            .alias(\"selected\")\n",
        "        )\n",
        "        .select([\"Id\", \"ranker_id\", \"score\", \"selected\"])\n",
        "    )\n",
        "\n",
        "    submission_path = os.path.join(SUBMIT_DIR, \"submission_dl_ranker.csv\")\n",
        "    submission.write_csv(submission_path)\n",
        "    print(f\"‚úÖ Submission saved to {submission_path}\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k4jrnjzyNWvB",
        "outputId": "3443419f-f6df-4ff9-deb1-e3b89e403804"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing deeprec_validate.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "--- Epoch 1/10 ---\n",
        "Validating:   0%|          | 0/2636 [00:00<?, ?it/s]/home/ionut/test_whisper/test2/deeprec_validate.py:508: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
        "  lengths = torch.tensor(lengths).to(device)\n",
        "Epoch 1: Train Loss=0.3545, Val Loss=0.2895, HitRate@3=0.4698, NDCG@3=0.3729, MAP@3=0.6141, LR=0.000084 (525.7s)\n",
        "üíæ Model improved (loss ‚Üì and hitrate ‚Üë), saved.\n",
        "\n",
        "--- Epoch 2/10 ---\n",
        "Epoch 2: Train Loss=0.2918, Val Loss=0.2843, HitRate@3=0.4837, NDCG@3=0.3828, MAP@3=0.6231, LR=0.000228 (526.9s)\n",
        "üíæ Model improved (loss ‚Üì and hitrate ‚Üë), saved.\n",
        "\n",
        "--- Epoch 3/10 ---\n",
        "Epoch 3: Train Loss=0.2820, Val Loss=0.2823, HitRate@3=0.4911, NDCG@3=0.3908, MAP@3=0.6333, LR=0.000300 (526.3s)\n",
        "üíæ Model improved (loss ‚Üì and hitrate ‚Üë), saved.\n",
        "\n",
        "--- Epoch 4/10 ---\n",
        "Epoch 4: Train Loss=0.2728, Val Loss=0.2706, HitRate@3=0.4956, NDCG@3=0.3971, MAP@3=0.6382, LR=0.000285 (526.6s)\n",
        "üíæ Model improved (loss ‚Üì and hitrate ‚Üë), saved.\n",
        "\n",
        "--- Epoch 5/10 ---\n",
        "Epoch 5: Train Loss=0.2612, Val Loss=0.2626, HitRate@3=0.5017, NDCG@3=0.4021, MAP@3=0.6423, LR=0.000244 (527.3s)\n",
        "üíæ Model improved (loss ‚Üì and hitrate ‚Üë), saved.\n",
        "\n",
        "--- Epoch 6/10 ---\n",
        "Epoch 6: Train Loss=0.2475, Val Loss=0.2570, HitRate@3=0.5114, NDCG@3=0.4110, MAP@3=0.6468, LR=0.000183 (527.9s)\n",
        "üíæ Model improved (loss ‚Üì and hitrate ‚Üë), saved.\n",
        "\n",
        "--- Epoch 7/10 ---\n",
        "Epoch 7: Train Loss=0.2366, Val Loss=0.2457, HitRate@3=0.5101, NDCG@3=0.4140, MAP@3=0.6579, LR=0.000117 (526.7s)\n",
        "\n",
        "--- Epoch 8/10 ---\n",
        "Epoch 8: Train Loss=0.2253, Val Loss=0.2430, HitRate@3=0.5141, NDCG@3=0.4162, MAP@3=0.6548, LR=0.000056 (526.6s)\n",
        "üíæ Model improved (loss ‚Üì and hitrate ‚Üë), saved.\n",
        "\n",
        "--- Epoch 9/10 ---\n",
        "Epoch 9: Train Loss=0.2166, Val Loss=0.2372, HitRate@3=0.5215, NDCG@3=0.4208, MAP@3=0.6594, LR=0.000015 (527.6s)\n",
        "üíæ Model improved (loss ‚Üì and hitrate ‚Üë), saved.\n",
        "\n",
        "--- Epoch 10/10 ---\n",
        "Epoch 10: Train Loss=0.2094, Val Loss=0.2379, HitRate@3=0.5202, NDCG@3=0.4192, MAP@3=0.6588, LR=0.000000 (526.7s)"
      ],
      "metadata": {
        "id": "k_wY8yOemchr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile deeprec_validate.py\n",
        "import os\n",
        "import time\n",
        "import random\n",
        "import torch\n",
        "import math\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import defaultdict\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "import polars as pl\n",
        "from tqdm import tqdm\n",
        "from src.feature import feature_engineering, feature_selection\n",
        "from transformers import get_scheduler\n",
        "from collections import Counter\n",
        "from torch.optim.lr_scheduler import OneCycleLR\n",
        "\n",
        "class RankDataset(Dataset):\n",
        "    def __init__(\n",
        "        self,\n",
        "        X: pl.DataFrame,\n",
        "        y: pl.Series,\n",
        "        groups: pl.DataFrame,\n",
        "        cat_features: list[str],\n",
        "        num_features: list[str],\n",
        "    ):\n",
        "        self.cat_features = cat_features\n",
        "        self.num_features = num_features\n",
        "        self.X_cat = {c: X[c].to_numpy() for c in cat_features}\n",
        "        self.X_num = X[self.num_features].to_numpy()\n",
        "        self.y = y.to_numpy()\n",
        "        self.groups = groups[\"ranker_id\"].to_numpy()\n",
        "\n",
        "        self.group_to_indices = defaultdict(list)\n",
        "        for i, g in enumerate(self.groups):\n",
        "            self.group_to_indices[g].append(i)\n",
        "        self.group_keys = list(self.group_to_indices.keys())\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.group_keys)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        g = self.group_keys[idx]\n",
        "        inds = self.group_to_indices[g]\n",
        "        length = len(inds)\n",
        "\n",
        "        x_cat = {\n",
        "            c: torch.LongTensor([\n",
        "                self.X_cat[c][i] if self.X_cat[c][i] >= 0 else 0 for i in inds\n",
        "            ])\n",
        "            for c in self.cat_features\n",
        "        }\n",
        "\n",
        "        x_num = torch.FloatTensor(self.X_num[inds])\n",
        "        y = torch.FloatTensor(self.y[inds]).reshape(-1)\n",
        "\n",
        "        return x_cat, x_num, y, length\n",
        "\n",
        "def collate_fn(batch):\n",
        "    batch_size = len(batch)\n",
        "    lengths = [b[3] for b in batch]\n",
        "    max_len = max(lengths)\n",
        "\n",
        "    padded_x_cat = {key: [] for key in batch[0][0].keys()}\n",
        "    padded_x_num = []\n",
        "    padded_y = []\n",
        "\n",
        "    num_dim = batch[0][1].shape[1]\n",
        "\n",
        "    for x_cat, x_num, y, length in batch:\n",
        "        pad_len = max_len - length\n",
        "\n",
        "        for key in padded_x_cat:\n",
        "            val = x_cat[key]\n",
        "            if pad_len > 0:\n",
        "                val = torch.cat([val, torch.zeros(pad_len, dtype=torch.long)])\n",
        "            padded_x_cat[key].append(val)\n",
        "\n",
        "        if pad_len > 0:\n",
        "            x_num = torch.cat([x_num, torch.zeros(pad_len, num_dim)])\n",
        "            y = torch.cat([y, torch.zeros(pad_len)])\n",
        "\n",
        "        padded_x_num.append(x_num)\n",
        "        padded_y.append(y)\n",
        "\n",
        "    padded_x_cat = {k: torch.stack(v) for k, v in padded_x_cat.items()}\n",
        "    padded_x_num = torch.stack(padded_x_num)\n",
        "    padded_y = torch.stack(padded_y)\n",
        "    lengths = torch.tensor(lengths, dtype=torch.long)\n",
        "\n",
        "    return padded_x_cat, padded_x_num, padded_y, lengths\n",
        "\n",
        "class SEModule(nn.Module):\n",
        "    def __init__(self, channel, reduction=4):\n",
        "        super().__init__()\n",
        "        self.attn_weights = nn.Sequential(\n",
        "            nn.Linear(channel, channel // reduction),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(channel // reduction, 1)\n",
        "        )\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: [B, N, C]\n",
        "        # Compute attention weights: [B, N, 1]\n",
        "        attn_raw = self.attn_weights(x)\n",
        "        attn = torch.softmax(attn_raw, dim=1)  # [B, N, 1]\n",
        "\n",
        "        # Weighted aggregation\n",
        "        pooled = (attn * x).sum(dim=1, keepdim=True)  # [B, 1, C]\n",
        "\n",
        "        scale = self.sigmoid(pooled)  # [B, 1, C]\n",
        "        return x * scale  # [B, N, C]\n",
        "\n",
        "\n",
        "class DLRankerAttention(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        cat_dims,\n",
        "        num_numeric_feats,\n",
        "        emb_dropout=0.1,\n",
        "        dropout=0.1,\n",
        "        num_heads=4,\n",
        "        num_layers=2,\n",
        "        dim_feedforward=128,\n",
        "        proj_dim=64,\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "        self.emb_dims = {\n",
        "            f: min(50, max(4, round(6 * math.log2(cat_dims[f] + 1)))) for f in cat_dims\n",
        "        }\n",
        "        self.embeddings = nn.ModuleDict(\n",
        "            {\n",
        "                f: nn.Embedding(cat_dims[f], self.emb_dims[f], padding_idx=0)\n",
        "                for f in cat_dims\n",
        "            }\n",
        "        )\n",
        "        self.emb_dropout = nn.Dropout(emb_dropout)\n",
        "\n",
        "        total_emb_dim = sum(self.emb_dims.values())\n",
        "        print(\n",
        "            f\"Categorial emb dim sum: {total_emb_dim}, Numerical dim: {num_numeric_feats}\"\n",
        "        )\n",
        "\n",
        "        self.cat_proj = nn.Linear(total_emb_dim, proj_dim)\n",
        "        self.cat_transformer = nn.TransformerEncoder(\n",
        "            nn.TransformerEncoderLayer(\n",
        "                d_model=proj_dim,\n",
        "                nhead=4,\n",
        "                dim_feedforward=dim_feedforward,\n",
        "                dropout=dropout,\n",
        "                batch_first=True,\n",
        "            ),\n",
        "            num_layers=1,\n",
        "        )\n",
        "\n",
        "\n",
        "        self.num_proj_in = nn.Linear(num_numeric_feats, proj_dim)\n",
        "        self.num_transformer = nn.TransformerEncoder(\n",
        "            nn.TransformerEncoderLayer(\n",
        "                d_model=proj_dim,\n",
        "                nhead=4,\n",
        "                dim_feedforward=dim_feedforward,\n",
        "                dropout=dropout,\n",
        "                batch_first=True,\n",
        "            ),\n",
        "            num_layers=1,\n",
        "        )\n",
        "        self.num_se = SEModule(proj_dim)\n",
        "        self.num_proj_out = nn.Sequential(\n",
        "            nn.Linear(proj_dim, proj_dim),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(dropout),\n",
        "        )\n",
        "\n",
        "        self.transformer_layers = nn.ModuleList(\n",
        "            [\n",
        "                nn.TransformerEncoderLayer(\n",
        "                    d_model=2 * proj_dim,\n",
        "                    nhead=num_heads,\n",
        "                    dim_feedforward=dim_feedforward,\n",
        "                    dropout=dropout,\n",
        "                    batch_first=True,\n",
        "                )\n",
        "                for _ in range(num_layers)\n",
        "            ]\n",
        "        )\n",
        "\n",
        "        self.mlp = nn.Sequential(\n",
        "            nn.Linear(2 * proj_dim, 128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(128, 64),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(64, 1),\n",
        "        )\n",
        "\n",
        "    def forward(self, x_cat: dict, x_num: torch.Tensor, attn_mask=None):\n",
        "        B, N, _ = x_num.shape  # x_num: [B, N, F_num]\n",
        "\n",
        "        cat_emb_list = []\n",
        "        for f, emb_layer in self.embeddings.items():\n",
        "            emb = emb_layer(x_cat[f])  # [B, N]\n",
        "            cat_emb_list.append(emb)\n",
        "        cat_embs = torch.cat(cat_emb_list, dim=-1)  # [B, N, total_emb_dim]\n",
        "        cat_embs = self.emb_dropout(cat_embs)\n",
        "        cat_feat = self.cat_proj(cat_embs)  # [B, N, proj_dim]\n",
        "        cat_feat = self.cat_transformer(cat_feat)  # [B, N, proj_dim]\n",
        "\n",
        "        num_feat = self.num_proj_in(x_num)  # [B, N, proj_dim]\n",
        "        num_feat = self.num_transformer(num_feat)  # [B, N, proj_dim]\n",
        "        num_feat = self.num_se(num_feat)  # [B, N, proj_dim]\n",
        "        num_feat = self.num_proj_out(num_feat)  # [B, N, proj_dim]\n",
        "\n",
        "        x = torch.cat([cat_feat, num_feat], dim=-1)  # [B, N, 2*proj_dim]\n",
        "\n",
        "        for layer in self.transformer_layers:\n",
        "            x = layer(x, src_key_padding_mask=attn_mask)\n",
        "\n",
        "        scores = self.mlp(x).squeeze(-1)  # [B, N]\n",
        "\n",
        "        return scores\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "def listmle_loss(scores, labels, lengths):\n",
        "    batch_size = scores.size(0)\n",
        "    total_loss = torch.tensor(0.0, device=scores.device, requires_grad=True)\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "\n",
        "        _, idx = torch.sort(y, descending=True)\n",
        "        s_sorted = s[idx]\n",
        "\n",
        "        parts = (\n",
        "            torch.logsumexp(s_sorted.unsqueeze(0).expand(l, -1).triu(diagonal=0), dim=1)\n",
        "            - s_sorted\n",
        "        )\n",
        "\n",
        "        total_loss = total_loss + parts.sum()\n",
        "\n",
        "    return total_loss / batch_size\n",
        "\"\"\"\n",
        "\n",
        "def hitrate_at_k(scores, labels, lengths, k=3, min_group_size=10):\n",
        "    batch_size = scores.size(0)\n",
        "    hits = 0\n",
        "    valid_count = 0\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        if l < min_group_size:\n",
        "            continue\n",
        "        length = min(l, k)\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "        _, topk_idx = torch.topk(s, length)\n",
        "        topk_labels = y[topk_idx]\n",
        "        hits += (topk_labels > 0).any().float()\n",
        "        valid_count += 1\n",
        "    return hits / valid_count if valid_count > 0 else torch.tensor(0.0, device=scores.device)\n",
        "\n",
        "\n",
        "def ndcg_at_k(scores, labels, lengths, k=3, min_group_size=10):\n",
        "    batch_size = scores.size(0)\n",
        "    total_ndcg = 0.0\n",
        "    valid_count = 0\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        if l < min_group_size:\n",
        "            continue\n",
        "\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "\n",
        "        _, idx_pred = torch.topk(s, min(k, l))\n",
        "        _, idx_ideal = torch.topk(y, min(k, l))\n",
        "\n",
        "        dcg = (y[idx_pred] / torch.log2(torch.arange(2, 2 + len(idx_pred), device=y.device).float())).sum()\n",
        "        idcg = (y[idx_ideal] / torch.log2(torch.arange(2, 2 + len(idx_ideal), device=y.device).float())).sum()\n",
        "\n",
        "        ndcg = dcg / idcg if idcg > 0 else 0.0\n",
        "        total_ndcg += ndcg\n",
        "        valid_count += 1\n",
        "\n",
        "    return total_ndcg / valid_count if valid_count > 0 else torch.tensor(0.0, device=scores.device)\n",
        "\n",
        "\n",
        "def map_at_k(scores, labels, lengths, k=3, min_group_size=10):\n",
        "    batch_size = scores.size(0)\n",
        "    total_ap = 0.0\n",
        "    valid_count = 0\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        if l < min_group_size:\n",
        "            continue\n",
        "\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "\n",
        "        _, idx_pred = torch.topk(s, min(k, l))\n",
        "        y_true = y[idx_pred] > 0\n",
        "\n",
        "        if y_true.sum() == 0:\n",
        "            continue\n",
        "\n",
        "        precisions = [(y_true[:j+1].float().sum() / (j+1)) for j in range(len(y_true)) if y_true[j]]\n",
        "        ap = torch.stack(precisions).mean()\n",
        "        total_ap += ap\n",
        "        valid_count += 1\n",
        "\n",
        "    return total_ap / valid_count if valid_count > 0 else torch.tensor(0.0, device=scores.device)\n",
        "\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "def listnet_loss(scores, labels, lengths):\n",
        "    batch_size = scores.size(0)\n",
        "    total_loss = 0.0\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "\n",
        "        s_softmax = torch.nn.functional.log_softmax(s, dim=0)\n",
        "        y_softmax = torch.nn.functional.softmax(y, dim=0)\n",
        "\n",
        "        loss = -torch.sum(y_softmax * s_softmax)\n",
        "        total_loss += loss\n",
        "\n",
        "    return total_loss / batch_size\n",
        "\"\"\"\n",
        "\n",
        "def ranknet_loss(scores, labels, lengths):\n",
        "    batch_size = scores.size(0)\n",
        "    total_loss = 0.0\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "\n",
        "        diff_scores = s.unsqueeze(1) - s.unsqueeze(0)\n",
        "        rel = y.unsqueeze(1) > y.unsqueeze(0)\n",
        "        label_diff = rel.float()\n",
        "\n",
        "        log_sigmoid = torch.nn.functional.logsigmoid(diff_scores)\n",
        "        pair_loss = -label_diff * log_sigmoid\n",
        "\n",
        "        total_loss += pair_loss.sum()\n",
        "\n",
        "    return total_loss / batch_size\n",
        "\n",
        "def xranknet_loss(scores, labels, lengths, temperature=1.0, margin=0.2, focus_topk=3):\n",
        "    \"\"\"\n",
        "    xRankNet with emphasis on top-K items (based on labels, not scores).\n",
        "    \"\"\"\n",
        "    batch_size = scores.size(0)\n",
        "    total_loss = 0.0\n",
        "    total_pairs = 0\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        if l < 2:\n",
        "            continue\n",
        "\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "\n",
        "        # Top-K mask based on ground truth labels\n",
        "        topk = min(focus_topk, l)\n",
        "        _, topk_idx = torch.topk(y, topk)\n",
        "        topk_mask = torch.zeros_like(y, dtype=torch.bool)\n",
        "        topk_mask[topk_idx] = True\n",
        "\n",
        "        # Create pairwise difference matrices\n",
        "        score_diff = s.unsqueeze(1) - s.unsqueeze(0)\n",
        "        label_diff = y.unsqueeze(1) - y.unsqueeze(0)\n",
        "\n",
        "        # valid pair: y_i > y_j and at least one of i, j is in top-K\n",
        "        valid_pairs = (label_diff > 0) & (\n",
        "            topk_mask.unsqueeze(1) | topk_mask.unsqueeze(0)\n",
        "        )\n",
        "\n",
        "        if valid_pairs.sum() == 0:\n",
        "            continue\n",
        "\n",
        "        importance = (label_diff.abs() * valid_pairs).float()\n",
        "\n",
        "        if margin > 0.0:\n",
        "            score_diff = score_diff - margin\n",
        "\n",
        "        score_diff = score_diff / temperature\n",
        "        pairwise_loss = -F.logsigmoid(score_diff) * importance\n",
        "\n",
        "        total_loss += pairwise_loss.sum()\n",
        "        total_pairs += importance.sum()\n",
        "\n",
        "    if total_pairs == 0:\n",
        "        return torch.tensor(0.0, device=scores.device, requires_grad=True)\n",
        "\n",
        "    return total_loss / total_pairs\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "def bpr_loss(scores, labels, lengths):\n",
        "    batch_size = scores.size(0)\n",
        "    total_loss = 0.0\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "\n",
        "        pos_mask = y > 0\n",
        "        neg_mask = y <= 0\n",
        "\n",
        "        pos_scores = s[pos_mask]\n",
        "        neg_scores = s[neg_mask]\n",
        "\n",
        "        if len(pos_scores) == 0 or len(neg_scores) == 0:\n",
        "            continue\n",
        "\n",
        "        pair_diff = pos_scores.unsqueeze(1) - neg_scores.unsqueeze(0)\n",
        "        loss = -F.logsigmoid(pair_diff).mean()\n",
        "        total_loss += loss\n",
        "\n",
        "    return total_loss / batch_size\n",
        "\"\"\"\n",
        "\n",
        "\"\"\"\n",
        "def lambdarank_loss(scores, labels, lengths, eps=1e-10):\n",
        "    batch_size = scores.size(0)\n",
        "    total_loss = 0.0\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "\n",
        "        if l < 2:\n",
        "            continue\n",
        "\n",
        "        _, rank_order = torch.sort(s, descending=True)\n",
        "        ideal_order = torch.sort(y, descending=True).indices\n",
        "\n",
        "        gain = 2 ** y - 1\n",
        "        discount = torch.log2(torch.arange(2, l + 2, device=y.device).float())\n",
        "\n",
        "        ideal_dcg = (gain[ideal_order] / discount).sum()\n",
        "        if ideal_dcg < eps:\n",
        "            continue\n",
        "\n",
        "        delta_ndcg = torch.zeros((l, l), device=y.device)\n",
        "\n",
        "        for i_idx in range(l):\n",
        "            for j_idx in range(l):\n",
        "                if y[i_idx] > y[j_idx]:\n",
        "                    change = (\n",
        "                        (1.0 / torch.log2(rank_order[i_idx] + 2.0))\n",
        "                        - (1.0 / torch.log2(rank_order[j_idx] + 2.0))\n",
        "                    ).abs()\n",
        "                    delta = (2 ** y[i_idx] - 2 ** y[j_idx]).abs() * change\n",
        "                    delta_ndcg[i_idx, j_idx] = delta / ideal_dcg\n",
        "\n",
        "        score_diffs = s.unsqueeze(1) - s.unsqueeze(0)\n",
        "        lambdas = -F.logsigmoid(score_diffs) * delta_ndcg\n",
        "        total_loss += lambdas.sum()\n",
        "\n",
        "    return total_loss / batch_size\n",
        "\"\"\"\n",
        "\n",
        "def train_one_epoch(model, loader, optimizer, device, scheduler):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "\n",
        "    for x_cat, x_num, y, lengths in tqdm(loader, desc=\"Training\", leave=False):\n",
        "        x_num, y = x_num.to(device), y.to(device)\n",
        "        if not isinstance(lengths, torch.Tensor):\n",
        "            lengths = torch.tensor(lengths)\n",
        "        lengths = lengths.detach().clone().to(device)\n",
        "        x_cat = {k: v.to(device) for k, v in x_cat.items()}\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        scores = model(x_cat, x_num)\n",
        "        loss = xranknet_loss(scores, y, lengths, temperature=1.0, margin=0.2, focus_topk=3)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    return total_loss / len(loader)\n",
        "\n",
        "\n",
        "def validate(model, loader, device, min_group_size=10):\n",
        "    model.eval()\n",
        "    total_hitrate = 0\n",
        "    total_ndcg = 0\n",
        "    total_map = 0\n",
        "    total_loss = 0\n",
        "    count = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for x_cat, x_num, y, lengths in tqdm(loader, desc=\"Validating\", leave=False):\n",
        "            x_num, y = x_num.to(device), y.to(device)\n",
        "            lengths = torch.tensor(lengths).to(device)\n",
        "            x_cat = {k: v.to(device) for k, v in x_cat.items()}\n",
        "\n",
        "            scores = model(x_cat, x_num)\n",
        "\n",
        "            hitrate = hitrate_at_k(scores, y, lengths, k=3, min_group_size=min_group_size)\n",
        "            ndcg = ndcg_at_k(scores, y, lengths, k=3, min_group_size=min_group_size)\n",
        "            map3 = map_at_k(scores, y, lengths, k=3, min_group_size=min_group_size)\n",
        "            loss = xranknet_loss(scores, y, lengths, temperature=1.0, margin=0.2, focus_topk=3)\n",
        "\n",
        "            batch_size = scores.size(0)\n",
        "            total_hitrate += hitrate * batch_size\n",
        "            total_ndcg += ndcg * batch_size\n",
        "            total_map += map3 * batch_size\n",
        "            total_loss += loss.item() * batch_size\n",
        "            count += batch_size\n",
        "\n",
        "    return total_loss / count, total_hitrate / count, total_ndcg / count, total_map / count\n",
        "\n",
        "\n",
        "def build_cat_dims(X, cat_features):\n",
        "    cat_dims = {}\n",
        "    for c in cat_features:\n",
        "        max_val = X[c].max()\n",
        "        if max_val < 0:\n",
        "            max_val = 0\n",
        "        cat_dims[c] = max_val + 1\n",
        "    return cat_dims\n",
        "\n",
        "\n",
        "def normalize_numeric_features(X, numeric_features, train_mask):\n",
        "    for col in numeric_features:\n",
        "        values = X[col].to_numpy()\n",
        "        train_vals = values[train_mask]\n",
        "        mean = train_vals.mean()\n",
        "        std = train_vals.std() if train_vals.std() > 0 else 1.0\n",
        "        norm_vals = (values - mean) / std\n",
        "        X = X.with_columns(pl.Series(col, norm_vals).alias(col))\n",
        "    return X\n",
        "\n",
        "\n",
        "def load_or_prepare_data(\n",
        "    data_dir,\n",
        "    train_file=\"train.parquet\",\n",
        "    test_file=\"test.parquet\",\n",
        "    cache_file=\"feature_engineered_val.parquet\",\n",
        "):\n",
        "    cache_path = os.path.join(data_dir, cache_file)\n",
        "\n",
        "    if os.path.exists(cache_path):\n",
        "        print(f\"Loading cached feature-engineered data from {cache_path} ...\")\n",
        "        df = pl.read_parquet(cache_path)\n",
        "\n",
        "        test = pl.read_parquet(os.path.join(data_dir, test_file)).drop(\"__index_level_0__\")\n",
        "        test_ids = test[\"Id\"]\n",
        "        test_rankers = test[\"ranker_id\"]\n",
        "    else:\n",
        "        print(\"Cached file not found, processing raw data ...\")\n",
        "\n",
        "        train = pl.read_parquet(os.path.join(data_dir, train_file)).drop(\"__index_level_0__\")\n",
        "        test = (\n",
        "            pl.read_parquet(os.path.join(data_dir, test_file))\n",
        "            .drop(\"__index_level_0__\")\n",
        "            .with_columns(pl.lit(0, dtype=pl.Int64).alias(\"selected\"))\n",
        "        )\n",
        "\n",
        "        test_ids = test[\"Id\"]\n",
        "        test_rankers = test[\"ranker_id\"]\n",
        "\n",
        "        df = pl.concat((train, test))\n",
        "        df = feature_engineering(df, full=True)\n",
        "\n",
        "        df = df.with_columns(\n",
        "            [pl.col(c).fill_null(0) for c in df.select(pl.selectors.numeric()).columns] +\n",
        "            [pl.col(c).fill_null(\"missing\") for c in df.select(pl.selectors.string()).columns]\n",
        "        )\n",
        "\n",
        "        os.makedirs(data_dir, exist_ok=True)\n",
        "        df.write_parquet(cache_path)\n",
        "        print(f\"Saved feature-engineered data to {cache_path}\")\n",
        "\n",
        "    return df, test_ids, test_rankers\n",
        "\n",
        "\n",
        "def prepare_data(data_dir):\n",
        "    df, test_ids, test_rankers = load_or_prepare_data(data_dir)\n",
        "\n",
        "    id_column = df[\"Id\"]\n",
        "    X, y, groups, cat_features, num_features = feature_selection(df)\n",
        "\n",
        "    X = X.with_columns(pl.Series(\"Id\", id_column[:X.shape[0]]))\n",
        "\n",
        "    X = X.with_columns(\n",
        "        [\n",
        "            (pl.col(c).rank(\"dense\") - 1).fill_null(-1).cast(pl.Int32)\n",
        "            for c in cat_features\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    train_size = 18145372\n",
        "    train_mask = np.arange(X.height) < train_size\n",
        "    X = normalize_numeric_features(X, num_features, train_mask)\n",
        "\n",
        "    return X, y, groups, cat_features, num_features, train_size, test_ids, test_rankers\n",
        "\n",
        "\n",
        "class EarlyStopping:\n",
        "    def __init__(self, patience=3, min_delta=0.00005):\n",
        "        self.patience = patience\n",
        "        self.min_delta = min_delta\n",
        "        self.best = float(\"-inf\")\n",
        "        self.counter = 0\n",
        "\n",
        "    def step(self, metric):\n",
        "        if metric > self.best + self.min_delta:\n",
        "            self.best = metric\n",
        "            self.counter = 0\n",
        "        else:\n",
        "            self.counter += 1\n",
        "        return self.counter >= self.patience\n",
        "\n",
        "\n",
        "def plot_group_size_distribution(dataset, save_path=None):\n",
        "    group_sizes = [len(v) for v in dataset.group_to_indices.values()]\n",
        "    plt.figure()\n",
        "    plt.hist(group_sizes, bins=100, log=True)\n",
        "    plt.xlabel(\"Group size (number of items per ranker_id)\")\n",
        "    plt.ylabel(\"Frequency (log scale)\")\n",
        "    plt.title(\"Distribution of Group Sizes\")\n",
        "    plt.grid(True)\n",
        "    if save_path:\n",
        "        plt.savefig(save_path)\n",
        "    else:\n",
        "        plt.show()\n",
        "    plt.close()\n",
        "\n",
        "\n",
        "def main():\n",
        "    DATA_DIR = \"./data\"\n",
        "    MODEL_DIR = \"model\"\n",
        "    SUBMIT_DIR = \"submission\"\n",
        "\n",
        "    best_val_loss = float(\"inf\")\n",
        "    best_hitrate = 0.0\n",
        "    model_path = os.path.join(MODEL_DIR, \"best_dl_ranker.pt\")\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "    val_hitrates = []\n",
        "    val_ndcgs = []\n",
        "    val_maps = []\n",
        "    learning_rates = []\n",
        "\n",
        "    os.makedirs(MODEL_DIR, exist_ok=True)\n",
        "    os.makedirs(SUBMIT_DIR, exist_ok=True)\n",
        "\n",
        "    early_stopper = EarlyStopping(patience=3, min_delta=0.001)\n",
        "\n",
        "    X, y, groups, cat_features, num_features, train_size, test_ids, test_rankers = prepare_data(DATA_DIR)\n",
        "\n",
        "    # Fill missing values\n",
        "    float_cols = [c for c, t in zip(X.columns, X.dtypes) if t == pl.Float64]\n",
        "    for col in float_cols:\n",
        "        X = X.with_columns(\n",
        "            pl.when(pl.col(col).is_nan()).then(0).otherwise(pl.col(col)).alias(col)\n",
        "        )\n",
        "\n",
        "    n1 = 16487352\n",
        "    # n1 = 17487300\n",
        "    n2 = train_size\n",
        "\n",
        "    X_tr, X_va, X_te = X[:n1], X[n1:n2], X[n2:]\n",
        "    y_tr, y_va, y_te = y[:n1], y[n1:n2], y[n2:]\n",
        "    groups_tr, groups_va, groups_te = groups[:n1], groups[n1:n2], groups[n2:]\n",
        "\n",
        "    # Inspect group sizes in validation set\n",
        "    val_rankers = groups_va[\"ranker_id\"].to_numpy()\n",
        "    val_group_counts = Counter(val_rankers)\n",
        "\n",
        "    print(\"\\nüìã Validation group statistics:\")\n",
        "    # Save detailed group info to file\n",
        "    group_info_path = os.path.join(MODEL_DIR, \"validation_groups_info.txt\")\n",
        "    with open(group_info_path, \"w\") as f:\n",
        "        f.write(f\"Total groups: {len(val_group_counts)}\\n\\n\")\n",
        "        f.write(\"GroupID\\tSize\\tStartIdx\\tEndIdx\\n\")\n",
        "\n",
        "        group_to_rows = defaultdict(list)\n",
        "        for i, g in enumerate(val_rankers):\n",
        "            group_to_rows[g].append(i)\n",
        "\n",
        "        for group_id, indices in sorted(group_to_rows.items()):\n",
        "            start_idx = indices[0]\n",
        "            end_idx = indices[-1]\n",
        "            size = len(indices)\n",
        "            f.write(f\"{group_id}\\t{size}\\t{start_idx}\\t{end_idx}\\n\")\n",
        "\n",
        "    print(f\"üìÅ Saved validation group info to {group_info_path}\")\n",
        "\n",
        "\n",
        "    cat_dims = build_cat_dims(X, cat_features)\n",
        "    num_numeric_feats = len(num_features)\n",
        "\n",
        "    train_dataset = RankDataset(X_tr, y_tr, groups_tr, cat_features, num_features)\n",
        "    val_dataset = RankDataset(X_va, y_va, groups_va, cat_features, num_features)\n",
        "    test_dataset = RankDataset(X_te, y_te, groups_te, cat_features, num_features)\n",
        "\n",
        "    plot_group_size_distribution(train_dataset, save_path=os.path.join(MODEL_DIR, \"group_sizes.png\"))\n",
        "    print(\"üìä Group size distribution saved.\")\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True, collate_fn=collate_fn)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=4, shuffle=False, collate_fn=collate_fn)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False, collate_fn=collate_fn)\n",
        "\n",
        "    print(\"‚úÖ Data loaders created.\")\n",
        "\n",
        "    num_epochs = 10\n",
        "    num_training_steps = num_epochs * len(train_loader)\n",
        "    num_warmup_steps = int(0.1 * num_training_steps)\n",
        "\n",
        "    learning_rate = 3e-4\n",
        "\n",
        "    model = DLRankerAttention(\n",
        "        cat_dims=cat_dims,\n",
        "        num_numeric_feats=num_numeric_feats,\n",
        "        emb_dropout=0.1,\n",
        "        dropout=0.1,\n",
        "        num_heads=4,\n",
        "        num_layers=2,\n",
        "        dim_feedforward=128,\n",
        "        proj_dim=64\n",
        "    ).to(device)\n",
        "\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=0.01)\n",
        "\n",
        "    scheduler = OneCycleLR(\n",
        "        optimizer,\n",
        "        max_lr=learning_rate,\n",
        "        steps_per_epoch=len(train_loader),\n",
        "        epochs=num_epochs,\n",
        "        pct_start=0.3,\n",
        "    )\n",
        "\n",
        "    best_hitrate = 0\n",
        "    for epoch in range(num_epochs):\n",
        "        print(f\"\\n--- Epoch {epoch+1}/{num_epochs} ---\")\n",
        "        start_time = time.time()\n",
        "\n",
        "        train_loss = train_one_epoch(model, train_loader, optimizer, device, scheduler)\n",
        "        val_loss, val_hitrate, val_ndcg, val_map = validate(model, val_loader, device, min_group_size=10)\n",
        "\n",
        "        train_losses.append(train_loss)\n",
        "        val_losses.append(val_loss)\n",
        "        val_hitrates.append(val_hitrate.item())\n",
        "        val_ndcgs.append(val_ndcg.item())\n",
        "        val_maps.append(val_map.item())\n",
        "\n",
        "        current_lr = scheduler.get_last_lr()\n",
        "        learning_rates.append(current_lr[0])\n",
        "\n",
        "        elapsed = time.time() - start_time\n",
        "        print(\n",
        "            f\"Epoch {epoch+1}: \"\n",
        "            f\"Train Loss={train_loss:.4f}, \"\n",
        "            f\"Val Loss={val_loss:.4f}, \"\n",
        "            f\"HitRate@3={val_hitrate:.4f}, \"\n",
        "            f\"NDCG@3={val_ndcg:.4f}, \"\n",
        "            f\"MAP@3={val_map:.4f}, \"\n",
        "            f\"LR={current_lr[0]:.6f} \"\n",
        "            f\"({elapsed:.1f}s)\"\n",
        "        )\n",
        "\n",
        "\n",
        "        if val_loss < best_val_loss and val_hitrate > best_hitrate:\n",
        "            best_val_loss = val_loss\n",
        "            best_hitrate = val_hitrate\n",
        "            torch.save(model.state_dict(), model_path)\n",
        "            print(\"üíæ Model improved (loss ‚Üì and hitrate ‚Üë), saved.\")\n",
        "\n",
        "        if early_stopper.step(-val_loss):\n",
        "            print(\"‚õî Early stopping triggered.\")\n",
        "            break\n",
        "\n",
        "    # Plot metrics\n",
        "    epochs = list(range(1, len(train_losses) + 1))\n",
        "\n",
        "    # Plot Loss Curve\n",
        "    plt.figure()\n",
        "    plt.plot(epochs, train_losses, label=\"Train Loss\")\n",
        "    plt.plot(epochs, val_losses, label=\"Val Loss\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.title(\"Training & Validation Loss\")\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.savefig(os.path.join(MODEL_DIR, \"loss_curve.png\"))\n",
        "    plt.close()\n",
        "\n",
        "    # Plot HitRate@3\n",
        "    plt.figure()\n",
        "    plt.plot(epochs, val_hitrates, label=\"Val HitRate@3\", color=\"green\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"HitRate@3\")\n",
        "    plt.title(\"Validation HitRate@3\")\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.savefig(os.path.join(MODEL_DIR, \"hitrate_curve.png\"))\n",
        "    plt.close()\n",
        "\n",
        "    # Plot Learning Rate\n",
        "    plt.figure()\n",
        "    plt.plot(epochs, learning_rates, label=\"Learning Rate\", color=\"orange\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"LR\")\n",
        "    plt.title(\"Learning Rate Schedule\")\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.savefig(os.path.join(MODEL_DIR, \"lr_curve.png\"))\n",
        "    plt.close()\n",
        "\n",
        "    # Plot NDCG@3\n",
        "    plt.figure()\n",
        "    plt.plot(epochs, val_ndcgs, label=\"Val NDCG@3\", color=\"purple\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"NDCG@3\")\n",
        "    plt.title(\"Validation NDCG@3\")\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.savefig(os.path.join(MODEL_DIR, \"ndcg_curve.png\"))\n",
        "    plt.close()\n",
        "\n",
        "    # Plot MAP@3\n",
        "    plt.figure()\n",
        "    plt.plot(epochs, val_maps, label=\"Val MAP@3\", color=\"red\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"MAP@3\")\n",
        "    plt.title(\"Validation MAP@3\")\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.savefig(os.path.join(MODEL_DIR, \"map_curve.png\"))\n",
        "    plt.close()\n",
        "\n",
        "    print(\"üìä Saved metric plots to model/\")\n",
        "\n",
        "    # Predict test set\n",
        "    model.load_state_dict(torch.load(model_path))\n",
        "    model.eval()\n",
        "\n",
        "    val_ids = X_va[\"Id\"]\n",
        "    val_rankers = groups_va[\"ranker_id\"]\n",
        "    val_labels = y_va\n",
        "\n",
        "    all_val_scores = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for x_cat, x_num, _, lengths in tqdm(val_loader, desc=\"Predicting validation set\"):\n",
        "            x_num = x_num.to(device)\n",
        "            x_cat = {k: v.to(device) for k, v in x_cat.items()}\n",
        "            scores = model(x_cat, x_num)\n",
        "\n",
        "            for i in range(scores.size(0)):\n",
        "                l = lengths[i]\n",
        "                all_val_scores.append(scores[i, :l].cpu().numpy())\n",
        "\n",
        "    all_val_scores = np.concatenate(all_val_scores)\n",
        "\n",
        "    assert len(all_val_scores) == X_va.shape[0], \\\n",
        "        f\"Mismatch: {len(all_val_scores)} scores vs {X_va.shape[0]} rows\"\n",
        "\n",
        "    val_df = X_va.with_columns([\n",
        "        pl.Series(\"Id\", val_ids),\n",
        "        pl.Series(\"ranker_id\", val_rankers),\n",
        "        pl.Series(\"score\", all_val_scores),\n",
        "        pl.Series(\"label\", val_labels)\n",
        "    ])\n",
        "\n",
        "    val_df = val_df.with_columns(\n",
        "        pl.col(\"score\")\n",
        "        .rank(method=\"ordinal\", descending=True)\n",
        "        .over(\"ranker_id\")\n",
        "        .cast(pl.Int32)\n",
        "        .alias(\"selected\")\n",
        "    )\n",
        "\n",
        "    val_save_path = os.path.join(MODEL_DIR, \"validation_preds_dl_full.csv\")\n",
        "    val_df.write_csv(val_save_path)\n",
        "    print(f\"‚úÖ Saved full validation predictions (with features) to {val_save_path}\")\n",
        "\n",
        "    all_scores = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for x_cat, x_num, _, lengths in tqdm(test_loader, desc=\"Predicting test set\"):\n",
        "            x_num = x_num.to(device)\n",
        "            x_cat = {k: v.to(device) for k, v in x_cat.items()}\n",
        "            scores = model(x_cat, x_num)\n",
        "\n",
        "            for i in range(scores.size(0)):\n",
        "                l = lengths[i]\n",
        "                all_scores.append(scores[i, :l].cpu().numpy())\n",
        "\n",
        "    all_scores = np.concatenate(all_scores)\n",
        "\n",
        "    assert len(all_scores) == X_te.shape[0], \\\n",
        "        f\"Mismatch: {len(all_scores)} scores vs {X_te.shape[0]} rows in X_te\"\n",
        "\n",
        "    submission_df = pl.DataFrame({\n",
        "        \"Id\": test_ids,\n",
        "        \"ranker_id\": test_rankers,\n",
        "        \"score\": all_scores\n",
        "    })\n",
        "\n",
        "    submission = (\n",
        "        submission_df\n",
        "        .with_columns(\n",
        "            pl.col(\"score\")\n",
        "            .rank(method=\"ordinal\", descending=True)\n",
        "            .over(\"ranker_id\")\n",
        "            .cast(pl.Int32)\n",
        "            .alias(\"selected\")\n",
        "        )\n",
        "        .select([\"Id\", \"ranker_id\", \"score\", \"selected\"])\n",
        "    )\n",
        "\n",
        "    submission_path = os.path.join(SUBMIT_DIR, \"submission_dl_ranker.csv\")\n",
        "    submission.write_csv(submission_path)\n",
        "    print(f\"‚úÖ Submission saved to {submission_path}\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xcSWoeoJnuth",
        "outputId": "3c1048bd-7fcf-402b-a208-3a2b088ac46d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting deeprec_validate.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "--- Epoch 1/10 ---\n",
        "Validating:   0%|          | 0/2636 [00:00<?, ?it/s]/home/ionut/test_whisper/test2/deeprec_validate.py:514: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
        "  lengths = torch.tensor(lengths).to(device)\n",
        "Epoch 1: Train Loss=0.3545, Val Loss=0.2954, HitRate@3=0.4755, NDCG@3=0.3781, MAP@3=0.6190, LR=0.000084 (528.2s)\n",
        "üíæ Model improved (loss ‚Üì and hitrate ‚Üë), saved.\n",
        "\n",
        "--- Epoch 2/10 ---\n",
        "Epoch 2: Train Loss=0.2903, Val Loss=0.2838, HitRate@3=0.4892, NDCG@3=0.3928, MAP@3=0.6393, LR=0.000228 (528.2s)\n",
        "üíæ Model improved (loss ‚Üì and hitrate ‚Üë), saved.\n",
        "\n",
        "--- Epoch 3/10 ---\n",
        "Epoch 3: Train Loss=0.2820, Val Loss=0.2683, HitRate@3=0.4981, NDCG@3=0.3975, MAP@3=0.6394, LR=0.000300 (526.6s)\n",
        "üíæ Model improved (loss ‚Üì and hitrate ‚Üë), saved.\n",
        "\n",
        "--- Epoch 4/10 ---\n",
        "Epoch 4: Train Loss=0.2730, Val Loss=0.2664, HitRate@3=0.4992, NDCG@3=0.3984, MAP@3=0.6379, LR=0.000285 (527.2s)\n",
        "üíæ Model improved (loss ‚Üì and hitrate ‚Üë), saved.\n",
        "\n",
        "--- Epoch 5/10 ---\n",
        "Epoch 5: Train Loss=0.2615, Val Loss=0.2689, HitRate@3=0.5097, NDCG@3=0.4082, MAP@3=0.6508, LR=0.000244 (527.0s)\n",
        "\n",
        "--- Epoch 6/10 ---\n",
        "Epoch 6: Train Loss=0.2497, Val Loss=0.2477, HitRate@3=0.5105, NDCG@3=0.4106, MAP@3=0.6481, LR=0.000183 (526.8s)\n",
        "üíæ Model improved (loss ‚Üì and hitrate ‚Üë), saved.\n",
        "\n",
        "--- Epoch 7/10 ---\n",
        "Epoch 7: Train Loss=0.2383, Val Loss=0.2443, HitRate@3=0.5101, NDCG@3=0.4102, MAP@3=0.6529, LR=0.000117 (526.7s)\n",
        "\n",
        "--- Epoch 8/10 ---\n",
        "Epoch 8: Train Loss=0.2265, Val Loss=0.2414, HitRate@3=0.5136, NDCG@3=0.4158, MAP@3=0.6597, LR=0.000056 (529.3s)\n",
        "üíæ Model improved (loss ‚Üì and hitrate ‚Üë), saved.\n",
        "\n",
        "--- Epoch 9/10 ---\n",
        "Epoch 9: Train Loss=0.2172, Val Loss=0.2373, HitRate@3=0.5187, NDCG@3=0.4203, MAP@3=0.6603, LR=0.000015 (528.3s)\n",
        "üíæ Model improved (loss ‚Üì and hitrate ‚Üë), saved.\n",
        "\n",
        "--- Epoch 10/10 ---\n",
        "Epoch 10: Train Loss=0.2116, Val Loss=0.2382, HitRate@3=0.5174, NDCG@3=0.4185, MAP@3=0.6578, LR=0.000000 (527.6s)"
      ],
      "metadata": {
        "id": "cl-TZzkPj0bI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile deeprec_validate.py\n",
        "import os\n",
        "import time\n",
        "import random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F_torch\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import defaultdict\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "import polars as pl\n",
        "from tqdm import tqdm\n",
        "from src.feature import feature_engineering, feature_selection\n",
        "from transformers import get_scheduler\n",
        "from collections import Counter\n",
        "from torch.optim.lr_scheduler import OneCycleLR\n",
        "\n",
        "class RankDataset(Dataset):\n",
        "    def __init__(\n",
        "        self,\n",
        "        X: pl.DataFrame,\n",
        "        y: pl.Series,\n",
        "        groups: pl.DataFrame,\n",
        "        cat_features: list[str],\n",
        "        num_features: list[str],\n",
        "    ):\n",
        "        self.cat_features = cat_features\n",
        "        self.num_features = num_features\n",
        "        self.X_cat = {c: X[c].to_numpy() for c in cat_features}\n",
        "        self.X_num = X[self.num_features].to_numpy()\n",
        "        self.y = y.to_numpy()\n",
        "        self.groups = groups[\"ranker_id\"].to_numpy()\n",
        "\n",
        "        self.group_to_indices = defaultdict(list)\n",
        "        for i, g in enumerate(self.groups):\n",
        "            self.group_to_indices[g].append(i)\n",
        "        self.group_keys = list(self.group_to_indices.keys())\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.group_keys)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        g = self.group_keys[idx]\n",
        "        inds = self.group_to_indices[g]\n",
        "        length = len(inds)\n",
        "\n",
        "        x_cat = {\n",
        "            c: torch.LongTensor([\n",
        "                self.X_cat[c][i] if self.X_cat[c][i] >= 0 else 0 for i in inds\n",
        "            ])\n",
        "            for c in self.cat_features\n",
        "        }\n",
        "\n",
        "        x_num = torch.FloatTensor(self.X_num[inds])\n",
        "        y = torch.FloatTensor(self.y[inds]).reshape(-1)\n",
        "\n",
        "        return x_cat, x_num, y, length\n",
        "\n",
        "def collate_fn(batch):\n",
        "    batch_size = len(batch)\n",
        "    lengths = [b[3] for b in batch]\n",
        "    max_len = max(lengths)\n",
        "\n",
        "    padded_x_cat = {key: [] for key in batch[0][0].keys()}\n",
        "    padded_x_num = []\n",
        "    padded_y = []\n",
        "\n",
        "    num_dim = batch[0][1].shape[1]\n",
        "\n",
        "    for x_cat, x_num, y, length in batch:\n",
        "        pad_len = max_len - length\n",
        "\n",
        "        for key in padded_x_cat:\n",
        "            val = x_cat[key]\n",
        "            if pad_len > 0:\n",
        "                val = torch.cat([val, torch.zeros(pad_len, dtype=torch.long)])\n",
        "            padded_x_cat[key].append(val)\n",
        "\n",
        "        if pad_len > 0:\n",
        "            x_num = torch.cat([x_num, torch.zeros(pad_len, num_dim)])\n",
        "            y = torch.cat([y, torch.zeros(pad_len)])\n",
        "\n",
        "        padded_x_num.append(x_num)\n",
        "        padded_y.append(y)\n",
        "\n",
        "    padded_x_cat = {k: torch.stack(v) for k, v in padded_x_cat.items()}\n",
        "    padded_x_num = torch.stack(padded_x_num)\n",
        "    padded_y = torch.stack(padded_y)\n",
        "    lengths = torch.tensor(lengths, dtype=torch.long)\n",
        "\n",
        "    return padded_x_cat, padded_x_num, padded_y, lengths\n",
        "\n",
        "class SEModule(nn.Module):\n",
        "    def __init__(self, channel, reduction=4):\n",
        "        super().__init__()\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(channel, channel // reduction),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(channel // reduction, channel),\n",
        "            nn.Sigmoid(),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: [B, N, C]\n",
        "        w = self.fc(x.mean(dim=1))\n",
        "        w = w.unsqueeze(1)  # [B, 1, C]\n",
        "        return x * w\n",
        "\n",
        "\n",
        "class DLRankerAttention(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        cat_dims,\n",
        "        num_numeric_feats,\n",
        "        emb_dropout=0.1,\n",
        "        dropout=0.1,\n",
        "        num_heads=4,\n",
        "        num_layers=2,\n",
        "        dim_feedforward=128,\n",
        "        proj_dim=64,\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "        self.emb_dims = {\n",
        "            f: min(50, max(4, round(6 * math.log2(cat_dims[f] + 1)))) for f in cat_dims\n",
        "        }\n",
        "        self.embeddings = nn.ModuleDict(\n",
        "            {\n",
        "                f: nn.Embedding(cat_dims[f], self.emb_dims[f], padding_idx=0)\n",
        "                for f in cat_dims\n",
        "            }\n",
        "        )\n",
        "        self.emb_dropout = nn.Dropout(emb_dropout)\n",
        "\n",
        "        total_emb_dim = sum(self.emb_dims.values())\n",
        "        print(\n",
        "            f\"Categorial emb dim sum: {total_emb_dim}, Numerical dim: {num_numeric_feats}\"\n",
        "        )\n",
        "\n",
        "        self.cat_proj = nn.Linear(total_emb_dim, proj_dim)\n",
        "        self.cat_transformer = nn.TransformerEncoder(\n",
        "            nn.TransformerEncoderLayer(\n",
        "                d_model=proj_dim,\n",
        "                nhead=4,\n",
        "                dim_feedforward=dim_feedforward,\n",
        "                dropout=dropout,\n",
        "                batch_first=True,\n",
        "            ),\n",
        "            num_layers=1,\n",
        "        )\n",
        "\n",
        "\n",
        "        self.num_proj_in = nn.Linear(num_numeric_feats, proj_dim)\n",
        "        self.num_transformer = nn.TransformerEncoder(\n",
        "            nn.TransformerEncoderLayer(\n",
        "                d_model=proj_dim,\n",
        "                nhead=4,\n",
        "                dim_feedforward=dim_feedforward,\n",
        "                dropout=dropout,\n",
        "                batch_first=True,\n",
        "            ),\n",
        "            num_layers=1,\n",
        "        )\n",
        "        self.num_se = SEModule(proj_dim)\n",
        "        self.num_proj_out = nn.Sequential(\n",
        "            nn.Linear(proj_dim, proj_dim),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(dropout),\n",
        "        )\n",
        "\n",
        "        self.transformer_layers = nn.ModuleList(\n",
        "            [\n",
        "                nn.TransformerEncoderLayer(\n",
        "                    d_model=2 * proj_dim,\n",
        "                    nhead=num_heads,\n",
        "                    dim_feedforward=dim_feedforward,\n",
        "                    dropout=dropout,\n",
        "                    batch_first=True,\n",
        "                )\n",
        "                for _ in range(num_layers)\n",
        "            ]\n",
        "        )\n",
        "\n",
        "        self.mlp = nn.Sequential(\n",
        "            nn.Linear(2 * proj_dim, 128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(128, 64),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(64, 1),\n",
        "        )\n",
        "\n",
        "    def forward(self, x_cat: dict, x_num: torch.Tensor, attn_mask=None):\n",
        "        B, N, _ = x_num.shape  # x_num: [B, N, F_num]\n",
        "\n",
        "        cat_emb_list = []\n",
        "        for f, emb_layer in self.embeddings.items():\n",
        "            emb = emb_layer(x_cat[f])  # [B, N]\n",
        "            cat_emb_list.append(emb)\n",
        "        cat_embs = torch.cat(cat_emb_list, dim=-1)  # [B, N, total_emb_dim]\n",
        "        cat_embs = self.emb_dropout(cat_embs)\n",
        "        cat_feat = self.cat_proj(cat_embs)  # [B, N, proj_dim]\n",
        "        cat_feat = self.cat_transformer(cat_feat)  # [B, N, proj_dim]\n",
        "\n",
        "        num_feat = self.num_proj_in(x_num)  # [B, N, proj_dim]\n",
        "        num_feat = self.num_transformer(num_feat)  # [B, N, proj_dim]\n",
        "        num_feat = self.num_se(num_feat)  # [B, N, proj_dim]\n",
        "        num_feat = self.num_proj_out(num_feat)  # [B, N, proj_dim]\n",
        "\n",
        "        x = torch.cat([cat_feat, num_feat], dim=-1)  # [B, N, 2*proj_dim]\n",
        "\n",
        "        for layer in self.transformer_layers:\n",
        "            x = layer(x, src_key_padding_mask=attn_mask)\n",
        "\n",
        "        scores = self.mlp(x).squeeze(-1)  # [B, N]\n",
        "\n",
        "        return scores\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "def listmle_loss(scores, labels, lengths):\n",
        "    batch_size = scores.size(0)\n",
        "    total_loss = torch.tensor(0.0, device=scores.device, requires_grad=True)\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "\n",
        "        _, idx = torch.sort(y, descending=True)\n",
        "        s_sorted = s[idx]\n",
        "\n",
        "        parts = (\n",
        "            torch.logsumexp(s_sorted.unsqueeze(0).expand(l, -1).triu(diagonal=0), dim=1)\n",
        "            - s_sorted\n",
        "        )\n",
        "\n",
        "        total_loss = total_loss + parts.sum()\n",
        "\n",
        "    return total_loss / batch_size\n",
        "\"\"\"\n",
        "\n",
        "def hitrate_at_k(scores, labels, lengths, k=3, min_group_size=10):\n",
        "    batch_size = scores.size(0)\n",
        "    hits = 0\n",
        "    valid_count = 0\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        if l < min_group_size:\n",
        "            continue\n",
        "        length = min(l, k)\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "        _, topk_idx = torch.topk(s, length)\n",
        "        topk_labels = y[topk_idx]\n",
        "        hits += (topk_labels > 0).any().float()\n",
        "        valid_count += 1\n",
        "    return hits / valid_count if valid_count > 0 else torch.tensor(0.0, device=scores.device)\n",
        "\n",
        "\n",
        "def ndcg_at_k(scores, labels, lengths, k=3, min_group_size=10):\n",
        "    batch_size = scores.size(0)\n",
        "    total_ndcg = 0.0\n",
        "    valid_count = 0\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        if l < min_group_size:\n",
        "            continue\n",
        "\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "\n",
        "        _, idx_pred = torch.topk(s, min(k, l))\n",
        "        _, idx_ideal = torch.topk(y, min(k, l))\n",
        "\n",
        "        dcg = (y[idx_pred] / torch.log2(torch.arange(2, 2 + len(idx_pred), device=y.device).float())).sum()\n",
        "        idcg = (y[idx_ideal] / torch.log2(torch.arange(2, 2 + len(idx_ideal), device=y.device).float())).sum()\n",
        "\n",
        "        ndcg = dcg / idcg if idcg > 0 else 0.0\n",
        "        total_ndcg += ndcg\n",
        "        valid_count += 1\n",
        "\n",
        "    return total_ndcg / valid_count if valid_count > 0 else torch.tensor(0.0, device=scores.device)\n",
        "\n",
        "\n",
        "def map_at_k(scores, labels, lengths, k=3, min_group_size=10):\n",
        "    batch_size = scores.size(0)\n",
        "    total_ap = 0.0\n",
        "    valid_count = 0\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        if l < min_group_size:\n",
        "            continue\n",
        "\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "\n",
        "        _, idx_pred = torch.topk(s, min(k, l))\n",
        "        y_true = y[idx_pred] > 0\n",
        "\n",
        "        if y_true.sum() == 0:\n",
        "            continue\n",
        "\n",
        "        precisions = [(y_true[:j+1].float().sum() / (j+1)) for j in range(len(y_true)) if y_true[j]]\n",
        "        ap = torch.stack(precisions).mean()\n",
        "        total_ap += ap\n",
        "        valid_count += 1\n",
        "\n",
        "    return total_ap / valid_count if valid_count > 0 else torch.tensor(0.0, device=scores.device)\n",
        "\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "def listnet_loss(scores, labels, lengths):\n",
        "    batch_size = scores.size(0)\n",
        "    total_loss = 0.0\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "\n",
        "        s_softmax = torch.nn.functional.log_softmax(s, dim=0)\n",
        "        y_softmax = torch.nn.functional.softmax(y, dim=0)\n",
        "\n",
        "        loss = -torch.sum(y_softmax * s_softmax)\n",
        "        total_loss += loss\n",
        "\n",
        "    return total_loss / batch_size\n",
        "\"\"\"\n",
        "\n",
        "def ranknet_loss(scores, labels, lengths):\n",
        "    batch_size = scores.size(0)\n",
        "    total_loss = 0.0\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "\n",
        "        diff_scores = s.unsqueeze(1) - s.unsqueeze(0)\n",
        "        rel = y.unsqueeze(1) > y.unsqueeze(0)\n",
        "        label_diff = rel.float()\n",
        "\n",
        "        log_sigmoid = torch.nn.functional.logsigmoid(diff_scores)\n",
        "        pair_loss = -label_diff * log_sigmoid\n",
        "\n",
        "        total_loss += pair_loss.sum()\n",
        "\n",
        "    return total_loss / batch_size\n",
        "\n",
        "def xranknet_loss(scores, labels, lengths, temperature=1.0, margin=0.2, focus_topk=3):\n",
        "    \"\"\"\n",
        "    xRankNet with emphasis on top-K items (based on labels, not scores).\n",
        "    \"\"\"\n",
        "    batch_size = scores.size(0)\n",
        "    total_loss = 0.0\n",
        "    total_pairs = 0\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        if l < 2:\n",
        "            continue\n",
        "\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "\n",
        "        # Top-K mask based on ground truth labels\n",
        "        topk = min(focus_topk, l)\n",
        "        _, topk_idx = torch.topk(y, topk)\n",
        "        topk_mask = torch.zeros_like(y, dtype=torch.bool)\n",
        "        topk_mask[topk_idx] = True\n",
        "\n",
        "        # Create pairwise difference matrices\n",
        "        score_diff = s.unsqueeze(1) - s.unsqueeze(0)\n",
        "        label_diff = y.unsqueeze(1) - y.unsqueeze(0)\n",
        "\n",
        "        # valid pair: y_i > y_j and at least one of i, j is in top-K\n",
        "        valid_pairs = (label_diff > 0) & (\n",
        "            topk_mask.unsqueeze(1) | topk_mask.unsqueeze(0)\n",
        "        )\n",
        "\n",
        "        if valid_pairs.sum() == 0:\n",
        "            continue\n",
        "\n",
        "        importance = (label_diff.abs() * valid_pairs).float()\n",
        "\n",
        "        if margin > 0.0:\n",
        "            score_diff = score_diff - margin\n",
        "\n",
        "        score_diff = score_diff / temperature\n",
        "        pairwise_loss = -F_torch.logsigmoid(score_diff) * importance\n",
        "\n",
        "        total_loss += pairwise_loss.sum()\n",
        "        total_pairs += importance.sum()\n",
        "\n",
        "    if total_pairs == 0:\n",
        "        return torch.tensor(0.0, device=scores.device, requires_grad=True)\n",
        "\n",
        "    return total_loss / total_pairs\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "def bpr_loss(scores, labels, lengths):\n",
        "    batch_size = scores.size(0)\n",
        "    total_loss = 0.0\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "\n",
        "        pos_mask = y > 0\n",
        "        neg_mask = y <= 0\n",
        "\n",
        "        pos_scores = s[pos_mask]\n",
        "        neg_scores = s[neg_mask]\n",
        "\n",
        "        if len(pos_scores) == 0 or len(neg_scores) == 0:\n",
        "            continue\n",
        "\n",
        "        pair_diff = pos_scores.unsqueeze(1) - neg_scores.unsqueeze(0)\n",
        "        loss = -F.logsigmoid(pair_diff).mean()\n",
        "        total_loss += loss\n",
        "\n",
        "    return total_loss / batch_size\n",
        "\"\"\"\n",
        "\n",
        "\"\"\"\n",
        "def lambdarank_loss(scores, labels, lengths, eps=1e-10):\n",
        "    batch_size = scores.size(0)\n",
        "    total_loss = 0.0\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "\n",
        "        if l < 2:\n",
        "            continue\n",
        "\n",
        "        _, rank_order = torch.sort(s, descending=True)\n",
        "        ideal_order = torch.sort(y, descending=True).indices\n",
        "\n",
        "        gain = 2 ** y - 1\n",
        "        discount = torch.log2(torch.arange(2, l + 2, device=y.device).float())\n",
        "\n",
        "        ideal_dcg = (gain[ideal_order] / discount).sum()\n",
        "        if ideal_dcg < eps:\n",
        "            continue\n",
        "\n",
        "        delta_ndcg = torch.zeros((l, l), device=y.device)\n",
        "\n",
        "        for i_idx in range(l):\n",
        "            for j_idx in range(l):\n",
        "                if y[i_idx] > y[j_idx]:\n",
        "                    change = (\n",
        "                        (1.0 / torch.log2(rank_order[i_idx] + 2.0))\n",
        "                        - (1.0 / torch.log2(rank_order[j_idx] + 2.0))\n",
        "                    ).abs()\n",
        "                    delta = (2 ** y[i_idx] - 2 ** y[j_idx]).abs() * change\n",
        "                    delta_ndcg[i_idx, j_idx] = delta / ideal_dcg\n",
        "\n",
        "        score_diffs = s.unsqueeze(1) - s.unsqueeze(0)\n",
        "        lambdas = -F.logsigmoid(score_diffs) * delta_ndcg\n",
        "        total_loss += lambdas.sum()\n",
        "\n",
        "    return total_loss / batch_size\n",
        "\"\"\"\n",
        "\n",
        "def train_one_epoch(model, loader, optimizer, device, scheduler):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "\n",
        "    for x_cat, x_num, y, lengths in tqdm(loader, desc=\"Training\", leave=False):\n",
        "        x_num, y = x_num.to(device), y.to(device)\n",
        "        if not isinstance(lengths, torch.Tensor):\n",
        "            lengths = torch.tensor(lengths)\n",
        "        lengths = lengths.detach().clone().to(device)\n",
        "        x_cat = {k: v.to(device) for k, v in x_cat.items()}\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        scores = model(x_cat, x_num)\n",
        "        loss = xranknet_loss(scores, y, lengths, temperature=1.0, margin=0.2, focus_topk=3)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    return total_loss / len(loader)\n",
        "\n",
        "\n",
        "def validate(model, loader, device, min_group_size=10):\n",
        "    model.eval()\n",
        "    total_hitrate = 0\n",
        "    total_ndcg = 0\n",
        "    total_map = 0\n",
        "    total_loss = 0\n",
        "    count = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for x_cat, x_num, y, lengths in tqdm(loader, desc=\"Validating\", leave=False):\n",
        "            x_num, y = x_num.to(device), y.to(device)\n",
        "            lengths = torch.tensor(lengths).to(device)\n",
        "            x_cat = {k: v.to(device) for k, v in x_cat.items()}\n",
        "\n",
        "            scores = model(x_cat, x_num)\n",
        "\n",
        "            hitrate = hitrate_at_k(scores, y, lengths, k=3, min_group_size=min_group_size)\n",
        "            ndcg = ndcg_at_k(scores, y, lengths, k=3, min_group_size=min_group_size)\n",
        "            map3 = map_at_k(scores, y, lengths, k=3, min_group_size=min_group_size)\n",
        "            loss = xranknet_loss(scores, y, lengths, temperature=1.0, margin=0.2, focus_topk=3)\n",
        "\n",
        "            batch_size = scores.size(0)\n",
        "            total_hitrate += hitrate * batch_size\n",
        "            total_ndcg += ndcg * batch_size\n",
        "            total_map += map3 * batch_size\n",
        "            total_loss += loss.item() * batch_size\n",
        "            count += batch_size\n",
        "\n",
        "    return total_loss / count, total_hitrate / count, total_ndcg / count, total_map / count\n",
        "\n",
        "\n",
        "def build_cat_dims(X, cat_features):\n",
        "    cat_dims = {}\n",
        "    for c in cat_features:\n",
        "        max_val = X[c].max()\n",
        "        if max_val < 0:\n",
        "            max_val = 0\n",
        "        cat_dims[c] = max_val + 1\n",
        "    return cat_dims\n",
        "\n",
        "\n",
        "def normalize_numeric_features(X, numeric_features, train_mask):\n",
        "    for col in numeric_features:\n",
        "        values = X[col].to_numpy()\n",
        "        train_vals = values[train_mask]\n",
        "        mean = train_vals.mean()\n",
        "        std = train_vals.std() if train_vals.std() > 0 else 1.0\n",
        "        norm_vals = (values - mean) / std\n",
        "        X = X.with_columns(pl.Series(col, norm_vals).alias(col))\n",
        "    return X\n",
        "\n",
        "\n",
        "def load_or_prepare_data(\n",
        "    data_dir,\n",
        "    train_file=\"train.parquet\",\n",
        "    test_file=\"test.parquet\",\n",
        "    cache_file=\"feature_engineered_val.parquet\",\n",
        "):\n",
        "    cache_path = os.path.join(data_dir, cache_file)\n",
        "\n",
        "    if os.path.exists(cache_path):\n",
        "        print(f\"Loading cached feature-engineered data from {cache_path} ...\")\n",
        "        df = pl.read_parquet(cache_path)\n",
        "\n",
        "        test = pl.read_parquet(os.path.join(data_dir, test_file)).drop(\"__index_level_0__\")\n",
        "        test_ids = test[\"Id\"]\n",
        "        test_rankers = test[\"ranker_id\"]\n",
        "    else:\n",
        "        print(\"Cached file not found, processing raw data ...\")\n",
        "\n",
        "        train = pl.read_parquet(os.path.join(data_dir, train_file)).drop(\"__index_level_0__\")\n",
        "        test = (\n",
        "            pl.read_parquet(os.path.join(data_dir, test_file))\n",
        "            .drop(\"__index_level_0__\")\n",
        "            .with_columns(pl.lit(0, dtype=pl.Int64).alias(\"selected\"))\n",
        "        )\n",
        "\n",
        "        test_ids = test[\"Id\"]\n",
        "        test_rankers = test[\"ranker_id\"]\n",
        "\n",
        "        df = pl.concat((train, test))\n",
        "        df = feature_engineering(df, full=True)\n",
        "\n",
        "        df = df.with_columns(\n",
        "            [pl.col(c).fill_null(0) for c in df.select(pl.selectors.numeric()).columns] +\n",
        "            [pl.col(c).fill_null(\"missing\") for c in df.select(pl.selectors.string()).columns]\n",
        "        )\n",
        "\n",
        "        os.makedirs(data_dir, exist_ok=True)\n",
        "        df.write_parquet(cache_path)\n",
        "        print(f\"Saved feature-engineered data to {cache_path}\")\n",
        "\n",
        "    return df, test_ids, test_rankers\n",
        "\n",
        "\n",
        "def prepare_data(data_dir):\n",
        "    df, test_ids, test_rankers = load_or_prepare_data(data_dir)\n",
        "\n",
        "    id_column = df[\"Id\"]\n",
        "    X, y, groups, cat_features, num_features = feature_selection(df)\n",
        "\n",
        "    X = X.with_columns(pl.Series(\"Id\", id_column[:X.shape[0]]))\n",
        "\n",
        "    X = X.with_columns(\n",
        "        [\n",
        "            (pl.col(c).rank(\"dense\") - 1).fill_null(-1).cast(pl.Int32)\n",
        "            for c in cat_features\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    train_size = 18145372\n",
        "    train_mask = np.arange(X.height) < train_size\n",
        "    X = normalize_numeric_features(X, num_features, train_mask)\n",
        "\n",
        "    return X, y, groups, cat_features, num_features, train_size, test_ids, test_rankers\n",
        "\n",
        "\n",
        "class EarlyStopping:\n",
        "    def __init__(self, patience=3, min_delta=0.00005):\n",
        "        self.patience = patience\n",
        "        self.min_delta = min_delta\n",
        "        self.best = float(\"-inf\")\n",
        "        self.counter = 0\n",
        "\n",
        "    def step(self, metric):\n",
        "        if metric > self.best + self.min_delta:\n",
        "            self.best = metric\n",
        "            self.counter = 0\n",
        "        else:\n",
        "            self.counter += 1\n",
        "        return self.counter >= self.patience\n",
        "\n",
        "\n",
        "def plot_group_size_distribution(dataset, save_path=None):\n",
        "    group_sizes = [len(v) for v in dataset.group_to_indices.values()]\n",
        "    plt.figure()\n",
        "    plt.hist(group_sizes, bins=100, log=True)\n",
        "    plt.xlabel(\"Group size (number of items per ranker_id)\")\n",
        "    plt.ylabel(\"Frequency (log scale)\")\n",
        "    plt.title(\"Distribution of Group Sizes\")\n",
        "    plt.grid(True)\n",
        "    if save_path:\n",
        "        plt.savefig(save_path)\n",
        "    else:\n",
        "        plt.show()\n",
        "    plt.close()\n",
        "\n",
        "\n",
        "def main():\n",
        "    DATA_DIR = \"./data\"\n",
        "    MODEL_DIR = \"model\"\n",
        "    SUBMIT_DIR = \"submission\"\n",
        "\n",
        "    best_val_loss = float(\"inf\")\n",
        "    best_hitrate = 0.0\n",
        "    model_path = os.path.join(MODEL_DIR, \"best_dl_ranker.pt\")\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "    val_hitrates = []\n",
        "    val_ndcgs = []\n",
        "    val_maps = []\n",
        "    learning_rates = []\n",
        "\n",
        "    os.makedirs(MODEL_DIR, exist_ok=True)\n",
        "    os.makedirs(SUBMIT_DIR, exist_ok=True)\n",
        "\n",
        "    early_stopper = EarlyStopping(patience=3, min_delta=0.001)\n",
        "\n",
        "    X, y, groups, cat_features, num_features, train_size, test_ids, test_rankers = prepare_data(DATA_DIR)\n",
        "\n",
        "    # Fill missing values\n",
        "    float_cols = [c for c, t in zip(X.columns, X.dtypes) if t == pl.Float64]\n",
        "    for col in float_cols:\n",
        "        X = X.with_columns(\n",
        "            pl.when(pl.col(col).is_nan()).then(0).otherwise(pl.col(col)).alias(col)\n",
        "        )\n",
        "\n",
        "    n1 = 16487352\n",
        "    # n1 = 17487300\n",
        "    n2 = train_size\n",
        "\n",
        "    X_tr, X_va, X_te = X[:n1], X[n1:n2], X[n2:]\n",
        "    y_tr, y_va, y_te = y[:n1], y[n1:n2], y[n2:]\n",
        "    groups_tr, groups_va, groups_te = groups[:n1], groups[n1:n2], groups[n2:]\n",
        "\n",
        "    # Inspect group sizes in validation set\n",
        "    val_rankers = groups_va[\"ranker_id\"].to_numpy()\n",
        "    val_group_counts = Counter(val_rankers)\n",
        "\n",
        "    print(\"\\nüìã Validation group statistics:\")\n",
        "    # Save detailed group info to file\n",
        "    group_info_path = os.path.join(MODEL_DIR, \"validation_groups_info.txt\")\n",
        "    with open(group_info_path, \"w\") as f:\n",
        "        f.write(f\"Total groups: {len(val_group_counts)}\\n\\n\")\n",
        "        f.write(\"GroupID\\tSize\\tStartIdx\\tEndIdx\\n\")\n",
        "\n",
        "        group_to_rows = defaultdict(list)\n",
        "        for i, g in enumerate(val_rankers):\n",
        "            group_to_rows[g].append(i)\n",
        "\n",
        "        for group_id, indices in sorted(group_to_rows.items()):\n",
        "            start_idx = indices[0]\n",
        "            end_idx = indices[-1]\n",
        "            size = len(indices)\n",
        "            f.write(f\"{group_id}\\t{size}\\t{start_idx}\\t{end_idx}\\n\")\n",
        "\n",
        "    print(f\"üìÅ Saved validation group info to {group_info_path}\")\n",
        "\n",
        "\n",
        "    cat_dims = build_cat_dims(X, cat_features)\n",
        "    num_numeric_feats = len(num_features)\n",
        "\n",
        "    train_dataset = RankDataset(X_tr, y_tr, groups_tr, cat_features, num_features)\n",
        "    val_dataset = RankDataset(X_va, y_va, groups_va, cat_features, num_features)\n",
        "    test_dataset = RankDataset(X_te, y_te, groups_te, cat_features, num_features)\n",
        "\n",
        "    plot_group_size_distribution(train_dataset, save_path=os.path.join(MODEL_DIR, \"group_sizes.png\"))\n",
        "    print(\"üìä Group size distribution saved.\")\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True, collate_fn=collate_fn)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=4, shuffle=False, collate_fn=collate_fn)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False, collate_fn=collate_fn)\n",
        "\n",
        "    print(\"‚úÖ Data loaders created.\")\n",
        "\n",
        "    num_epochs = 10\n",
        "    num_training_steps = num_epochs * len(train_loader)\n",
        "    num_warmup_steps = int(0.1 * num_training_steps)\n",
        "\n",
        "    learning_rate = 3e-4\n",
        "\n",
        "    model = DLRankerAttention(\n",
        "        cat_dims=cat_dims,\n",
        "        num_numeric_feats=num_numeric_feats,\n",
        "        emb_dropout=0.1,\n",
        "        dropout=0.1,\n",
        "        num_heads=4,\n",
        "        num_layers=2,\n",
        "        dim_feedforward=128,\n",
        "        proj_dim=64\n",
        "    ).to(device)\n",
        "\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=0.01)\n",
        "\n",
        "    scheduler = OneCycleLR(\n",
        "        optimizer,\n",
        "        max_lr=learning_rate,\n",
        "        steps_per_epoch=len(train_loader),\n",
        "        epochs=num_epochs,\n",
        "        pct_start=0.3,\n",
        "    )\n",
        "\n",
        "    best_hitrate = 0\n",
        "    for epoch in range(num_epochs):\n",
        "        print(f\"\\n--- Epoch {epoch+1}/{num_epochs} ---\")\n",
        "        start_time = time.time()\n",
        "\n",
        "        train_loss = train_one_epoch(model, train_loader, optimizer, device, scheduler)\n",
        "        val_loss, val_hitrate, val_ndcg, val_map = validate(model, val_loader, device, min_group_size=10)\n",
        "\n",
        "        train_losses.append(train_loss)\n",
        "        val_losses.append(val_loss)\n",
        "        val_hitrates.append(val_hitrate.item())\n",
        "        val_ndcgs.append(val_ndcg.item())\n",
        "        val_maps.append(val_map.item())\n",
        "\n",
        "        current_lr = scheduler.get_last_lr()\n",
        "        learning_rates.append(current_lr[0])\n",
        "\n",
        "        elapsed = time.time() - start_time\n",
        "        print(\n",
        "            f\"Epoch {epoch+1}: \"\n",
        "            f\"Train Loss={train_loss:.4f}, \"\n",
        "            f\"Val Loss={val_loss:.4f}, \"\n",
        "            f\"HitRate@3={val_hitrate:.4f}, \"\n",
        "            f\"NDCG@3={val_ndcg:.4f}, \"\n",
        "            f\"MAP@3={val_map:.4f}, \"\n",
        "            f\"LR={current_lr[0]:.6f} \"\n",
        "            f\"({elapsed:.1f}s)\"\n",
        "        )\n",
        "\n",
        "\n",
        "        if val_loss < best_val_loss and val_hitrate > best_hitrate:\n",
        "            best_val_loss = val_loss\n",
        "            best_hitrate = val_hitrate\n",
        "            torch.save(model.state_dict(), model_path)\n",
        "            print(\"üíæ Model improved (loss ‚Üì and hitrate ‚Üë), saved.\")\n",
        "\n",
        "        if early_stopper.step(-val_loss):\n",
        "            print(\"‚õî Early stopping triggered.\")\n",
        "            break\n",
        "\n",
        "    # Plot metrics\n",
        "    epochs = list(range(1, len(train_losses) + 1))\n",
        "\n",
        "    # Plot Loss Curve\n",
        "    plt.figure()\n",
        "    plt.plot(epochs, train_losses, label=\"Train Loss\")\n",
        "    plt.plot(epochs, val_losses, label=\"Val Loss\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.title(\"Training & Validation Loss\")\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.savefig(os.path.join(MODEL_DIR, \"loss_curve.png\"))\n",
        "    plt.close()\n",
        "\n",
        "    # Plot HitRate@3\n",
        "    plt.figure()\n",
        "    plt.plot(epochs, val_hitrates, label=\"Val HitRate@3\", color=\"green\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"HitRate@3\")\n",
        "    plt.title(\"Validation HitRate@3\")\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.savefig(os.path.join(MODEL_DIR, \"hitrate_curve.png\"))\n",
        "    plt.close()\n",
        "\n",
        "    # Plot Learning Rate\n",
        "    plt.figure()\n",
        "    plt.plot(epochs, learning_rates, label=\"Learning Rate\", color=\"orange\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"LR\")\n",
        "    plt.title(\"Learning Rate Schedule\")\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.savefig(os.path.join(MODEL_DIR, \"lr_curve.png\"))\n",
        "    plt.close()\n",
        "\n",
        "    # Plot NDCG@3\n",
        "    plt.figure()\n",
        "    plt.plot(epochs, val_ndcgs, label=\"Val NDCG@3\", color=\"purple\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"NDCG@3\")\n",
        "    plt.title(\"Validation NDCG@3\")\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.savefig(os.path.join(MODEL_DIR, \"ndcg_curve.png\"))\n",
        "    plt.close()\n",
        "\n",
        "    # Plot MAP@3\n",
        "    plt.figure()\n",
        "    plt.plot(epochs, val_maps, label=\"Val MAP@3\", color=\"red\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"MAP@3\")\n",
        "    plt.title(\"Validation MAP@3\")\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.savefig(os.path.join(MODEL_DIR, \"map_curve.png\"))\n",
        "    plt.close()\n",
        "\n",
        "    print(\"üìä Saved metric plots to model/\")\n",
        "\n",
        "    # Predict test set\n",
        "    model.load_state_dict(torch.load(model_path))\n",
        "    model.eval()\n",
        "\n",
        "    val_ids = X_va[\"Id\"]\n",
        "    val_rankers = groups_va[\"ranker_id\"]\n",
        "    val_labels = y_va\n",
        "\n",
        "    all_val_scores = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for x_cat, x_num, _, lengths in tqdm(val_loader, desc=\"Predicting validation set\"):\n",
        "            x_num = x_num.to(device)\n",
        "            x_cat = {k: v.to(device) for k, v in x_cat.items()}\n",
        "            scores = model(x_cat, x_num)\n",
        "\n",
        "            for i in range(scores.size(0)):\n",
        "                l = lengths[i]\n",
        "                all_val_scores.append(scores[i, :l].cpu().numpy())\n",
        "\n",
        "    all_val_scores = np.concatenate(all_val_scores)\n",
        "\n",
        "    assert len(all_val_scores) == X_va.shape[0], \\\n",
        "        f\"Mismatch: {len(all_val_scores)} scores vs {X_va.shape[0]} rows\"\n",
        "\n",
        "    val_df = X_va.with_columns([\n",
        "        pl.Series(\"Id\", val_ids),\n",
        "        pl.Series(\"ranker_id\", val_rankers),\n",
        "        pl.Series(\"score\", all_val_scores),\n",
        "        pl.Series(\"label\", val_labels)\n",
        "    ])\n",
        "\n",
        "    val_df = val_df.with_columns(\n",
        "        pl.col(\"score\")\n",
        "        .rank(method=\"ordinal\", descending=True)\n",
        "        .over(\"ranker_id\")\n",
        "        .cast(pl.Int32)\n",
        "        .alias(\"selected\")\n",
        "    )\n",
        "\n",
        "    val_save_path = os.path.join(MODEL_DIR, \"validation_preds_dl_full.csv\")\n",
        "    val_df.write_csv(val_save_path)\n",
        "    print(f\"‚úÖ Saved full validation predictions (with features) to {val_save_path}\")\n",
        "\n",
        "    all_scores = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for x_cat, x_num, _, lengths in tqdm(test_loader, desc=\"Predicting test set\"):\n",
        "            x_num = x_num.to(device)\n",
        "            x_cat = {k: v.to(device) for k, v in x_cat.items()}\n",
        "            scores = model(x_cat, x_num)\n",
        "\n",
        "            for i in range(scores.size(0)):\n",
        "                l = lengths[i]\n",
        "                all_scores.append(scores[i, :l].cpu().numpy())\n",
        "\n",
        "    all_scores = np.concatenate(all_scores)\n",
        "\n",
        "    assert len(all_scores) == X_te.shape[0], \\\n",
        "        f\"Mismatch: {len(all_scores)} scores vs {X_te.shape[0]} rows in X_te\"\n",
        "\n",
        "    submission_df = pl.DataFrame({\n",
        "        \"Id\": test_ids,\n",
        "        \"ranker_id\": test_rankers,\n",
        "        \"score\": all_scores\n",
        "    })\n",
        "\n",
        "    submission = (\n",
        "        submission_df\n",
        "        .with_columns(\n",
        "            pl.col(\"score\")\n",
        "            .rank(method=\"ordinal\", descending=True)\n",
        "            .over(\"ranker_id\")\n",
        "            .cast(pl.Int32)\n",
        "            .alias(\"selected\")\n",
        "        )\n",
        "        .select([\"Id\", \"ranker_id\", \"score\", \"selected\"])\n",
        "    )\n",
        "\n",
        "    submission_path = os.path.join(SUBMIT_DIR, \"submission_dl_ranker.csv\")\n",
        "    submission.write_csv(submission_path)\n",
        "    print(f\"‚úÖ Submission saved to {submission_path}\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0S5ai64Fklts",
        "outputId": "d90abdbf-c5b8-4569-9267-554908e94a94"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing deeprec_validate.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "--- Epoch 1/10 ---\n",
        "Validating:   0%|          | 0/2636 [00:00<?, ?it/s]/home/ionut/test_whisper/test2/deeprec_validate.py:508: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
        "  lengths = torch.tensor(lengths).to(device)\n",
        "Epoch 1: Train Loss=0.3580, Val Loss=0.3073, HitRate@3=0.4722, NDCG@3=0.3754, MAP@3=0.6183, LR=0.000084 (526.0s)\n",
        "üíæ Model improved (loss ‚Üì and hitrate ‚Üë), saved.\n",
        "\n",
        "--- Epoch 2/10 ---\n",
        "Epoch 2: Train Loss=0.2921, Val Loss=0.2864, HitRate@3=0.4816, NDCG@3=0.3847, MAP@3=0.6289, LR=0.000228 (523.1s)\n",
        "üíæ Model improved (loss ‚Üì and hitrate ‚Üë), saved.\n",
        "\n",
        "--- Epoch 3/10 ---\n",
        "Epoch 3: Train Loss=0.2842, Val Loss=0.2741, HitRate@3=0.4945, NDCG@3=0.3944, MAP@3=0.6335, LR=0.000300 (524.0s)\n",
        "üíæ Model improved (loss ‚Üì and hitrate ‚Üë), saved.\n",
        "\n",
        "--- Epoch 4/10 ---\n",
        "Epoch 4: Train Loss=0.2726, Val Loss=0.2650, HitRate@3=0.5035, NDCG@3=0.4064, MAP@3=0.6556, LR=0.000285 (525.6s)\n",
        "üíæ Model improved (loss ‚Üì and hitrate ‚Üë), saved.\n",
        "\n",
        "--- Epoch 5/10 ---\n",
        "Epoch 5: Train Loss=0.2621, Val Loss=0.2646, HitRate@3=0.5002, NDCG@3=0.4039, MAP@3=0.6522, LR=0.000244 (523.4s)\n",
        "\n",
        "--- Epoch 6/10 ---\n",
        "Epoch 6: Train Loss=0.2503, Val Loss=0.2512, HitRate@3=0.5078, NDCG@3=0.4116, MAP@3=0.6629, LR=0.000183 (525.8s)\n",
        "üíæ Model improved (loss ‚Üì and hitrate ‚Üë), saved.\n",
        "\n",
        "--- Epoch 7/10 ---\n",
        "Epoch 7: Train Loss=0.2384, Val Loss=0.2425, HitRate@3=0.5176, NDCG@3=0.4197, MAP@3=0.6664, LR=0.000117 (524.7s)\n",
        "üíæ Model improved (loss ‚Üì and hitrate ‚Üë), saved.\n",
        "\n",
        "--- Epoch 8/10 ---\n",
        "Epoch 8: Train Loss=0.2274, Val Loss=0.2395, HitRate@3=0.5143, NDCG@3=0.4200, MAP@3=0.6729, LR=0.000056 (524.9s)\n",
        "\n",
        "--- Epoch 9/10 ---\n",
        "Epoch 9: Train Loss=0.2173, Val Loss=0.2351, HitRate@3=0.5193, NDCG@3=0.4224, MAP@3=0.6707, LR=0.000015 (524.9s)\n",
        "üíæ Model improved (loss ‚Üì and hitrate ‚Üë), saved.\n",
        "\n",
        "--- Epoch 10/10 ---\n",
        "Epoch 10: Train Loss=0.2132, Val Loss=0.2355, HitRate@3=0.5183, NDCG@3=0.4220, MAP@3=0.6721, LR=0.000000 (524.9s)"
      ],
      "metadata": {
        "id": "sxKmUUGo9vhv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile deeprec_validate.py\n",
        "import os\n",
        "import time\n",
        "import random\n",
        "import torch\n",
        "import math\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import defaultdict\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "import polars as pl\n",
        "from tqdm import tqdm\n",
        "from src.feature import feature_engineering, feature_selection\n",
        "from transformers import get_scheduler\n",
        "from collections import Counter\n",
        "from torch.optim.lr_scheduler import OneCycleLR\n",
        "\n",
        "class RankDataset(Dataset):\n",
        "    def __init__(\n",
        "        self,\n",
        "        X: pl.DataFrame,\n",
        "        y: pl.Series,\n",
        "        groups: pl.DataFrame,\n",
        "        cat_features: list[str],\n",
        "        num_features: list[str],\n",
        "    ):\n",
        "        self.cat_features = cat_features\n",
        "        self.num_features = num_features\n",
        "        self.X_cat = {c: X[c].to_numpy() for c in cat_features}\n",
        "        self.X_num = X[self.num_features].to_numpy()\n",
        "        self.y = y.to_numpy()\n",
        "        self.groups = groups[\"ranker_id\"].to_numpy()\n",
        "\n",
        "        self.group_to_indices = defaultdict(list)\n",
        "        for i, g in enumerate(self.groups):\n",
        "            self.group_to_indices[g].append(i)\n",
        "        self.group_keys = list(self.group_to_indices.keys())\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.group_keys)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        g = self.group_keys[idx]\n",
        "        inds = self.group_to_indices[g]\n",
        "        length = len(inds)\n",
        "\n",
        "        x_cat = {\n",
        "            c: torch.LongTensor([\n",
        "                self.X_cat[c][i] if self.X_cat[c][i] >= 0 else 0 for i in inds\n",
        "            ])\n",
        "            for c in self.cat_features\n",
        "        }\n",
        "\n",
        "        x_num = torch.FloatTensor(self.X_num[inds])\n",
        "        y = torch.FloatTensor(self.y[inds]).reshape(-1)\n",
        "\n",
        "        return x_cat, x_num, y, length\n",
        "\n",
        "def collate_fn(batch):\n",
        "    batch_size = len(batch)\n",
        "    lengths = [b[3] for b in batch]\n",
        "    max_len = max(lengths)\n",
        "\n",
        "    padded_x_cat = {key: [] for key in batch[0][0].keys()}\n",
        "    padded_x_num = []\n",
        "    padded_y = []\n",
        "\n",
        "    num_dim = batch[0][1].shape[1]\n",
        "\n",
        "    for x_cat, x_num, y, length in batch:\n",
        "        pad_len = max_len - length\n",
        "\n",
        "        for key in padded_x_cat:\n",
        "            val = x_cat[key]\n",
        "            if pad_len > 0:\n",
        "                val = torch.cat([val, torch.zeros(pad_len, dtype=torch.long)])\n",
        "            padded_x_cat[key].append(val)\n",
        "\n",
        "        if pad_len > 0:\n",
        "            x_num = torch.cat([x_num, torch.zeros(pad_len, num_dim)])\n",
        "            y = torch.cat([y, torch.zeros(pad_len)])\n",
        "\n",
        "        padded_x_num.append(x_num)\n",
        "        padded_y.append(y)\n",
        "\n",
        "    padded_x_cat = {k: torch.stack(v) for k, v in padded_x_cat.items()}\n",
        "    padded_x_num = torch.stack(padded_x_num)\n",
        "    padded_y = torch.stack(padded_y)\n",
        "    lengths = torch.tensor(lengths, dtype=torch.long)\n",
        "\n",
        "    return padded_x_cat, padded_x_num, padded_y, lengths\n",
        "\n",
        "class SEModule(nn.Module):\n",
        "    def __init__(self, channel, reduction=4):\n",
        "        super().__init__()\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(channel, channel // reduction),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(channel // reduction, channel),\n",
        "            nn.Sigmoid(),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: [B, N, C]\n",
        "        w = self.fc(x.mean(dim=1))\n",
        "        w = w.unsqueeze(1)  # [B, 1, C]\n",
        "        return x * w\n",
        "\n",
        "\n",
        "class DLRankerAttention(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        cat_dims,\n",
        "        num_numeric_feats,\n",
        "        emb_dropout=0.1,\n",
        "        dropout=0.1,\n",
        "        num_heads=4,\n",
        "        num_layers=2,\n",
        "        dim_feedforward=128,\n",
        "        proj_dim=64,\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "        self.emb_dims = {\n",
        "            f: min(50, max(4, round(6 * math.log2(cat_dims[f] + 1)))) for f in cat_dims\n",
        "        }\n",
        "        self.embeddings = nn.ModuleDict({\n",
        "            f: nn.Embedding(cat_dims[f], self.emb_dims[f], padding_idx=0)\n",
        "            for f in cat_dims\n",
        "        })\n",
        "        self.emb_dropout = nn.Dropout(emb_dropout)\n",
        "\n",
        "        total_emb_dim = sum(self.emb_dims.values())\n",
        "        print(f\"Categorial emb dim sum: {total_emb_dim}, Numerical dim: {num_numeric_feats}\")\n",
        "\n",
        "        self.cat_proj = nn.Linear(total_emb_dim, proj_dim)\n",
        "        self.cat_transformer = nn.TransformerEncoder(\n",
        "            nn.TransformerEncoderLayer(\n",
        "                d_model=proj_dim,\n",
        "                nhead=4,\n",
        "                dim_feedforward=dim_feedforward,\n",
        "                dropout=dropout,\n",
        "                batch_first=True,\n",
        "            ),\n",
        "            num_layers=1,\n",
        "        )\n",
        "\n",
        "        self.num_proj_in = nn.Linear(num_numeric_feats, proj_dim)\n",
        "        self.num_transformer = nn.TransformerEncoder(\n",
        "            nn.TransformerEncoderLayer(\n",
        "                d_model=proj_dim,\n",
        "                nhead=4,\n",
        "                dim_feedforward=dim_feedforward,\n",
        "                dropout=dropout,\n",
        "                batch_first=True,\n",
        "            ),\n",
        "            num_layers=1,\n",
        "        )\n",
        "        self.num_se = SEModule(proj_dim)\n",
        "        self.num_proj_out = nn.Sequential(\n",
        "            nn.Linear(proj_dim, proj_dim),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(dropout),\n",
        "        )\n",
        "\n",
        "        # üîÅ Cross-attention: cat attends to num\n",
        "        self.cross_attn_cat2num = nn.MultiheadAttention(\n",
        "            embed_dim=proj_dim,\n",
        "            num_heads=4,\n",
        "            dropout=dropout,\n",
        "            batch_first=True,\n",
        "        )\n",
        "\n",
        "        self.transformer_layers = nn.ModuleList([\n",
        "            nn.TransformerEncoderLayer(\n",
        "                d_model=2 * proj_dim,\n",
        "                nhead=num_heads,\n",
        "                dim_feedforward=dim_feedforward,\n",
        "                dropout=dropout,\n",
        "                batch_first=True,\n",
        "            )\n",
        "            for _ in range(num_layers)\n",
        "        ])\n",
        "\n",
        "        self.mlp = nn.Sequential(\n",
        "            nn.Linear(2 * proj_dim, 128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(128, 64),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(64, 1),\n",
        "        )\n",
        "\n",
        "    def forward(self, x_cat: dict, x_num: torch.Tensor, attn_mask=None):\n",
        "        B, N, _ = x_num.shape  # x_num: [B, N, F_num]\n",
        "\n",
        "        # Categorical embeddings\n",
        "        cat_embs = torch.cat([self.embeddings[f](x_cat[f]) for f in x_cat], dim=-1)\n",
        "        cat_embs = self.emb_dropout(cat_embs)\n",
        "        cat_feat = self.cat_proj(cat_embs)  # [B, N, D]\n",
        "        cat_feat = self.cat_transformer(cat_feat)  # [B, N, D]\n",
        "\n",
        "        # Numeric features\n",
        "        num_feat = self.num_proj_in(x_num)\n",
        "        num_feat = self.num_transformer(num_feat)\n",
        "        num_feat = self.num_se(num_feat)\n",
        "        num_feat = self.num_proj_out(num_feat)\n",
        "\n",
        "        # Cross-attention: categorical features attend over numeric ones\n",
        "        cat_feat_attn, _ = self.cross_attn_cat2num(\n",
        "            query=cat_feat, key=num_feat, value=num_feat\n",
        "        )\n",
        "        cat_feat = cat_feat + cat_feat_attn  # residual connection\n",
        "\n",
        "        # Final concatenation\n",
        "        x = torch.cat([cat_feat, num_feat], dim=-1)\n",
        "\n",
        "        for layer in self.transformer_layers:\n",
        "            x = layer(x, src_key_padding_mask=attn_mask)\n",
        "\n",
        "        scores = self.mlp(x).squeeze(-1)  # [B, N]\n",
        "        return scores\n",
        "\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "def listmle_loss(scores, labels, lengths):\n",
        "    batch_size = scores.size(0)\n",
        "    total_loss = torch.tensor(0.0, device=scores.device, requires_grad=True)\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "\n",
        "        _, idx = torch.sort(y, descending=True)\n",
        "        s_sorted = s[idx]\n",
        "\n",
        "        parts = (\n",
        "            torch.logsumexp(s_sorted.unsqueeze(0).expand(l, -1).triu(diagonal=0), dim=1)\n",
        "            - s_sorted\n",
        "        )\n",
        "\n",
        "        total_loss = total_loss + parts.sum()\n",
        "\n",
        "    return total_loss / batch_size\n",
        "\"\"\"\n",
        "\n",
        "def hitrate_at_k(scores, labels, lengths, k=3, min_group_size=10):\n",
        "    batch_size = scores.size(0)\n",
        "    hits = 0\n",
        "    valid_count = 0\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        if l < min_group_size:\n",
        "            continue\n",
        "        length = min(l, k)\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "        _, topk_idx = torch.topk(s, length)\n",
        "        topk_labels = y[topk_idx]\n",
        "        hits += (topk_labels > 0).any().float()\n",
        "        valid_count += 1\n",
        "    return hits / valid_count if valid_count > 0 else torch.tensor(0.0, device=scores.device)\n",
        "\n",
        "\n",
        "def ndcg_at_k(scores, labels, lengths, k=3, min_group_size=10):\n",
        "    batch_size = scores.size(0)\n",
        "    total_ndcg = 0.0\n",
        "    valid_count = 0\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        if l < min_group_size:\n",
        "            continue\n",
        "\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "\n",
        "        _, idx_pred = torch.topk(s, min(k, l))\n",
        "        _, idx_ideal = torch.topk(y, min(k, l))\n",
        "\n",
        "        dcg = (y[idx_pred] / torch.log2(torch.arange(2, 2 + len(idx_pred), device=y.device).float())).sum()\n",
        "        idcg = (y[idx_ideal] / torch.log2(torch.arange(2, 2 + len(idx_ideal), device=y.device).float())).sum()\n",
        "\n",
        "        ndcg = dcg / idcg if idcg > 0 else 0.0\n",
        "        total_ndcg += ndcg\n",
        "        valid_count += 1\n",
        "\n",
        "    return total_ndcg / valid_count if valid_count > 0 else torch.tensor(0.0, device=scores.device)\n",
        "\n",
        "\n",
        "def map_at_k(scores, labels, lengths, k=3, min_group_size=10):\n",
        "    batch_size = scores.size(0)\n",
        "    total_ap = 0.0\n",
        "    valid_count = 0\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        if l < min_group_size:\n",
        "            continue\n",
        "\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "\n",
        "        _, idx_pred = torch.topk(s, min(k, l))\n",
        "        y_true = y[idx_pred] > 0\n",
        "\n",
        "        if y_true.sum() == 0:\n",
        "            continue\n",
        "\n",
        "        precisions = [(y_true[:j+1].float().sum() / (j+1)) for j in range(len(y_true)) if y_true[j]]\n",
        "        ap = torch.stack(precisions).mean()\n",
        "        total_ap += ap\n",
        "        valid_count += 1\n",
        "\n",
        "    return total_ap / valid_count if valid_count > 0 else torch.tensor(0.0, device=scores.device)\n",
        "\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "def listnet_loss(scores, labels, lengths):\n",
        "    batch_size = scores.size(0)\n",
        "    total_loss = 0.0\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "\n",
        "        s_softmax = torch.nn.functional.log_softmax(s, dim=0)\n",
        "        y_softmax = torch.nn.functional.softmax(y, dim=0)\n",
        "\n",
        "        loss = -torch.sum(y_softmax * s_softmax)\n",
        "        total_loss += loss\n",
        "\n",
        "    return total_loss / batch_size\n",
        "\"\"\"\n",
        "\n",
        "def ranknet_loss(scores, labels, lengths):\n",
        "    batch_size = scores.size(0)\n",
        "    total_loss = 0.0\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "\n",
        "        diff_scores = s.unsqueeze(1) - s.unsqueeze(0)\n",
        "        rel = y.unsqueeze(1) > y.unsqueeze(0)\n",
        "        label_diff = rel.float()\n",
        "\n",
        "        log_sigmoid = torch.nn.functional.logsigmoid(diff_scores)\n",
        "        pair_loss = -label_diff * log_sigmoid\n",
        "\n",
        "        total_loss += pair_loss.sum()\n",
        "\n",
        "    return total_loss / batch_size\n",
        "\n",
        "def xranknet_loss(scores, labels, lengths, temperature=1.0, margin=0.2, focus_topk=3):\n",
        "    \"\"\"\n",
        "    xRankNet with emphasis on top-K items (based on labels, not scores).\n",
        "    \"\"\"\n",
        "    batch_size = scores.size(0)\n",
        "    total_loss = 0.0\n",
        "    total_pairs = 0\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        if l < 2:\n",
        "            continue\n",
        "\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "\n",
        "        # Top-K mask based on ground truth labels\n",
        "        topk = min(focus_topk, l)\n",
        "        _, topk_idx = torch.topk(y, topk)\n",
        "        topk_mask = torch.zeros_like(y, dtype=torch.bool)\n",
        "        topk_mask[topk_idx] = True\n",
        "\n",
        "        # Create pairwise difference matrices\n",
        "        score_diff = s.unsqueeze(1) - s.unsqueeze(0)\n",
        "        label_diff = y.unsqueeze(1) - y.unsqueeze(0)\n",
        "\n",
        "        # valid pair: y_i > y_j and at least one of i, j is in top-K\n",
        "        valid_pairs = (label_diff > 0) & (\n",
        "            topk_mask.unsqueeze(1) | topk_mask.unsqueeze(0)\n",
        "        )\n",
        "\n",
        "        if valid_pairs.sum() == 0:\n",
        "            continue\n",
        "\n",
        "        importance = (label_diff.abs() * valid_pairs).float()\n",
        "\n",
        "        if margin > 0.0:\n",
        "            score_diff = score_diff - margin\n",
        "\n",
        "        score_diff = score_diff / temperature\n",
        "        pairwise_loss = -F.logsigmoid(score_diff) * importance\n",
        "\n",
        "        total_loss += pairwise_loss.sum()\n",
        "        total_pairs += importance.sum()\n",
        "\n",
        "    if total_pairs == 0:\n",
        "        return torch.tensor(0.0, device=scores.device, requires_grad=True)\n",
        "\n",
        "    return total_loss / total_pairs\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "def bpr_loss(scores, labels, lengths):\n",
        "    batch_size = scores.size(0)\n",
        "    total_loss = 0.0\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "\n",
        "        pos_mask = y > 0\n",
        "        neg_mask = y <= 0\n",
        "\n",
        "        pos_scores = s[pos_mask]\n",
        "        neg_scores = s[neg_mask]\n",
        "\n",
        "        if len(pos_scores) == 0 or len(neg_scores) == 0:\n",
        "            continue\n",
        "\n",
        "        pair_diff = pos_scores.unsqueeze(1) - neg_scores.unsqueeze(0)\n",
        "        loss = -F.logsigmoid(pair_diff).mean()\n",
        "        total_loss += loss\n",
        "\n",
        "    return total_loss / batch_size\n",
        "\"\"\"\n",
        "\n",
        "\"\"\"\n",
        "def lambdarank_loss(scores, labels, lengths, eps=1e-10):\n",
        "    batch_size = scores.size(0)\n",
        "    total_loss = 0.0\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "\n",
        "        if l < 2:\n",
        "            continue\n",
        "\n",
        "        _, rank_order = torch.sort(s, descending=True)\n",
        "        ideal_order = torch.sort(y, descending=True).indices\n",
        "\n",
        "        gain = 2 ** y - 1\n",
        "        discount = torch.log2(torch.arange(2, l + 2, device=y.device).float())\n",
        "\n",
        "        ideal_dcg = (gain[ideal_order] / discount).sum()\n",
        "        if ideal_dcg < eps:\n",
        "            continue\n",
        "\n",
        "        delta_ndcg = torch.zeros((l, l), device=y.device)\n",
        "\n",
        "        for i_idx in range(l):\n",
        "            for j_idx in range(l):\n",
        "                if y[i_idx] > y[j_idx]:\n",
        "                    change = (\n",
        "                        (1.0 / torch.log2(rank_order[i_idx] + 2.0))\n",
        "                        - (1.0 / torch.log2(rank_order[j_idx] + 2.0))\n",
        "                    ).abs()\n",
        "                    delta = (2 ** y[i_idx] - 2 ** y[j_idx]).abs() * change\n",
        "                    delta_ndcg[i_idx, j_idx] = delta / ideal_dcg\n",
        "\n",
        "        score_diffs = s.unsqueeze(1) - s.unsqueeze(0)\n",
        "        lambdas = -F.logsigmoid(score_diffs) * delta_ndcg\n",
        "        total_loss += lambdas.sum()\n",
        "\n",
        "    return total_loss / batch_size\n",
        "\"\"\"\n",
        "\n",
        "def train_one_epoch(model, loader, optimizer, device, scheduler):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "\n",
        "    for x_cat, x_num, y, lengths in tqdm(loader, desc=\"Training\", leave=False):\n",
        "        x_num, y = x_num.to(device), y.to(device)\n",
        "        if not isinstance(lengths, torch.Tensor):\n",
        "            lengths = torch.tensor(lengths)\n",
        "        lengths = lengths.detach().clone().to(device)\n",
        "        x_cat = {k: v.to(device) for k, v in x_cat.items()}\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        scores = model(x_cat, x_num)\n",
        "        loss = xranknet_loss(scores, y, lengths, temperature=1.0, margin=0.2, focus_topk=3)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    return total_loss / len(loader)\n",
        "\n",
        "\n",
        "def validate(model, loader, device, min_group_size=10):\n",
        "    model.eval()\n",
        "    total_hitrate = 0\n",
        "    total_ndcg = 0\n",
        "    total_map = 0\n",
        "    total_loss = 0\n",
        "    count = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for x_cat, x_num, y, lengths in tqdm(loader, desc=\"Validating\", leave=False):\n",
        "            x_num, y = x_num.to(device), y.to(device)\n",
        "            lengths = torch.tensor(lengths).to(device)\n",
        "            x_cat = {k: v.to(device) for k, v in x_cat.items()}\n",
        "\n",
        "            scores = model(x_cat, x_num)\n",
        "\n",
        "            hitrate = hitrate_at_k(scores, y, lengths, k=3, min_group_size=min_group_size)\n",
        "            ndcg = ndcg_at_k(scores, y, lengths, k=3, min_group_size=min_group_size)\n",
        "            map3 = map_at_k(scores, y, lengths, k=3, min_group_size=min_group_size)\n",
        "            loss = xranknet_loss(scores, y, lengths, temperature=1.0, margin=0.2, focus_topk=3)\n",
        "\n",
        "            batch_size = scores.size(0)\n",
        "            total_hitrate += hitrate * batch_size\n",
        "            total_ndcg += ndcg * batch_size\n",
        "            total_map += map3 * batch_size\n",
        "            total_loss += loss.item() * batch_size\n",
        "            count += batch_size\n",
        "\n",
        "    return total_loss / count, total_hitrate / count, total_ndcg / count, total_map / count\n",
        "\n",
        "\n",
        "def build_cat_dims(X, cat_features):\n",
        "    cat_dims = {}\n",
        "    for c in cat_features:\n",
        "        max_val = X[c].max()\n",
        "        if max_val < 0:\n",
        "            max_val = 0\n",
        "        cat_dims[c] = max_val + 1\n",
        "    return cat_dims\n",
        "\n",
        "\n",
        "def normalize_numeric_features(X, numeric_features, train_mask):\n",
        "    for col in numeric_features:\n",
        "        values = X[col].to_numpy()\n",
        "        train_vals = values[train_mask]\n",
        "        mean = train_vals.mean()\n",
        "        std = train_vals.std() if train_vals.std() > 0 else 1.0\n",
        "        norm_vals = (values - mean) / std\n",
        "        X = X.with_columns(pl.Series(col, norm_vals).alias(col))\n",
        "    return X\n",
        "\n",
        "\n",
        "def load_or_prepare_data(\n",
        "    data_dir,\n",
        "    train_file=\"train.parquet\",\n",
        "    test_file=\"test.parquet\",\n",
        "    cache_file=\"feature_engineered_val.parquet\",\n",
        "):\n",
        "    cache_path = os.path.join(data_dir, cache_file)\n",
        "\n",
        "    if os.path.exists(cache_path):\n",
        "        print(f\"Loading cached feature-engineered data from {cache_path} ...\")\n",
        "        df = pl.read_parquet(cache_path)\n",
        "\n",
        "        test = pl.read_parquet(os.path.join(data_dir, test_file)).drop(\"__index_level_0__\")\n",
        "        test_ids = test[\"Id\"]\n",
        "        test_rankers = test[\"ranker_id\"]\n",
        "    else:\n",
        "        print(\"Cached file not found, processing raw data ...\")\n",
        "\n",
        "        train = pl.read_parquet(os.path.join(data_dir, train_file)).drop(\"__index_level_0__\")\n",
        "        test = (\n",
        "            pl.read_parquet(os.path.join(data_dir, test_file))\n",
        "            .drop(\"__index_level_0__\")\n",
        "            .with_columns(pl.lit(0, dtype=pl.Int64).alias(\"selected\"))\n",
        "        )\n",
        "\n",
        "        test_ids = test[\"Id\"]\n",
        "        test_rankers = test[\"ranker_id\"]\n",
        "\n",
        "        df = pl.concat((train, test))\n",
        "        df = feature_engineering(df, full=True)\n",
        "\n",
        "        df = df.with_columns(\n",
        "            [pl.col(c).fill_null(0) for c in df.select(pl.selectors.numeric()).columns] +\n",
        "            [pl.col(c).fill_null(\"missing\") for c in df.select(pl.selectors.string()).columns]\n",
        "        )\n",
        "\n",
        "        os.makedirs(data_dir, exist_ok=True)\n",
        "        df.write_parquet(cache_path)\n",
        "        print(f\"Saved feature-engineered data to {cache_path}\")\n",
        "\n",
        "    return df, test_ids, test_rankers\n",
        "\n",
        "\n",
        "def prepare_data(data_dir):\n",
        "    df, test_ids, test_rankers = load_or_prepare_data(data_dir)\n",
        "\n",
        "    id_column = df[\"Id\"]\n",
        "    X, y, groups, cat_features, num_features = feature_selection(df)\n",
        "\n",
        "    X = X.with_columns(pl.Series(\"Id\", id_column[:X.shape[0]]))\n",
        "\n",
        "    X = X.with_columns(\n",
        "        [\n",
        "            (pl.col(c).rank(\"dense\") - 1).fill_null(-1).cast(pl.Int32)\n",
        "            for c in cat_features\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    train_size = 18145372\n",
        "    train_mask = np.arange(X.height) < train_size\n",
        "    X = normalize_numeric_features(X, num_features, train_mask)\n",
        "\n",
        "    return X, y, groups, cat_features, num_features, train_size, test_ids, test_rankers\n",
        "\n",
        "\n",
        "class EarlyStopping:\n",
        "    def __init__(self, patience=3, min_delta=0.00005):\n",
        "        self.patience = patience\n",
        "        self.min_delta = min_delta\n",
        "        self.best = float(\"-inf\")\n",
        "        self.counter = 0\n",
        "\n",
        "    def step(self, metric):\n",
        "        if metric > self.best + self.min_delta:\n",
        "            self.best = metric\n",
        "            self.counter = 0\n",
        "        else:\n",
        "            self.counter += 1\n",
        "        return self.counter >= self.patience\n",
        "\n",
        "\n",
        "def plot_group_size_distribution(dataset, save_path=None):\n",
        "    group_sizes = [len(v) for v in dataset.group_to_indices.values()]\n",
        "    plt.figure()\n",
        "    plt.hist(group_sizes, bins=100, log=True)\n",
        "    plt.xlabel(\"Group size (number of items per ranker_id)\")\n",
        "    plt.ylabel(\"Frequency (log scale)\")\n",
        "    plt.title(\"Distribution of Group Sizes\")\n",
        "    plt.grid(True)\n",
        "    if save_path:\n",
        "        plt.savefig(save_path)\n",
        "    else:\n",
        "        plt.show()\n",
        "    plt.close()\n",
        "\n",
        "\n",
        "def main():\n",
        "    DATA_DIR = \"./data\"\n",
        "    MODEL_DIR = \"model\"\n",
        "    SUBMIT_DIR = \"submission\"\n",
        "\n",
        "    best_val_loss = float(\"inf\")\n",
        "    best_hitrate = 0.0\n",
        "    model_path = os.path.join(MODEL_DIR, \"best_dl_ranker.pt\")\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "    val_hitrates = []\n",
        "    val_ndcgs = []\n",
        "    val_maps = []\n",
        "    learning_rates = []\n",
        "\n",
        "    os.makedirs(MODEL_DIR, exist_ok=True)\n",
        "    os.makedirs(SUBMIT_DIR, exist_ok=True)\n",
        "\n",
        "    early_stopper = EarlyStopping(patience=3, min_delta=0.001)\n",
        "\n",
        "    X, y, groups, cat_features, num_features, train_size, test_ids, test_rankers = prepare_data(DATA_DIR)\n",
        "\n",
        "    # Fill missing values\n",
        "    float_cols = [c for c, t in zip(X.columns, X.dtypes) if t == pl.Float64]\n",
        "    for col in float_cols:\n",
        "        X = X.with_columns(\n",
        "            pl.when(pl.col(col).is_nan()).then(0).otherwise(pl.col(col)).alias(col)\n",
        "        )\n",
        "\n",
        "    n1 = 16487352\n",
        "    # n1 = 17487300\n",
        "    n2 = train_size\n",
        "\n",
        "    X_tr, X_va, X_te = X[:n1], X[n1:n2], X[n2:]\n",
        "    y_tr, y_va, y_te = y[:n1], y[n1:n2], y[n2:]\n",
        "    groups_tr, groups_va, groups_te = groups[:n1], groups[n1:n2], groups[n2:]\n",
        "\n",
        "    # Inspect group sizes in validation set\n",
        "    val_rankers = groups_va[\"ranker_id\"].to_numpy()\n",
        "    val_group_counts = Counter(val_rankers)\n",
        "\n",
        "    print(\"\\nüìã Validation group statistics:\")\n",
        "    # Save detailed group info to file\n",
        "    group_info_path = os.path.join(MODEL_DIR, \"validation_groups_info.txt\")\n",
        "    with open(group_info_path, \"w\") as f:\n",
        "        f.write(f\"Total groups: {len(val_group_counts)}\\n\\n\")\n",
        "        f.write(\"GroupID\\tSize\\tStartIdx\\tEndIdx\\n\")\n",
        "\n",
        "        group_to_rows = defaultdict(list)\n",
        "        for i, g in enumerate(val_rankers):\n",
        "            group_to_rows[g].append(i)\n",
        "\n",
        "        for group_id, indices in sorted(group_to_rows.items()):\n",
        "            start_idx = indices[0]\n",
        "            end_idx = indices[-1]\n",
        "            size = len(indices)\n",
        "            f.write(f\"{group_id}\\t{size}\\t{start_idx}\\t{end_idx}\\n\")\n",
        "\n",
        "    print(f\"üìÅ Saved validation group info to {group_info_path}\")\n",
        "\n",
        "\n",
        "    cat_dims = build_cat_dims(X, cat_features)\n",
        "    num_numeric_feats = len(num_features)\n",
        "\n",
        "    train_dataset = RankDataset(X_tr, y_tr, groups_tr, cat_features, num_features)\n",
        "    val_dataset = RankDataset(X_va, y_va, groups_va, cat_features, num_features)\n",
        "    test_dataset = RankDataset(X_te, y_te, groups_te, cat_features, num_features)\n",
        "\n",
        "    plot_group_size_distribution(train_dataset, save_path=os.path.join(MODEL_DIR, \"group_sizes.png\"))\n",
        "    print(\"üìä Group size distribution saved.\")\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True, collate_fn=collate_fn)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=4, shuffle=False, collate_fn=collate_fn)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False, collate_fn=collate_fn)\n",
        "\n",
        "    print(\"‚úÖ Data loaders created.\")\n",
        "\n",
        "    num_epochs = 10\n",
        "    num_training_steps = num_epochs * len(train_loader)\n",
        "    num_warmup_steps = int(0.1 * num_training_steps)\n",
        "\n",
        "    learning_rate = 3e-4\n",
        "\n",
        "    model = DLRankerAttention(\n",
        "        cat_dims=cat_dims,\n",
        "        num_numeric_feats=num_numeric_feats,\n",
        "        emb_dropout=0.1,\n",
        "        dropout=0.1,\n",
        "        num_heads=4,\n",
        "        num_layers=2,\n",
        "        dim_feedforward=128,\n",
        "        proj_dim=64\n",
        "    ).to(device)\n",
        "\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=0.01)\n",
        "\n",
        "    scheduler = OneCycleLR(\n",
        "        optimizer,\n",
        "        max_lr=learning_rate,\n",
        "        steps_per_epoch=len(train_loader),\n",
        "        epochs=num_epochs,\n",
        "        pct_start=0.3,\n",
        "    )\n",
        "\n",
        "    best_hitrate = 0\n",
        "    for epoch in range(num_epochs):\n",
        "        print(f\"\\n--- Epoch {epoch+1}/{num_epochs} ---\")\n",
        "        start_time = time.time()\n",
        "\n",
        "        train_loss = train_one_epoch(model, train_loader, optimizer, device, scheduler)\n",
        "        val_loss, val_hitrate, val_ndcg, val_map = validate(model, val_loader, device, min_group_size=10)\n",
        "\n",
        "        train_losses.append(train_loss)\n",
        "        val_losses.append(val_loss)\n",
        "        val_hitrates.append(val_hitrate.item())\n",
        "        val_ndcgs.append(val_ndcg.item())\n",
        "        val_maps.append(val_map.item())\n",
        "\n",
        "        current_lr = scheduler.get_last_lr()\n",
        "        learning_rates.append(current_lr[0])\n",
        "\n",
        "        elapsed = time.time() - start_time\n",
        "        print(\n",
        "            f\"Epoch {epoch+1}: \"\n",
        "            f\"Train Loss={train_loss:.4f}, \"\n",
        "            f\"Val Loss={val_loss:.4f}, \"\n",
        "            f\"HitRate@3={val_hitrate:.4f}, \"\n",
        "            f\"NDCG@3={val_ndcg:.4f}, \"\n",
        "            f\"MAP@3={val_map:.4f}, \"\n",
        "            f\"LR={current_lr[0]:.6f} \"\n",
        "            f\"({elapsed:.1f}s)\"\n",
        "        )\n",
        "\n",
        "\n",
        "        if val_loss < best_val_loss and val_hitrate > best_hitrate:\n",
        "            best_val_loss = val_loss\n",
        "            best_hitrate = val_hitrate\n",
        "            torch.save(model.state_dict(), model_path)\n",
        "            print(\"üíæ Model improved (loss ‚Üì and hitrate ‚Üë), saved.\")\n",
        "\n",
        "        if early_stopper.step(-val_loss):\n",
        "            print(\"‚õî Early stopping triggered.\")\n",
        "            break\n",
        "\n",
        "    # Plot metrics\n",
        "    epochs = list(range(1, len(train_losses) + 1))\n",
        "\n",
        "    # Plot Loss Curve\n",
        "    plt.figure()\n",
        "    plt.plot(epochs, train_losses, label=\"Train Loss\")\n",
        "    plt.plot(epochs, val_losses, label=\"Val Loss\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.title(\"Training & Validation Loss\")\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.savefig(os.path.join(MODEL_DIR, \"loss_curve.png\"))\n",
        "    plt.close()\n",
        "\n",
        "    # Plot HitRate@3\n",
        "    plt.figure()\n",
        "    plt.plot(epochs, val_hitrates, label=\"Val HitRate@3\", color=\"green\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"HitRate@3\")\n",
        "    plt.title(\"Validation HitRate@3\")\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.savefig(os.path.join(MODEL_DIR, \"hitrate_curve.png\"))\n",
        "    plt.close()\n",
        "\n",
        "    # Plot Learning Rate\n",
        "    plt.figure()\n",
        "    plt.plot(epochs, learning_rates, label=\"Learning Rate\", color=\"orange\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"LR\")\n",
        "    plt.title(\"Learning Rate Schedule\")\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.savefig(os.path.join(MODEL_DIR, \"lr_curve.png\"))\n",
        "    plt.close()\n",
        "\n",
        "    # Plot NDCG@3\n",
        "    plt.figure()\n",
        "    plt.plot(epochs, val_ndcgs, label=\"Val NDCG@3\", color=\"purple\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"NDCG@3\")\n",
        "    plt.title(\"Validation NDCG@3\")\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.savefig(os.path.join(MODEL_DIR, \"ndcg_curve.png\"))\n",
        "    plt.close()\n",
        "\n",
        "    # Plot MAP@3\n",
        "    plt.figure()\n",
        "    plt.plot(epochs, val_maps, label=\"Val MAP@3\", color=\"red\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"MAP@3\")\n",
        "    plt.title(\"Validation MAP@3\")\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.savefig(os.path.join(MODEL_DIR, \"map_curve.png\"))\n",
        "    plt.close()\n",
        "\n",
        "    print(\"üìä Saved metric plots to model/\")\n",
        "\n",
        "    # Predict test set\n",
        "    model.load_state_dict(torch.load(model_path))\n",
        "    model.eval()\n",
        "\n",
        "    val_ids = X_va[\"Id\"]\n",
        "    val_rankers = groups_va[\"ranker_id\"]\n",
        "    val_labels = y_va\n",
        "\n",
        "    all_val_scores = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for x_cat, x_num, _, lengths in tqdm(val_loader, desc=\"Predicting validation set\"):\n",
        "            x_num = x_num.to(device)\n",
        "            x_cat = {k: v.to(device) for k, v in x_cat.items()}\n",
        "            scores = model(x_cat, x_num)\n",
        "\n",
        "            for i in range(scores.size(0)):\n",
        "                l = lengths[i]\n",
        "                all_val_scores.append(scores[i, :l].cpu().numpy())\n",
        "\n",
        "    all_val_scores = np.concatenate(all_val_scores)\n",
        "\n",
        "    assert len(all_val_scores) == X_va.shape[0], \\\n",
        "        f\"Mismatch: {len(all_val_scores)} scores vs {X_va.shape[0]} rows\"\n",
        "\n",
        "    val_df = X_va.with_columns([\n",
        "        pl.Series(\"Id\", val_ids),\n",
        "        pl.Series(\"ranker_id\", val_rankers),\n",
        "        pl.Series(\"score\", all_val_scores),\n",
        "        pl.Series(\"label\", val_labels)\n",
        "    ])\n",
        "\n",
        "    val_df = val_df.with_columns(\n",
        "        pl.col(\"score\")\n",
        "        .rank(method=\"ordinal\", descending=True)\n",
        "        .over(\"ranker_id\")\n",
        "        .cast(pl.Int32)\n",
        "        .alias(\"selected\")\n",
        "    )\n",
        "\n",
        "    val_save_path = os.path.join(MODEL_DIR, \"validation_preds_dl_full.csv\")\n",
        "    val_df.write_csv(val_save_path)\n",
        "    print(f\"‚úÖ Saved full validation predictions (with features) to {val_save_path}\")\n",
        "\n",
        "    all_scores = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for x_cat, x_num, _, lengths in tqdm(test_loader, desc=\"Predicting test set\"):\n",
        "            x_num = x_num.to(device)\n",
        "            x_cat = {k: v.to(device) for k, v in x_cat.items()}\n",
        "            scores = model(x_cat, x_num)\n",
        "\n",
        "            for i in range(scores.size(0)):\n",
        "                l = lengths[i]\n",
        "                all_scores.append(scores[i, :l].cpu().numpy())\n",
        "\n",
        "    all_scores = np.concatenate(all_scores)\n",
        "\n",
        "    assert len(all_scores) == X_te.shape[0], \\\n",
        "        f\"Mismatch: {len(all_scores)} scores vs {X_te.shape[0]} rows in X_te\"\n",
        "\n",
        "    submission_df = pl.DataFrame({\n",
        "        \"Id\": test_ids,\n",
        "        \"ranker_id\": test_rankers,\n",
        "        \"score\": all_scores\n",
        "    })\n",
        "\n",
        "    submission = (\n",
        "        submission_df\n",
        "        .with_columns(\n",
        "            pl.col(\"score\")\n",
        "            .rank(method=\"ordinal\", descending=True)\n",
        "            .over(\"ranker_id\")\n",
        "            .cast(pl.Int32)\n",
        "            .alias(\"selected\")\n",
        "        )\n",
        "        .select([\"Id\", \"ranker_id\", \"score\", \"selected\"])\n",
        "    )\n",
        "\n",
        "    submission_path = os.path.join(SUBMIT_DIR, \"submission_dl_ranker.csv\")\n",
        "    submission.write_csv(submission_path)\n",
        "    print(f\"‚úÖ Submission saved to {submission_path}\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7axxWu-C9yP-",
        "outputId": "a94e5d9a-b89a-43b3-b95f-c94367a6c49d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing deeprec_validate.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "--- Epoch 1/10 ---\n",
        "Validating:   0%|          | 0/2636 [00:00<?, ?it/s]/home/ionut/test_whisper/test2/deeprec_validate.py:514: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
        "  lengths = torch.tensor(lengths).to(device)\n",
        "Epoch 1: Train Loss=0.3553, Val Loss=0.2916, HitRate@3=0.4702, NDCG@3=0.3754, MAP@3=0.6230, LR=0.000084 (603.4s)\n",
        "üíæ Model improved (loss ‚Üì and hitrate ‚Üë), saved.\n",
        "\n",
        "--- Epoch 2/10 ---\n",
        "Epoch 2: Train Loss=0.2888, Val Loss=0.2995, HitRate@3=0.4790, NDCG@3=0.3844, MAP@3=0.6299, LR=0.000228 (606.1s)\n",
        "\n",
        "--- Epoch 3/10 ---\n",
        "Epoch 3: Train Loss=0.2827, Val Loss=0.2797, HitRate@3=0.4871, NDCG@3=0.3905, MAP@3=0.6381, LR=0.000300 (605.5s)\n",
        "üíæ Model improved (loss ‚Üì and hitrate ‚Üë), saved.\n",
        "\n",
        "--- Epoch 4/10 ---\n",
        "Epoch 4: Train Loss=0.2730, Val Loss=0.2689, HitRate@3=0.4972, NDCG@3=0.4001, MAP@3=0.6466, LR=0.000285 (605.4s)\n",
        "üíæ Model improved (loss ‚Üì and hitrate ‚Üë), saved.\n",
        "\n",
        "--- Epoch 5/10 ---\n",
        "Epoch 5: Train Loss=0.2611, Val Loss=0.2590, HitRate@3=0.5090, NDCG@3=0.4130, MAP@3=0.6582, LR=0.000244 (606.7s)\n",
        "üíæ Model improved (loss ‚Üì and hitrate ‚Üë), saved.\n",
        "\n",
        "--- Epoch 6/10 ---\n",
        "Epoch 6: Train Loss=0.2488, Val Loss=0.2531, HitRate@3=0.5133, NDCG@3=0.4112, MAP@3=0.6480, LR=0.000183 (606.2s)\n",
        "üíæ Model improved (loss ‚Üì and hitrate ‚Üë), saved.\n",
        "\n",
        "--- Epoch 7/10 ---\n",
        "Epoch 7: Train Loss=0.2380, Val Loss=0.2465, HitRate@3=0.5169, NDCG@3=0.4165, MAP@3=0.6582, LR=0.000117 (605.7s)\n",
        "üíæ Model improved (loss ‚Üì and hitrate ‚Üë), saved.\n",
        "\n",
        "--- Epoch 8/10 ---\n",
        "Epoch 8: Train Loss=0.2273, Val Loss=0.2419, HitRate@3=0.5184, NDCG@3=0.4189, MAP@3=0.6609, LR=0.000056 (607.1s)\n",
        "üíæ Model improved (loss ‚Üì and hitrate ‚Üë), saved.\n",
        "\n",
        "--- Epoch 9/10 ---\n",
        "Epoch 9: Train Loss=0.2176, Val Loss=0.2353, HitRate@3=0.5224, NDCG@3=0.4229, MAP@3=0.6617, LR=0.000015 (606.9s)\n",
        "üíæ Model improved (loss ‚Üì and hitrate ‚Üë), saved.\n",
        "\n",
        "--- Epoch 10/10 ---\n",
        "Epoch 10: Train Loss=0.2144, Val Loss=0.2350, HitRate@3=0.5216, NDCG@3=0.4224, MAP@3=0.6614, LR=0.000000 (605.8s)"
      ],
      "metadata": {
        "id": "uUb4xFY0aW15"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**0.49242**"
      ],
      "metadata": {
        "id": "Uyiko0zw2E5j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile deeprec_full_training.py\n",
        "import os\n",
        "import time\n",
        "import random\n",
        "import torch\n",
        "import math\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F_torch\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import defaultdict\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "import polars as pl\n",
        "from tqdm import tqdm\n",
        "from src.feature import feature_engineering, feature_selection\n",
        "from transformers import get_scheduler\n",
        "from collections import Counter\n",
        "from torch.optim.lr_scheduler import OneCycleLR\n",
        "\n",
        "class RankDataset(Dataset):\n",
        "    def __init__(\n",
        "        self,\n",
        "        X: pl.DataFrame,\n",
        "        y: pl.Series,\n",
        "        groups: pl.DataFrame,\n",
        "        cat_features: list[str],\n",
        "        num_features: list[str],\n",
        "    ):\n",
        "        self.cat_features = cat_features\n",
        "        self.num_features = num_features\n",
        "        self.X_cat = {c: X[c].to_numpy() for c in cat_features}\n",
        "        self.X_num = X[self.num_features].to_numpy()\n",
        "        self.y = y.to_numpy()\n",
        "        self.groups = groups[\"ranker_id\"].to_numpy()\n",
        "\n",
        "        self.group_to_indices = defaultdict(list)\n",
        "        for i, g in enumerate(self.groups):\n",
        "            self.group_to_indices[g].append(i)\n",
        "        self.group_keys = list(self.group_to_indices.keys())\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.group_keys)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        g = self.group_keys[idx]\n",
        "        inds = self.group_to_indices[g]\n",
        "        length = len(inds)\n",
        "\n",
        "        x_cat = {\n",
        "            c: torch.LongTensor([\n",
        "                self.X_cat[c][i] if self.X_cat[c][i] >= 0 else 0 for i in inds\n",
        "            ])\n",
        "            for c in self.cat_features\n",
        "        }\n",
        "\n",
        "        x_num = torch.FloatTensor(self.X_num[inds])\n",
        "        y = torch.FloatTensor(self.y[inds]).reshape(-1)\n",
        "\n",
        "        return x_cat, x_num, y, length\n",
        "\n",
        "def collate_fn(batch):\n",
        "    batch_size = len(batch)\n",
        "    lengths = [b[3] for b in batch]\n",
        "    max_len = max(lengths)\n",
        "\n",
        "    padded_x_cat = {key: [] for key in batch[0][0].keys()}\n",
        "    padded_x_num = []\n",
        "    padded_y = []\n",
        "\n",
        "    num_dim = batch[0][1].shape[1]\n",
        "\n",
        "    for x_cat, x_num, y, length in batch:\n",
        "        pad_len = max_len - length\n",
        "\n",
        "        for key in padded_x_cat:\n",
        "            val = x_cat[key]\n",
        "            if pad_len > 0:\n",
        "                val = torch.cat([val, torch.zeros(pad_len, dtype=torch.long)])\n",
        "            padded_x_cat[key].append(val)\n",
        "\n",
        "        if pad_len > 0:\n",
        "            x_num = torch.cat([x_num, torch.zeros(pad_len, num_dim)])\n",
        "            y = torch.cat([y, torch.zeros(pad_len)])\n",
        "\n",
        "        padded_x_num.append(x_num)\n",
        "        padded_y.append(y)\n",
        "\n",
        "    padded_x_cat = {k: torch.stack(v) for k, v in padded_x_cat.items()}\n",
        "    padded_x_num = torch.stack(padded_x_num)\n",
        "    padded_y = torch.stack(padded_y)\n",
        "    lengths = torch.tensor(lengths, dtype=torch.long)\n",
        "\n",
        "    return padded_x_cat, padded_x_num, padded_y, lengths\n",
        "\n",
        "class SEModule(nn.Module):\n",
        "    def __init__(self, channel, reduction=4):\n",
        "        super().__init__()\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(channel, channel // reduction),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(channel // reduction, channel),\n",
        "            nn.Sigmoid(),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: [B, N, C]\n",
        "        w = self.fc(x.mean(dim=1))\n",
        "        w = w.unsqueeze(1)  # [B, 1, C]\n",
        "        return x * w\n",
        "\n",
        "\n",
        "class DLRankerAttention(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        cat_dims,\n",
        "        num_numeric_feats,\n",
        "        emb_dropout=0.1,\n",
        "        dropout=0.1,\n",
        "        num_heads=4,\n",
        "        num_layers=2,\n",
        "        dim_feedforward=128,\n",
        "        proj_dim=64,\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "        self.emb_dims = {\n",
        "            f: min(50, max(4, round(6 * math.log2(cat_dims[f] + 1)))) for f in cat_dims\n",
        "        }\n",
        "        self.embeddings = nn.ModuleDict({\n",
        "            f: nn.Embedding(cat_dims[f], self.emb_dims[f], padding_idx=0)\n",
        "            for f in cat_dims\n",
        "        })\n",
        "        self.emb_dropout = nn.Dropout(emb_dropout)\n",
        "\n",
        "        total_emb_dim = sum(self.emb_dims.values())\n",
        "        print(f\"Categorial emb dim sum: {total_emb_dim}, Numerical dim: {num_numeric_feats}\")\n",
        "\n",
        "        self.cat_proj = nn.Linear(total_emb_dim, proj_dim)\n",
        "        self.cat_transformer = nn.TransformerEncoder(\n",
        "            nn.TransformerEncoderLayer(\n",
        "                d_model=proj_dim,\n",
        "                nhead=4,\n",
        "                dim_feedforward=dim_feedforward,\n",
        "                dropout=dropout,\n",
        "                batch_first=True,\n",
        "            ),\n",
        "            num_layers=1,\n",
        "        )\n",
        "\n",
        "        self.num_proj_in = nn.Linear(num_numeric_feats, proj_dim)\n",
        "        self.num_transformer = nn.TransformerEncoder(\n",
        "            nn.TransformerEncoderLayer(\n",
        "                d_model=proj_dim,\n",
        "                nhead=4,\n",
        "                dim_feedforward=dim_feedforward,\n",
        "                dropout=dropout,\n",
        "                batch_first=True,\n",
        "            ),\n",
        "            num_layers=1,\n",
        "        )\n",
        "        self.num_se = SEModule(proj_dim)\n",
        "        self.num_proj_out = nn.Sequential(\n",
        "            nn.Linear(proj_dim, proj_dim),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(dropout),\n",
        "        )\n",
        "\n",
        "        # üîÅ Cross-attention: cat attends to num\n",
        "        self.cross_attn_cat2num = nn.MultiheadAttention(\n",
        "            embed_dim=proj_dim,\n",
        "            num_heads=4,\n",
        "            dropout=dropout,\n",
        "            batch_first=True,\n",
        "        )\n",
        "\n",
        "        self.transformer_layers = nn.ModuleList([\n",
        "            nn.TransformerEncoderLayer(\n",
        "                d_model=2 * proj_dim,\n",
        "                nhead=num_heads,\n",
        "                dim_feedforward=dim_feedforward,\n",
        "                dropout=dropout,\n",
        "                batch_first=True,\n",
        "            )\n",
        "            for _ in range(num_layers)\n",
        "        ])\n",
        "\n",
        "        self.mlp = nn.Sequential(\n",
        "            nn.Linear(2 * proj_dim, 128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(128, 64),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(64, 1),\n",
        "        )\n",
        "\n",
        "    def forward(self, x_cat: dict, x_num: torch.Tensor, attn_mask=None):\n",
        "        B, N, _ = x_num.shape  # x_num: [B, N, F_num]\n",
        "\n",
        "        # Categorical embeddings\n",
        "        cat_embs = torch.cat([self.embeddings[f](x_cat[f]) for f in x_cat], dim=-1)\n",
        "        cat_embs = self.emb_dropout(cat_embs)\n",
        "        cat_feat = self.cat_proj(cat_embs)  # [B, N, D]\n",
        "        cat_feat = self.cat_transformer(cat_feat)  # [B, N, D]\n",
        "\n",
        "        # Numeric features\n",
        "        num_feat = self.num_proj_in(x_num)\n",
        "        num_feat = self.num_transformer(num_feat)\n",
        "        num_feat = self.num_se(num_feat)\n",
        "        num_feat = self.num_proj_out(num_feat)\n",
        "\n",
        "        # Cross-attention: categorical features attend over numeric ones\n",
        "        cat_feat_attn, _ = self.cross_attn_cat2num(\n",
        "            query=cat_feat, key=num_feat, value=num_feat\n",
        "        )\n",
        "        cat_feat = cat_feat + cat_feat_attn  # residual connection\n",
        "\n",
        "        # Final concatenation\n",
        "        x = torch.cat([cat_feat, num_feat], dim=-1)\n",
        "\n",
        "        for layer in self.transformer_layers:\n",
        "            x = layer(x, src_key_padding_mask=attn_mask)\n",
        "\n",
        "        scores = self.mlp(x).squeeze(-1)  # [B, N]\n",
        "        return scores\n",
        "\n",
        "\"\"\"\n",
        "def listmle_loss(scores, labels, lengths):\n",
        "    batch_size = scores.size(0)\n",
        "    total_loss = torch.tensor(0.0, device=scores.device, requires_grad=True)\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "\n",
        "        _, idx = torch.sort(y, descending=True)\n",
        "        s_sorted = s[idx]\n",
        "\n",
        "        parts = (\n",
        "            torch.logsumexp(s_sorted.unsqueeze(0).expand(l, -1).triu(diagonal=0), dim=1)\n",
        "            - s_sorted\n",
        "        )\n",
        "\n",
        "        total_loss = total_loss + parts.sum()\n",
        "\n",
        "    return total_loss / batch_size\n",
        "\"\"\"\n",
        "\n",
        "def hitrate_at_k(scores, labels, lengths, k=3):\n",
        "    batch_size = scores.size(0)\n",
        "    hits = 0\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        length = min(l, k)\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "        _, topk_idx = torch.topk(s, length)\n",
        "        topk_labels = y[topk_idx]\n",
        "        hits += (topk_labels > 0).any().float()\n",
        "    return hits / batch_size\n",
        "\n",
        "\"\"\"\n",
        "def listnet_loss(scores, labels, lengths):\n",
        "    batch_size = scores.size(0)\n",
        "    total_loss = 0.0\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "\n",
        "        s_softmax = torch.nn.functional.log_softmax(s, dim=0)\n",
        "        y_softmax = torch.nn.functional.softmax(y, dim=0)\n",
        "\n",
        "        loss = -torch.sum(y_softmax * s_softmax)\n",
        "        total_loss += loss\n",
        "\n",
        "    return total_loss / batch_size\n",
        "\"\"\"\n",
        "\n",
        "def ranknet_loss(scores, labels, lengths):\n",
        "    batch_size = scores.size(0)\n",
        "    total_loss = 0.0\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "\n",
        "        diff_scores = s.unsqueeze(1) - s.unsqueeze(0)\n",
        "        rel = y.unsqueeze(1) > y.unsqueeze(0)\n",
        "        label_diff = rel.float()\n",
        "\n",
        "        log_sigmoid = torch.nn.functional.logsigmoid(diff_scores)\n",
        "        pair_loss = -label_diff * log_sigmoid\n",
        "\n",
        "        total_loss += pair_loss.sum()\n",
        "\n",
        "    return total_loss / batch_size\n",
        "\n",
        "def xranknet_loss(scores, labels, lengths, temperature=1.0, margin=0.2, focus_topk=3):\n",
        "    \"\"\"\n",
        "    xRankNet with emphasis on top-K items (based on labels, not scores).\n",
        "    \"\"\"\n",
        "    batch_size = scores.size(0)\n",
        "    total_loss = 0.0\n",
        "    total_pairs = 0\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        if l < 2:\n",
        "            continue\n",
        "\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "\n",
        "        # Top-K mask based on ground truth labels\n",
        "        topk = min(focus_topk, l)\n",
        "        _, topk_idx = torch.topk(y, topk)\n",
        "        topk_mask = torch.zeros_like(y, dtype=torch.bool)\n",
        "        topk_mask[topk_idx] = True\n",
        "\n",
        "        # Create pairwise difference matrices\n",
        "        score_diff = s.unsqueeze(1) - s.unsqueeze(0)\n",
        "        label_diff = y.unsqueeze(1) - y.unsqueeze(0)\n",
        "\n",
        "        # valid pair: y_i > y_j and at least one of i, j is in top-K\n",
        "        valid_pairs = (label_diff > 0) & (\n",
        "            topk_mask.unsqueeze(1) | topk_mask.unsqueeze(0)\n",
        "        )\n",
        "\n",
        "        if valid_pairs.sum() == 0:\n",
        "            continue\n",
        "\n",
        "        importance = (label_diff.abs() * valid_pairs).float()\n",
        "\n",
        "        if margin > 0.0:\n",
        "            score_diff = score_diff - margin\n",
        "\n",
        "        score_diff = score_diff / temperature\n",
        "        pairwise_loss = -F_torch.logsigmoid(score_diff) * importance\n",
        "\n",
        "        total_loss += pairwise_loss.sum()\n",
        "        total_pairs += importance.sum()\n",
        "\n",
        "    if total_pairs == 0:\n",
        "        return torch.tensor(0.0, device=scores.device, requires_grad=True)\n",
        "\n",
        "    return total_loss / total_pairs\n",
        "\n",
        "def train_one_epoch(model, loader, optimizer, device, scheduler):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "\n",
        "    for x_cat, x_num, y, lengths in tqdm(loader, desc=\"Training\", leave=False):\n",
        "        x_num, y = x_num.to(device), y.to(device)\n",
        "        if not isinstance(lengths, torch.Tensor):\n",
        "            lengths = torch.tensor(lengths)\n",
        "        lengths = lengths.detach().clone().to(device)\n",
        "        x_cat = {k: v.to(device) for k, v in x_cat.items()}\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        scores = model(x_cat, x_num)\n",
        "        loss = xranknet_loss(scores, y, lengths, temperature=1.0, margin=0.2, focus_topk=3)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    return total_loss / len(loader)\n",
        "\n",
        "\n",
        "def validate(model, loader, device):\n",
        "    model.eval()\n",
        "    total_hitrate = 0\n",
        "    total_loss = 0\n",
        "    count = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for x_cat, x_num, y, lengths in tqdm(loader, desc=\"Validating\", leave=False):\n",
        "\n",
        "            x_num, y = x_num.to(device), y.to(device)\n",
        "            lengths = torch.tensor(lengths).to(device)\n",
        "            x_cat = {k: v.to(device) for k, v in x_cat.items()}\n",
        "            scores = model(x_cat, x_num)\n",
        "\n",
        "            hitrate = hitrate_at_k(scores, y, lengths, k=3)\n",
        "            loss = xranknet_loss(scores, y, lengths, temperature=1.0, margin=0.2, focus_topk=3)\n",
        "\n",
        "            total_hitrate += hitrate * scores.size(0)\n",
        "            total_loss += loss.item() * scores.size(0)\n",
        "            count += scores.size(0)\n",
        "\n",
        "    avg_hitrate = total_hitrate / count\n",
        "    avg_loss = total_loss / count\n",
        "    return avg_loss, avg_hitrate\n",
        "\n",
        "\n",
        "def build_cat_dims(X, cat_features):\n",
        "    cat_dims = {}\n",
        "    for c in cat_features:\n",
        "        max_val = X[c].max()\n",
        "        if max_val < 0:\n",
        "            max_val = 0\n",
        "        cat_dims[c] = max_val + 1\n",
        "    return cat_dims\n",
        "\n",
        "\n",
        "def normalize_numeric_features(X, numeric_features, train_mask):\n",
        "    for col in numeric_features:\n",
        "        values = X[col].to_numpy()\n",
        "        train_vals = values[train_mask]\n",
        "        mean = train_vals.mean()\n",
        "        std = train_vals.std() if train_vals.std() > 0 else 1.0\n",
        "        norm_vals = (values - mean) / std\n",
        "        X = X.with_columns(pl.Series(col, norm_vals).alias(col))\n",
        "    return X\n",
        "\n",
        "\n",
        "def load_or_prepare_data(\n",
        "    data_dir,\n",
        "    train_file=\"train.parquet\",\n",
        "    test_file=\"test.parquet\",\n",
        "    cache_file=\"feature_engineered_val.parquet\",\n",
        "):\n",
        "    cache_path = os.path.join(data_dir, cache_file)\n",
        "\n",
        "    if os.path.exists(cache_path):\n",
        "        print(f\"Loading cached feature-engineered data from {cache_path} ...\")\n",
        "        df = pl.read_parquet(cache_path)\n",
        "\n",
        "        test = pl.read_parquet(os.path.join(data_dir, test_file)).drop(\"__index_level_0__\")\n",
        "        test_ids = test[\"Id\"]\n",
        "        test_rankers = test[\"ranker_id\"]\n",
        "    else:\n",
        "        print(\"Cached file not found, processing raw data ...\")\n",
        "\n",
        "        train = pl.read_parquet(os.path.join(data_dir, train_file)).drop(\"__index_level_0__\")\n",
        "        test = (\n",
        "            pl.read_parquet(os.path.join(data_dir, test_file))\n",
        "            .drop(\"__index_level_0__\")\n",
        "            .with_columns(pl.lit(0, dtype=pl.Int64).alias(\"selected\"))\n",
        "        )\n",
        "\n",
        "        test_ids = test[\"Id\"]\n",
        "        test_rankers = test[\"ranker_id\"]\n",
        "\n",
        "        df = pl.concat((train, test))\n",
        "        df = feature_engineering(df, full=True)\n",
        "\n",
        "        df = df.with_columns(\n",
        "            [pl.col(c).fill_null(0) for c in df.select(pl.selectors.numeric()).columns] +\n",
        "            [pl.col(c).fill_null(\"missing\") for c in df.select(pl.selectors.string()).columns]\n",
        "        )\n",
        "\n",
        "        os.makedirs(data_dir, exist_ok=True)\n",
        "        df.write_parquet(cache_path)\n",
        "        print(f\"Saved feature-engineered data to {cache_path}\")\n",
        "\n",
        "    return df, test_ids, test_rankers\n",
        "\n",
        "\n",
        "def prepare_data(data_dir):\n",
        "    df, test_ids, test_rankers = load_or_prepare_data(data_dir)\n",
        "\n",
        "    id_column = df[\"Id\"]\n",
        "    X, y, groups, cat_features, num_features = feature_selection(df)\n",
        "\n",
        "    X = X.with_columns(pl.Series(\"Id\", id_column[:X.shape[0]]))\n",
        "\n",
        "    X = X.with_columns(\n",
        "        [\n",
        "            (pl.col(c).rank(\"dense\") - 1).fill_null(-1).cast(pl.Int32)\n",
        "            for c in cat_features\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    train_size = 18145372\n",
        "    train_mask = np.arange(X.height) < train_size\n",
        "    X = normalize_numeric_features(X, num_features, train_mask)\n",
        "\n",
        "    return X, y, groups, cat_features, num_features, train_size, test_ids, test_rankers\n",
        "\n",
        "\n",
        "class EarlyStopping:\n",
        "    def __init__(self, patience=3, min_delta=0.001):\n",
        "        self.patience = patience\n",
        "        self.min_delta = min_delta\n",
        "        self.best = float(\"-inf\")\n",
        "        self.counter = 0\n",
        "\n",
        "    def step(self, metric):\n",
        "        if metric > self.best + self.min_delta:\n",
        "            self.best = metric\n",
        "            self.counter = 0\n",
        "        else:\n",
        "            self.counter += 1\n",
        "        return self.counter >= self.patience\n",
        "\n",
        "\n",
        "def plot_group_size_distribution(dataset, save_path=None):\n",
        "    group_sizes = [len(v) for v in dataset.group_to_indices.values()]\n",
        "    plt.figure()\n",
        "    plt.hist(group_sizes, bins=100, log=True)\n",
        "    plt.xlabel(\"Group size (number of items per ranker_id)\")\n",
        "    plt.ylabel(\"Frequency (log scale)\")\n",
        "    plt.title(\"Distribution of Group Sizes\")\n",
        "    plt.grid(True)\n",
        "    if save_path:\n",
        "        plt.savefig(save_path)\n",
        "    else:\n",
        "        plt.show()\n",
        "    plt.close()\n",
        "\n",
        "\n",
        "def main():\n",
        "    DATA_DIR = \"./data\"\n",
        "    MODEL_DIR = \"model\"\n",
        "    SUBMIT_DIR = \"submission\"\n",
        "\n",
        "    model_path = os.path.join(MODEL_DIR, \"best_dl_ranker.pt\")\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    train_losses = []\n",
        "    learning_rates = []\n",
        "\n",
        "    os.makedirs(MODEL_DIR, exist_ok=True)\n",
        "    os.makedirs(SUBMIT_DIR, exist_ok=True)\n",
        "\n",
        "    early_stopper = EarlyStopping(patience=3, min_delta=0.001)\n",
        "\n",
        "    X, y, groups, cat_features, num_features, train_size, test_ids, test_rankers = prepare_data(DATA_DIR)\n",
        "\n",
        "    # Fill missing values\n",
        "    float_cols = [c for c, t in zip(X.columns, X.dtypes) if t == pl.Float64]\n",
        "    for col in float_cols:\n",
        "        X = X.with_columns(\n",
        "            pl.when(pl.col(col).is_nan()).then(0).otherwise(pl.col(col)).alias(col)\n",
        "        )\n",
        "\n",
        "    n2 = train_size\n",
        "\n",
        "    X_tr, X_te = X[:n2], X[n2:]\n",
        "    y_tr, y_te = y[:n2], y[n2:]\n",
        "    groups_tr, groups_te = groups[:n2], groups[n2:]\n",
        "\n",
        "    cat_dims = build_cat_dims(X, cat_features)\n",
        "    num_numeric_feats = len(num_features)\n",
        "\n",
        "    train_dataset = RankDataset(X_tr, y_tr, groups_tr, cat_features, num_features)\n",
        "    test_dataset = RankDataset(X_te, y_te, groups_te, cat_features, num_features)\n",
        "\n",
        "    plot_group_size_distribution(train_dataset, save_path=os.path.join(MODEL_DIR, \"group_sizes.png\"))\n",
        "    print(\"üìä Group size distribution saved.\")\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True, collate_fn=collate_fn)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False, collate_fn=collate_fn)\n",
        "\n",
        "    print(\"‚úÖ Data loaders created.\")\n",
        "\n",
        "    num_epochs = 10\n",
        "    num_training_steps = num_epochs * len(train_loader)\n",
        "    num_warmup_steps = int(0.1 * num_training_steps)\n",
        "\n",
        "    learning_rate = 3e-4\n",
        "\n",
        "    model = DLRankerAttention(\n",
        "        cat_dims=cat_dims,\n",
        "        num_numeric_feats=num_numeric_feats,\n",
        "        emb_dropout=0.1,\n",
        "        dropout=0.1,\n",
        "        num_heads=4,\n",
        "        num_layers=2,\n",
        "        dim_feedforward=128,\n",
        "        proj_dim=64\n",
        "    ).to(device)\n",
        "\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=0.05)\n",
        "\n",
        "    scheduler = OneCycleLR(\n",
        "        optimizer,\n",
        "        max_lr=learning_rate,\n",
        "        steps_per_epoch=len(train_loader),\n",
        "        epochs=num_epochs,\n",
        "        pct_start=0.3,\n",
        "    )\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print(f\"\\n--- Epoch {epoch+1}/{num_epochs} ---\")\n",
        "        start_time = time.time()\n",
        "\n",
        "        train_loss = train_one_epoch(model, train_loader, optimizer, device, scheduler)\n",
        "\n",
        "        train_losses.append(train_loss)\n",
        "\n",
        "        current_lr = scheduler.get_last_lr()\n",
        "        learning_rates.append(current_lr[0])\n",
        "\n",
        "        elapsed = time.time() - start_time\n",
        "        print(\n",
        "            f\"Epoch {epoch+1}: \"\n",
        "            f\"Train Loss={train_loss:.4f}, \"\n",
        "            f\"LR={current_lr[0]:.6f} \"\n",
        "            f\"({elapsed:.1f}s)\"\n",
        "        )\n",
        "\n",
        "        torch.save(model.state_dict(), model_path)\n",
        "        print(\"üíæ Model improved (loss ‚Üì and hitrate ‚Üë), saved.\")\n",
        "\n",
        "    # Plot metrics\n",
        "    epochs = list(range(1, len(train_losses) + 1))\n",
        "\n",
        "    # Predict test set\n",
        "    model.load_state_dict(torch.load(model_path))\n",
        "    model.eval()\n",
        "    all_scores = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for x_cat, x_num, _, lengths in tqdm(test_loader, desc=\"Predicting test set\"):\n",
        "            x_num = x_num.to(device)\n",
        "            x_cat = {k: v.to(device) for k, v in x_cat.items()}\n",
        "            scores = model(x_cat, x_num)\n",
        "\n",
        "            for i in range(scores.size(0)):\n",
        "                l = lengths[i]\n",
        "                all_scores.append(scores[i, :l].cpu().numpy())\n",
        "\n",
        "    all_scores = np.concatenate(all_scores)\n",
        "\n",
        "    assert len(all_scores) == X_te.shape[0], \\\n",
        "        f\"Mismatch: {len(all_scores)} scores vs {X_te.shape[0]} rows in X_te\"\n",
        "\n",
        "    submission_df = pl.DataFrame({\n",
        "        \"Id\": test_ids,\n",
        "        \"ranker_id\": test_rankers,\n",
        "        \"score\": all_scores\n",
        "    })\n",
        "\n",
        "    submission = (\n",
        "        submission_df\n",
        "        .with_columns(\n",
        "            pl.col(\"score\")\n",
        "            .rank(method=\"ordinal\", descending=True)\n",
        "            .over(\"ranker_id\")\n",
        "            .cast(pl.Int32)\n",
        "            .alias(\"selected\")\n",
        "        )\n",
        "        .select([\"Id\", \"ranker_id\", \"selected\"])\n",
        "    )\n",
        "\n",
        "\n",
        "    submission_path = os.path.join(SUBMIT_DIR, \"submission_dl_ranker.parquet\")\n",
        "    submission.write_parquet(submission_path)\n",
        "    print(f\"‚úÖ Submission saved to {submission_path}\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gWRcIlh_ainC",
        "outputId": "9112c498-22be-4195-d9b0-19be7d73d1be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing deeprec_full_training.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile deeprec_validate.py\n",
        "import os\n",
        "import time\n",
        "import random\n",
        "import torch\n",
        "import math\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import defaultdict\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "import polars as pl\n",
        "from tqdm import tqdm\n",
        "from src.feature import feature_engineering, feature_selection\n",
        "from transformers import get_scheduler\n",
        "from collections import Counter\n",
        "from torch.optim.lr_scheduler import OneCycleLR\n",
        "\n",
        "class RankDataset(Dataset):\n",
        "    def __init__(\n",
        "        self,\n",
        "        X: pl.DataFrame,\n",
        "        y: pl.Series,\n",
        "        groups: pl.DataFrame,\n",
        "        cat_features: list[str],\n",
        "        num_features: list[str],\n",
        "    ):\n",
        "        self.cat_features = cat_features\n",
        "        self.num_features = num_features\n",
        "        self.X_cat = {c: X[c].to_numpy() for c in cat_features}\n",
        "        self.X_num = X[self.num_features].to_numpy()\n",
        "        self.y = y.to_numpy()\n",
        "        self.groups = groups[\"ranker_id\"].to_numpy()\n",
        "\n",
        "        self.group_to_indices = defaultdict(list)\n",
        "        for i, g in enumerate(self.groups):\n",
        "            self.group_to_indices[g].append(i)\n",
        "        self.group_keys = list(self.group_to_indices.keys())\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.group_keys)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        g = self.group_keys[idx]\n",
        "        inds = self.group_to_indices[g]\n",
        "        length = len(inds)\n",
        "\n",
        "        x_cat = {\n",
        "            c: torch.LongTensor([\n",
        "                self.X_cat[c][i] if self.X_cat[c][i] >= 0 else 0 for i in inds\n",
        "            ])\n",
        "            for c in self.cat_features\n",
        "        }\n",
        "\n",
        "        x_num = torch.FloatTensor(self.X_num[inds])\n",
        "        y = torch.FloatTensor(self.y[inds]).reshape(-1)\n",
        "\n",
        "        return x_cat, x_num, y, length\n",
        "\n",
        "def collate_fn(batch):\n",
        "    batch_size = len(batch)\n",
        "    lengths = [b[3] for b in batch]\n",
        "    max_len = max(lengths)\n",
        "\n",
        "    padded_x_cat = {key: [] for key in batch[0][0].keys()}\n",
        "    padded_x_num = []\n",
        "    padded_y = []\n",
        "\n",
        "    num_dim = batch[0][1].shape[1]\n",
        "\n",
        "    for x_cat, x_num, y, length in batch:\n",
        "        pad_len = max_len - length\n",
        "\n",
        "        for key in padded_x_cat:\n",
        "            val = x_cat[key]\n",
        "            if pad_len > 0:\n",
        "                val = torch.cat([val, torch.zeros(pad_len, dtype=torch.long)])\n",
        "            padded_x_cat[key].append(val)\n",
        "\n",
        "        if pad_len > 0:\n",
        "            x_num = torch.cat([x_num, torch.zeros(pad_len, num_dim)])\n",
        "            y = torch.cat([y, torch.zeros(pad_len)])\n",
        "\n",
        "        padded_x_num.append(x_num)\n",
        "        padded_y.append(y)\n",
        "\n",
        "    padded_x_cat = {k: torch.stack(v) for k, v in padded_x_cat.items()}\n",
        "    padded_x_num = torch.stack(padded_x_num)\n",
        "    padded_y = torch.stack(padded_y)\n",
        "    lengths = torch.tensor(lengths, dtype=torch.long)\n",
        "\n",
        "    return padded_x_cat, padded_x_num, padded_y, lengths\n",
        "\n",
        "class SEModule(nn.Module):\n",
        "    def __init__(self, channel, reduction=4):\n",
        "        super().__init__()\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(channel, channel // reduction),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(channel // reduction, channel),\n",
        "            nn.Sigmoid(),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: [B, N, C]\n",
        "        w = self.fc(x.mean(dim=1))\n",
        "        w = w.unsqueeze(1)  # [B, 1, C]\n",
        "        return x * w\n",
        "\n",
        "\n",
        "class DLRankerAttention(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        cat_dims,\n",
        "        num_numeric_feats,\n",
        "        emb_dropout=0.1,\n",
        "        dropout=0.1,\n",
        "        num_heads=4,\n",
        "        num_layers=2,\n",
        "        dim_feedforward=128,\n",
        "        proj_dim=64,\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "        self.emb_dims = {\n",
        "            f: min(50, max(4, round(6 * math.log2(cat_dims[f] + 1)))) for f in cat_dims\n",
        "        }\n",
        "        self.embeddings = nn.ModuleDict({\n",
        "            f: nn.Embedding(cat_dims[f], self.emb_dims[f], padding_idx=0)\n",
        "            for f in cat_dims\n",
        "        })\n",
        "        self.emb_dropout = nn.Dropout(emb_dropout)\n",
        "\n",
        "        total_emb_dim = sum(self.emb_dims.values())\n",
        "        print(f\"Categorial emb dim sum: {total_emb_dim}, Numerical dim: {num_numeric_feats}\")\n",
        "\n",
        "        self.cat_proj = nn.Linear(total_emb_dim, proj_dim)\n",
        "        self.cat_transformer = nn.TransformerEncoder(\n",
        "            nn.TransformerEncoderLayer(\n",
        "                d_model=proj_dim,\n",
        "                nhead=4,\n",
        "                dim_feedforward=dim_feedforward,\n",
        "                dropout=dropout,\n",
        "                batch_first=True,\n",
        "            ),\n",
        "            num_layers=1,\n",
        "        )\n",
        "\n",
        "        self.num_proj_in = nn.Linear(num_numeric_feats, proj_dim)\n",
        "        self.num_transformer = nn.TransformerEncoder(\n",
        "            nn.TransformerEncoderLayer(\n",
        "                d_model=proj_dim,\n",
        "                nhead=4,\n",
        "                dim_feedforward=dim_feedforward,\n",
        "                dropout=dropout,\n",
        "                batch_first=True,\n",
        "            ),\n",
        "            num_layers=1,\n",
        "        )\n",
        "        self.num_se = SEModule(proj_dim)\n",
        "        self.num_proj_out = nn.Sequential(\n",
        "            nn.Linear(proj_dim, proj_dim),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(dropout),\n",
        "        )\n",
        "\n",
        "        # üîÅ Cross-attention: cat attends to num\n",
        "        self.cross_attn_cat2num = nn.MultiheadAttention(\n",
        "            embed_dim=proj_dim,\n",
        "            num_heads=4,\n",
        "            dropout=dropout,\n",
        "            batch_first=True,\n",
        "        )\n",
        "\n",
        "        self.transformer_layers = nn.ModuleList([\n",
        "            nn.TransformerEncoderLayer(\n",
        "                d_model=2 * proj_dim,\n",
        "                nhead=num_heads,\n",
        "                dim_feedforward=dim_feedforward,\n",
        "                dropout=dropout,\n",
        "                batch_first=True,\n",
        "            )\n",
        "            for _ in range(num_layers)\n",
        "        ])\n",
        "\n",
        "        self.mlp = nn.Sequential(\n",
        "            nn.Linear(2 * proj_dim, 128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(128, 64),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(64, 1),\n",
        "        )\n",
        "\n",
        "    def forward(self, x_cat: dict, x_num: torch.Tensor, attn_mask=None):\n",
        "        B, N, _ = x_num.shape  # x_num: [B, N, F_num]\n",
        "\n",
        "        # Categorical embeddings\n",
        "        cat_embs = torch.cat([self.embeddings[f](x_cat[f]) for f in x_cat], dim=-1)\n",
        "        cat_embs = self.emb_dropout(cat_embs)\n",
        "        cat_feat = self.cat_proj(cat_embs)  # [B, N, D]\n",
        "        cat_feat = self.cat_transformer(cat_feat)  # [B, N, D]\n",
        "\n",
        "        # Numeric features\n",
        "        num_feat = self.num_proj_in(x_num)\n",
        "        num_feat = self.num_transformer(num_feat)\n",
        "        num_feat = self.num_se(num_feat)\n",
        "        num_feat = self.num_proj_out(num_feat)\n",
        "\n",
        "        # Cross-attention: categorical features attend over numeric ones\n",
        "        cat_feat_attn, _ = self.cross_attn_cat2num(\n",
        "            query=cat_feat, key=num_feat, value=num_feat\n",
        "        )\n",
        "        cat_feat = cat_feat + cat_feat_attn  # residual connection\n",
        "\n",
        "        # Final concatenation\n",
        "        x = torch.cat([cat_feat, num_feat], dim=-1)\n",
        "\n",
        "        for layer in self.transformer_layers:\n",
        "            x = layer(x, src_key_padding_mask=attn_mask)\n",
        "\n",
        "        scores = self.mlp(x).squeeze(-1)  # [B, N]\n",
        "        return scores\n",
        "\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "def listmle_loss(scores, labels, lengths):\n",
        "    batch_size = scores.size(0)\n",
        "    total_loss = torch.tensor(0.0, device=scores.device, requires_grad=True)\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "\n",
        "        _, idx = torch.sort(y, descending=True)\n",
        "        s_sorted = s[idx]\n",
        "\n",
        "        parts = (\n",
        "            torch.logsumexp(s_sorted.unsqueeze(0).expand(l, -1).triu(diagonal=0), dim=1)\n",
        "            - s_sorted\n",
        "        )\n",
        "\n",
        "        total_loss = total_loss + parts.sum()\n",
        "\n",
        "    return total_loss / batch_size\n",
        "\"\"\"\n",
        "\n",
        "def hitrate_at_k(scores, labels, lengths, k=3, min_group_size=10):\n",
        "    batch_size = scores.size(0)\n",
        "    hits = 0\n",
        "    valid_count = 0\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        if l < min_group_size:\n",
        "            continue\n",
        "        length = min(l, k)\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "        _, topk_idx = torch.topk(s, length)\n",
        "        topk_labels = y[topk_idx]\n",
        "        hits += (topk_labels > 0).any().float()\n",
        "        valid_count += 1\n",
        "    return hits / valid_count if valid_count > 0 else torch.tensor(0.0, device=scores.device)\n",
        "\n",
        "\n",
        "def ndcg_at_k(scores, labels, lengths, k=3, min_group_size=10):\n",
        "    batch_size = scores.size(0)\n",
        "    total_ndcg = 0.0\n",
        "    valid_count = 0\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        if l < min_group_size:\n",
        "            continue\n",
        "\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "\n",
        "        _, idx_pred = torch.topk(s, min(k, l))\n",
        "        _, idx_ideal = torch.topk(y, min(k, l))\n",
        "\n",
        "        dcg = (y[idx_pred] / torch.log2(torch.arange(2, 2 + len(idx_pred), device=y.device).float())).sum()\n",
        "        idcg = (y[idx_ideal] / torch.log2(torch.arange(2, 2 + len(idx_ideal), device=y.device).float())).sum()\n",
        "\n",
        "        ndcg = dcg / idcg if idcg > 0 else 0.0\n",
        "        total_ndcg += ndcg\n",
        "        valid_count += 1\n",
        "\n",
        "    return total_ndcg / valid_count if valid_count > 0 else torch.tensor(0.0, device=scores.device)\n",
        "\n",
        "\n",
        "def map_at_k(scores, labels, lengths, k=3, min_group_size=10):\n",
        "    batch_size = scores.size(0)\n",
        "    total_ap = 0.0\n",
        "    valid_count = 0\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        if l < min_group_size:\n",
        "            continue\n",
        "\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "\n",
        "        _, idx_pred = torch.topk(s, min(k, l))\n",
        "        y_true = y[idx_pred] > 0\n",
        "\n",
        "        if y_true.sum() == 0:\n",
        "            continue\n",
        "\n",
        "        precisions = [(y_true[:j+1].float().sum() / (j+1)) for j in range(len(y_true)) if y_true[j]]\n",
        "        ap = torch.stack(precisions).mean()\n",
        "        total_ap += ap\n",
        "        valid_count += 1\n",
        "\n",
        "    return total_ap / valid_count if valid_count > 0 else torch.tensor(0.0, device=scores.device)\n",
        "\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "def listnet_loss(scores, labels, lengths):\n",
        "    batch_size = scores.size(0)\n",
        "    total_loss = 0.0\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "\n",
        "        s_softmax = torch.nn.functional.log_softmax(s, dim=0)\n",
        "        y_softmax = torch.nn.functional.softmax(y, dim=0)\n",
        "\n",
        "        loss = -torch.sum(y_softmax * s_softmax)\n",
        "        total_loss += loss\n",
        "\n",
        "    return total_loss / batch_size\n",
        "\"\"\"\n",
        "\n",
        "def ranknet_loss(scores, labels, lengths):\n",
        "    batch_size = scores.size(0)\n",
        "    total_loss = 0.0\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "\n",
        "        diff_scores = s.unsqueeze(1) - s.unsqueeze(0)\n",
        "        rel = y.unsqueeze(1) > y.unsqueeze(0)\n",
        "        label_diff = rel.float()\n",
        "\n",
        "        log_sigmoid = torch.nn.functional.logsigmoid(diff_scores)\n",
        "        pair_loss = -label_diff * log_sigmoid\n",
        "\n",
        "        total_loss += pair_loss.sum()\n",
        "\n",
        "    return total_loss / batch_size\n",
        "\n",
        "def xranknet_loss(scores, labels, lengths, temperature=1.0, margin=0.2, focus_topk=3):\n",
        "    \"\"\"\n",
        "    xRankNet with emphasis on top-K items (based on labels, not scores).\n",
        "    \"\"\"\n",
        "    batch_size = scores.size(0)\n",
        "    total_loss = 0.0\n",
        "    total_pairs = 0\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        if l < 2:\n",
        "            continue\n",
        "\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "\n",
        "        # Top-K mask based on ground truth labels\n",
        "        topk = min(focus_topk, l)\n",
        "        _, topk_idx = torch.topk(y, topk)\n",
        "        topk_mask = torch.zeros_like(y, dtype=torch.bool)\n",
        "        topk_mask[topk_idx] = True\n",
        "\n",
        "        # Create pairwise difference matrices\n",
        "        score_diff = s.unsqueeze(1) - s.unsqueeze(0)\n",
        "        label_diff = y.unsqueeze(1) - y.unsqueeze(0)\n",
        "\n",
        "        # valid pair: y_i > y_j and at least one of i, j is in top-K\n",
        "        valid_pairs = (label_diff > 0) & (\n",
        "            topk_mask.unsqueeze(1) | topk_mask.unsqueeze(0)\n",
        "        )\n",
        "\n",
        "        if valid_pairs.sum() == 0:\n",
        "            continue\n",
        "\n",
        "        importance = (label_diff.abs() * valid_pairs).float()\n",
        "\n",
        "        if margin > 0.0:\n",
        "            score_diff = score_diff - margin\n",
        "\n",
        "        score_diff = score_diff / temperature\n",
        "        pairwise_loss = -F.logsigmoid(score_diff) * importance\n",
        "\n",
        "        total_loss += pairwise_loss.sum()\n",
        "        total_pairs += importance.sum()\n",
        "\n",
        "    if total_pairs == 0:\n",
        "        return torch.tensor(0.0, device=scores.device, requires_grad=True)\n",
        "\n",
        "    return total_loss / total_pairs\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "def bpr_loss(scores, labels, lengths):\n",
        "    batch_size = scores.size(0)\n",
        "    total_loss = 0.0\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "\n",
        "        pos_mask = y > 0\n",
        "        neg_mask = y <= 0\n",
        "\n",
        "        pos_scores = s[pos_mask]\n",
        "        neg_scores = s[neg_mask]\n",
        "\n",
        "        if len(pos_scores) == 0 or len(neg_scores) == 0:\n",
        "            continue\n",
        "\n",
        "        pair_diff = pos_scores.unsqueeze(1) - neg_scores.unsqueeze(0)\n",
        "        loss = -F.logsigmoid(pair_diff).mean()\n",
        "        total_loss += loss\n",
        "\n",
        "    return total_loss / batch_size\n",
        "\"\"\"\n",
        "\n",
        "\"\"\"\n",
        "def lambdarank_loss(scores, labels, lengths, eps=1e-10):\n",
        "    batch_size = scores.size(0)\n",
        "    total_loss = 0.0\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "\n",
        "        if l < 2:\n",
        "            continue\n",
        "\n",
        "        _, rank_order = torch.sort(s, descending=True)\n",
        "        ideal_order = torch.sort(y, descending=True).indices\n",
        "\n",
        "        gain = 2 ** y - 1\n",
        "        discount = torch.log2(torch.arange(2, l + 2, device=y.device).float())\n",
        "\n",
        "        ideal_dcg = (gain[ideal_order] / discount).sum()\n",
        "        if ideal_dcg < eps:\n",
        "            continue\n",
        "\n",
        "        delta_ndcg = torch.zeros((l, l), device=y.device)\n",
        "\n",
        "        for i_idx in range(l):\n",
        "            for j_idx in range(l):\n",
        "                if y[i_idx] > y[j_idx]:\n",
        "                    change = (\n",
        "                        (1.0 / torch.log2(rank_order[i_idx] + 2.0))\n",
        "                        - (1.0 / torch.log2(rank_order[j_idx] + 2.0))\n",
        "                    ).abs()\n",
        "                    delta = (2 ** y[i_idx] - 2 ** y[j_idx]).abs() * change\n",
        "                    delta_ndcg[i_idx, j_idx] = delta / ideal_dcg\n",
        "\n",
        "        score_diffs = s.unsqueeze(1) - s.unsqueeze(0)\n",
        "        lambdas = -F.logsigmoid(score_diffs) * delta_ndcg\n",
        "        total_loss += lambdas.sum()\n",
        "\n",
        "    return total_loss / batch_size\n",
        "\"\"\"\n",
        "\n",
        "def train_one_epoch(model, loader, optimizer, device, scheduler):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "\n",
        "    for x_cat, x_num, y, lengths in tqdm(loader, desc=\"Training\", leave=False):\n",
        "        x_num, y = x_num.to(device), y.to(device)\n",
        "        if not isinstance(lengths, torch.Tensor):\n",
        "            lengths = torch.tensor(lengths)\n",
        "        lengths = lengths.detach().clone().to(device)\n",
        "        x_cat = {k: v.to(device) for k, v in x_cat.items()}\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        scores = model(x_cat, x_num)\n",
        "        loss = xranknet_loss(scores, y, lengths, temperature=1.0, margin=0.2, focus_topk=3)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    return total_loss / len(loader)\n",
        "\n",
        "\n",
        "def validate(model, loader, device, min_group_size=10):\n",
        "    model.eval()\n",
        "    total_hitrate = 0\n",
        "    total_ndcg = 0\n",
        "    total_map = 0\n",
        "    total_loss = 0\n",
        "    count = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for x_cat, x_num, y, lengths in tqdm(loader, desc=\"Validating\", leave=False):\n",
        "            x_num, y = x_num.to(device), y.to(device)\n",
        "            lengths = torch.tensor(lengths).to(device)\n",
        "            x_cat = {k: v.to(device) for k, v in x_cat.items()}\n",
        "\n",
        "            scores = model(x_cat, x_num)\n",
        "\n",
        "            hitrate = hitrate_at_k(scores, y, lengths, k=3, min_group_size=min_group_size)\n",
        "            ndcg = ndcg_at_k(scores, y, lengths, k=3, min_group_size=min_group_size)\n",
        "            map3 = map_at_k(scores, y, lengths, k=3, min_group_size=min_group_size)\n",
        "            loss = xranknet_loss(scores, y, lengths, temperature=1.0, margin=0.2, focus_topk=3)\n",
        "\n",
        "            batch_size = scores.size(0)\n",
        "            total_hitrate += hitrate * batch_size\n",
        "            total_ndcg += ndcg * batch_size\n",
        "            total_map += map3 * batch_size\n",
        "            total_loss += loss.item() * batch_size\n",
        "            count += batch_size\n",
        "\n",
        "    return total_loss / count, total_hitrate / count, total_ndcg / count, total_map / count\n",
        "\n",
        "\n",
        "def build_cat_dims(X, cat_features):\n",
        "    cat_dims = {}\n",
        "    for c in cat_features:\n",
        "        max_val = X[c].max()\n",
        "        if max_val < 0:\n",
        "            max_val = 0\n",
        "        cat_dims[c] = max_val + 1\n",
        "    return cat_dims\n",
        "\n",
        "\n",
        "def normalize_numeric_features(X, numeric_features, train_mask):\n",
        "    for col in numeric_features:\n",
        "        values = X[col].to_numpy()\n",
        "        train_vals = values[train_mask]\n",
        "        mean = train_vals.mean()\n",
        "        std = train_vals.std() if train_vals.std() > 0 else 1.0\n",
        "        norm_vals = (values - mean) / std\n",
        "        X = X.with_columns(pl.Series(col, norm_vals).alias(col))\n",
        "    return X\n",
        "\n",
        "\n",
        "def load_or_prepare_data(\n",
        "    data_dir,\n",
        "    train_file=\"train.parquet\",\n",
        "    test_file=\"test.parquet\",\n",
        "    cache_file=\"feature_engineered_val.parquet\",\n",
        "):\n",
        "    cache_path = os.path.join(data_dir, cache_file)\n",
        "\n",
        "    if os.path.exists(cache_path):\n",
        "        print(f\"Loading cached feature-engineered data from {cache_path} ...\")\n",
        "        df = pl.read_parquet(cache_path)\n",
        "\n",
        "        test = pl.read_parquet(os.path.join(data_dir, test_file)).drop(\"__index_level_0__\")\n",
        "        test_ids = test[\"Id\"]\n",
        "        test_rankers = test[\"ranker_id\"]\n",
        "    else:\n",
        "        print(\"Cached file not found, processing raw data ...\")\n",
        "\n",
        "        train = pl.read_parquet(os.path.join(data_dir, train_file)).drop(\"__index_level_0__\")\n",
        "        test = (\n",
        "            pl.read_parquet(os.path.join(data_dir, test_file))\n",
        "            .drop(\"__index_level_0__\")\n",
        "            .with_columns(pl.lit(0, dtype=pl.Int64).alias(\"selected\"))\n",
        "        )\n",
        "\n",
        "        test_ids = test[\"Id\"]\n",
        "        test_rankers = test[\"ranker_id\"]\n",
        "\n",
        "        df = pl.concat((train, test))\n",
        "        df = feature_engineering(df, full=True)\n",
        "\n",
        "        df = df.with_columns(\n",
        "            [pl.col(c).fill_null(0) for c in df.select(pl.selectors.numeric()).columns] +\n",
        "            [pl.col(c).fill_null(\"missing\") for c in df.select(pl.selectors.string()).columns]\n",
        "        )\n",
        "\n",
        "        os.makedirs(data_dir, exist_ok=True)\n",
        "        df.write_parquet(cache_path)\n",
        "        print(f\"Saved feature-engineered data to {cache_path}\")\n",
        "\n",
        "    return df, test_ids, test_rankers\n",
        "\n",
        "\n",
        "def prepare_data(data_dir):\n",
        "    df, test_ids, test_rankers = load_or_prepare_data(data_dir)\n",
        "\n",
        "    id_column = df[\"Id\"]\n",
        "    X, y, groups, cat_features, num_features = feature_selection(df)\n",
        "\n",
        "    X = X.with_columns(pl.Series(\"Id\", id_column[:X.shape[0]]))\n",
        "\n",
        "    X = X.with_columns(\n",
        "        [\n",
        "            (pl.col(c).rank(\"dense\") - 1).fill_null(-1).cast(pl.Int32)\n",
        "            for c in cat_features\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    train_size = 18145372\n",
        "    train_mask = np.arange(X.height) < train_size\n",
        "    X = normalize_numeric_features(X, num_features, train_mask)\n",
        "\n",
        "    return X, y, groups, cat_features, num_features, train_size, test_ids, test_rankers\n",
        "\n",
        "\n",
        "class EarlyStopping:\n",
        "    def __init__(self, patience=3, min_delta=0.00005):\n",
        "        self.patience = patience\n",
        "        self.min_delta = min_delta\n",
        "        self.best = float(\"-inf\")\n",
        "        self.counter = 0\n",
        "\n",
        "    def step(self, metric):\n",
        "        if metric > self.best + self.min_delta:\n",
        "            self.best = metric\n",
        "            self.counter = 0\n",
        "        else:\n",
        "            self.counter += 1\n",
        "        return self.counter >= self.patience\n",
        "\n",
        "\n",
        "def plot_group_size_distribution(dataset, save_path=None):\n",
        "    group_sizes = [len(v) for v in dataset.group_to_indices.values()]\n",
        "    plt.figure()\n",
        "    plt.hist(group_sizes, bins=100, log=True)\n",
        "    plt.xlabel(\"Group size (number of items per ranker_id)\")\n",
        "    plt.ylabel(\"Frequency (log scale)\")\n",
        "    plt.title(\"Distribution of Group Sizes\")\n",
        "    plt.grid(True)\n",
        "    if save_path:\n",
        "        plt.savefig(save_path)\n",
        "    else:\n",
        "        plt.show()\n",
        "    plt.close()\n",
        "\n",
        "\n",
        "def main():\n",
        "    DATA_DIR = \"./data\"\n",
        "    MODEL_DIR = \"model\"\n",
        "    SUBMIT_DIR = \"submission\"\n",
        "\n",
        "    best_val_loss = float(\"inf\")\n",
        "    best_hitrate = 0.0\n",
        "    model_path = os.path.join(MODEL_DIR, \"best_dl_ranker.pt\")\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "    val_hitrates = []\n",
        "    val_ndcgs = []\n",
        "    val_maps = []\n",
        "    learning_rates = []\n",
        "\n",
        "    os.makedirs(MODEL_DIR, exist_ok=True)\n",
        "    os.makedirs(SUBMIT_DIR, exist_ok=True)\n",
        "\n",
        "    early_stopper = EarlyStopping(patience=3, min_delta=0.001)\n",
        "\n",
        "    X, y, groups, cat_features, num_features, train_size, test_ids, test_rankers = prepare_data(DATA_DIR)\n",
        "\n",
        "    # Fill missing values\n",
        "    float_cols = [c for c, t in zip(X.columns, X.dtypes) if t == pl.Float64]\n",
        "    for col in float_cols:\n",
        "        X = X.with_columns(\n",
        "            pl.when(pl.col(col).is_nan()).then(0).otherwise(pl.col(col)).alias(col)\n",
        "        )\n",
        "\n",
        "    n1 = 16487352\n",
        "    # n1 = 17487300\n",
        "    n2 = train_size\n",
        "\n",
        "    X_tr, X_va, X_te = X[:n1], X[n1:n2], X[n2:]\n",
        "    y_tr, y_va, y_te = y[:n1], y[n1:n2], y[n2:]\n",
        "    groups_tr, groups_va, groups_te = groups[:n1], groups[n1:n2], groups[n2:]\n",
        "\n",
        "    # Inspect group sizes in validation set\n",
        "    val_rankers = groups_va[\"ranker_id\"].to_numpy()\n",
        "    val_group_counts = Counter(val_rankers)\n",
        "\n",
        "    print(\"\\nüìã Validation group statistics:\")\n",
        "    # Save detailed group info to file\n",
        "    group_info_path = os.path.join(MODEL_DIR, \"validation_groups_info.txt\")\n",
        "    with open(group_info_path, \"w\") as f:\n",
        "        f.write(f\"Total groups: {len(val_group_counts)}\\n\\n\")\n",
        "        f.write(\"GroupID\\tSize\\tStartIdx\\tEndIdx\\n\")\n",
        "\n",
        "        group_to_rows = defaultdict(list)\n",
        "        for i, g in enumerate(val_rankers):\n",
        "            group_to_rows[g].append(i)\n",
        "\n",
        "        for group_id, indices in sorted(group_to_rows.items()):\n",
        "            start_idx = indices[0]\n",
        "            end_idx = indices[-1]\n",
        "            size = len(indices)\n",
        "            f.write(f\"{group_id}\\t{size}\\t{start_idx}\\t{end_idx}\\n\")\n",
        "\n",
        "    print(f\"üìÅ Saved validation group info to {group_info_path}\")\n",
        "\n",
        "\n",
        "    cat_dims = build_cat_dims(X, cat_features)\n",
        "    num_numeric_feats = len(num_features)\n",
        "\n",
        "    train_dataset = RankDataset(X_tr, y_tr, groups_tr, cat_features, num_features)\n",
        "    val_dataset = RankDataset(X_va, y_va, groups_va, cat_features, num_features)\n",
        "    test_dataset = RankDataset(X_te, y_te, groups_te, cat_features, num_features)\n",
        "\n",
        "    plot_group_size_distribution(train_dataset, save_path=os.path.join(MODEL_DIR, \"group_sizes.png\"))\n",
        "    print(\"üìä Group size distribution saved.\")\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True, collate_fn=collate_fn)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=4, shuffle=False, collate_fn=collate_fn)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False, collate_fn=collate_fn)\n",
        "\n",
        "    print(\"‚úÖ Data loaders created.\")\n",
        "\n",
        "    num_epochs = 10\n",
        "    num_training_steps = num_epochs * len(train_loader)\n",
        "    num_warmup_steps = int(0.1 * num_training_steps)\n",
        "\n",
        "    learning_rate = 3e-4\n",
        "\n",
        "    model = DLRankerAttention(\n",
        "        cat_dims=cat_dims,\n",
        "        num_numeric_feats=num_numeric_feats,\n",
        "        emb_dropout=0.1,\n",
        "        dropout=0.1,\n",
        "        num_heads=4,\n",
        "        num_layers=2,\n",
        "        dim_feedforward=128,\n",
        "        proj_dim=64\n",
        "    ).to(device)\n",
        "\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=0.01)\n",
        "\n",
        "    scheduler = OneCycleLR(\n",
        "        optimizer,\n",
        "        max_lr=learning_rate,\n",
        "        steps_per_epoch=len(train_loader),\n",
        "        epochs=num_epochs,\n",
        "        pct_start=0.3,\n",
        "    )\n",
        "\n",
        "    best_hitrate = 0\n",
        "    for epoch in range(num_epochs):\n",
        "        print(f\"\\n--- Epoch {epoch+1}/{num_epochs} ---\")\n",
        "        start_time = time.time()\n",
        "\n",
        "        train_loss = train_one_epoch(model, train_loader, optimizer, device, scheduler)\n",
        "        val_loss, val_hitrate, val_ndcg, val_map = validate(model, val_loader, device, min_group_size=10)\n",
        "\n",
        "        train_losses.append(train_loss)\n",
        "        val_losses.append(val_loss)\n",
        "        val_hitrates.append(val_hitrate.item())\n",
        "        val_ndcgs.append(val_ndcg.item())\n",
        "        val_maps.append(val_map.item())\n",
        "\n",
        "        current_lr = scheduler.get_last_lr()\n",
        "        learning_rates.append(current_lr[0])\n",
        "\n",
        "        elapsed = time.time() - start_time\n",
        "        print(\n",
        "            f\"Epoch {epoch+1}: \"\n",
        "            f\"Train Loss={train_loss:.4f}, \"\n",
        "            f\"Val Loss={val_loss:.4f}, \"\n",
        "            f\"HitRate@3={val_hitrate:.4f}, \"\n",
        "            f\"NDCG@3={val_ndcg:.4f}, \"\n",
        "            f\"MAP@3={val_map:.4f}, \"\n",
        "            f\"LR={current_lr[0]:.6f} \"\n",
        "            f\"({elapsed:.1f}s)\"\n",
        "        )\n",
        "\n",
        "\n",
        "        if val_loss < best_val_loss and val_hitrate > best_hitrate:\n",
        "            best_val_loss = val_loss\n",
        "            best_hitrate = val_hitrate\n",
        "            torch.save(model.state_dict(), model_path)\n",
        "            print(\"üíæ Model improved (loss ‚Üì and hitrate ‚Üë), saved.\")\n",
        "\n",
        "        if early_stopper.step(-val_loss):\n",
        "            print(\"‚õî Early stopping triggered.\")\n",
        "            break\n",
        "\n",
        "    # Plot metrics\n",
        "    epochs = list(range(1, len(train_losses) + 1))\n",
        "\n",
        "    # Plot Loss Curve\n",
        "    plt.figure()\n",
        "    plt.plot(epochs, train_losses, label=\"Train Loss\")\n",
        "    plt.plot(epochs, val_losses, label=\"Val Loss\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.title(\"Training & Validation Loss\")\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.savefig(os.path.join(MODEL_DIR, \"loss_curve.png\"))\n",
        "    plt.close()\n",
        "\n",
        "    # Plot HitRate@3\n",
        "    plt.figure()\n",
        "    plt.plot(epochs, val_hitrates, label=\"Val HitRate@3\", color=\"green\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"HitRate@3\")\n",
        "    plt.title(\"Validation HitRate@3\")\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.savefig(os.path.join(MODEL_DIR, \"hitrate_curve.png\"))\n",
        "    plt.close()\n",
        "\n",
        "    # Plot Learning Rate\n",
        "    plt.figure()\n",
        "    plt.plot(epochs, learning_rates, label=\"Learning Rate\", color=\"orange\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"LR\")\n",
        "    plt.title(\"Learning Rate Schedule\")\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.savefig(os.path.join(MODEL_DIR, \"lr_curve.png\"))\n",
        "    plt.close()\n",
        "\n",
        "    # Plot NDCG@3\n",
        "    plt.figure()\n",
        "    plt.plot(epochs, val_ndcgs, label=\"Val NDCG@3\", color=\"purple\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"NDCG@3\")\n",
        "    plt.title(\"Validation NDCG@3\")\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.savefig(os.path.join(MODEL_DIR, \"ndcg_curve.png\"))\n",
        "    plt.close()\n",
        "\n",
        "    # Plot MAP@3\n",
        "    plt.figure()\n",
        "    plt.plot(epochs, val_maps, label=\"Val MAP@3\", color=\"red\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"MAP@3\")\n",
        "    plt.title(\"Validation MAP@3\")\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.savefig(os.path.join(MODEL_DIR, \"map_curve.png\"))\n",
        "    plt.close()\n",
        "\n",
        "    print(\"üìä Saved metric plots to model/\")\n",
        "\n",
        "    # Predict test set\n",
        "    model.load_state_dict(torch.load(model_path))\n",
        "    model.eval()\n",
        "\n",
        "    val_ids = X_va[\"Id\"]\n",
        "    val_rankers = groups_va[\"ranker_id\"]\n",
        "    val_labels = y_va\n",
        "\n",
        "    all_val_scores = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for x_cat, x_num, _, lengths in tqdm(val_loader, desc=\"Predicting validation set\"):\n",
        "            x_num = x_num.to(device)\n",
        "            x_cat = {k: v.to(device) for k, v in x_cat.items()}\n",
        "            scores = model(x_cat, x_num)\n",
        "\n",
        "            for i in range(scores.size(0)):\n",
        "                l = lengths[i]\n",
        "                all_val_scores.append(scores[i, :l].cpu().numpy())\n",
        "\n",
        "    all_val_scores = np.concatenate(all_val_scores)\n",
        "\n",
        "    assert len(all_val_scores) == X_va.shape[0], \\\n",
        "        f\"Mismatch: {len(all_val_scores)} scores vs {X_va.shape[0]} rows\"\n",
        "\n",
        "    val_df = X_va.with_columns([\n",
        "        pl.Series(\"Id\", val_ids),\n",
        "        pl.Series(\"ranker_id\", val_rankers),\n",
        "        pl.Series(\"score\", all_val_scores),\n",
        "        pl.Series(\"label\", val_labels)\n",
        "    ])\n",
        "\n",
        "    val_df = val_df.with_columns(\n",
        "        pl.col(\"score\")\n",
        "        .rank(method=\"ordinal\", descending=True)\n",
        "        .over(\"ranker_id\")\n",
        "        .cast(pl.Int32)\n",
        "        .alias(\"selected\")\n",
        "    )\n",
        "\n",
        "    val_save_path = os.path.join(MODEL_DIR, \"validation_preds_dl_full.csv\")\n",
        "    val_df.write_csv(val_save_path)\n",
        "    print(f\"‚úÖ Saved full validation predictions (with features) to {val_save_path}\")\n",
        "\n",
        "    all_scores = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for x_cat, x_num, _, lengths in tqdm(test_loader, desc=\"Predicting test set\"):\n",
        "            x_num = x_num.to(device)\n",
        "            x_cat = {k: v.to(device) for k, v in x_cat.items()}\n",
        "            scores = model(x_cat, x_num)\n",
        "\n",
        "            for i in range(scores.size(0)):\n",
        "                l = lengths[i]\n",
        "                all_scores.append(scores[i, :l].cpu().numpy())\n",
        "\n",
        "    all_scores = np.concatenate(all_scores)\n",
        "\n",
        "    assert len(all_scores) == X_te.shape[0], \\\n",
        "        f\"Mismatch: {len(all_scores)} scores vs {X_te.shape[0]} rows in X_te\"\n",
        "\n",
        "    submission_df = pl.DataFrame({\n",
        "        \"Id\": test_ids,\n",
        "        \"ranker_id\": test_rankers,\n",
        "        \"score\": all_scores\n",
        "    })\n",
        "\n",
        "    submission = (\n",
        "        submission_df\n",
        "        .with_columns(\n",
        "            pl.col(\"score\")\n",
        "            .rank(method=\"ordinal\", descending=True)\n",
        "            .over(\"ranker_id\")\n",
        "            .cast(pl.Int32)\n",
        "            .alias(\"selected\")\n",
        "        )\n",
        "        .select([\"Id\", \"ranker_id\", \"score\", \"selected\"])\n",
        "    )\n",
        "\n",
        "    submission_path = os.path.join(SUBMIT_DIR, \"submission_dl_ranker.csv\")\n",
        "    submission.write_csv(submission_path)\n",
        "    print(f\"‚úÖ Submission saved to {submission_path}\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "-EUiQZRyq1Mk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "--- Epoch 1/10 ---\n",
        "Validating:   0%|          | 0/2636 [00:00<?, ?it/s]/home/ionut/test_whisper/test2/deeprec_validate.py:514: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
        "  lengths = torch.tensor(lengths).to(device)\n",
        "Epoch 1: Train Loss=0.3580, Val Loss=0.2927, HitRate@3=0.4690, NDCG@3=0.3748, MAP@3=0.6188, LR=0.000084 (603.3s)\n",
        "üíæ Model improved (loss ‚Üì and hitrate ‚Üë), saved.\n",
        "\n",
        "--- Epoch 2/10 ---\n",
        "Epoch 2: Train Loss=0.2948, Val Loss=0.2915, HitRate@3=0.4916, NDCG@3=0.3909, MAP@3=0.6313, LR=0.000228 (602.0s)\n",
        "üíæ Model improved (loss ‚Üì and hitrate ‚Üë), saved.\n",
        "\n",
        "--- Epoch 3/10 ---\n",
        "Epoch 3: Train Loss=0.2844, Val Loss=0.2868, HitRate@3=0.4795, NDCG@3=0.3840, MAP@3=0.6288, LR=0.000300 (602.7s)\n",
        "\n",
        "--- Epoch 4/10 ---\n",
        "Epoch 4: Train Loss=0.2730, Val Loss=0.2706, HitRate@3=0.5048, NDCG@3=0.4039, MAP@3=0.6460, LR=0.000285 (602.9s)\n",
        "üíæ Model improved (loss ‚Üì and hitrate ‚Üë), saved.\n",
        "\n",
        "--- Epoch 5/10 ---\n",
        "Epoch 5: Train Loss=0.2602, Val Loss=0.2665, HitRate@3=0.5052, NDCG@3=0.4054, MAP@3=0.6491, LR=0.000244 (604.2s)\n",
        "üíæ Model improved (loss ‚Üì and hitrate ‚Üë), saved.\n",
        "\n",
        "--- Epoch 6/10 ---\n",
        "Epoch 6: Train Loss=0.2494, Val Loss=0.2492, HitRate@3=0.5137, NDCG@3=0.4133, MAP@3=0.6567, LR=0.000183 (603.5s)\n",
        "üíæ Model improved (loss ‚Üì and hitrate ‚Üë), saved.\n",
        "\n",
        "--- Epoch 7/10 ---\n",
        "Epoch 7: Train Loss=0.2389, Val Loss=0.2436, HitRate@3=0.5102, NDCG@3=0.4138, MAP@3=0.6654, LR=0.000117 (603.3s)\n",
        "\n",
        "--- Epoch 8/10 ---\n",
        "Epoch 8: Train Loss=0.2268, Val Loss=0.2384, HitRate@3=0.5139, NDCG@3=0.4175, MAP@3=0.6631, LR=0.000056 (603.8s)\n",
        "üíæ Model improved (loss ‚Üì and hitrate ‚Üë), saved.\n",
        "\n",
        "--- Epoch 9/10 ---\n",
        "Epoch 9: Train Loss=0.2170, Val Loss=0.2367, HitRate@3=0.5182, NDCG@3=0.4185, MAP@3=0.6599, LR=0.000015 (605.2s)\n",
        "üíæ Model improved (loss ‚Üì and hitrate ‚Üë), saved.\n",
        "\n",
        "--- Epoch 10/10 ---\n",
        "Epoch 10: Train Loss=0.2123, Val Loss=0.2378, HitRate@3=0.5173, NDCG@3=0.4195, MAP@3=0.6624, LR=0.000000 (602.7s)"
      ],
      "metadata": {
        "id": "rN00fr80q5LH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile deeprec_validate.py\n",
        "import os\n",
        "import time\n",
        "import random\n",
        "import torch\n",
        "import math\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import defaultdict\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "import polars as pl\n",
        "from tqdm import tqdm\n",
        "from src.feature import feature_engineering, feature_selection\n",
        "from transformers import get_scheduler\n",
        "from collections import Counter\n",
        "from torch.optim.lr_scheduler import OneCycleLR\n",
        "\n",
        "seed = 42\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "class RankDataset(Dataset):\n",
        "    def __init__(\n",
        "        self,\n",
        "        X: pl.DataFrame,\n",
        "        y: pl.Series,\n",
        "        groups: pl.DataFrame,\n",
        "        cat_features: list[str],\n",
        "        num_features: list[str],\n",
        "    ):\n",
        "        self.cat_features = cat_features\n",
        "        self.num_features = num_features\n",
        "        self.X_cat = {c: X[c].to_numpy() for c in cat_features}\n",
        "        self.X_num = X[self.num_features].to_numpy()\n",
        "        self.y = y.to_numpy()\n",
        "        self.groups = groups[\"ranker_id\"].to_numpy()\n",
        "\n",
        "        self.group_to_indices = defaultdict(list)\n",
        "        for i, g in enumerate(self.groups):\n",
        "            self.group_to_indices[g].append(i)\n",
        "        self.group_keys = list(self.group_to_indices.keys())\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.group_keys)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        g = self.group_keys[idx]\n",
        "        inds = self.group_to_indices[g]\n",
        "        length = len(inds)\n",
        "\n",
        "        x_cat = {\n",
        "            c: torch.LongTensor([\n",
        "                self.X_cat[c][i] if self.X_cat[c][i] >= 0 else 0 for i in inds\n",
        "            ])\n",
        "            for c in self.cat_features\n",
        "        }\n",
        "\n",
        "        x_num = torch.FloatTensor(self.X_num[inds])\n",
        "        y = torch.FloatTensor(self.y[inds]).reshape(-1)\n",
        "\n",
        "        return x_cat, x_num, y, length\n",
        "\n",
        "def collate_fn(batch):\n",
        "    batch_size = len(batch)\n",
        "    lengths = [b[3] for b in batch]\n",
        "    max_len = max(lengths)\n",
        "\n",
        "    padded_x_cat = {key: [] for key in batch[0][0].keys()}\n",
        "    padded_x_num = []\n",
        "    padded_y = []\n",
        "\n",
        "    num_dim = batch[0][1].shape[1]\n",
        "\n",
        "    for x_cat, x_num, y, length in batch:\n",
        "        pad_len = max_len - length\n",
        "\n",
        "        for key in padded_x_cat:\n",
        "            val = x_cat[key]\n",
        "            if pad_len > 0:\n",
        "                val = torch.cat([val, torch.zeros(pad_len, dtype=torch.long)])\n",
        "            padded_x_cat[key].append(val)\n",
        "\n",
        "        if pad_len > 0:\n",
        "            x_num = torch.cat([x_num, torch.zeros(pad_len, num_dim)])\n",
        "            y = torch.cat([y, torch.zeros(pad_len)])\n",
        "\n",
        "        padded_x_num.append(x_num)\n",
        "        padded_y.append(y)\n",
        "\n",
        "    padded_x_cat = {k: torch.stack(v) for k, v in padded_x_cat.items()}\n",
        "    padded_x_num = torch.stack(padded_x_num)\n",
        "    padded_y = torch.stack(padded_y)\n",
        "    lengths = torch.tensor(lengths, dtype=torch.long)\n",
        "\n",
        "    return padded_x_cat, padded_x_num, padded_y, lengths\n",
        "\n",
        "class SEModule(nn.Module):\n",
        "    def __init__(self, channel, reduction=4):\n",
        "        super().__init__()\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(channel, channel // reduction),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(channel // reduction, channel),\n",
        "            nn.Sigmoid(),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: [B, N, C]\n",
        "        w = self.fc(x.mean(dim=1))\n",
        "        w = w.unsqueeze(1)  # [B, 1, C]\n",
        "        return x * w\n",
        "\n",
        "\n",
        "class FiLM(nn.Module):\n",
        "    def __init__(self, feature_dim):\n",
        "        super().__init__()\n",
        "        self.gamma = nn.Linear(feature_dim, feature_dim)\n",
        "        self.beta = nn.Linear(feature_dim, feature_dim)\n",
        "\n",
        "    def forward(self, x, cond):\n",
        "        gamma = self.gamma(cond)\n",
        "        beta = self.beta(cond)\n",
        "        return gamma * x + beta\n",
        "\n",
        "\n",
        "class DLRankerAttention(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        cat_dims,\n",
        "        num_numeric_feats,\n",
        "        emb_dropout=0.1,\n",
        "        dropout=0.1,\n",
        "        num_heads=4,\n",
        "        num_layers=2,\n",
        "        dim_feedforward=128,\n",
        "        proj_dim=64,\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "        self.emb_dims = {\n",
        "            f: min(50, max(4, round(6 * math.log2(cat_dims[f] + 1)))) for f in cat_dims\n",
        "        }\n",
        "        self.embeddings = nn.ModuleDict({\n",
        "            f: nn.Embedding(cat_dims[f], self.emb_dims[f], padding_idx=0)\n",
        "            for f in cat_dims\n",
        "        })\n",
        "        self.emb_dropout = nn.Dropout(emb_dropout)\n",
        "\n",
        "        total_emb_dim = sum(self.emb_dims.values())\n",
        "        print(f\"Categorial emb dim sum: {total_emb_dim}, Numerical dim: {num_numeric_feats}\")\n",
        "\n",
        "        self.cat_proj = nn.Linear(total_emb_dim, proj_dim)\n",
        "        self.cat_transformer = nn.TransformerEncoder(\n",
        "            nn.TransformerEncoderLayer(\n",
        "                d_model=proj_dim,\n",
        "                nhead=4,\n",
        "                dim_feedforward=dim_feedforward,\n",
        "                dropout=dropout,\n",
        "                batch_first=True,\n",
        "            ),\n",
        "            num_layers=1,\n",
        "        )\n",
        "\n",
        "        self.num_proj_in = nn.Linear(num_numeric_feats, proj_dim)\n",
        "        self.num_transformer = nn.TransformerEncoder(\n",
        "            nn.TransformerEncoderLayer(\n",
        "                d_model=proj_dim,\n",
        "                nhead=4,\n",
        "                dim_feedforward=dim_feedforward,\n",
        "                dropout=dropout,\n",
        "                batch_first=True,\n",
        "            ),\n",
        "            num_layers=1,\n",
        "        )\n",
        "        self.num_se = SEModule(proj_dim)\n",
        "        self.num_proj_out = nn.Sequential(\n",
        "            nn.Linear(proj_dim, proj_dim),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(dropout),\n",
        "        )\n",
        "\n",
        "        # üîÅ Cross-attention: cat attends to num\n",
        "        self.cross_attn_cat2num = nn.MultiheadAttention(\n",
        "            embed_dim=proj_dim,\n",
        "            num_heads=4,\n",
        "            dropout=dropout,\n",
        "            batch_first=True,\n",
        "        )\n",
        "\n",
        "        self.film = FiLM(proj_dim)  # üîß FiLM added here\n",
        "\n",
        "        self.transformer_layers = nn.ModuleList([\n",
        "            nn.TransformerEncoderLayer(\n",
        "                d_model=2 * proj_dim,\n",
        "                nhead=num_heads,\n",
        "                dim_feedforward=dim_feedforward,\n",
        "                dropout=dropout,\n",
        "                batch_first=True,\n",
        "            )\n",
        "            for _ in range(num_layers)\n",
        "        ])\n",
        "\n",
        "        self.mlp = nn.Sequential(\n",
        "            nn.Linear(2 * proj_dim, 128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(128, 64),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(64, 1),\n",
        "        )\n",
        "\n",
        "    def forward(self, x_cat: dict, x_num: torch.Tensor, attn_mask=None):\n",
        "        B, N, _ = x_num.shape  # x_num: [B, N, F_num]\n",
        "\n",
        "        # Categorical embeddings\n",
        "        cat_embs = torch.cat([self.embeddings[f](x_cat[f]) for f in x_cat], dim=-1)\n",
        "        cat_embs = self.emb_dropout(cat_embs)\n",
        "        cat_feat = self.cat_proj(cat_embs)  # [B, N, D]\n",
        "        cat_feat = self.cat_transformer(cat_feat)  # [B, N, D]\n",
        "\n",
        "        # Numeric features\n",
        "        num_feat = self.num_proj_in(x_num)\n",
        "        num_feat = self.num_transformer(num_feat)\n",
        "        num_feat = self.num_se(num_feat)\n",
        "        num_feat = self.num_proj_out(num_feat)\n",
        "\n",
        "        # üîß FiLM: condition cat_feat on num_feat\n",
        "        cat_feat = self.film(cat_feat, num_feat)\n",
        "\n",
        "        # Cross-attention: categorical features attend over numeric ones\n",
        "        cat_feat_attn, _ = self.cross_attn_cat2num(\n",
        "            query=cat_feat, key=num_feat, value=num_feat\n",
        "        )\n",
        "        cat_feat = cat_feat + cat_feat_attn  # residual connection\n",
        "\n",
        "        # Final concatenation\n",
        "        x = torch.cat([cat_feat, num_feat], dim=-1)\n",
        "\n",
        "        for layer in self.transformer_layers:\n",
        "            x = layer(x, src_key_padding_mask=attn_mask)\n",
        "\n",
        "        scores = self.mlp(x).squeeze(-1)  # [B, N]\n",
        "        return scores\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "def listmle_loss(scores, labels, lengths):\n",
        "    batch_size = scores.size(0)\n",
        "    total_loss = torch.tensor(0.0, device=scores.device, requires_grad=True)\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "\n",
        "        _, idx = torch.sort(y, descending=True)\n",
        "        s_sorted = s[idx]\n",
        "\n",
        "        parts = (\n",
        "            torch.logsumexp(s_sorted.unsqueeze(0).expand(l, -1).triu(diagonal=0), dim=1)\n",
        "            - s_sorted\n",
        "        )\n",
        "\n",
        "        total_loss = total_loss + parts.sum()\n",
        "\n",
        "    return total_loss / batch_size\n",
        "\"\"\"\n",
        "\n",
        "def hitrate_at_k(scores, labels, lengths, k=3, min_group_size=10):\n",
        "    batch_size = scores.size(0)\n",
        "    hits = 0\n",
        "    valid_count = 0\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        if l < min_group_size:\n",
        "            continue\n",
        "        length = min(l, k)\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "        _, topk_idx = torch.topk(s, length)\n",
        "        topk_labels = y[topk_idx]\n",
        "        hits += (topk_labels > 0).any().float()\n",
        "        valid_count += 1\n",
        "    return hits / valid_count if valid_count > 0 else torch.tensor(0.0, device=scores.device)\n",
        "\n",
        "\n",
        "def ndcg_at_k(scores, labels, lengths, k=3, min_group_size=10):\n",
        "    batch_size = scores.size(0)\n",
        "    total_ndcg = 0.0\n",
        "    valid_count = 0\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        if l < min_group_size:\n",
        "            continue\n",
        "\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "\n",
        "        _, idx_pred = torch.topk(s, min(k, l))\n",
        "        _, idx_ideal = torch.topk(y, min(k, l))\n",
        "\n",
        "        dcg = (y[idx_pred] / torch.log2(torch.arange(2, 2 + len(idx_pred), device=y.device).float())).sum()\n",
        "        idcg = (y[idx_ideal] / torch.log2(torch.arange(2, 2 + len(idx_ideal), device=y.device).float())).sum()\n",
        "\n",
        "        ndcg = dcg / idcg if idcg > 0 else 0.0\n",
        "        total_ndcg += ndcg\n",
        "        valid_count += 1\n",
        "\n",
        "    return total_ndcg / valid_count if valid_count > 0 else torch.tensor(0.0, device=scores.device)\n",
        "\n",
        "\n",
        "def map_at_k(scores, labels, lengths, k=3, min_group_size=10):\n",
        "    batch_size = scores.size(0)\n",
        "    total_ap = 0.0\n",
        "    valid_count = 0\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        if l < min_group_size:\n",
        "            continue\n",
        "\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "\n",
        "        _, idx_pred = torch.topk(s, min(k, l))\n",
        "        y_true = y[idx_pred] > 0\n",
        "\n",
        "        if y_true.sum() == 0:\n",
        "            continue\n",
        "\n",
        "        precisions = [(y_true[:j+1].float().sum() / (j+1)) for j in range(len(y_true)) if y_true[j]]\n",
        "        ap = torch.stack(precisions).mean()\n",
        "        total_ap += ap\n",
        "        valid_count += 1\n",
        "\n",
        "    return total_ap / valid_count if valid_count > 0 else torch.tensor(0.0, device=scores.device)\n",
        "\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "def listnet_loss(scores, labels, lengths):\n",
        "    batch_size = scores.size(0)\n",
        "    total_loss = 0.0\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "\n",
        "        s_softmax = torch.nn.functional.log_softmax(s, dim=0)\n",
        "        y_softmax = torch.nn.functional.softmax(y, dim=0)\n",
        "\n",
        "        loss = -torch.sum(y_softmax * s_softmax)\n",
        "        total_loss += loss\n",
        "\n",
        "    return total_loss / batch_size\n",
        "\"\"\"\n",
        "\n",
        "def ranknet_loss(scores, labels, lengths):\n",
        "    batch_size = scores.size(0)\n",
        "    total_loss = 0.0\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "\n",
        "        diff_scores = s.unsqueeze(1) - s.unsqueeze(0)\n",
        "        rel = y.unsqueeze(1) > y.unsqueeze(0)\n",
        "        label_diff = rel.float()\n",
        "\n",
        "        log_sigmoid = torch.nn.functional.logsigmoid(diff_scores)\n",
        "        pair_loss = -label_diff * log_sigmoid\n",
        "\n",
        "        total_loss += pair_loss.sum()\n",
        "\n",
        "    return total_loss / batch_size\n",
        "\n",
        "def xranknet_loss(scores, labels, lengths, temperature=1.0, margin=0.2, focus_topk=3):\n",
        "    \"\"\"\n",
        "    xRankNet with emphasis on top-K items (based on labels, not scores).\n",
        "    \"\"\"\n",
        "    batch_size = scores.size(0)\n",
        "    total_loss = 0.0\n",
        "    total_pairs = 0\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        if l < 2:\n",
        "            continue\n",
        "\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "\n",
        "        # Top-K mask based on ground truth labels\n",
        "        topk = min(focus_topk, l)\n",
        "        _, topk_idx = torch.topk(y, topk)\n",
        "        topk_mask = torch.zeros_like(y, dtype=torch.bool)\n",
        "        topk_mask[topk_idx] = True\n",
        "\n",
        "        # Create pairwise difference matrices\n",
        "        score_diff = s.unsqueeze(1) - s.unsqueeze(0)\n",
        "        label_diff = y.unsqueeze(1) - y.unsqueeze(0)\n",
        "\n",
        "        # valid pair: y_i > y_j and at least one of i, j is in top-K\n",
        "        valid_pairs = (label_diff > 0) & (\n",
        "            topk_mask.unsqueeze(1) | topk_mask.unsqueeze(0)\n",
        "        )\n",
        "\n",
        "        if valid_pairs.sum() == 0:\n",
        "            continue\n",
        "\n",
        "        importance = (label_diff.abs() * valid_pairs).float()\n",
        "\n",
        "        if margin > 0.0:\n",
        "            score_diff = score_diff - margin\n",
        "\n",
        "        score_diff = score_diff / temperature\n",
        "        pairwise_loss = -F.logsigmoid(score_diff) * importance\n",
        "\n",
        "        total_loss += pairwise_loss.sum()\n",
        "        total_pairs += importance.sum()\n",
        "\n",
        "    if total_pairs == 0:\n",
        "        return torch.tensor(0.0, device=scores.device, requires_grad=True)\n",
        "\n",
        "    return total_loss / total_pairs\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "def bpr_loss(scores, labels, lengths):\n",
        "    batch_size = scores.size(0)\n",
        "    total_loss = 0.0\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "\n",
        "        pos_mask = y > 0\n",
        "        neg_mask = y <= 0\n",
        "\n",
        "        pos_scores = s[pos_mask]\n",
        "        neg_scores = s[neg_mask]\n",
        "\n",
        "        if len(pos_scores) == 0 or len(neg_scores) == 0:\n",
        "            continue\n",
        "\n",
        "        pair_diff = pos_scores.unsqueeze(1) - neg_scores.unsqueeze(0)\n",
        "        loss = -F.logsigmoid(pair_diff).mean()\n",
        "        total_loss += loss\n",
        "\n",
        "    return total_loss / batch_size\n",
        "\"\"\"\n",
        "\n",
        "\"\"\"\n",
        "def lambdarank_loss(scores, labels, lengths, eps=1e-10):\n",
        "    batch_size = scores.size(0)\n",
        "    total_loss = 0.0\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "\n",
        "        if l < 2:\n",
        "            continue\n",
        "\n",
        "        _, rank_order = torch.sort(s, descending=True)\n",
        "        ideal_order = torch.sort(y, descending=True).indices\n",
        "\n",
        "        gain = 2 ** y - 1\n",
        "        discount = torch.log2(torch.arange(2, l + 2, device=y.device).float())\n",
        "\n",
        "        ideal_dcg = (gain[ideal_order] / discount).sum()\n",
        "        if ideal_dcg < eps:\n",
        "            continue\n",
        "\n",
        "        delta_ndcg = torch.zeros((l, l), device=y.device)\n",
        "\n",
        "        for i_idx in range(l):\n",
        "            for j_idx in range(l):\n",
        "                if y[i_idx] > y[j_idx]:\n",
        "                    change = (\n",
        "                        (1.0 / torch.log2(rank_order[i_idx] + 2.0))\n",
        "                        - (1.0 / torch.log2(rank_order[j_idx] + 2.0))\n",
        "                    ).abs()\n",
        "                    delta = (2 ** y[i_idx] - 2 ** y[j_idx]).abs() * change\n",
        "                    delta_ndcg[i_idx, j_idx] = delta / ideal_dcg\n",
        "\n",
        "        score_diffs = s.unsqueeze(1) - s.unsqueeze(0)\n",
        "        lambdas = -F.logsigmoid(score_diffs) * delta_ndcg\n",
        "        total_loss += lambdas.sum()\n",
        "\n",
        "    return total_loss / batch_size\n",
        "\"\"\"\n",
        "\n",
        "def train_one_epoch(model, loader, optimizer, device, scheduler):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "\n",
        "    for x_cat, x_num, y, lengths in tqdm(loader, desc=\"Training\", leave=False):\n",
        "        x_num, y = x_num.to(device), y.to(device)\n",
        "        if not isinstance(lengths, torch.Tensor):\n",
        "            lengths = torch.tensor(lengths)\n",
        "        lengths = lengths.detach().clone().to(device)\n",
        "        x_cat = {k: v.to(device) for k, v in x_cat.items()}\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        scores = model(x_cat, x_num)\n",
        "        loss = xranknet_loss(scores, y, lengths, temperature=1.0, margin=0.2, focus_topk=3)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    return total_loss / len(loader)\n",
        "\n",
        "\n",
        "def validate(model, loader, device, min_group_size=10):\n",
        "    model.eval()\n",
        "    total_hitrate = 0\n",
        "    total_ndcg = 0\n",
        "    total_map = 0\n",
        "    total_loss = 0\n",
        "    count = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for x_cat, x_num, y, lengths in tqdm(loader, desc=\"Validating\", leave=False):\n",
        "            x_num, y = x_num.to(device), y.to(device)\n",
        "            lengths = torch.tensor(lengths).to(device)\n",
        "            x_cat = {k: v.to(device) for k, v in x_cat.items()}\n",
        "\n",
        "            scores = model(x_cat, x_num)\n",
        "\n",
        "            hitrate = hitrate_at_k(scores, y, lengths, k=3, min_group_size=min_group_size)\n",
        "            ndcg = ndcg_at_k(scores, y, lengths, k=3, min_group_size=min_group_size)\n",
        "            map3 = map_at_k(scores, y, lengths, k=3, min_group_size=min_group_size)\n",
        "            loss = xranknet_loss(scores, y, lengths, temperature=1.0, margin=0.2, focus_topk=3)\n",
        "\n",
        "            batch_size = scores.size(0)\n",
        "            total_hitrate += hitrate * batch_size\n",
        "            total_ndcg += ndcg * batch_size\n",
        "            total_map += map3 * batch_size\n",
        "            total_loss += loss.item() * batch_size\n",
        "            count += batch_size\n",
        "\n",
        "    return total_loss / count, total_hitrate / count, total_ndcg / count, total_map / count\n",
        "\n",
        "\n",
        "def build_cat_dims(X, cat_features):\n",
        "    cat_dims = {}\n",
        "    for c in cat_features:\n",
        "        max_val = X[c].max()\n",
        "        if max_val < 0:\n",
        "            max_val = 0\n",
        "        cat_dims[c] = max_val + 1\n",
        "    return cat_dims\n",
        "\n",
        "\n",
        "def normalize_numeric_features(X, numeric_features, train_mask):\n",
        "    for col in numeric_features:\n",
        "        values = X[col].to_numpy()\n",
        "        train_vals = values[train_mask]\n",
        "        mean = train_vals.mean()\n",
        "        std = train_vals.std() if train_vals.std() > 0 else 1.0\n",
        "        norm_vals = (values - mean) / std\n",
        "        X = X.with_columns(pl.Series(col, norm_vals).alias(col))\n",
        "    return X\n",
        "\n",
        "\n",
        "def load_or_prepare_data(\n",
        "    data_dir,\n",
        "    train_file=\"train.parquet\",\n",
        "    test_file=\"test.parquet\",\n",
        "    cache_file=\"feature_engineered_val.parquet\",\n",
        "):\n",
        "    cache_path = os.path.join(data_dir, cache_file)\n",
        "\n",
        "    if os.path.exists(cache_path):\n",
        "        print(f\"Loading cached feature-engineered data from {cache_path} ...\")\n",
        "        df = pl.read_parquet(cache_path)\n",
        "\n",
        "        test = pl.read_parquet(os.path.join(data_dir, test_file)).drop(\"__index_level_0__\")\n",
        "        test_ids = test[\"Id\"]\n",
        "        test_rankers = test[\"ranker_id\"]\n",
        "    else:\n",
        "        print(\"Cached file not found, processing raw data ...\")\n",
        "\n",
        "        train = pl.read_parquet(os.path.join(data_dir, train_file)).drop(\"__index_level_0__\")\n",
        "        test = (\n",
        "            pl.read_parquet(os.path.join(data_dir, test_file))\n",
        "            .drop(\"__index_level_0__\")\n",
        "            .with_columns(pl.lit(0, dtype=pl.Int64).alias(\"selected\"))\n",
        "        )\n",
        "\n",
        "        test_ids = test[\"Id\"]\n",
        "        test_rankers = test[\"ranker_id\"]\n",
        "\n",
        "        df = pl.concat((train, test))\n",
        "        df = feature_engineering(df, full=True)\n",
        "\n",
        "        df = df.with_columns(\n",
        "            [pl.col(c).fill_null(0) for c in df.select(pl.selectors.numeric()).columns] +\n",
        "            [pl.col(c).fill_null(\"missing\") for c in df.select(pl.selectors.string()).columns]\n",
        "        )\n",
        "\n",
        "        os.makedirs(data_dir, exist_ok=True)\n",
        "        df.write_parquet(cache_path)\n",
        "        print(f\"Saved feature-engineered data to {cache_path}\")\n",
        "\n",
        "    return df, test_ids, test_rankers\n",
        "\n",
        "\n",
        "def prepare_data(data_dir):\n",
        "    df, test_ids, test_rankers = load_or_prepare_data(data_dir)\n",
        "\n",
        "    id_column = df[\"Id\"]\n",
        "    X, y, groups, cat_features, num_features = feature_selection(df)\n",
        "\n",
        "    X = X.with_columns(pl.Series(\"Id\", id_column[:X.shape[0]]))\n",
        "\n",
        "    X = X.with_columns(\n",
        "        [\n",
        "            (pl.col(c).rank(\"dense\") - 1).fill_null(-1).cast(pl.Int32)\n",
        "            for c in cat_features\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    train_size = 18145372\n",
        "    train_mask = np.arange(X.height) < train_size\n",
        "    X = normalize_numeric_features(X, num_features, train_mask)\n",
        "\n",
        "    return X, y, groups, cat_features, num_features, train_size, test_ids, test_rankers\n",
        "\n",
        "\n",
        "class EarlyStopping:\n",
        "    def __init__(self, patience=3, min_delta=0.00005):\n",
        "        self.patience = patience\n",
        "        self.min_delta = min_delta\n",
        "        self.best = float(\"-inf\")\n",
        "        self.counter = 0\n",
        "\n",
        "    def step(self, metric):\n",
        "        if metric > self.best + self.min_delta:\n",
        "            self.best = metric\n",
        "            self.counter = 0\n",
        "        else:\n",
        "            self.counter += 1\n",
        "        return self.counter >= self.patience\n",
        "\n",
        "\n",
        "def plot_group_size_distribution(dataset, save_path=None):\n",
        "    group_sizes = [len(v) for v in dataset.group_to_indices.values()]\n",
        "    plt.figure()\n",
        "    plt.hist(group_sizes, bins=100, log=True)\n",
        "    plt.xlabel(\"Group size (number of items per ranker_id)\")\n",
        "    plt.ylabel(\"Frequency (log scale)\")\n",
        "    plt.title(\"Distribution of Group Sizes\")\n",
        "    plt.grid(True)\n",
        "    if save_path:\n",
        "        plt.savefig(save_path)\n",
        "    else:\n",
        "        plt.show()\n",
        "    plt.close()\n",
        "\n",
        "\n",
        "def main():\n",
        "    DATA_DIR = \"./data\"\n",
        "    MODEL_DIR = \"model\"\n",
        "    SUBMIT_DIR = \"submission\"\n",
        "\n",
        "    best_val_loss = float(\"inf\")\n",
        "    best_hitrate = 0.0\n",
        "    model_path = os.path.join(MODEL_DIR, \"best_dl_ranker.pt\")\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "    val_hitrates = []\n",
        "    val_ndcgs = []\n",
        "    val_maps = []\n",
        "    learning_rates = []\n",
        "\n",
        "    os.makedirs(MODEL_DIR, exist_ok=True)\n",
        "    os.makedirs(SUBMIT_DIR, exist_ok=True)\n",
        "\n",
        "    early_stopper = EarlyStopping(patience=3, min_delta=0.001)\n",
        "\n",
        "    X, y, groups, cat_features, num_features, train_size, test_ids, test_rankers = prepare_data(DATA_DIR)\n",
        "\n",
        "    # Fill missing values\n",
        "    float_cols = [c for c, t in zip(X.columns, X.dtypes) if t == pl.Float64]\n",
        "    for col in float_cols:\n",
        "        X = X.with_columns(\n",
        "            pl.when(pl.col(col).is_nan()).then(0).otherwise(pl.col(col)).alias(col)\n",
        "        )\n",
        "\n",
        "    n1 = 16487352\n",
        "    # n1 = 17487300\n",
        "    n2 = train_size\n",
        "\n",
        "    X_tr, X_va, X_te = X[:n1], X[n1:n2], X[n2:]\n",
        "    y_tr, y_va, y_te = y[:n1], y[n1:n2], y[n2:]\n",
        "    groups_tr, groups_va, groups_te = groups[:n1], groups[n1:n2], groups[n2:]\n",
        "\n",
        "    # Inspect group sizes in validation set\n",
        "    val_rankers = groups_va[\"ranker_id\"].to_numpy()\n",
        "    val_group_counts = Counter(val_rankers)\n",
        "\n",
        "    print(\"\\nüìã Validation group statistics:\")\n",
        "    # Save detailed group info to file\n",
        "    group_info_path = os.path.join(MODEL_DIR, \"validation_groups_info.txt\")\n",
        "    with open(group_info_path, \"w\") as f:\n",
        "        f.write(f\"Total groups: {len(val_group_counts)}\\n\\n\")\n",
        "        f.write(\"GroupID\\tSize\\tStartIdx\\tEndIdx\\n\")\n",
        "\n",
        "        group_to_rows = defaultdict(list)\n",
        "        for i, g in enumerate(val_rankers):\n",
        "            group_to_rows[g].append(i)\n",
        "\n",
        "        for group_id, indices in sorted(group_to_rows.items()):\n",
        "            start_idx = indices[0]\n",
        "            end_idx = indices[-1]\n",
        "            size = len(indices)\n",
        "            f.write(f\"{group_id}\\t{size}\\t{start_idx}\\t{end_idx}\\n\")\n",
        "\n",
        "    print(f\"üìÅ Saved validation group info to {group_info_path}\")\n",
        "\n",
        "\n",
        "    cat_dims = build_cat_dims(X, cat_features)\n",
        "    num_numeric_feats = len(num_features)\n",
        "\n",
        "    train_dataset = RankDataset(X_tr, y_tr, groups_tr, cat_features, num_features)\n",
        "    val_dataset = RankDataset(X_va, y_va, groups_va, cat_features, num_features)\n",
        "    test_dataset = RankDataset(X_te, y_te, groups_te, cat_features, num_features)\n",
        "\n",
        "    plot_group_size_distribution(train_dataset, save_path=os.path.join(MODEL_DIR, \"group_sizes.png\"))\n",
        "    print(\"üìä Group size distribution saved.\")\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True, collate_fn=collate_fn)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=4, shuffle=False, collate_fn=collate_fn)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False, collate_fn=collate_fn)\n",
        "\n",
        "    print(\"‚úÖ Data loaders created.\")\n",
        "\n",
        "    num_epochs = 10\n",
        "    num_training_steps = num_epochs * len(train_loader)\n",
        "    num_warmup_steps = int(0.1 * num_training_steps)\n",
        "\n",
        "    learning_rate = 3e-4\n",
        "\n",
        "    model = DLRankerAttention(\n",
        "        cat_dims=cat_dims,\n",
        "        num_numeric_feats=num_numeric_feats,\n",
        "        emb_dropout=0.1,\n",
        "        dropout=0.1,\n",
        "        num_heads=4,\n",
        "        num_layers=2,\n",
        "        dim_feedforward=128,\n",
        "        proj_dim=64\n",
        "    ).to(device)\n",
        "\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=0.01)\n",
        "\n",
        "    scheduler = OneCycleLR(\n",
        "        optimizer,\n",
        "        max_lr=learning_rate,\n",
        "        steps_per_epoch=len(train_loader),\n",
        "        epochs=num_epochs,\n",
        "        pct_start=0.3,\n",
        "    )\n",
        "\n",
        "    best_hitrate = 0\n",
        "    for epoch in range(num_epochs):\n",
        "        print(f\"\\n--- Epoch {epoch+1}/{num_epochs} ---\")\n",
        "        start_time = time.time()\n",
        "\n",
        "        train_loss = train_one_epoch(model, train_loader, optimizer, device, scheduler)\n",
        "        val_loss, val_hitrate, val_ndcg, val_map = validate(model, val_loader, device, min_group_size=10)\n",
        "\n",
        "        train_losses.append(train_loss)\n",
        "        val_losses.append(val_loss)\n",
        "        val_hitrates.append(val_hitrate.item())\n",
        "        val_ndcgs.append(val_ndcg.item())\n",
        "        val_maps.append(val_map.item())\n",
        "\n",
        "        current_lr = scheduler.get_last_lr()\n",
        "        learning_rates.append(current_lr[0])\n",
        "\n",
        "        elapsed = time.time() - start_time\n",
        "        print(\n",
        "            f\"Epoch {epoch+1}: \"\n",
        "            f\"Train Loss={train_loss:.4f}, \"\n",
        "            f\"Val Loss={val_loss:.4f}, \"\n",
        "            f\"HitRate@3={val_hitrate:.4f}, \"\n",
        "            f\"NDCG@3={val_ndcg:.4f}, \"\n",
        "            f\"MAP@3={val_map:.4f}, \"\n",
        "            f\"LR={current_lr[0]:.6f} \"\n",
        "            f\"({elapsed:.1f}s)\"\n",
        "        )\n",
        "\n",
        "\n",
        "        if val_loss < best_val_loss and val_hitrate > best_hitrate:\n",
        "            best_val_loss = val_loss\n",
        "            best_hitrate = val_hitrate\n",
        "            torch.save(model.state_dict(), model_path)\n",
        "            print(\"üíæ Model improved (loss ‚Üì and hitrate ‚Üë), saved.\")\n",
        "\n",
        "        if early_stopper.step(-val_loss):\n",
        "            print(\"‚õî Early stopping triggered.\")\n",
        "            break\n",
        "\n",
        "    # Plot metrics\n",
        "    epochs = list(range(1, len(train_losses) + 1))\n",
        "\n",
        "    # Plot Loss Curve\n",
        "    plt.figure()\n",
        "    plt.plot(epochs, train_losses, label=\"Train Loss\")\n",
        "    plt.plot(epochs, val_losses, label=\"Val Loss\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.title(\"Training & Validation Loss\")\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.savefig(os.path.join(MODEL_DIR, \"loss_curve.png\"))\n",
        "    plt.close()\n",
        "\n",
        "    # Plot HitRate@3\n",
        "    plt.figure()\n",
        "    plt.plot(epochs, val_hitrates, label=\"Val HitRate@3\", color=\"green\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"HitRate@3\")\n",
        "    plt.title(\"Validation HitRate@3\")\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.savefig(os.path.join(MODEL_DIR, \"hitrate_curve.png\"))\n",
        "    plt.close()\n",
        "\n",
        "    # Plot Learning Rate\n",
        "    plt.figure()\n",
        "    plt.plot(epochs, learning_rates, label=\"Learning Rate\", color=\"orange\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"LR\")\n",
        "    plt.title(\"Learning Rate Schedule\")\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.savefig(os.path.join(MODEL_DIR, \"lr_curve.png\"))\n",
        "    plt.close()\n",
        "\n",
        "    # Plot NDCG@3\n",
        "    plt.figure()\n",
        "    plt.plot(epochs, val_ndcgs, label=\"Val NDCG@3\", color=\"purple\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"NDCG@3\")\n",
        "    plt.title(\"Validation NDCG@3\")\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.savefig(os.path.join(MODEL_DIR, \"ndcg_curve.png\"))\n",
        "    plt.close()\n",
        "\n",
        "    # Plot MAP@3\n",
        "    plt.figure()\n",
        "    plt.plot(epochs, val_maps, label=\"Val MAP@3\", color=\"red\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"MAP@3\")\n",
        "    plt.title(\"Validation MAP@3\")\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.savefig(os.path.join(MODEL_DIR, \"map_curve.png\"))\n",
        "    plt.close()\n",
        "\n",
        "    print(\"üìä Saved metric plots to model/\")\n",
        "\n",
        "    # Predict test set\n",
        "    model.load_state_dict(torch.load(model_path))\n",
        "    model.eval()\n",
        "\n",
        "    val_ids = X_va[\"Id\"]\n",
        "    val_rankers = groups_va[\"ranker_id\"]\n",
        "    val_labels = y_va\n",
        "\n",
        "    all_val_scores = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for x_cat, x_num, _, lengths in tqdm(val_loader, desc=\"Predicting validation set\"):\n",
        "            x_num = x_num.to(device)\n",
        "            x_cat = {k: v.to(device) for k, v in x_cat.items()}\n",
        "            scores = model(x_cat, x_num)\n",
        "\n",
        "            for i in range(scores.size(0)):\n",
        "                l = lengths[i]\n",
        "                all_val_scores.append(scores[i, :l].cpu().numpy())\n",
        "\n",
        "    all_val_scores = np.concatenate(all_val_scores)\n",
        "\n",
        "    assert len(all_val_scores) == X_va.shape[0], \\\n",
        "        f\"Mismatch: {len(all_val_scores)} scores vs {X_va.shape[0]} rows\"\n",
        "\n",
        "    val_df = X_va.with_columns([\n",
        "        pl.Series(\"Id\", val_ids),\n",
        "        pl.Series(\"ranker_id\", val_rankers),\n",
        "        pl.Series(\"score\", all_val_scores),\n",
        "        pl.Series(\"label\", val_labels)\n",
        "    ])\n",
        "\n",
        "    val_df = val_df.with_columns(\n",
        "        pl.col(\"score\")\n",
        "        .rank(method=\"ordinal\", descending=True)\n",
        "        .over(\"ranker_id\")\n",
        "        .cast(pl.Int32)\n",
        "        .alias(\"selected\")\n",
        "    )\n",
        "\n",
        "    val_save_path = os.path.join(MODEL_DIR, \"validation_preds_dl_full.csv\")\n",
        "    val_df.write_csv(val_save_path)\n",
        "    print(f\"‚úÖ Saved full validation predictions (with features) to {val_save_path}\")\n",
        "\n",
        "    all_scores = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for x_cat, x_num, _, lengths in tqdm(test_loader, desc=\"Predicting test set\"):\n",
        "            x_num = x_num.to(device)\n",
        "            x_cat = {k: v.to(device) for k, v in x_cat.items()}\n",
        "            scores = model(x_cat, x_num)\n",
        "\n",
        "            for i in range(scores.size(0)):\n",
        "                l = lengths[i]\n",
        "                all_scores.append(scores[i, :l].cpu().numpy())\n",
        "\n",
        "    all_scores = np.concatenate(all_scores)\n",
        "\n",
        "    assert len(all_scores) == X_te.shape[0], \\\n",
        "        f\"Mismatch: {len(all_scores)} scores vs {X_te.shape[0]} rows in X_te\"\n",
        "\n",
        "    submission_df = pl.DataFrame({\n",
        "        \"Id\": test_ids,\n",
        "        \"ranker_id\": test_rankers,\n",
        "        \"score\": all_scores\n",
        "    })\n",
        "\n",
        "    submission = (\n",
        "        submission_df\n",
        "        .with_columns(\n",
        "            pl.col(\"score\")\n",
        "            .rank(method=\"ordinal\", descending=True)\n",
        "            .over(\"ranker_id\")\n",
        "            .cast(pl.Int32)\n",
        "            .alias(\"selected\")\n",
        "        )\n",
        "        .select([\"Id\", \"ranker_id\", \"score\", \"selected\"])\n",
        "    )\n",
        "\n",
        "    submission_path = os.path.join(SUBMIT_DIR, \"submission_dl_ranker.csv\")\n",
        "    submission.write_csv(submission_path)\n",
        "    print(f\"‚úÖ Submission saved to {submission_path}\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0hD7ovObq6RO",
        "outputId": "b1100bca-7ba2-4618-ff50-412c7ae1a178"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing deeprec_validate.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "--- Epoch 1/10 ---\n",
        "Validating:   0%|          | 0/2636 [00:00<?, ?it/s]/home/ionut/test_whisper/test2/deeprec_validate.py:539: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
        "  lengths = torch.tensor(lengths).to(device)\n",
        "Epoch 1: Train Loss=0.3532, Val Loss=0.2842, HitRate@3=0.4737, NDCG@3=0.3744, MAP@3=0.6171, LR=0.000084 (606.6s)\n",
        "üíæ Model improved (loss ‚Üì and hitrate ‚Üë), saved.\n",
        "\n",
        "--- Epoch 2/10 ---\n",
        "Epoch 2: Train Loss=0.2870, Val Loss=0.2817, HitRate@3=0.4937, NDCG@3=0.3932, MAP@3=0.6340, LR=0.000228 (606.0s)\n",
        "üíæ Model improved (loss ‚Üì and hitrate ‚Üë), saved.\n",
        "\n",
        "--- Epoch 3/10 ---\n",
        "Epoch 3: Train Loss=0.2801, Val Loss=0.2765, HitRate@3=0.4908, NDCG@3=0.3937, MAP@3=0.6371, LR=0.000300 (606.7s)\n",
        "\n",
        "--- Epoch 4/10 ---\n",
        "Epoch 4: Train Loss=0.2674, Val Loss=0.2707, HitRate@3=0.5011, NDCG@3=0.4046, MAP@3=0.6516, LR=0.000285 (607.3s)\n",
        "üíæ Model improved (loss ‚Üì and hitrate ‚Üë), saved.\n",
        "\n",
        "--- Epoch 5/10 ---\n",
        "Epoch 5: Train Loss=0.2552, Val Loss=0.2633, HitRate@3=0.5073, NDCG@3=0.4089, MAP@3=0.6550, LR=0.000244 (605.9s)\n",
        "üíæ Model improved (loss ‚Üì and hitrate ‚Üë), saved.\n",
        "\n",
        "--- Epoch 6/10 ---\n",
        "Epoch 6: Train Loss=0.2444, Val Loss=0.2532, HitRate@3=0.5089, NDCG@3=0.4110, MAP@3=0.6536, LR=0.000183 (608.0s)\n",
        "üíæ Model improved (loss ‚Üì and hitrate ‚Üë), saved.\n",
        "\n",
        "--- Epoch 7/10 ---\n",
        "Epoch 7: Train Loss=0.2333, Val Loss=0.2459, HitRate@3=0.5113, NDCG@3=0.4127, MAP@3=0.6572, LR=0.000117 (607.7s)\n",
        "üíæ Model improved (loss ‚Üì and hitrate ‚Üë), saved.\n",
        "\n",
        "--- Epoch 8/10 ---\n",
        "Epoch 8: Train Loss=0.2222, Val Loss=0.2433, HitRate@3=0.5203, NDCG@3=0.4194, MAP@3=0.6590, LR=0.000056 (607.7s)\n",
        "üíæ Model improved (loss ‚Üì and hitrate ‚Üë), saved.\n",
        "\n",
        "--- Epoch 9/10 ---\n",
        "Epoch 9: Train Loss=0.2128, Val Loss=0.2403, HitRate@3=0.5148, NDCG@3=0.4175, MAP@3=0.6627, LR=0.000015 (605.9s)\n",
        "\n",
        "--- Epoch 10/10 ---\n",
        "Epoch 10: Train Loss=0.2067, Val Loss=0.2391, HitRate@3=0.5153, NDCG@3=0.4173, MAP@3=0.6602, LR=0.000000 (606.9s)"
      ],
      "metadata": {
        "id": "FiYtwQ1O9uCl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile deeprec_validate.py\n",
        "import os\n",
        "import time\n",
        "import random\n",
        "import torch\n",
        "import math\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import defaultdict\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "import polars as pl\n",
        "from tqdm import tqdm\n",
        "from src.feature import feature_engineering, feature_selection\n",
        "from transformers import get_scheduler\n",
        "from collections import Counter\n",
        "from torch.optim.lr_scheduler import OneCycleLR\n",
        "\n",
        "seed = 42\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "class RankDataset(Dataset):\n",
        "    def __init__(\n",
        "        self,\n",
        "        X: pl.DataFrame,\n",
        "        y: pl.Series,\n",
        "        groups: pl.DataFrame,\n",
        "        cat_features: list[str],\n",
        "        num_features: list[str],\n",
        "    ):\n",
        "        self.cat_features = cat_features\n",
        "        self.num_features = num_features\n",
        "        self.X_cat = {c: X[c].to_numpy() for c in cat_features}\n",
        "        self.X_num = X[self.num_features].to_numpy()\n",
        "        self.y = y.to_numpy()\n",
        "        self.groups = groups[\"ranker_id\"].to_numpy()\n",
        "\n",
        "        self.group_to_indices = defaultdict(list)\n",
        "        for i, g in enumerate(self.groups):\n",
        "            self.group_to_indices[g].append(i)\n",
        "        self.group_keys = list(self.group_to_indices.keys())\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.group_keys)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        g = self.group_keys[idx]\n",
        "        inds = self.group_to_indices[g]\n",
        "        length = len(inds)\n",
        "\n",
        "        x_cat = {\n",
        "            c: torch.LongTensor([\n",
        "                self.X_cat[c][i] if self.X_cat[c][i] >= 0 else 0 for i in inds\n",
        "            ])\n",
        "            for c in self.cat_features\n",
        "        }\n",
        "\n",
        "        x_num = torch.FloatTensor(self.X_num[inds])\n",
        "        y = torch.FloatTensor(self.y[inds]).reshape(-1)\n",
        "\n",
        "        return x_cat, x_num, y, length\n",
        "\n",
        "def collate_fn(batch):\n",
        "    batch_size = len(batch)\n",
        "    lengths = [b[3] for b in batch]\n",
        "    max_len = max(lengths)\n",
        "\n",
        "    padded_x_cat = {key: [] for key in batch[0][0].keys()}\n",
        "    padded_x_num = []\n",
        "    padded_y = []\n",
        "\n",
        "    num_dim = batch[0][1].shape[1]\n",
        "\n",
        "    for x_cat, x_num, y, length in batch:\n",
        "        pad_len = max_len - length\n",
        "\n",
        "        for key in padded_x_cat:\n",
        "            val = x_cat[key]\n",
        "            if pad_len > 0:\n",
        "                val = torch.cat([val, torch.zeros(pad_len, dtype=torch.long)])\n",
        "            padded_x_cat[key].append(val)\n",
        "\n",
        "        if pad_len > 0:\n",
        "            x_num = torch.cat([x_num, torch.zeros(pad_len, num_dim)])\n",
        "            y = torch.cat([y, torch.zeros(pad_len)])\n",
        "\n",
        "        padded_x_num.append(x_num)\n",
        "        padded_y.append(y)\n",
        "\n",
        "    padded_x_cat = {k: torch.stack(v) for k, v in padded_x_cat.items()}\n",
        "    padded_x_num = torch.stack(padded_x_num)\n",
        "    padded_y = torch.stack(padded_y)\n",
        "    lengths = torch.tensor(lengths, dtype=torch.long)\n",
        "\n",
        "    return padded_x_cat, padded_x_num, padded_y, lengths\n",
        "\n",
        "class SEModule(nn.Module):\n",
        "    def __init__(self, channel, reduction=4):\n",
        "        super().__init__()\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(channel, channel // reduction),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(channel // reduction, channel),\n",
        "            nn.Sigmoid(),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: [B, N, C]\n",
        "        w = self.fc(x.mean(dim=1))\n",
        "        w = w.unsqueeze(1)  # [B, 1, C]\n",
        "        return x * w\n",
        "\n",
        "\n",
        "class FiLM(nn.Module):\n",
        "    def __init__(self, feature_dim):\n",
        "        super().__init__()\n",
        "        self.gamma = nn.Linear(feature_dim, feature_dim)\n",
        "        self.beta = nn.Linear(feature_dim, feature_dim)\n",
        "\n",
        "    def forward(self, x, cond):\n",
        "        gamma = self.gamma(cond)\n",
        "        beta = self.beta(cond)\n",
        "        return gamma * x + beta\n",
        "\n",
        "class GatedFiLM(nn.Module):\n",
        "    def __init__(self, feature_dim):\n",
        "        super().__init__()\n",
        "        self.gamma = nn.Linear(feature_dim, feature_dim)\n",
        "        self.beta = nn.Linear(feature_dim, feature_dim)\n",
        "        self.gate = nn.Sequential(\n",
        "            nn.Linear(feature_dim, feature_dim),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x, cond):\n",
        "        gamma = self.gamma(cond)\n",
        "        beta = self.beta(cond)\n",
        "        modulated = gamma * x + beta\n",
        "        gate = self.gate(cond).unsqueeze(1)  # [B, 1, D]\n",
        "        return x * (1 - gate) + modulated * gate\n",
        "\n",
        "class FiLMWithGate(nn.Module):\n",
        "    def __init__(self, feature_dim):\n",
        "        super().__init__()\n",
        "        self.gamma = nn.Linear(feature_dim, feature_dim)\n",
        "        self.beta = nn.Linear(feature_dim, feature_dim)\n",
        "        self.gate = nn.Sequential(\n",
        "            nn.Linear(feature_dim, feature_dim),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x, cond):\n",
        "        gamma = self.gamma(cond)\n",
        "        beta = self.beta(cond)\n",
        "        modulated = gamma * x + beta\n",
        "        gate = self.gate(cond)\n",
        "        return x * (1 - gate) + modulated * gate\n",
        "\n",
        "class DLRankerAttention(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        cat_dims,\n",
        "        num_numeric_feats,\n",
        "        emb_dropout=0.1,\n",
        "        dropout=0.1,\n",
        "        num_heads=4,\n",
        "        num_layers=2,\n",
        "        dim_feedforward=128,\n",
        "        proj_dim=64,\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "        self.emb_dims = {\n",
        "            f: min(50, max(4, round(6 * math.log2(cat_dims[f] + 1)))) for f in cat_dims\n",
        "        }\n",
        "        self.embeddings = nn.ModuleDict({\n",
        "            f: nn.Embedding(cat_dims[f], self.emb_dims[f], padding_idx=0)\n",
        "            for f in cat_dims\n",
        "        })\n",
        "        self.emb_dropout = nn.Dropout(emb_dropout)\n",
        "\n",
        "        total_emb_dim = sum(self.emb_dims.values())\n",
        "        print(f\"Categorial emb dim sum: {total_emb_dim}, Numerical dim: {num_numeric_feats}\")\n",
        "\n",
        "        self.cat_proj = nn.Linear(total_emb_dim, proj_dim)\n",
        "        self.cat_transformer = nn.TransformerEncoder(\n",
        "            nn.TransformerEncoderLayer(\n",
        "                d_model=proj_dim,\n",
        "                nhead=4,\n",
        "                dim_feedforward=dim_feedforward,\n",
        "                dropout=dropout,\n",
        "                batch_first=True,\n",
        "            ),\n",
        "            num_layers=1,\n",
        "        )\n",
        "\n",
        "        self.num_proj_in = nn.Linear(num_numeric_feats, proj_dim)\n",
        "        self.num_transformer = nn.TransformerEncoder(\n",
        "            nn.TransformerEncoderLayer(\n",
        "                d_model=proj_dim,\n",
        "                nhead=4,\n",
        "                dim_feedforward=dim_feedforward,\n",
        "                dropout=dropout,\n",
        "                batch_first=True,\n",
        "            ),\n",
        "            num_layers=1,\n",
        "        )\n",
        "        self.num_se = SEModule(proj_dim)\n",
        "        self.num_proj_out = nn.Sequential(\n",
        "            nn.Linear(proj_dim, proj_dim),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(dropout),\n",
        "        )\n",
        "\n",
        "        # üîÅ Cross-attention: cat attends to num\n",
        "        self.cross_attn_cat2num = nn.MultiheadAttention(\n",
        "            embed_dim=proj_dim,\n",
        "            num_heads=4,\n",
        "            dropout=dropout,\n",
        "            batch_first=True,\n",
        "        )\n",
        "\n",
        "        self.film = FiLMWithGate(proj_dim)\n",
        "\n",
        "        self.transformer_layers = nn.ModuleList([\n",
        "            nn.TransformerEncoderLayer(\n",
        "                d_model=2 * proj_dim,\n",
        "                nhead=num_heads,\n",
        "                dim_feedforward=dim_feedforward,\n",
        "                dropout=dropout,\n",
        "                batch_first=True,\n",
        "            )\n",
        "            for _ in range(num_layers)\n",
        "        ])\n",
        "\n",
        "        self.mlp = nn.Sequential(\n",
        "            nn.Linear(2 * proj_dim, 128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(128, 64),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(64, 1),\n",
        "        )\n",
        "\n",
        "    def forward(self, x_cat: dict, x_num: torch.Tensor, attn_mask=None):\n",
        "        B, N, _ = x_num.shape  # x_num: [B, N, F_num]\n",
        "\n",
        "        # Categorical embeddings\n",
        "        cat_embs = torch.cat([self.embeddings[f](x_cat[f]) for f in x_cat], dim=-1)\n",
        "        cat_embs = self.emb_dropout(cat_embs)\n",
        "        cat_feat = self.cat_proj(cat_embs)  # [B, N, D]\n",
        "        cat_feat = self.cat_transformer(cat_feat)  # [B, N, D]\n",
        "\n",
        "        # Numeric features\n",
        "        num_feat = self.num_proj_in(x_num)\n",
        "        num_feat = self.num_transformer(num_feat)\n",
        "        num_feat = self.num_se(num_feat)\n",
        "        num_feat = self.num_proj_out(num_feat)\n",
        "\n",
        "        cat_feat = self.film(cat_feat, num_feat)\n",
        "\n",
        "        # Cross-attention: categorical features attend over numeric ones\n",
        "        cat_feat_attn, _ = self.cross_attn_cat2num(\n",
        "            query=cat_feat, key=num_feat, value=num_feat\n",
        "        )\n",
        "        cat_feat = cat_feat + cat_feat_attn  # residual connection\n",
        "\n",
        "        # Final concatenation\n",
        "        x = torch.cat([cat_feat, num_feat], dim=-1)\n",
        "\n",
        "        for layer in self.transformer_layers:\n",
        "            x = layer(x, src_key_padding_mask=attn_mask)\n",
        "\n",
        "        scores = self.mlp(x).squeeze(-1)  # [B, N]\n",
        "        return scores\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "def listmle_loss(scores, labels, lengths):\n",
        "    batch_size = scores.size(0)\n",
        "    total_loss = torch.tensor(0.0, device=scores.device, requires_grad=True)\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "\n",
        "        _, idx = torch.sort(y, descending=True)\n",
        "        s_sorted = s[idx]\n",
        "\n",
        "        parts = (\n",
        "            torch.logsumexp(s_sorted.unsqueeze(0).expand(l, -1).triu(diagonal=0), dim=1)\n",
        "            - s_sorted\n",
        "        )\n",
        "\n",
        "        total_loss = total_loss + parts.sum()\n",
        "\n",
        "    return total_loss / batch_size\n",
        "\"\"\"\n",
        "\n",
        "def hitrate_at_k(scores, labels, lengths, k=3, min_group_size=10):\n",
        "    batch_size = scores.size(0)\n",
        "    hits = 0\n",
        "    valid_count = 0\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        if l < min_group_size:\n",
        "            continue\n",
        "        length = min(l, k)\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "        _, topk_idx = torch.topk(s, length)\n",
        "        topk_labels = y[topk_idx]\n",
        "        hits += (topk_labels > 0).any().float()\n",
        "        valid_count += 1\n",
        "    return hits / valid_count if valid_count > 0 else torch.tensor(0.0, device=scores.device)\n",
        "\n",
        "\n",
        "def ndcg_at_k(scores, labels, lengths, k=3, min_group_size=10):\n",
        "    batch_size = scores.size(0)\n",
        "    total_ndcg = 0.0\n",
        "    valid_count = 0\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        if l < min_group_size:\n",
        "            continue\n",
        "\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "\n",
        "        _, idx_pred = torch.topk(s, min(k, l))\n",
        "        _, idx_ideal = torch.topk(y, min(k, l))\n",
        "\n",
        "        dcg = (y[idx_pred] / torch.log2(torch.arange(2, 2 + len(idx_pred), device=y.device).float())).sum()\n",
        "        idcg = (y[idx_ideal] / torch.log2(torch.arange(2, 2 + len(idx_ideal), device=y.device).float())).sum()\n",
        "\n",
        "        ndcg = dcg / idcg if idcg > 0 else 0.0\n",
        "        total_ndcg += ndcg\n",
        "        valid_count += 1\n",
        "\n",
        "    return total_ndcg / valid_count if valid_count > 0 else torch.tensor(0.0, device=scores.device)\n",
        "\n",
        "\n",
        "def map_at_k(scores, labels, lengths, k=3, min_group_size=10):\n",
        "    batch_size = scores.size(0)\n",
        "    total_ap = 0.0\n",
        "    valid_count = 0\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        if l < min_group_size:\n",
        "            continue\n",
        "\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "\n",
        "        _, idx_pred = torch.topk(s, min(k, l))\n",
        "        y_true = y[idx_pred] > 0\n",
        "\n",
        "        if y_true.sum() == 0:\n",
        "            continue\n",
        "\n",
        "        precisions = [(y_true[:j+1].float().sum() / (j+1)) for j in range(len(y_true)) if y_true[j]]\n",
        "        ap = torch.stack(precisions).mean()\n",
        "        total_ap += ap\n",
        "        valid_count += 1\n",
        "\n",
        "    return total_ap / valid_count if valid_count > 0 else torch.tensor(0.0, device=scores.device)\n",
        "\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "def listnet_loss(scores, labels, lengths):\n",
        "    batch_size = scores.size(0)\n",
        "    total_loss = 0.0\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "\n",
        "        s_softmax = torch.nn.functional.log_softmax(s, dim=0)\n",
        "        y_softmax = torch.nn.functional.softmax(y, dim=0)\n",
        "\n",
        "        loss = -torch.sum(y_softmax * s_softmax)\n",
        "        total_loss += loss\n",
        "\n",
        "    return total_loss / batch_size\n",
        "\"\"\"\n",
        "\n",
        "def ranknet_loss(scores, labels, lengths):\n",
        "    batch_size = scores.size(0)\n",
        "    total_loss = 0.0\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "\n",
        "        diff_scores = s.unsqueeze(1) - s.unsqueeze(0)\n",
        "        rel = y.unsqueeze(1) > y.unsqueeze(0)\n",
        "        label_diff = rel.float()\n",
        "\n",
        "        log_sigmoid = torch.nn.functional.logsigmoid(diff_scores)\n",
        "        pair_loss = -label_diff * log_sigmoid\n",
        "\n",
        "        total_loss += pair_loss.sum()\n",
        "\n",
        "    return total_loss / batch_size\n",
        "\n",
        "def xranknet_loss(scores, labels, lengths, temperature=1.0, margin=0.2, focus_topk=3):\n",
        "    \"\"\"\n",
        "    xRankNet with emphasis on top-K items (based on labels, not scores).\n",
        "    \"\"\"\n",
        "    batch_size = scores.size(0)\n",
        "    total_loss = 0.0\n",
        "    total_pairs = 0\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        if l < 2:\n",
        "            continue\n",
        "\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "\n",
        "        # Top-K mask based on ground truth labels\n",
        "        topk = min(focus_topk, l)\n",
        "        _, topk_idx = torch.topk(y, topk)\n",
        "        topk_mask = torch.zeros_like(y, dtype=torch.bool)\n",
        "        topk_mask[topk_idx] = True\n",
        "\n",
        "        # Create pairwise difference matrices\n",
        "        score_diff = s.unsqueeze(1) - s.unsqueeze(0)\n",
        "        label_diff = y.unsqueeze(1) - y.unsqueeze(0)\n",
        "\n",
        "        # valid pair: y_i > y_j and at least one of i, j is in top-K\n",
        "        valid_pairs = (label_diff > 0) & (\n",
        "            topk_mask.unsqueeze(1) | topk_mask.unsqueeze(0)\n",
        "        )\n",
        "\n",
        "        if valid_pairs.sum() == 0:\n",
        "            continue\n",
        "\n",
        "        importance = (label_diff.abs() * valid_pairs).float()\n",
        "\n",
        "        if margin > 0.0:\n",
        "            score_diff = score_diff - margin\n",
        "\n",
        "        score_diff = score_diff / temperature\n",
        "        pairwise_loss = -F.logsigmoid(score_diff) * importance\n",
        "\n",
        "        total_loss += pairwise_loss.sum()\n",
        "        total_pairs += importance.sum()\n",
        "\n",
        "    if total_pairs == 0:\n",
        "        return torch.tensor(0.0, device=scores.device, requires_grad=True)\n",
        "\n",
        "    return total_loss / total_pairs\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "def bpr_loss(scores, labels, lengths):\n",
        "    batch_size = scores.size(0)\n",
        "    total_loss = 0.0\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "\n",
        "        pos_mask = y > 0\n",
        "        neg_mask = y <= 0\n",
        "\n",
        "        pos_scores = s[pos_mask]\n",
        "        neg_scores = s[neg_mask]\n",
        "\n",
        "        if len(pos_scores) == 0 or len(neg_scores) == 0:\n",
        "            continue\n",
        "\n",
        "        pair_diff = pos_scores.unsqueeze(1) - neg_scores.unsqueeze(0)\n",
        "        loss = -F.logsigmoid(pair_diff).mean()\n",
        "        total_loss += loss\n",
        "\n",
        "    return total_loss / batch_size\n",
        "\"\"\"\n",
        "\n",
        "\"\"\"\n",
        "def lambdarank_loss(scores, labels, lengths, eps=1e-10):\n",
        "    batch_size = scores.size(0)\n",
        "    total_loss = 0.0\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "\n",
        "        if l < 2:\n",
        "            continue\n",
        "\n",
        "        _, rank_order = torch.sort(s, descending=True)\n",
        "        ideal_order = torch.sort(y, descending=True).indices\n",
        "\n",
        "        gain = 2 ** y - 1\n",
        "        discount = torch.log2(torch.arange(2, l + 2, device=y.device).float())\n",
        "\n",
        "        ideal_dcg = (gain[ideal_order] / discount).sum()\n",
        "        if ideal_dcg < eps:\n",
        "            continue\n",
        "\n",
        "        delta_ndcg = torch.zeros((l, l), device=y.device)\n",
        "\n",
        "        for i_idx in range(l):\n",
        "            for j_idx in range(l):\n",
        "                if y[i_idx] > y[j_idx]:\n",
        "                    change = (\n",
        "                        (1.0 / torch.log2(rank_order[i_idx] + 2.0))\n",
        "                        - (1.0 / torch.log2(rank_order[j_idx] + 2.0))\n",
        "                    ).abs()\n",
        "                    delta = (2 ** y[i_idx] - 2 ** y[j_idx]).abs() * change\n",
        "                    delta_ndcg[i_idx, j_idx] = delta / ideal_dcg\n",
        "\n",
        "        score_diffs = s.unsqueeze(1) - s.unsqueeze(0)\n",
        "        lambdas = -F.logsigmoid(score_diffs) * delta_ndcg\n",
        "        total_loss += lambdas.sum()\n",
        "\n",
        "    return total_loss / batch_size\n",
        "\"\"\"\n",
        "\n",
        "def train_one_epoch(model, loader, optimizer, device, scheduler):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "\n",
        "    for x_cat, x_num, y, lengths in tqdm(loader, desc=\"Training\", leave=False):\n",
        "        x_num, y = x_num.to(device), y.to(device)\n",
        "        if not isinstance(lengths, torch.Tensor):\n",
        "            lengths = torch.tensor(lengths)\n",
        "        lengths = lengths.detach().clone().to(device)\n",
        "        x_cat = {k: v.to(device) for k, v in x_cat.items()}\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        scores = model(x_cat, x_num)\n",
        "        loss = xranknet_loss(scores, y, lengths, temperature=1.0, margin=0.2, focus_topk=3)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    return total_loss / len(loader)\n",
        "\n",
        "\n",
        "def validate(model, loader, device, min_group_size=10):\n",
        "    model.eval()\n",
        "    total_hitrate = 0\n",
        "    total_ndcg = 0\n",
        "    total_map = 0\n",
        "    total_loss = 0\n",
        "    count = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for x_cat, x_num, y, lengths in tqdm(loader, desc=\"Validating\", leave=False):\n",
        "            x_num, y = x_num.to(device), y.to(device)\n",
        "            lengths = torch.tensor(lengths).to(device)\n",
        "            x_cat = {k: v.to(device) for k, v in x_cat.items()}\n",
        "\n",
        "            scores = model(x_cat, x_num)\n",
        "\n",
        "            hitrate = hitrate_at_k(scores, y, lengths, k=3, min_group_size=min_group_size)\n",
        "            ndcg = ndcg_at_k(scores, y, lengths, k=3, min_group_size=min_group_size)\n",
        "            map3 = map_at_k(scores, y, lengths, k=3, min_group_size=min_group_size)\n",
        "            loss = xranknet_loss(scores, y, lengths, temperature=1.0, margin=0.2, focus_topk=3)\n",
        "\n",
        "            batch_size = scores.size(0)\n",
        "            total_hitrate += hitrate * batch_size\n",
        "            total_ndcg += ndcg * batch_size\n",
        "            total_map += map3 * batch_size\n",
        "            total_loss += loss.item() * batch_size\n",
        "            count += batch_size\n",
        "\n",
        "    return total_loss / count, total_hitrate / count, total_ndcg / count, total_map / count\n",
        "\n",
        "\n",
        "def build_cat_dims(X, cat_features):\n",
        "    cat_dims = {}\n",
        "    for c in cat_features:\n",
        "        max_val = X[c].max()\n",
        "        if max_val < 0:\n",
        "            max_val = 0\n",
        "        cat_dims[c] = max_val + 1\n",
        "    return cat_dims\n",
        "\n",
        "\n",
        "def normalize_numeric_features(X, numeric_features, train_mask):\n",
        "    for col in numeric_features:\n",
        "        values = X[col].to_numpy()\n",
        "        train_vals = values[train_mask]\n",
        "        mean = train_vals.mean()\n",
        "        std = train_vals.std() if train_vals.std() > 0 else 1.0\n",
        "        norm_vals = (values - mean) / std\n",
        "        X = X.with_columns(pl.Series(col, norm_vals).alias(col))\n",
        "    return X\n",
        "\n",
        "\n",
        "def load_or_prepare_data(\n",
        "    data_dir,\n",
        "    train_file=\"train.parquet\",\n",
        "    test_file=\"test.parquet\",\n",
        "    cache_file=\"feature_engineered_val.parquet\",\n",
        "):\n",
        "    cache_path = os.path.join(data_dir, cache_file)\n",
        "\n",
        "    if os.path.exists(cache_path):\n",
        "        print(f\"Loading cached feature-engineered data from {cache_path} ...\")\n",
        "        df = pl.read_parquet(cache_path)\n",
        "\n",
        "        test = pl.read_parquet(os.path.join(data_dir, test_file)).drop(\"__index_level_0__\")\n",
        "        test_ids = test[\"Id\"]\n",
        "        test_rankers = test[\"ranker_id\"]\n",
        "    else:\n",
        "        print(\"Cached file not found, processing raw data ...\")\n",
        "\n",
        "        train = pl.read_parquet(os.path.join(data_dir, train_file)).drop(\"__index_level_0__\")\n",
        "        test = (\n",
        "            pl.read_parquet(os.path.join(data_dir, test_file))\n",
        "            .drop(\"__index_level_0__\")\n",
        "            .with_columns(pl.lit(0, dtype=pl.Int64).alias(\"selected\"))\n",
        "        )\n",
        "\n",
        "        test_ids = test[\"Id\"]\n",
        "        test_rankers = test[\"ranker_id\"]\n",
        "\n",
        "        df = pl.concat((train, test))\n",
        "        df = feature_engineering(df, full=True)\n",
        "\n",
        "        df = df.with_columns(\n",
        "            [pl.col(c).fill_null(0) for c in df.select(pl.selectors.numeric()).columns] +\n",
        "            [pl.col(c).fill_null(\"missing\") for c in df.select(pl.selectors.string()).columns]\n",
        "        )\n",
        "\n",
        "        os.makedirs(data_dir, exist_ok=True)\n",
        "        df.write_parquet(cache_path)\n",
        "        print(f\"Saved feature-engineered data to {cache_path}\")\n",
        "\n",
        "    return df, test_ids, test_rankers\n",
        "\n",
        "\n",
        "def prepare_data(data_dir):\n",
        "    df, test_ids, test_rankers = load_or_prepare_data(data_dir)\n",
        "\n",
        "    id_column = df[\"Id\"]\n",
        "    X, y, groups, cat_features, num_features = feature_selection(df)\n",
        "\n",
        "    X = X.with_columns(pl.Series(\"Id\", id_column[:X.shape[0]]))\n",
        "\n",
        "    X = X.with_columns(\n",
        "        [\n",
        "            (pl.col(c).rank(\"dense\") - 1).fill_null(-1).cast(pl.Int32)\n",
        "            for c in cat_features\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    train_size = 18145372\n",
        "    train_mask = np.arange(X.height) < train_size\n",
        "    X = normalize_numeric_features(X, num_features, train_mask)\n",
        "\n",
        "    return X, y, groups, cat_features, num_features, train_size, test_ids, test_rankers\n",
        "\n",
        "\n",
        "class EarlyStopping:\n",
        "    def __init__(self, patience=3, min_delta=0.00005):\n",
        "        self.patience = patience\n",
        "        self.min_delta = min_delta\n",
        "        self.best = float(\"-inf\")\n",
        "        self.counter = 0\n",
        "\n",
        "    def step(self, metric):\n",
        "        if metric > self.best + self.min_delta:\n",
        "            self.best = metric\n",
        "            self.counter = 0\n",
        "        else:\n",
        "            self.counter += 1\n",
        "        return self.counter >= self.patience\n",
        "\n",
        "\n",
        "def plot_group_size_distribution(dataset, save_path=None):\n",
        "    group_sizes = [len(v) for v in dataset.group_to_indices.values()]\n",
        "    plt.figure()\n",
        "    plt.hist(group_sizes, bins=100, log=True)\n",
        "    plt.xlabel(\"Group size (number of items per ranker_id)\")\n",
        "    plt.ylabel(\"Frequency (log scale)\")\n",
        "    plt.title(\"Distribution of Group Sizes\")\n",
        "    plt.grid(True)\n",
        "    if save_path:\n",
        "        plt.savefig(save_path)\n",
        "    else:\n",
        "        plt.show()\n",
        "    plt.close()\n",
        "\n",
        "\n",
        "def main():\n",
        "    DATA_DIR = \"./data\"\n",
        "    MODEL_DIR = \"model\"\n",
        "    SUBMIT_DIR = \"submission\"\n",
        "\n",
        "    best_val_loss = float(\"inf\")\n",
        "    best_hitrate = 0.0\n",
        "    model_path = os.path.join(MODEL_DIR, \"best_dl_ranker.pt\")\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "    val_hitrates = []\n",
        "    val_ndcgs = []\n",
        "    val_maps = []\n",
        "    learning_rates = []\n",
        "\n",
        "    os.makedirs(MODEL_DIR, exist_ok=True)\n",
        "    os.makedirs(SUBMIT_DIR, exist_ok=True)\n",
        "\n",
        "    early_stopper = EarlyStopping(patience=3, min_delta=0.001)\n",
        "\n",
        "    X, y, groups, cat_features, num_features, train_size, test_ids, test_rankers = prepare_data(DATA_DIR)\n",
        "\n",
        "    # Fill missing values\n",
        "    float_cols = [c for c, t in zip(X.columns, X.dtypes) if t == pl.Float64]\n",
        "    for col in float_cols:\n",
        "        X = X.with_columns(\n",
        "            pl.when(pl.col(col).is_nan()).then(0).otherwise(pl.col(col)).alias(col)\n",
        "        )\n",
        "\n",
        "    n1 = 16487352\n",
        "    # n1 = 17487300\n",
        "    n2 = train_size\n",
        "\n",
        "    X_tr, X_va, X_te = X[:n1], X[n1:n2], X[n2:]\n",
        "    y_tr, y_va, y_te = y[:n1], y[n1:n2], y[n2:]\n",
        "    groups_tr, groups_va, groups_te = groups[:n1], groups[n1:n2], groups[n2:]\n",
        "\n",
        "    # Inspect group sizes in validation set\n",
        "    val_rankers = groups_va[\"ranker_id\"].to_numpy()\n",
        "    val_group_counts = Counter(val_rankers)\n",
        "\n",
        "    print(\"\\nüìã Validation group statistics:\")\n",
        "    # Save detailed group info to file\n",
        "    group_info_path = os.path.join(MODEL_DIR, \"validation_groups_info.txt\")\n",
        "    with open(group_info_path, \"w\") as f:\n",
        "        f.write(f\"Total groups: {len(val_group_counts)}\\n\\n\")\n",
        "        f.write(\"GroupID\\tSize\\tStartIdx\\tEndIdx\\n\")\n",
        "\n",
        "        group_to_rows = defaultdict(list)\n",
        "        for i, g in enumerate(val_rankers):\n",
        "            group_to_rows[g].append(i)\n",
        "\n",
        "        for group_id, indices in sorted(group_to_rows.items()):\n",
        "            start_idx = indices[0]\n",
        "            end_idx = indices[-1]\n",
        "            size = len(indices)\n",
        "            f.write(f\"{group_id}\\t{size}\\t{start_idx}\\t{end_idx}\\n\")\n",
        "\n",
        "    print(f\"üìÅ Saved validation group info to {group_info_path}\")\n",
        "\n",
        "\n",
        "    cat_dims = build_cat_dims(X, cat_features)\n",
        "    num_numeric_feats = len(num_features)\n",
        "\n",
        "    train_dataset = RankDataset(X_tr, y_tr, groups_tr, cat_features, num_features)\n",
        "    val_dataset = RankDataset(X_va, y_va, groups_va, cat_features, num_features)\n",
        "    test_dataset = RankDataset(X_te, y_te, groups_te, cat_features, num_features)\n",
        "\n",
        "    plot_group_size_distribution(train_dataset, save_path=os.path.join(MODEL_DIR, \"group_sizes.png\"))\n",
        "    print(\"üìä Group size distribution saved.\")\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True, collate_fn=collate_fn)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=4, shuffle=False, collate_fn=collate_fn)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False, collate_fn=collate_fn)\n",
        "\n",
        "    print(\"‚úÖ Data loaders created.\")\n",
        "\n",
        "    num_epochs = 10\n",
        "    num_training_steps = num_epochs * len(train_loader)\n",
        "    num_warmup_steps = int(0.1 * num_training_steps)\n",
        "\n",
        "    learning_rate = 3e-4\n",
        "\n",
        "    model = DLRankerAttention(\n",
        "        cat_dims=cat_dims,\n",
        "        num_numeric_feats=num_numeric_feats,\n",
        "        emb_dropout=0.1,\n",
        "        dropout=0.1,\n",
        "        num_heads=4,\n",
        "        num_layers=2,\n",
        "        dim_feedforward=128,\n",
        "        proj_dim=64\n",
        "    ).to(device)\n",
        "\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=0.01)\n",
        "\n",
        "    scheduler = OneCycleLR(\n",
        "        optimizer,\n",
        "        max_lr=learning_rate,\n",
        "        steps_per_epoch=len(train_loader),\n",
        "        epochs=num_epochs,\n",
        "        pct_start=0.3,\n",
        "    )\n",
        "\n",
        "    best_hitrate = 0\n",
        "    for epoch in range(num_epochs):\n",
        "        print(f\"\\n--- Epoch {epoch+1}/{num_epochs} ---\")\n",
        "        start_time = time.time()\n",
        "\n",
        "        train_loss = train_one_epoch(model, train_loader, optimizer, device, scheduler)\n",
        "        val_loss, val_hitrate, val_ndcg, val_map = validate(model, val_loader, device, min_group_size=10)\n",
        "\n",
        "        train_losses.append(train_loss)\n",
        "        val_losses.append(val_loss)\n",
        "        val_hitrates.append(val_hitrate.item())\n",
        "        val_ndcgs.append(val_ndcg.item())\n",
        "        val_maps.append(val_map.item())\n",
        "\n",
        "        current_lr = scheduler.get_last_lr()\n",
        "        learning_rates.append(current_lr[0])\n",
        "\n",
        "        elapsed = time.time() - start_time\n",
        "        print(\n",
        "            f\"Epoch {epoch+1}: \"\n",
        "            f\"Train Loss={train_loss:.4f}, \"\n",
        "            f\"Val Loss={val_loss:.4f}, \"\n",
        "            f\"HitRate@3={val_hitrate:.4f}, \"\n",
        "            f\"NDCG@3={val_ndcg:.4f}, \"\n",
        "            f\"MAP@3={val_map:.4f}, \"\n",
        "            f\"LR={current_lr[0]:.6f} \"\n",
        "            f\"({elapsed:.1f}s)\"\n",
        "        )\n",
        "\n",
        "\n",
        "        if val_loss < best_val_loss and val_hitrate > best_hitrate:\n",
        "            best_val_loss = val_loss\n",
        "            best_hitrate = val_hitrate\n",
        "            torch.save(model.state_dict(), model_path)\n",
        "            print(\"üíæ Model improved (loss ‚Üì and hitrate ‚Üë), saved.\")\n",
        "\n",
        "        if early_stopper.step(-val_loss):\n",
        "            print(\"‚õî Early stopping triggered.\")\n",
        "            break\n",
        "\n",
        "    # Plot metrics\n",
        "    epochs = list(range(1, len(train_losses) + 1))\n",
        "\n",
        "    # Plot Loss Curve\n",
        "    plt.figure()\n",
        "    plt.plot(epochs, train_losses, label=\"Train Loss\")\n",
        "    plt.plot(epochs, val_losses, label=\"Val Loss\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.title(\"Training & Validation Loss\")\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.savefig(os.path.join(MODEL_DIR, \"loss_curve.png\"))\n",
        "    plt.close()\n",
        "\n",
        "    # Plot HitRate@3\n",
        "    plt.figure()\n",
        "    plt.plot(epochs, val_hitrates, label=\"Val HitRate@3\", color=\"green\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"HitRate@3\")\n",
        "    plt.title(\"Validation HitRate@3\")\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.savefig(os.path.join(MODEL_DIR, \"hitrate_curve.png\"))\n",
        "    plt.close()\n",
        "\n",
        "    # Plot Learning Rate\n",
        "    plt.figure()\n",
        "    plt.plot(epochs, learning_rates, label=\"Learning Rate\", color=\"orange\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"LR\")\n",
        "    plt.title(\"Learning Rate Schedule\")\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.savefig(os.path.join(MODEL_DIR, \"lr_curve.png\"))\n",
        "    plt.close()\n",
        "\n",
        "    # Plot NDCG@3\n",
        "    plt.figure()\n",
        "    plt.plot(epochs, val_ndcgs, label=\"Val NDCG@3\", color=\"purple\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"NDCG@3\")\n",
        "    plt.title(\"Validation NDCG@3\")\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.savefig(os.path.join(MODEL_DIR, \"ndcg_curve.png\"))\n",
        "    plt.close()\n",
        "\n",
        "    # Plot MAP@3\n",
        "    plt.figure()\n",
        "    plt.plot(epochs, val_maps, label=\"Val MAP@3\", color=\"red\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"MAP@3\")\n",
        "    plt.title(\"Validation MAP@3\")\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.savefig(os.path.join(MODEL_DIR, \"map_curve.png\"))\n",
        "    plt.close()\n",
        "\n",
        "    print(\"üìä Saved metric plots to model/\")\n",
        "\n",
        "    # Predict test set\n",
        "    model.load_state_dict(torch.load(model_path))\n",
        "    model.eval()\n",
        "\n",
        "    val_ids = X_va[\"Id\"]\n",
        "    val_rankers = groups_va[\"ranker_id\"]\n",
        "    val_labels = y_va\n",
        "\n",
        "    all_val_scores = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for x_cat, x_num, _, lengths in tqdm(val_loader, desc=\"Predicting validation set\"):\n",
        "            x_num = x_num.to(device)\n",
        "            x_cat = {k: v.to(device) for k, v in x_cat.items()}\n",
        "            scores = model(x_cat, x_num)\n",
        "\n",
        "            for i in range(scores.size(0)):\n",
        "                l = lengths[i]\n",
        "                all_val_scores.append(scores[i, :l].cpu().numpy())\n",
        "\n",
        "    all_val_scores = np.concatenate(all_val_scores)\n",
        "\n",
        "    assert len(all_val_scores) == X_va.shape[0], \\\n",
        "        f\"Mismatch: {len(all_val_scores)} scores vs {X_va.shape[0]} rows\"\n",
        "\n",
        "    val_df = X_va.with_columns([\n",
        "        pl.Series(\"Id\", val_ids),\n",
        "        pl.Series(\"ranker_id\", val_rankers),\n",
        "        pl.Series(\"score\", all_val_scores),\n",
        "        pl.Series(\"label\", val_labels)\n",
        "    ])\n",
        "\n",
        "    val_df = val_df.with_columns(\n",
        "        pl.col(\"score\")\n",
        "        .rank(method=\"ordinal\", descending=True)\n",
        "        .over(\"ranker_id\")\n",
        "        .cast(pl.Int32)\n",
        "        .alias(\"selected\")\n",
        "    )\n",
        "\n",
        "    val_save_path = os.path.join(MODEL_DIR, \"validation_preds_dl_full.csv\")\n",
        "    val_df.write_csv(val_save_path)\n",
        "    print(f\"‚úÖ Saved full validation predictions (with features) to {val_save_path}\")\n",
        "\n",
        "    all_scores = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for x_cat, x_num, _, lengths in tqdm(test_loader, desc=\"Predicting test set\"):\n",
        "            x_num = x_num.to(device)\n",
        "            x_cat = {k: v.to(device) for k, v in x_cat.items()}\n",
        "            scores = model(x_cat, x_num)\n",
        "\n",
        "            for i in range(scores.size(0)):\n",
        "                l = lengths[i]\n",
        "                all_scores.append(scores[i, :l].cpu().numpy())\n",
        "\n",
        "    all_scores = np.concatenate(all_scores)\n",
        "\n",
        "    assert len(all_scores) == X_te.shape[0], \\\n",
        "        f\"Mismatch: {len(all_scores)} scores vs {X_te.shape[0]} rows in X_te\"\n",
        "\n",
        "    submission_df = pl.DataFrame({\n",
        "        \"Id\": test_ids,\n",
        "        \"ranker_id\": test_rankers,\n",
        "        \"score\": all_scores\n",
        "    })\n",
        "\n",
        "    submission = (\n",
        "        submission_df\n",
        "        .with_columns(\n",
        "            pl.col(\"score\")\n",
        "            .rank(method=\"ordinal\", descending=True)\n",
        "            .over(\"ranker_id\")\n",
        "            .cast(pl.Int32)\n",
        "            .alias(\"selected\")\n",
        "        )\n",
        "        .select([\"Id\", \"ranker_id\", \"score\", \"selected\"])\n",
        "    )\n",
        "\n",
        "    submission_path = os.path.join(SUBMIT_DIR, \"submission_dl_ranker.csv\")\n",
        "    submission.write_csv(submission_path)\n",
        "    print(f\"‚úÖ Submission saved to {submission_path}\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LT1XBTuH9vEV",
        "outputId": "8e565a60-ef76-4375-8042-e97f8296ee8e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing deeprec_validate.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "--- Epoch 1/10 ---\n",
        "Validating:   0%|          | 0/2636 [00:00<?, ?it/s]/home/ionut/test_whisper/test2/deeprec_validate.py:572: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
        "  lengths = torch.tensor(lengths).to(device)\n",
        "Epoch 1: Train Loss=0.3535, Val Loss=0.2908, HitRate@3=0.4750, NDCG@3=0.3747, MAP@3=0.6154, LR=0.000084 (608.8s)\n",
        "üíæ Model improved (loss ‚Üì and hitrate ‚Üë), saved.\n",
        "\n",
        "--- Epoch 2/10 ---\n",
        "Epoch 2: Train Loss=0.2880, Val Loss=0.2807, HitRate@3=0.4787, NDCG@3=0.3795, MAP@3=0.6216, LR=0.000228 (607.4s)\n",
        "üíæ Model improved (loss ‚Üì and hitrate ‚Üë), saved.\n",
        "\n",
        "--- Epoch 3/10 ---\n",
        "Epoch 3: Train Loss=0.2791, Val Loss=0.2792, HitRate@3=0.4949, NDCG@3=0.3958, MAP@3=0.6354, LR=0.000300 (607.1s)\n",
        "üíæ Model improved (loss ‚Üì and hitrate ‚Üë), saved.\n",
        "\n",
        "--- Epoch 4/10 ---\n",
        "Epoch 4: Train Loss=0.2690, Val Loss=0.2638, HitRate@3=0.4938, NDCG@3=0.3942, MAP@3=0.6413, LR=0.000285 (608.7s)\n",
        "\n",
        "--- Epoch 5/10 ---\n",
        "Epoch 5: Train Loss=0.2589, Val Loss=0.2574, HitRate@3=0.5080, NDCG@3=0.4081, MAP@3=0.6508, LR=0.000244 (608.2s)\n",
        "üíæ Model improved (loss ‚Üì and hitrate ‚Üë), saved.\n",
        "\n",
        "--- Epoch 6/10 ---\n",
        "Epoch 6: Train Loss=0.2463, Val Loss=0.2520, HitRate@3=0.5059, NDCG@3=0.4104, MAP@3=0.6566, LR=0.000183 (609.7s)\n",
        "\n",
        "--- Epoch 7/10 ---\n",
        "Epoch 7: Train Loss=0.2340, Val Loss=0.2463, HitRate@3=0.5077, NDCG@3=0.4089, MAP@3=0.6525, LR=0.000117 (610.3s)\n",
        "\n",
        "--- Epoch 8/10 ---\n",
        "Epoch 8: Train Loss=0.2219, Val Loss=0.2379, HitRate@3=0.5146, NDCG@3=0.4153, MAP@3=0.6556, LR=0.000056 (609.1s)\n",
        "üíæ Model improved (loss ‚Üì and hitrate ‚Üë), saved.\n",
        "\n",
        "--- Epoch 9/10 ---\n",
        "Epoch 9: Train Loss=0.2123, Val Loss=0.2381, HitRate@3=0.5138, NDCG@3=0.4137, MAP@3=0.6546, LR=0.000015 (609.5s)\n",
        "\n",
        "--- Epoch 10/10 ---\n",
        "Epoch 10: Train Loss=0.2071, Val Loss=0.2386, HitRate@3=0.5153, NDCG@3=0.4158, MAP@3=0.6595, LR=0.000000 (609.3s)"
      ],
      "metadata": {
        "id": "fmdr_2Ci1vjn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile deeprec_validate.py\n",
        "import os\n",
        "import time\n",
        "import random\n",
        "import torch\n",
        "import math\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import defaultdict\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "import polars as pl\n",
        "from tqdm import tqdm\n",
        "from src.feature import feature_engineering, feature_selection\n",
        "from transformers import get_scheduler\n",
        "from collections import Counter\n",
        "from torch.optim.lr_scheduler import OneCycleLR\n",
        "\n",
        "seed = 42\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "class RankDataset(Dataset):\n",
        "    def __init__(\n",
        "        self,\n",
        "        X: pl.DataFrame,\n",
        "        y: pl.Series,\n",
        "        groups: pl.DataFrame,\n",
        "        cat_features: list[str],\n",
        "        num_features: list[str],\n",
        "    ):\n",
        "        self.cat_features = cat_features\n",
        "        self.num_features = num_features\n",
        "        self.X_cat = {c: X[c].to_numpy() for c in cat_features}\n",
        "        self.X_num = X[self.num_features].to_numpy()\n",
        "        self.y = y.to_numpy()\n",
        "        self.groups = groups[\"ranker_id\"].to_numpy()\n",
        "\n",
        "        self.group_to_indices = defaultdict(list)\n",
        "        for i, g in enumerate(self.groups):\n",
        "            self.group_to_indices[g].append(i)\n",
        "        self.group_keys = list(self.group_to_indices.keys())\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.group_keys)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        g = self.group_keys[idx]\n",
        "        inds = self.group_to_indices[g]\n",
        "        length = len(inds)\n",
        "\n",
        "        x_cat = {\n",
        "            c: torch.LongTensor([\n",
        "                self.X_cat[c][i] if self.X_cat[c][i] >= 0 else 0 for i in inds\n",
        "            ])\n",
        "            for c in self.cat_features\n",
        "        }\n",
        "\n",
        "        x_num = torch.FloatTensor(self.X_num[inds])\n",
        "        y = torch.FloatTensor(self.y[inds]).reshape(-1)\n",
        "\n",
        "        return x_cat, x_num, y, length\n",
        "\n",
        "def collate_fn(batch):\n",
        "    batch_size = len(batch)\n",
        "    lengths = [b[3] for b in batch]\n",
        "    max_len = max(lengths)\n",
        "\n",
        "    padded_x_cat = {key: [] for key in batch[0][0].keys()}\n",
        "    padded_x_num = []\n",
        "    padded_y = []\n",
        "\n",
        "    num_dim = batch[0][1].shape[1]\n",
        "\n",
        "    for x_cat, x_num, y, length in batch:\n",
        "        pad_len = max_len - length\n",
        "\n",
        "        for key in padded_x_cat:\n",
        "            val = x_cat[key]\n",
        "            if pad_len > 0:\n",
        "                val = torch.cat([val, torch.zeros(pad_len, dtype=torch.long)])\n",
        "            padded_x_cat[key].append(val)\n",
        "\n",
        "        if pad_len > 0:\n",
        "            x_num = torch.cat([x_num, torch.zeros(pad_len, num_dim)])\n",
        "            y = torch.cat([y, torch.zeros(pad_len)])\n",
        "\n",
        "        padded_x_num.append(x_num)\n",
        "        padded_y.append(y)\n",
        "\n",
        "    padded_x_cat = {k: torch.stack(v) for k, v in padded_x_cat.items()}\n",
        "    padded_x_num = torch.stack(padded_x_num)\n",
        "    padded_y = torch.stack(padded_y)\n",
        "    lengths = torch.tensor(lengths, dtype=torch.long)\n",
        "\n",
        "    return padded_x_cat, padded_x_num, padded_y, lengths\n",
        "\n",
        "class SEModule(nn.Module):\n",
        "    def __init__(self, channel, reduction=4):\n",
        "        super().__init__()\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(channel, channel // reduction),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(channel // reduction, channel),\n",
        "            nn.Sigmoid(),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: [B, N, C]\n",
        "        w = self.fc(x.mean(dim=1))  # [B, C]\n",
        "        return x * w.unsqueeze(1)   # [B, 1, C] => broadcasted\n",
        "\n",
        "\n",
        "class FiLM(nn.Module):\n",
        "    def __init__(self, feature_dim):\n",
        "        super().__init__()\n",
        "        self.gamma = nn.Linear(feature_dim, feature_dim)\n",
        "        self.beta = nn.Linear(feature_dim, feature_dim)\n",
        "\n",
        "    def forward(self, x, cond):\n",
        "        return self.gamma(cond) * x + self.beta(cond)\n",
        "\n",
        "\n",
        "class DLRankerAttention(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        cat_dims,\n",
        "        num_numeric_feats,\n",
        "        emb_dropout=0.1,\n",
        "        dropout=0.1,\n",
        "        num_heads=4,\n",
        "        num_layers=2,\n",
        "        dim_feedforward=128,\n",
        "        proj_dim=64,\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "        # 1. Categorical embedding layers\n",
        "        self.emb_dims = {\n",
        "            f: min(50, max(4, round(6 * math.log2(cat_dims[f] + 1)))) for f in cat_dims\n",
        "        }\n",
        "        self.embeddings = nn.ModuleDict({\n",
        "            f: nn.Embedding(cat_dims[f], self.emb_dims[f], padding_idx=0)\n",
        "            for f in cat_dims\n",
        "        })\n",
        "        self.emb_dropout = nn.Dropout(emb_dropout)\n",
        "        total_emb_dim = sum(self.emb_dims.values())\n",
        "\n",
        "        # 2. Category & numeric projections\n",
        "        self.cat_proj = nn.Linear(total_emb_dim, proj_dim)\n",
        "        self.num_proj_in = nn.Linear(num_numeric_feats, proj_dim)\n",
        "\n",
        "        # 3. Per-type Transformer encoding\n",
        "        self.cat_transformer = nn.TransformerEncoder(\n",
        "            nn.TransformerEncoderLayer(\n",
        "                d_model=proj_dim,\n",
        "                nhead=num_heads,\n",
        "                dim_feedforward=dim_feedforward,\n",
        "                dropout=dropout,\n",
        "                batch_first=True,\n",
        "            ),\n",
        "            num_layers=1,\n",
        "        )\n",
        "        self.num_transformer = nn.TransformerEncoder(\n",
        "            nn.TransformerEncoderLayer(\n",
        "                d_model=proj_dim,\n",
        "                nhead=num_heads,\n",
        "                dim_feedforward=dim_feedforward,\n",
        "                dropout=dropout,\n",
        "                batch_first=True,\n",
        "            ),\n",
        "            num_layers=1,\n",
        "        )\n",
        "\n",
        "        # 4. Numeric feature squeeze-excite & MLP\n",
        "        self.num_se = SEModule(proj_dim)\n",
        "        self.num_proj_out = nn.Sequential(\n",
        "            nn.Linear(proj_dim, proj_dim),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(dropout),\n",
        "        )\n",
        "\n",
        "        # 5. Cross-attention: cat ‚Üí num and num ‚Üí cat\n",
        "        self.cross_attn_cat2num = nn.MultiheadAttention(\n",
        "            embed_dim=proj_dim, num_heads=num_heads, dropout=dropout, batch_first=True\n",
        "        )\n",
        "        self.cross_attn_num2cat = nn.MultiheadAttention(\n",
        "            embed_dim=proj_dim, num_heads=num_heads, dropout=dropout, batch_first=True\n",
        "        )\n",
        "\n",
        "        # 6. FiLM layer (condition cat on num)\n",
        "        self.film = FiLM(proj_dim)\n",
        "\n",
        "        # 7. Joint Transformer stack (after fusion)\n",
        "        self.transformer_layers = nn.ModuleList([\n",
        "            nn.TransformerEncoderLayer(\n",
        "                d_model=2 * proj_dim,\n",
        "                nhead=num_heads,\n",
        "                dim_feedforward=dim_feedforward,\n",
        "                dropout=dropout,\n",
        "                batch_first=True,\n",
        "            )\n",
        "            for _ in range(num_layers)\n",
        "        ])\n",
        "\n",
        "        # 8. Final MLP\n",
        "        self.mlp = nn.Sequential(\n",
        "            nn.Linear(2 * proj_dim, 128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(128, 64),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(64, 1),\n",
        "        )\n",
        "\n",
        "        print(f\"‚úÖ DLRankerAttention initialized | Cat emb dim: {total_emb_dim} ‚Üí {proj_dim}, Num feats: {num_numeric_feats}\")\n",
        "\n",
        "    def forward(self, x_cat: dict, x_num: torch.Tensor, attn_mask=None):\n",
        "        B, N, _ = x_num.shape  # x_num: [B, N, num_feats]\n",
        "\n",
        "        # 1. Embed and encode categorical inputs\n",
        "        cat_embs = torch.cat([self.embeddings[f](x_cat[f]) for f in x_cat], dim=-1)\n",
        "        cat_feat = self.cat_proj(self.emb_dropout(cat_embs))  # [B, N, D]\n",
        "        cat_feat = self.cat_transformer(cat_feat)\n",
        "\n",
        "        # 2. Encode numeric features\n",
        "        num_feat = self.num_proj_in(x_num)\n",
        "        num_feat = self.num_transformer(num_feat)\n",
        "        num_feat = self.num_se(num_feat)\n",
        "        num_feat = self.num_proj_out(num_feat)\n",
        "\n",
        "        # 3. FiLM conditioning: cat_feat conditioned on num_feat\n",
        "        cat_feat = self.film(cat_feat, num_feat)\n",
        "\n",
        "        # 4. Dual cross-attention\n",
        "        # cat ‚Üí num\n",
        "        cat_attn, _ = self.cross_attn_cat2num(query=cat_feat, key=num_feat, value=num_feat)\n",
        "        cat_feat = cat_feat + cat_attn  # residual\n",
        "        # num ‚Üí cat\n",
        "        num_attn, _ = self.cross_attn_num2cat(query=num_feat, key=cat_feat, value=cat_feat)\n",
        "        num_feat = num_feat + num_attn  # residual\n",
        "\n",
        "        # 5. Fusion & joint transformer\n",
        "        x = torch.cat([cat_feat, num_feat], dim=-1)\n",
        "        for layer in self.transformer_layers:\n",
        "            x = layer(x, src_key_padding_mask=attn_mask)\n",
        "\n",
        "        # 6. Final MLP score\n",
        "        return self.mlp(x).squeeze(-1)  # [B, N]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "def listmle_loss(scores, labels, lengths):\n",
        "    batch_size = scores.size(0)\n",
        "    total_loss = torch.tensor(0.0, device=scores.device, requires_grad=True)\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "\n",
        "        _, idx = torch.sort(y, descending=True)\n",
        "        s_sorted = s[idx]\n",
        "\n",
        "        parts = (\n",
        "            torch.logsumexp(s_sorted.unsqueeze(0).expand(l, -1).triu(diagonal=0), dim=1)\n",
        "            - s_sorted\n",
        "        )\n",
        "\n",
        "        total_loss = total_loss + parts.sum()\n",
        "\n",
        "    return total_loss / batch_size\n",
        "\"\"\"\n",
        "\n",
        "def hitrate_at_k(scores, labels, lengths, k=3, min_group_size=10):\n",
        "    batch_size = scores.size(0)\n",
        "    hits = 0\n",
        "    valid_count = 0\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        if l < min_group_size:\n",
        "            continue\n",
        "        length = min(l, k)\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "        _, topk_idx = torch.topk(s, length)\n",
        "        topk_labels = y[topk_idx]\n",
        "        hits += (topk_labels > 0).any().float()\n",
        "        valid_count += 1\n",
        "    return hits / valid_count if valid_count > 0 else torch.tensor(0.0, device=scores.device)\n",
        "\n",
        "\n",
        "def ndcg_at_k(scores, labels, lengths, k=3, min_group_size=10):\n",
        "    batch_size = scores.size(0)\n",
        "    total_ndcg = 0.0\n",
        "    valid_count = 0\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        if l < min_group_size:\n",
        "            continue\n",
        "\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "\n",
        "        _, idx_pred = torch.topk(s, min(k, l))\n",
        "        _, idx_ideal = torch.topk(y, min(k, l))\n",
        "\n",
        "        dcg = (y[idx_pred] / torch.log2(torch.arange(2, 2 + len(idx_pred), device=y.device).float())).sum()\n",
        "        idcg = (y[idx_ideal] / torch.log2(torch.arange(2, 2 + len(idx_ideal), device=y.device).float())).sum()\n",
        "\n",
        "        ndcg = dcg / idcg if idcg > 0 else 0.0\n",
        "        total_ndcg += ndcg\n",
        "        valid_count += 1\n",
        "\n",
        "    return total_ndcg / valid_count if valid_count > 0 else torch.tensor(0.0, device=scores.device)\n",
        "\n",
        "\n",
        "def map_at_k(scores, labels, lengths, k=3, min_group_size=10):\n",
        "    batch_size = scores.size(0)\n",
        "    total_ap = 0.0\n",
        "    valid_count = 0\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        if l < min_group_size:\n",
        "            continue\n",
        "\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "\n",
        "        _, idx_pred = torch.topk(s, min(k, l))\n",
        "        y_true = y[idx_pred] > 0\n",
        "\n",
        "        if y_true.sum() == 0:\n",
        "            continue\n",
        "\n",
        "        precisions = [(y_true[:j+1].float().sum() / (j+1)) for j in range(len(y_true)) if y_true[j]]\n",
        "        ap = torch.stack(precisions).mean()\n",
        "        total_ap += ap\n",
        "        valid_count += 1\n",
        "\n",
        "    return total_ap / valid_count if valid_count > 0 else torch.tensor(0.0, device=scores.device)\n",
        "\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "def listnet_loss(scores, labels, lengths):\n",
        "    batch_size = scores.size(0)\n",
        "    total_loss = 0.0\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "\n",
        "        s_softmax = torch.nn.functional.log_softmax(s, dim=0)\n",
        "        y_softmax = torch.nn.functional.softmax(y, dim=0)\n",
        "\n",
        "        loss = -torch.sum(y_softmax * s_softmax)\n",
        "        total_loss += loss\n",
        "\n",
        "    return total_loss / batch_size\n",
        "\"\"\"\n",
        "\n",
        "def ranknet_loss(scores, labels, lengths):\n",
        "    batch_size = scores.size(0)\n",
        "    total_loss = 0.0\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "\n",
        "        diff_scores = s.unsqueeze(1) - s.unsqueeze(0)\n",
        "        rel = y.unsqueeze(1) > y.unsqueeze(0)\n",
        "        label_diff = rel.float()\n",
        "\n",
        "        log_sigmoid = torch.nn.functional.logsigmoid(diff_scores)\n",
        "        pair_loss = -label_diff * log_sigmoid\n",
        "\n",
        "        total_loss += pair_loss.sum()\n",
        "\n",
        "    return total_loss / batch_size\n",
        "\n",
        "def xranknet_loss(scores, labels, lengths, temperature=1.0, margin=0.2, focus_topk=3):\n",
        "    \"\"\"\n",
        "    xRankNet with emphasis on top-K items (based on labels, not scores).\n",
        "    \"\"\"\n",
        "    batch_size = scores.size(0)\n",
        "    total_loss = 0.0\n",
        "    total_pairs = 0\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        if l < 2:\n",
        "            continue\n",
        "\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "\n",
        "        # Top-K mask based on ground truth labels\n",
        "        topk = min(focus_topk, l)\n",
        "        _, topk_idx = torch.topk(y, topk)\n",
        "        topk_mask = torch.zeros_like(y, dtype=torch.bool)\n",
        "        topk_mask[topk_idx] = True\n",
        "\n",
        "        # Create pairwise difference matrices\n",
        "        score_diff = s.unsqueeze(1) - s.unsqueeze(0)\n",
        "        label_diff = y.unsqueeze(1) - y.unsqueeze(0)\n",
        "\n",
        "        # valid pair: y_i > y_j and at least one of i, j is in top-K\n",
        "        valid_pairs = (label_diff > 0) & (\n",
        "            topk_mask.unsqueeze(1) | topk_mask.unsqueeze(0)\n",
        "        )\n",
        "\n",
        "        if valid_pairs.sum() == 0:\n",
        "            continue\n",
        "\n",
        "        importance = (label_diff.abs() * valid_pairs).float()\n",
        "\n",
        "        if margin > 0.0:\n",
        "            score_diff = score_diff - margin\n",
        "\n",
        "        score_diff = score_diff / temperature\n",
        "        pairwise_loss = -F.logsigmoid(score_diff) * importance\n",
        "\n",
        "        total_loss += pairwise_loss.sum()\n",
        "        total_pairs += importance.sum()\n",
        "\n",
        "    if total_pairs == 0:\n",
        "        return torch.tensor(0.0, device=scores.device, requires_grad=True)\n",
        "\n",
        "    return total_loss / total_pairs\n",
        "\n",
        "\n",
        "def bpr_loss(scores, labels, lengths):\n",
        "    batch_size = scores.size(0)\n",
        "    total_loss = 0.0\n",
        "    valid_batches = 0\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "\n",
        "        pos_mask = y > 0\n",
        "        neg_mask = y <= 0\n",
        "\n",
        "        pos_scores = s[pos_mask]\n",
        "        neg_scores = s[neg_mask]\n",
        "\n",
        "        if len(pos_scores) == 0 or len(neg_scores) == 0:\n",
        "            continue\n",
        "\n",
        "        pair_diff = pos_scores.unsqueeze(1) - neg_scores.unsqueeze(0)\n",
        "        loss = -F.logsigmoid(pair_diff).mean()\n",
        "        total_loss += loss\n",
        "        valid_batches += 1\n",
        "\n",
        "    return total_loss / valid_batches if valid_batches > 0 else torch.tensor(0.0, device=scores.device)\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "def lambdarank_loss(scores, labels, lengths, eps=1e-10):\n",
        "    batch_size = scores.size(0)\n",
        "    total_loss = 0.0\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "\n",
        "        if l < 2:\n",
        "            continue\n",
        "\n",
        "        _, rank_order = torch.sort(s, descending=True)\n",
        "        ideal_order = torch.sort(y, descending=True).indices\n",
        "\n",
        "        gain = 2 ** y - 1\n",
        "        discount = torch.log2(torch.arange(2, l + 2, device=y.device).float())\n",
        "\n",
        "        ideal_dcg = (gain[ideal_order] / discount).sum()\n",
        "        if ideal_dcg < eps:\n",
        "            continue\n",
        "\n",
        "        delta_ndcg = torch.zeros((l, l), device=y.device)\n",
        "\n",
        "        for i_idx in range(l):\n",
        "            for j_idx in range(l):\n",
        "                if y[i_idx] > y[j_idx]:\n",
        "                    change = (\n",
        "                        (1.0 / torch.log2(rank_order[i_idx] + 2.0))\n",
        "                        - (1.0 / torch.log2(rank_order[j_idx] + 2.0))\n",
        "                    ).abs()\n",
        "                    delta = (2 ** y[i_idx] - 2 ** y[j_idx]).abs() * change\n",
        "                    delta_ndcg[i_idx, j_idx] = delta / ideal_dcg\n",
        "\n",
        "        score_diffs = s.unsqueeze(1) - s.unsqueeze(0)\n",
        "        lambdas = -F.logsigmoid(score_diffs) * delta_ndcg\n",
        "        total_loss += lambdas.sum()\n",
        "\n",
        "    return total_loss / batch_size\n",
        "\"\"\"\n",
        "\n",
        "def train_one_epoch(model, loader, optimizer, device, scheduler):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "\n",
        "    for x_cat, x_num, y, lengths in tqdm(loader, desc=\"Training\", leave=False):\n",
        "        x_num, y = x_num.to(device), y.to(device)\n",
        "        if not isinstance(lengths, torch.Tensor):\n",
        "            lengths = torch.tensor(lengths)\n",
        "        lengths = lengths.detach().clone().to(device)\n",
        "        x_cat = {k: v.to(device) for k, v in x_cat.items()}\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        scores = model(x_cat, x_num)\n",
        "        loss_xrank = xranknet_loss(scores, y, lengths, temperature=1.0, margin=0.2, focus_topk=3)\n",
        "        loss_bpr = bpr_loss(scores, y, lengths)\n",
        "        loss = 0.8 * loss_xrank + 0.2 * loss_bpr\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    return total_loss / len(loader)\n",
        "\n",
        "\n",
        "def validate(model, loader, device, min_group_size=10):\n",
        "    model.eval()\n",
        "    total_hitrate = 0\n",
        "    total_ndcg = 0\n",
        "    total_map = 0\n",
        "    total_loss = 0\n",
        "    count = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for x_cat, x_num, y, lengths in tqdm(loader, desc=\"Validating\", leave=False):\n",
        "            x_num, y = x_num.to(device), y.to(device)\n",
        "            lengths = torch.tensor(lengths).to(device)\n",
        "            x_cat = {k: v.to(device) for k, v in x_cat.items()}\n",
        "\n",
        "            scores = model(x_cat, x_num)\n",
        "\n",
        "            hitrate = hitrate_at_k(scores, y, lengths, k=3, min_group_size=min_group_size)\n",
        "            ndcg = ndcg_at_k(scores, y, lengths, k=3, min_group_size=min_group_size)\n",
        "            map3 = map_at_k(scores, y, lengths, k=3, min_group_size=min_group_size)\n",
        "            loss_xrank = xranknet_loss(scores, y, lengths, temperature=1.0, margin=0.2, focus_topk=3)\n",
        "            loss_bpr = bpr_loss(scores, y, lengths)\n",
        "            loss = 0.8 * loss_xrank + 0.2 * loss_bpr\n",
        "\n",
        "            batch_size = scores.size(0)\n",
        "            total_hitrate += hitrate * batch_size\n",
        "            total_ndcg += ndcg * batch_size\n",
        "            total_map += map3 * batch_size\n",
        "            total_loss += loss.item() * batch_size\n",
        "            count += batch_size\n",
        "\n",
        "    return total_loss / count, total_hitrate / count, total_ndcg / count, total_map / count\n",
        "\n",
        "\n",
        "def build_cat_dims(X, cat_features):\n",
        "    cat_dims = {}\n",
        "    for c in cat_features:\n",
        "        max_val = X[c].max()\n",
        "        if max_val < 0:\n",
        "            max_val = 0\n",
        "        cat_dims[c] = max_val + 1\n",
        "    return cat_dims\n",
        "\n",
        "\n",
        "def normalize_numeric_features(X, numeric_features, train_mask):\n",
        "    for col in numeric_features:\n",
        "        values = X[col].to_numpy()\n",
        "        train_vals = values[train_mask]\n",
        "        mean = train_vals.mean()\n",
        "        std = train_vals.std() if train_vals.std() > 0 else 1.0\n",
        "        norm_vals = (values - mean) / std\n",
        "        X = X.with_columns(pl.Series(col, norm_vals).alias(col))\n",
        "    return X\n",
        "\n",
        "\n",
        "def load_or_prepare_data(\n",
        "    data_dir,\n",
        "    train_file=\"train.parquet\",\n",
        "    test_file=\"test.parquet\",\n",
        "    cache_file=\"feature_engineered_val.parquet\",\n",
        "):\n",
        "    cache_path = os.path.join(data_dir, cache_file)\n",
        "\n",
        "    if os.path.exists(cache_path):\n",
        "        print(f\"Loading cached feature-engineered data from {cache_path} ...\")\n",
        "        df = pl.read_parquet(cache_path)\n",
        "\n",
        "        test = pl.read_parquet(os.path.join(data_dir, test_file)).drop(\"__index_level_0__\")\n",
        "        test_ids = test[\"Id\"]\n",
        "        test_rankers = test[\"ranker_id\"]\n",
        "    else:\n",
        "        print(\"Cached file not found, processing raw data ...\")\n",
        "\n",
        "        train = pl.read_parquet(os.path.join(data_dir, train_file)).drop(\"__index_level_0__\")\n",
        "        test = (\n",
        "            pl.read_parquet(os.path.join(data_dir, test_file))\n",
        "            .drop(\"__index_level_0__\")\n",
        "            .with_columns(pl.lit(0, dtype=pl.Int64).alias(\"selected\"))\n",
        "        )\n",
        "\n",
        "        test_ids = test[\"Id\"]\n",
        "        test_rankers = test[\"ranker_id\"]\n",
        "\n",
        "        df = pl.concat((train, test))\n",
        "        df = feature_engineering(df, full=True)\n",
        "\n",
        "        df = df.with_columns(\n",
        "            [pl.col(c).fill_null(0) for c in df.select(pl.selectors.numeric()).columns] +\n",
        "            [pl.col(c).fill_null(\"missing\") for c in df.select(pl.selectors.string()).columns]\n",
        "        )\n",
        "\n",
        "        os.makedirs(data_dir, exist_ok=True)\n",
        "        df.write_parquet(cache_path)\n",
        "        print(f\"Saved feature-engineered data to {cache_path}\")\n",
        "\n",
        "    return df, test_ids, test_rankers\n",
        "\n",
        "\n",
        "def prepare_data(data_dir):\n",
        "    df, test_ids, test_rankers = load_or_prepare_data(data_dir)\n",
        "\n",
        "    id_column = df[\"Id\"]\n",
        "    X, y, groups, cat_features, num_features = feature_selection(df)\n",
        "\n",
        "    X = X.with_columns(pl.Series(\"Id\", id_column[:X.shape[0]]))\n",
        "\n",
        "    X = X.with_columns(\n",
        "        [\n",
        "            (pl.col(c).rank(\"dense\") - 1).fill_null(-1).cast(pl.Int32)\n",
        "            for c in cat_features\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    train_size = 18145372\n",
        "    train_mask = np.arange(X.height) < train_size\n",
        "    X = normalize_numeric_features(X, num_features, train_mask)\n",
        "\n",
        "    return X, y, groups, cat_features, num_features, train_size, test_ids, test_rankers\n",
        "\n",
        "\n",
        "class EarlyStopping:\n",
        "    def __init__(self, patience=3, min_delta=0.00005):\n",
        "        self.patience = patience\n",
        "        self.min_delta = min_delta\n",
        "        self.best = float(\"-inf\")\n",
        "        self.counter = 0\n",
        "\n",
        "    def step(self, metric):\n",
        "        if metric > self.best + self.min_delta:\n",
        "            self.best = metric\n",
        "            self.counter = 0\n",
        "        else:\n",
        "            self.counter += 1\n",
        "        return self.counter >= self.patience\n",
        "\n",
        "\n",
        "def plot_group_size_distribution(dataset, save_path=None):\n",
        "    group_sizes = [len(v) for v in dataset.group_to_indices.values()]\n",
        "    plt.figure()\n",
        "    plt.hist(group_sizes, bins=100, log=True)\n",
        "    plt.xlabel(\"Group size (number of items per ranker_id)\")\n",
        "    plt.ylabel(\"Frequency (log scale)\")\n",
        "    plt.title(\"Distribution of Group Sizes\")\n",
        "    plt.grid(True)\n",
        "    if save_path:\n",
        "        plt.savefig(save_path)\n",
        "    else:\n",
        "        plt.show()\n",
        "    plt.close()\n",
        "\n",
        "\n",
        "def main():\n",
        "    DATA_DIR = \"./data\"\n",
        "    MODEL_DIR = \"model\"\n",
        "    SUBMIT_DIR = \"submission\"\n",
        "\n",
        "    best_val_loss = float(\"inf\")\n",
        "    best_hitrate = 0.0\n",
        "    model_path = os.path.join(MODEL_DIR, \"best_dl_ranker.pt\")\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "    val_hitrates = []\n",
        "    val_ndcgs = []\n",
        "    val_maps = []\n",
        "    learning_rates = []\n",
        "\n",
        "    os.makedirs(MODEL_DIR, exist_ok=True)\n",
        "    os.makedirs(SUBMIT_DIR, exist_ok=True)\n",
        "\n",
        "    early_stopper = EarlyStopping(patience=3, min_delta=0.001)\n",
        "\n",
        "    X, y, groups, cat_features, num_features, train_size, test_ids, test_rankers = prepare_data(DATA_DIR)\n",
        "\n",
        "    # Fill missing values\n",
        "    float_cols = [c for c, t in zip(X.columns, X.dtypes) if t == pl.Float64]\n",
        "    for col in float_cols:\n",
        "        X = X.with_columns(\n",
        "            pl.when(pl.col(col).is_nan()).then(0).otherwise(pl.col(col)).alias(col)\n",
        "        )\n",
        "\n",
        "    n1 = 16487352\n",
        "    # n1 = 17487300\n",
        "    n2 = train_size\n",
        "\n",
        "    X_tr, X_va, X_te = X[:n1], X[n1:n2], X[n2:]\n",
        "    y_tr, y_va, y_te = y[:n1], y[n1:n2], y[n2:]\n",
        "    groups_tr, groups_va, groups_te = groups[:n1], groups[n1:n2], groups[n2:]\n",
        "\n",
        "    # Inspect group sizes in validation set\n",
        "    val_rankers = groups_va[\"ranker_id\"].to_numpy()\n",
        "    val_group_counts = Counter(val_rankers)\n",
        "\n",
        "    print(\"\\nüìã Validation group statistics:\")\n",
        "    # Save detailed group info to file\n",
        "    group_info_path = os.path.join(MODEL_DIR, \"validation_groups_info.txt\")\n",
        "    with open(group_info_path, \"w\") as f:\n",
        "        f.write(f\"Total groups: {len(val_group_counts)}\\n\\n\")\n",
        "        f.write(\"GroupID\\tSize\\tStartIdx\\tEndIdx\\n\")\n",
        "\n",
        "        group_to_rows = defaultdict(list)\n",
        "        for i, g in enumerate(val_rankers):\n",
        "            group_to_rows[g].append(i)\n",
        "\n",
        "        for group_id, indices in sorted(group_to_rows.items()):\n",
        "            start_idx = indices[0]\n",
        "            end_idx = indices[-1]\n",
        "            size = len(indices)\n",
        "            f.write(f\"{group_id}\\t{size}\\t{start_idx}\\t{end_idx}\\n\")\n",
        "\n",
        "    print(f\"üìÅ Saved validation group info to {group_info_path}\")\n",
        "\n",
        "\n",
        "    cat_dims = build_cat_dims(X, cat_features)\n",
        "    num_numeric_feats = len(num_features)\n",
        "\n",
        "    train_dataset = RankDataset(X_tr, y_tr, groups_tr, cat_features, num_features)\n",
        "    val_dataset = RankDataset(X_va, y_va, groups_va, cat_features, num_features)\n",
        "    test_dataset = RankDataset(X_te, y_te, groups_te, cat_features, num_features)\n",
        "\n",
        "    plot_group_size_distribution(train_dataset, save_path=os.path.join(MODEL_DIR, \"group_sizes.png\"))\n",
        "    print(\"üìä Group size distribution saved.\")\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=2, shuffle=True, collate_fn=collate_fn)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=2, shuffle=False, collate_fn=collate_fn)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=4, shuffle=False, collate_fn=collate_fn)\n",
        "\n",
        "    print(\"‚úÖ Data loaders created.\")\n",
        "\n",
        "    num_epochs = 10\n",
        "    num_training_steps = num_epochs * len(train_loader)\n",
        "    num_warmup_steps = int(0.1 * num_training_steps)\n",
        "\n",
        "    learning_rate = 3e-4\n",
        "\n",
        "    model = DLRankerAttention(\n",
        "        cat_dims=cat_dims,\n",
        "        num_numeric_feats=num_numeric_feats,\n",
        "        emb_dropout=0.1,\n",
        "        dropout=0.1,\n",
        "        num_heads=4,\n",
        "        num_layers=2,\n",
        "        dim_feedforward=128,\n",
        "        proj_dim=64\n",
        "    ).to(device)\n",
        "\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=0.01)\n",
        "\n",
        "    scheduler = OneCycleLR(\n",
        "        optimizer,\n",
        "        max_lr=learning_rate,\n",
        "        steps_per_epoch=len(train_loader),\n",
        "        epochs=num_epochs,\n",
        "        pct_start=0.3,\n",
        "    )\n",
        "\n",
        "    best_hitrate = 0\n",
        "    for epoch in range(num_epochs):\n",
        "        print(f\"\\n--- Epoch {epoch+1}/{num_epochs} ---\")\n",
        "        start_time = time.time()\n",
        "\n",
        "        train_loss = train_one_epoch(model, train_loader, optimizer, device, scheduler)\n",
        "        val_loss, val_hitrate, val_ndcg, val_map = validate(model, val_loader, device, min_group_size=10)\n",
        "\n",
        "        train_losses.append(train_loss)\n",
        "        val_losses.append(val_loss)\n",
        "        val_hitrates.append(val_hitrate.item())\n",
        "        val_ndcgs.append(val_ndcg.item())\n",
        "        val_maps.append(val_map.item())\n",
        "\n",
        "        current_lr = scheduler.get_last_lr()\n",
        "        learning_rates.append(current_lr[0])\n",
        "\n",
        "        elapsed = time.time() - start_time\n",
        "        print(\n",
        "            f\"Epoch {epoch+1}: \"\n",
        "            f\"Train Loss={train_loss:.4f}, \"\n",
        "            f\"Val Loss={val_loss:.4f}, \"\n",
        "            f\"HitRate@3={val_hitrate:.4f}, \"\n",
        "            f\"NDCG@3={val_ndcg:.4f}, \"\n",
        "            f\"MAP@3={val_map:.4f}, \"\n",
        "            f\"LR={current_lr[0]:.6f} \"\n",
        "            f\"({elapsed:.1f}s)\"\n",
        "        )\n",
        "\n",
        "\n",
        "        if val_loss < best_val_loss and val_hitrate > best_hitrate:\n",
        "            best_val_loss = val_loss\n",
        "            best_hitrate = val_hitrate\n",
        "            torch.save(model.state_dict(), model_path)\n",
        "            print(\"üíæ Model improved (loss ‚Üì and hitrate ‚Üë), saved.\")\n",
        "\n",
        "        if early_stopper.step(-val_loss):\n",
        "            print(\"‚õî Early stopping triggered.\")\n",
        "            break\n",
        "\n",
        "    # Plot metrics\n",
        "    epochs = list(range(1, len(train_losses) + 1))\n",
        "\n",
        "    # Plot Loss Curve\n",
        "    plt.figure()\n",
        "    plt.plot(epochs, train_losses, label=\"Train Loss\")\n",
        "    plt.plot(epochs, val_losses, label=\"Val Loss\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.title(\"Training & Validation Loss\")\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.savefig(os.path.join(MODEL_DIR, \"loss_curve.png\"))\n",
        "    plt.close()\n",
        "\n",
        "    # Plot HitRate@3\n",
        "    plt.figure()\n",
        "    plt.plot(epochs, val_hitrates, label=\"Val HitRate@3\", color=\"green\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"HitRate@3\")\n",
        "    plt.title(\"Validation HitRate@3\")\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.savefig(os.path.join(MODEL_DIR, \"hitrate_curve.png\"))\n",
        "    plt.close()\n",
        "\n",
        "    # Plot Learning Rate\n",
        "    plt.figure()\n",
        "    plt.plot(epochs, learning_rates, label=\"Learning Rate\", color=\"orange\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"LR\")\n",
        "    plt.title(\"Learning Rate Schedule\")\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.savefig(os.path.join(MODEL_DIR, \"lr_curve.png\"))\n",
        "    plt.close()\n",
        "\n",
        "    # Plot NDCG@3\n",
        "    plt.figure()\n",
        "    plt.plot(epochs, val_ndcgs, label=\"Val NDCG@3\", color=\"purple\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"NDCG@3\")\n",
        "    plt.title(\"Validation NDCG@3\")\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.savefig(os.path.join(MODEL_DIR, \"ndcg_curve.png\"))\n",
        "    plt.close()\n",
        "\n",
        "    # Plot MAP@3\n",
        "    plt.figure()\n",
        "    plt.plot(epochs, val_maps, label=\"Val MAP@3\", color=\"red\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"MAP@3\")\n",
        "    plt.title(\"Validation MAP@3\")\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.savefig(os.path.join(MODEL_DIR, \"map_curve.png\"))\n",
        "    plt.close()\n",
        "\n",
        "    print(\"üìä Saved metric plots to model/\")\n",
        "\n",
        "    # Predict test set\n",
        "    model.load_state_dict(torch.load(model_path))\n",
        "    model.eval()\n",
        "\n",
        "    val_ids = X_va[\"Id\"]\n",
        "    val_rankers = groups_va[\"ranker_id\"]\n",
        "    val_labels = y_va\n",
        "\n",
        "    all_val_scores = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for x_cat, x_num, _, lengths in tqdm(val_loader, desc=\"Predicting validation set\"):\n",
        "            x_num = x_num.to(device)\n",
        "            x_cat = {k: v.to(device) for k, v in x_cat.items()}\n",
        "            scores = model(x_cat, x_num)\n",
        "\n",
        "            for i in range(scores.size(0)):\n",
        "                l = lengths[i]\n",
        "                all_val_scores.append(scores[i, :l].cpu().numpy())\n",
        "\n",
        "    all_val_scores = np.concatenate(all_val_scores)\n",
        "\n",
        "    assert len(all_val_scores) == X_va.shape[0], \\\n",
        "        f\"Mismatch: {len(all_val_scores)} scores vs {X_va.shape[0]} rows\"\n",
        "\n",
        "    val_df = X_va.with_columns([\n",
        "        pl.Series(\"Id\", val_ids),\n",
        "        pl.Series(\"ranker_id\", val_rankers),\n",
        "        pl.Series(\"score\", all_val_scores),\n",
        "        pl.Series(\"label\", val_labels)\n",
        "    ])\n",
        "\n",
        "    val_df = val_df.with_columns(\n",
        "        pl.col(\"score\")\n",
        "        .rank(method=\"ordinal\", descending=True)\n",
        "        .over(\"ranker_id\")\n",
        "        .cast(pl.Int32)\n",
        "        .alias(\"selected\")\n",
        "    )\n",
        "\n",
        "    val_save_path = os.path.join(MODEL_DIR, \"validation_preds_dl_full.csv\")\n",
        "    val_df.write_csv(val_save_path)\n",
        "    print(f\"‚úÖ Saved full validation predictions (with features) to {val_save_path}\")\n",
        "\n",
        "    all_scores = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for x_cat, x_num, _, lengths in tqdm(test_loader, desc=\"Predicting test set\"):\n",
        "            x_num = x_num.to(device)\n",
        "            x_cat = {k: v.to(device) for k, v in x_cat.items()}\n",
        "            scores = model(x_cat, x_num)\n",
        "\n",
        "            for i in range(scores.size(0)):\n",
        "                l = lengths[i]\n",
        "                all_scores.append(scores[i, :l].cpu().numpy())\n",
        "\n",
        "    all_scores = np.concatenate(all_scores)\n",
        "\n",
        "    assert len(all_scores) == X_te.shape[0], \\\n",
        "        f\"Mismatch: {len(all_scores)} scores vs {X_te.shape[0]} rows in X_te\"\n",
        "\n",
        "    submission_df = pl.DataFrame({\n",
        "        \"Id\": test_ids,\n",
        "        \"ranker_id\": test_rankers,\n",
        "        \"score\": all_scores\n",
        "    })\n",
        "\n",
        "    submission = (\n",
        "        submission_df\n",
        "        .with_columns(\n",
        "            pl.col(\"score\")\n",
        "            .rank(method=\"ordinal\", descending=True)\n",
        "            .over(\"ranker_id\")\n",
        "            .cast(pl.Int32)\n",
        "            .alias(\"selected\")\n",
        "        )\n",
        "        .select([\"Id\", \"ranker_id\", \"score\", \"selected\"])\n",
        "    )\n",
        "\n",
        "    submission_path = os.path.join(SUBMIT_DIR, \"submission_dl_ranker.csv\")\n",
        "    submission.write_csv(submission_path)\n",
        "    print(f\"‚úÖ Submission saved to {submission_path}\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WATbk1Do2l6q",
        "outputId": "fef42746-03f7-4106-be79-ba5ab8656d15"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting deeprec_validate.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "--- Epoch 1/10 ---\n",
        "Validating:   0%|          | 0/5271 [00:00<?, ?it/s]/home/ionut/test_whisper/test2/deeprec_validate.py:548: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
        "  lengths = torch.tensor(lengths).to(device)\n",
        "Epoch 1: Train Loss=0.3237, Val Loss=0.2817, HitRate@3=0.4741, NDCG@3=0.3777, MAP@3=0.4713, LR=0.000084 (704.4s)\n",
        "üíæ Model improved (loss ‚Üì and hitrate ‚Üë), saved.\n",
        "\n",
        "--- Epoch 2/10 ---\n",
        "Epoch 2: Train Loss=0.2787, Val Loss=0.2757, HitRate@3=0.4745, NDCG@3=0.3811, MAP@3=0.4802, LR=0.000228 (704.8s)\n",
        "üíæ Model improved (loss ‚Üì and hitrate ‚Üë), saved.\n",
        "\n",
        "--- Epoch 3/10 ---\n",
        "Epoch 3: Train Loss=0.2752, Val Loss=0.2666, HitRate@3=0.4797, NDCG@3=0.3843, MAP@3=0.4793, LR=0.000300 (704.7s)\n",
        "üíæ Model improved (loss ‚Üì and hitrate ‚Üë), saved.\n",
        "\n",
        "--- Epoch 4/10 ---\n",
        "Epoch 4: Train Loss=0.2670, Val Loss=0.2687, HitRate@3=0.4779, NDCG@3=0.3859, MAP@3=0.4843, LR=0.000285 (704.3s)\n",
        "\n",
        "--- Epoch 5/10 ---\n",
        "Epoch 5: Train Loss=0.2574, Val Loss=0.2619, HitRate@3=0.4943, NDCG@3=0.3993, MAP@3=0.4953, LR=0.000244 (705.1s)\n",
        "üíæ Model improved (loss ‚Üì and hitrate ‚Üë), saved.\n",
        "\n",
        "--- Epoch 6/10 ---\n",
        "Epoch 6: Train Loss=0.2471, Val Loss=0.2546, HitRate@3=0.4929, NDCG@3=0.3953, MAP@3=0.4882, LR=0.000183 (705.4s)\n",
        "\n",
        "--- Epoch 7/10 ---\n",
        "Epoch 7: Train Loss=0.2375, Val Loss=0.2474, HitRate@3=0.5009, NDCG@3=0.4054, MAP@3=0.5024, LR=0.000117 (704.9s)\n",
        "üíæ Model improved (loss ‚Üì and hitrate ‚Üë), saved.\n",
        "\n",
        "--- Epoch 8/10 ---\n",
        "Epoch 8: Train Loss=0.2256, Val Loss=0.2428, HitRate@3=0.5071, NDCG@3=0.4120, MAP@3=0.5097, LR=0.000056 (705.4s)\n",
        "üíæ Model improved (loss ‚Üì and hitrate ‚Üë), saved.\n",
        "\n",
        "--- Epoch 9/10 ---\n",
        "Epoch 9: Train Loss=0.2163, Val Loss=0.2407, HitRate@3=0.5057, NDCG@3=0.4102, MAP@3=0.5077, LR=0.000015 (705.6s)\n",
        "\n",
        "--- Epoch 10/10 ---\n",
        "Epoch 10: Train Loss=0.2115, Val Loss=0.2413, HitRate@3=0.5083, NDCG@3=0.4108, MAP@3=0.5073, LR=0.000000 (706.1s)\n",
        "üíæ Model improved (loss ‚Üì and hitrate ‚Üë), saved."
      ],
      "metadata": {
        "id": "ULyi6jBremgP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile deeprec_validate.py\n",
        "import os\n",
        "import time\n",
        "import random\n",
        "import torch\n",
        "import math\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import defaultdict\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "import polars as pl\n",
        "from tqdm import tqdm\n",
        "from src.feature import feature_engineering, feature_selection\n",
        "from transformers import get_scheduler\n",
        "from collections import Counter\n",
        "from torch.optim.lr_scheduler import OneCycleLR\n",
        "\n",
        "seed = 42\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "class RankDataset(Dataset):\n",
        "    def __init__(\n",
        "        self,\n",
        "        X: pl.DataFrame,\n",
        "        y: pl.Series,\n",
        "        groups: pl.DataFrame,\n",
        "        cat_features: list[str],\n",
        "        num_features: list[str],\n",
        "    ):\n",
        "        self.cat_features = cat_features\n",
        "        self.num_features = num_features\n",
        "        self.X_cat = {c: X[c].to_numpy() for c in cat_features}\n",
        "        self.X_num = X[self.num_features].to_numpy()\n",
        "        self.y = y.to_numpy()\n",
        "        self.groups = groups[\"ranker_id\"].to_numpy()\n",
        "\n",
        "        self.group_to_indices = defaultdict(list)\n",
        "        for i, g in enumerate(self.groups):\n",
        "            self.group_to_indices[g].append(i)\n",
        "        self.group_keys = list(self.group_to_indices.keys())\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.group_keys)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        g = self.group_keys[idx]\n",
        "        inds = self.group_to_indices[g]\n",
        "        length = len(inds)\n",
        "\n",
        "        x_cat = {\n",
        "            c: torch.LongTensor([\n",
        "                self.X_cat[c][i] if self.X_cat[c][i] >= 0 else 0 for i in inds\n",
        "            ])\n",
        "            for c in self.cat_features\n",
        "        }\n",
        "\n",
        "        x_num = torch.FloatTensor(self.X_num[inds])\n",
        "        y = torch.FloatTensor(self.y[inds]).reshape(-1)\n",
        "\n",
        "        return x_cat, x_num, y, length\n",
        "\n",
        "def collate_fn(batch):\n",
        "    batch_size = len(batch)\n",
        "    lengths = [b[3] for b in batch]\n",
        "    max_len = max(lengths)\n",
        "\n",
        "    padded_x_cat = {key: [] for key in batch[0][0].keys()}\n",
        "    padded_x_num = []\n",
        "    padded_y = []\n",
        "\n",
        "    num_dim = batch[0][1].shape[1]\n",
        "\n",
        "    for x_cat, x_num, y, length in batch:\n",
        "        pad_len = max_len - length\n",
        "\n",
        "        for key in padded_x_cat:\n",
        "            val = x_cat[key]\n",
        "            if pad_len > 0:\n",
        "                val = torch.cat([val, torch.zeros(pad_len, dtype=torch.long)])\n",
        "            padded_x_cat[key].append(val)\n",
        "\n",
        "        if pad_len > 0:\n",
        "            x_num = torch.cat([x_num, torch.zeros(pad_len, num_dim)])\n",
        "            y = torch.cat([y, torch.zeros(pad_len)])\n",
        "\n",
        "        padded_x_num.append(x_num)\n",
        "        padded_y.append(y)\n",
        "\n",
        "    padded_x_cat = {k: torch.stack(v) for k, v in padded_x_cat.items()}\n",
        "    padded_x_num = torch.stack(padded_x_num)\n",
        "    padded_y = torch.stack(padded_y)\n",
        "    lengths = torch.tensor(lengths, dtype=torch.long)\n",
        "\n",
        "    return padded_x_cat, padded_x_num, padded_y, lengths\n",
        "\n",
        "class SEModule(nn.Module):\n",
        "    def __init__(self, channel, reduction=4):\n",
        "        super().__init__()\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(channel, channel // reduction),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(channel // reduction, channel),\n",
        "            nn.Sigmoid(),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: [B, N, C]\n",
        "        w = self.fc(x.mean(dim=1))\n",
        "        w = w.unsqueeze(1)  # [B, 1, C]\n",
        "        return x * w\n",
        "\n",
        "\n",
        "class FiLM(nn.Module):\n",
        "    def __init__(self, feature_dim):\n",
        "        super().__init__()\n",
        "        self.gamma = nn.Linear(feature_dim, feature_dim)\n",
        "        self.beta = nn.Linear(feature_dim, feature_dim)\n",
        "\n",
        "    def forward(self, x, cond):\n",
        "        gamma = self.gamma(cond)\n",
        "        beta = self.beta(cond)\n",
        "        return gamma * x + beta\n",
        "\n",
        "\n",
        "class DLRankerAttention(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        cat_dims,\n",
        "        num_numeric_feats,\n",
        "        emb_dropout=0.1,\n",
        "        dropout=0.1,\n",
        "        num_heads=4,\n",
        "        num_layers=2,\n",
        "        dim_feedforward=128,\n",
        "        proj_dim=64,\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "        self.emb_dims = {\n",
        "            f: min(50, max(4, round(6 * math.log2(cat_dims[f] + 1)))) for f in cat_dims\n",
        "        }\n",
        "        self.embeddings = nn.ModuleDict({\n",
        "            f: nn.Embedding(cat_dims[f], self.emb_dims[f], padding_idx=0)\n",
        "            for f in cat_dims\n",
        "        })\n",
        "        self.emb_dropout = nn.Dropout(emb_dropout)\n",
        "\n",
        "        total_emb_dim = sum(self.emb_dims.values())\n",
        "        print(f\"Categorial emb dim sum: {total_emb_dim}, Numerical dim: {num_numeric_feats}\")\n",
        "\n",
        "        self.cat_proj = nn.Linear(total_emb_dim, proj_dim)\n",
        "        self.cat_transformer = nn.TransformerEncoder(\n",
        "            nn.TransformerEncoderLayer(\n",
        "                d_model=proj_dim,\n",
        "                nhead=4,\n",
        "                dim_feedforward=dim_feedforward,\n",
        "                dropout=dropout,\n",
        "                batch_first=True,\n",
        "            ),\n",
        "            num_layers=1,\n",
        "        )\n",
        "\n",
        "        self.num_proj_in = nn.Linear(num_numeric_feats, proj_dim)\n",
        "        self.num_transformer = nn.TransformerEncoder(\n",
        "            nn.TransformerEncoderLayer(\n",
        "                d_model=proj_dim,\n",
        "                nhead=4,\n",
        "                dim_feedforward=dim_feedforward,\n",
        "                dropout=dropout,\n",
        "                batch_first=True,\n",
        "            ),\n",
        "            num_layers=1,\n",
        "        )\n",
        "        self.num_se = SEModule(proj_dim)\n",
        "        self.num_proj_out = nn.Sequential(\n",
        "            nn.Linear(proj_dim, proj_dim),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(dropout),\n",
        "        )\n",
        "\n",
        "        # üîÅ Cross-attention: cat attends to num\n",
        "        self.cross_attn_cat2num = nn.MultiheadAttention(\n",
        "            embed_dim=proj_dim,\n",
        "            num_heads=4,\n",
        "            dropout=dropout,\n",
        "            batch_first=True,\n",
        "        )\n",
        "\n",
        "        self.film = FiLM(proj_dim)  # üîß FiLM added here\n",
        "\n",
        "        self.transformer_layers = nn.ModuleList([\n",
        "            nn.TransformerEncoderLayer(\n",
        "                d_model=2 * proj_dim,\n",
        "                nhead=num_heads,\n",
        "                dim_feedforward=dim_feedforward,\n",
        "                dropout=dropout,\n",
        "                batch_first=True,\n",
        "            )\n",
        "            for _ in range(num_layers)\n",
        "        ])\n",
        "\n",
        "        self.mlp = nn.Sequential(\n",
        "            nn.Linear(2 * proj_dim, 128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(128, 64),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(64, 1),\n",
        "        )\n",
        "\n",
        "    def forward(self, x_cat: dict, x_num: torch.Tensor, attn_mask=None):\n",
        "        B, N, _ = x_num.shape  # x_num: [B, N, F_num]\n",
        "\n",
        "        # Categorical embeddings\n",
        "        cat_embs = torch.cat([self.embeddings[f](x_cat[f]) for f in x_cat], dim=-1)\n",
        "        cat_embs = self.emb_dropout(cat_embs)\n",
        "        cat_feat = self.cat_proj(cat_embs)  # [B, N, D]\n",
        "        cat_feat = self.cat_transformer(cat_feat)  # [B, N, D]\n",
        "\n",
        "        # Numeric features\n",
        "        num_feat = self.num_proj_in(x_num)\n",
        "        num_feat = self.num_transformer(num_feat)\n",
        "        num_feat = self.num_se(num_feat)\n",
        "        num_feat = self.num_proj_out(num_feat)\n",
        "\n",
        "        # üîß FiLM: condition cat_feat on num_feat\n",
        "        cat_feat = self.film(cat_feat, num_feat)\n",
        "\n",
        "        # Cross-attention: categorical features attend over numeric ones\n",
        "        cat_feat_attn, _ = self.cross_attn_cat2num(\n",
        "            query=cat_feat, key=num_feat, value=num_feat\n",
        "        )\n",
        "        cat_feat = cat_feat + cat_feat_attn  # residual connection\n",
        "\n",
        "        # Final concatenation\n",
        "        x = torch.cat([cat_feat, num_feat], dim=-1)\n",
        "\n",
        "        for layer in self.transformer_layers:\n",
        "            x = layer(x, src_key_padding_mask=attn_mask)\n",
        "\n",
        "        scores = self.mlp(x).squeeze(-1)  # [B, N]\n",
        "        return scores\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "def listmle_loss(scores, labels, lengths):\n",
        "    batch_size = scores.size(0)\n",
        "    total_loss = torch.tensor(0.0, device=scores.device, requires_grad=True)\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "\n",
        "        _, idx = torch.sort(y, descending=True)\n",
        "        s_sorted = s[idx]\n",
        "\n",
        "        parts = (\n",
        "            torch.logsumexp(s_sorted.unsqueeze(0).expand(l, -1).triu(diagonal=0), dim=1)\n",
        "            - s_sorted\n",
        "        )\n",
        "\n",
        "        total_loss = total_loss + parts.sum()\n",
        "\n",
        "    return total_loss / batch_size\n",
        "\"\"\"\n",
        "\n",
        "def hitrate_at_k(scores, labels, lengths, k=3, min_group_size=10):\n",
        "    batch_size = scores.size(0)\n",
        "    hits = 0\n",
        "    valid_count = 0\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        if l < min_group_size:\n",
        "            continue\n",
        "        length = min(l, k)\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "        _, topk_idx = torch.topk(s, length)\n",
        "        topk_labels = y[topk_idx]\n",
        "        hits += (topk_labels > 0).any().float()\n",
        "        valid_count += 1\n",
        "    return hits / valid_count if valid_count > 0 else torch.tensor(0.0, device=scores.device)\n",
        "\n",
        "\n",
        "def ndcg_at_k(scores, labels, lengths, k=3, min_group_size=10):\n",
        "    batch_size = scores.size(0)\n",
        "    total_ndcg = 0.0\n",
        "    valid_count = 0\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        if l < min_group_size:\n",
        "            continue\n",
        "\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "\n",
        "        _, idx_pred = torch.topk(s, min(k, l))\n",
        "        _, idx_ideal = torch.topk(y, min(k, l))\n",
        "\n",
        "        dcg = (y[idx_pred] / torch.log2(torch.arange(2, 2 + len(idx_pred), device=y.device).float())).sum()\n",
        "        idcg = (y[idx_ideal] / torch.log2(torch.arange(2, 2 + len(idx_ideal), device=y.device).float())).sum()\n",
        "\n",
        "        ndcg = dcg / idcg if idcg > 0 else 0.0\n",
        "        total_ndcg += ndcg\n",
        "        valid_count += 1\n",
        "\n",
        "    return total_ndcg / valid_count if valid_count > 0 else torch.tensor(0.0, device=scores.device)\n",
        "\n",
        "\n",
        "def map_at_k(scores, labels, lengths, k=3, min_group_size=10):\n",
        "    batch_size = scores.size(0)\n",
        "    total_ap = 0.0\n",
        "    valid_count = 0\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        if l < min_group_size:\n",
        "            continue\n",
        "\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "\n",
        "        _, idx_pred = torch.topk(s, min(k, l))\n",
        "        y_true = y[idx_pred] > 0\n",
        "\n",
        "        if y_true.sum() == 0:\n",
        "            continue\n",
        "\n",
        "        precisions = [(y_true[:j+1].float().sum() / (j+1)) for j in range(len(y_true)) if y_true[j]]\n",
        "        ap = torch.stack(precisions).mean()\n",
        "        total_ap += ap\n",
        "        valid_count += 1\n",
        "\n",
        "    return total_ap / valid_count if valid_count > 0 else torch.tensor(0.0, device=scores.device)\n",
        "\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "def listnet_loss(scores, labels, lengths):\n",
        "    batch_size = scores.size(0)\n",
        "    total_loss = 0.0\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "\n",
        "        s_softmax = torch.nn.functional.log_softmax(s, dim=0)\n",
        "        y_softmax = torch.nn.functional.softmax(y, dim=0)\n",
        "\n",
        "        loss = -torch.sum(y_softmax * s_softmax)\n",
        "        total_loss += loss\n",
        "\n",
        "    return total_loss / batch_size\n",
        "\"\"\"\n",
        "\n",
        "def ranknet_loss(scores, labels, lengths):\n",
        "    batch_size = scores.size(0)\n",
        "    total_loss = 0.0\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "\n",
        "        diff_scores = s.unsqueeze(1) - s.unsqueeze(0)\n",
        "        rel = y.unsqueeze(1) > y.unsqueeze(0)\n",
        "        label_diff = rel.float()\n",
        "\n",
        "        log_sigmoid = torch.nn.functional.logsigmoid(diff_scores)\n",
        "        pair_loss = -label_diff * log_sigmoid\n",
        "\n",
        "        total_loss += pair_loss.sum()\n",
        "\n",
        "    return total_loss / batch_size\n",
        "\n",
        "def xranknet_loss(scores, labels, lengths, temperature=1.0, margin=0.2, focus_topk=3):\n",
        "    \"\"\"\n",
        "    xRankNet with emphasis on top-K items (based on labels, not scores).\n",
        "    \"\"\"\n",
        "    batch_size = scores.size(0)\n",
        "    total_loss = 0.0\n",
        "    total_pairs = 0\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        if l < 2:\n",
        "            continue\n",
        "\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "\n",
        "        # Top-K mask based on ground truth labels\n",
        "        topk = min(focus_topk, l)\n",
        "        _, topk_idx = torch.topk(y, topk)\n",
        "        topk_mask = torch.zeros_like(y, dtype=torch.bool)\n",
        "        topk_mask[topk_idx] = True\n",
        "\n",
        "        # Create pairwise difference matrices\n",
        "        score_diff = s.unsqueeze(1) - s.unsqueeze(0)\n",
        "        label_diff = y.unsqueeze(1) - y.unsqueeze(0)\n",
        "\n",
        "        # valid pair: y_i > y_j and at least one of i, j is in top-K\n",
        "        valid_pairs = (label_diff > 0) & (\n",
        "            topk_mask.unsqueeze(1) | topk_mask.unsqueeze(0)\n",
        "        )\n",
        "\n",
        "        if valid_pairs.sum() == 0:\n",
        "            continue\n",
        "\n",
        "        importance = (label_diff.abs() * valid_pairs).float()\n",
        "\n",
        "        if margin > 0.0:\n",
        "            score_diff = score_diff - margin\n",
        "\n",
        "        score_diff = score_diff / temperature\n",
        "        pairwise_loss = -F.logsigmoid(score_diff) * importance\n",
        "\n",
        "        total_loss += pairwise_loss.sum()\n",
        "        total_pairs += importance.sum()\n",
        "\n",
        "    if total_pairs == 0:\n",
        "        return torch.tensor(0.0, device=scores.device, requires_grad=True)\n",
        "\n",
        "    return total_loss / total_pairs\n",
        "\n",
        "def multi_focus_xranknet_loss(scores, labels, lengths, focus_tiers=[3, 5, 10], weights=[1.0, 0.5, 0.2], margin=0.2, temperature=1.0):\n",
        "    \"\"\"\n",
        "    Multi-tier xRankNet Loss.\n",
        "    Emphasizes top-K labels using weighted pairwise loss with optional margin and temperature scaling.\n",
        "    \"\"\"\n",
        "    batch_size = scores.size(0)\n",
        "    total_loss = 0.0\n",
        "    total_pairs = 0.0\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        if l < 2:\n",
        "            continue\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "\n",
        "        loss_i = 0.0\n",
        "        weight_i = 0.0\n",
        "\n",
        "        for focus_k, w in zip(focus_tiers, weights):\n",
        "            topk = min(focus_k, l)\n",
        "            topk_idx = torch.topk(y, topk).indices\n",
        "            topk_mask = torch.zeros_like(y, dtype=torch.bool)\n",
        "            topk_mask[topk_idx] = True\n",
        "\n",
        "            score_diff = s.unsqueeze(1) - s.unsqueeze(0)\n",
        "            label_diff = y.unsqueeze(1) - y.unsqueeze(0)\n",
        "\n",
        "            valid_pairs = (label_diff > 0) & (topk_mask.unsqueeze(1) | topk_mask.unsqueeze(0))\n",
        "            importance = label_diff.abs() * valid_pairs.float()\n",
        "\n",
        "            if importance.sum() == 0:\n",
        "                continue\n",
        "\n",
        "            score_diff = (score_diff - margin) / temperature\n",
        "            pairwise_loss = -F.logsigmoid(score_diff) * importance\n",
        "\n",
        "            loss_i += w * pairwise_loss.sum()\n",
        "            weight_i += w * importance.sum()\n",
        "\n",
        "        if weight_i > 0:\n",
        "            total_loss += loss_i\n",
        "            total_pairs += weight_i\n",
        "\n",
        "    return total_loss / total_pairs if total_pairs > 0 else torch.tensor(0.0, device=scores.device, requires_grad=True)\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "def bpr_loss(scores, labels, lengths):\n",
        "    batch_size = scores.size(0)\n",
        "    total_loss = 0.0\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "\n",
        "        pos_mask = y > 0\n",
        "        neg_mask = y <= 0\n",
        "\n",
        "        pos_scores = s[pos_mask]\n",
        "        neg_scores = s[neg_mask]\n",
        "\n",
        "        if len(pos_scores) == 0 or len(neg_scores) == 0:\n",
        "            continue\n",
        "\n",
        "        pair_diff = pos_scores.unsqueeze(1) - neg_scores.unsqueeze(0)\n",
        "        loss = -F.logsigmoid(pair_diff).mean()\n",
        "        total_loss += loss\n",
        "\n",
        "    return total_loss / batch_size\n",
        "\"\"\"\n",
        "\n",
        "\"\"\"\n",
        "def lambdarank_loss(scores, labels, lengths, eps=1e-10):\n",
        "    batch_size = scores.size(0)\n",
        "    total_loss = 0.0\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "\n",
        "        if l < 2:\n",
        "            continue\n",
        "\n",
        "        _, rank_order = torch.sort(s, descending=True)\n",
        "        ideal_order = torch.sort(y, descending=True).indices\n",
        "\n",
        "        gain = 2 ** y - 1\n",
        "        discount = torch.log2(torch.arange(2, l + 2, device=y.device).float())\n",
        "\n",
        "        ideal_dcg = (gain[ideal_order] / discount).sum()\n",
        "        if ideal_dcg < eps:\n",
        "            continue\n",
        "\n",
        "        delta_ndcg = torch.zeros((l, l), device=y.device)\n",
        "\n",
        "        for i_idx in range(l):\n",
        "            for j_idx in range(l):\n",
        "                if y[i_idx] > y[j_idx]:\n",
        "                    change = (\n",
        "                        (1.0 / torch.log2(rank_order[i_idx] + 2.0))\n",
        "                        - (1.0 / torch.log2(rank_order[j_idx] + 2.0))\n",
        "                    ).abs()\n",
        "                    delta = (2 ** y[i_idx] - 2 ** y[j_idx]).abs() * change\n",
        "                    delta_ndcg[i_idx, j_idx] = delta / ideal_dcg\n",
        "\n",
        "        score_diffs = s.unsqueeze(1) - s.unsqueeze(0)\n",
        "        lambdas = -F.logsigmoid(score_diffs) * delta_ndcg\n",
        "        total_loss += lambdas.sum()\n",
        "\n",
        "    return total_loss / batch_size\n",
        "\"\"\"\n",
        "\n",
        "def train_one_epoch(model, loader, optimizer, device, scheduler):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "\n",
        "    for x_cat, x_num, y, lengths in tqdm(loader, desc=\"Training\", leave=False):\n",
        "        x_num, y = x_num.to(device), y.to(device)\n",
        "        if not isinstance(lengths, torch.Tensor):\n",
        "            lengths = torch.tensor(lengths)\n",
        "        lengths = lengths.detach().clone().to(device)\n",
        "        x_cat = {k: v.to(device) for k, v in x_cat.items()}\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        scores = model(x_cat, x_num)\n",
        "        loss = multi_focus_xranknet_loss(scores, y, lengths, focus_tiers=[3, 5, 10], weights=[1.0, 0.5, 0.2], margin=0.2, temperature=1.0)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    return total_loss / len(loader)\n",
        "\n",
        "\n",
        "def validate(model, loader, device, min_group_size=10):\n",
        "    model.eval()\n",
        "    total_hitrate = 0\n",
        "    total_ndcg = 0\n",
        "    total_map = 0\n",
        "    total_loss = 0\n",
        "    count = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for x_cat, x_num, y, lengths in tqdm(loader, desc=\"Validating\", leave=False):\n",
        "            x_num, y = x_num.to(device), y.to(device)\n",
        "            lengths = torch.tensor(lengths).to(device)\n",
        "            x_cat = {k: v.to(device) for k, v in x_cat.items()}\n",
        "\n",
        "            scores = model(x_cat, x_num)\n",
        "\n",
        "            hitrate = hitrate_at_k(scores, y, lengths, k=3, min_group_size=min_group_size)\n",
        "            ndcg = ndcg_at_k(scores, y, lengths, k=3, min_group_size=min_group_size)\n",
        "            map3 = map_at_k(scores, y, lengths, k=3, min_group_size=min_group_size)\n",
        "            loss = multi_focus_xranknet_loss(scores, y, lengths, focus_tiers=[3, 5, 10], weights=[1.0, 0.5, 0.2], margin=0.2, temperature=1.0)\n",
        "\n",
        "            batch_size = scores.size(0)\n",
        "            total_hitrate += hitrate * batch_size\n",
        "            total_ndcg += ndcg * batch_size\n",
        "            total_map += map3 * batch_size\n",
        "            total_loss += loss.item() * batch_size\n",
        "            count += batch_size\n",
        "\n",
        "    return total_loss / count, total_hitrate / count, total_ndcg / count, total_map / count\n",
        "\n",
        "\n",
        "def build_cat_dims(X, cat_features):\n",
        "    cat_dims = {}\n",
        "    for c in cat_features:\n",
        "        max_val = X[c].max()\n",
        "        if max_val < 0:\n",
        "            max_val = 0\n",
        "        cat_dims[c] = max_val + 1\n",
        "    return cat_dims\n",
        "\n",
        "\n",
        "def normalize_numeric_features(X, numeric_features, train_mask):\n",
        "    for col in numeric_features:\n",
        "        values = X[col].to_numpy()\n",
        "        train_vals = values[train_mask]\n",
        "        mean = train_vals.mean()\n",
        "        std = train_vals.std() if train_vals.std() > 0 else 1.0\n",
        "        norm_vals = (values - mean) / std\n",
        "        X = X.with_columns(pl.Series(col, norm_vals).alias(col))\n",
        "    return X\n",
        "\n",
        "\n",
        "def load_or_prepare_data(\n",
        "    data_dir,\n",
        "    train_file=\"train.parquet\",\n",
        "    test_file=\"test.parquet\",\n",
        "    cache_file=\"feature_engineered_val.parquet\",\n",
        "):\n",
        "    cache_path = os.path.join(data_dir, cache_file)\n",
        "\n",
        "    if os.path.exists(cache_path):\n",
        "        print(f\"Loading cached feature-engineered data from {cache_path} ...\")\n",
        "        df = pl.read_parquet(cache_path)\n",
        "\n",
        "        test = pl.read_parquet(os.path.join(data_dir, test_file)).drop(\"__index_level_0__\")\n",
        "        test_ids = test[\"Id\"]\n",
        "        test_rankers = test[\"ranker_id\"]\n",
        "    else:\n",
        "        print(\"Cached file not found, processing raw data ...\")\n",
        "\n",
        "        train = pl.read_parquet(os.path.join(data_dir, train_file)).drop(\"__index_level_0__\")\n",
        "        test = (\n",
        "            pl.read_parquet(os.path.join(data_dir, test_file))\n",
        "            .drop(\"__index_level_0__\")\n",
        "            .with_columns(pl.lit(0, dtype=pl.Int64).alias(\"selected\"))\n",
        "        )\n",
        "\n",
        "        test_ids = test[\"Id\"]\n",
        "        test_rankers = test[\"ranker_id\"]\n",
        "\n",
        "        df = pl.concat((train, test))\n",
        "        df = feature_engineering(df, full=True)\n",
        "\n",
        "        df = df.with_columns(\n",
        "            [pl.col(c).fill_null(0) for c in df.select(pl.selectors.numeric()).columns] +\n",
        "            [pl.col(c).fill_null(\"missing\") for c in df.select(pl.selectors.string()).columns]\n",
        "        )\n",
        "\n",
        "        os.makedirs(data_dir, exist_ok=True)\n",
        "        df.write_parquet(cache_path)\n",
        "        print(f\"Saved feature-engineered data to {cache_path}\")\n",
        "\n",
        "    return df, test_ids, test_rankers\n",
        "\n",
        "\n",
        "def prepare_data(data_dir):\n",
        "    df, test_ids, test_rankers = load_or_prepare_data(data_dir)\n",
        "\n",
        "    id_column = df[\"Id\"]\n",
        "    X, y, groups, cat_features, num_features = feature_selection(df)\n",
        "\n",
        "    X = X.with_columns(pl.Series(\"Id\", id_column[:X.shape[0]]))\n",
        "\n",
        "    X = X.with_columns(\n",
        "        [\n",
        "            (pl.col(c).rank(\"dense\") - 1).fill_null(-1).cast(pl.Int32)\n",
        "            for c in cat_features\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    train_size = 18145372\n",
        "    train_mask = np.arange(X.height) < train_size\n",
        "    X = normalize_numeric_features(X, num_features, train_mask)\n",
        "\n",
        "    return X, y, groups, cat_features, num_features, train_size, test_ids, test_rankers\n",
        "\n",
        "\n",
        "class EarlyStopping:\n",
        "    def __init__(self, patience=3, min_delta=0.00005):\n",
        "        self.patience = patience\n",
        "        self.min_delta = min_delta\n",
        "        self.best = float(\"-inf\")\n",
        "        self.counter = 0\n",
        "\n",
        "    def step(self, metric):\n",
        "        if metric > self.best + self.min_delta:\n",
        "            self.best = metric\n",
        "            self.counter = 0\n",
        "        else:\n",
        "            self.counter += 1\n",
        "        return self.counter >= self.patience\n",
        "\n",
        "\n",
        "def plot_group_size_distribution(dataset, save_path=None):\n",
        "    group_sizes = [len(v) for v in dataset.group_to_indices.values()]\n",
        "    plt.figure()\n",
        "    plt.hist(group_sizes, bins=100, log=True)\n",
        "    plt.xlabel(\"Group size (number of items per ranker_id)\")\n",
        "    plt.ylabel(\"Frequency (log scale)\")\n",
        "    plt.title(\"Distribution of Group Sizes\")\n",
        "    plt.grid(True)\n",
        "    if save_path:\n",
        "        plt.savefig(save_path)\n",
        "    else:\n",
        "        plt.show()\n",
        "    plt.close()\n",
        "\n",
        "\n",
        "def main():\n",
        "    DATA_DIR = \"./data\"\n",
        "    MODEL_DIR = \"model\"\n",
        "    SUBMIT_DIR = \"submission\"\n",
        "\n",
        "    best_val_loss = float(\"inf\")\n",
        "    best_hitrate = 0.0\n",
        "    model_path = os.path.join(MODEL_DIR, \"best_dl_ranker.pt\")\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "    val_hitrates = []\n",
        "    val_ndcgs = []\n",
        "    val_maps = []\n",
        "    learning_rates = []\n",
        "\n",
        "    os.makedirs(MODEL_DIR, exist_ok=True)\n",
        "    os.makedirs(SUBMIT_DIR, exist_ok=True)\n",
        "\n",
        "    early_stopper = EarlyStopping(patience=3, min_delta=0.001)\n",
        "\n",
        "    X, y, groups, cat_features, num_features, train_size, test_ids, test_rankers = prepare_data(DATA_DIR)\n",
        "\n",
        "    # Fill missing values\n",
        "    float_cols = [c for c, t in zip(X.columns, X.dtypes) if t == pl.Float64]\n",
        "    for col in float_cols:\n",
        "        X = X.with_columns(\n",
        "            pl.when(pl.col(col).is_nan()).then(0).otherwise(pl.col(col)).alias(col)\n",
        "        )\n",
        "\n",
        "    n1 = 16487352\n",
        "    # n1 = 17487300\n",
        "    n2 = train_size\n",
        "\n",
        "    X_tr, X_va, X_te = X[:n1], X[n1:n2], X[n2:]\n",
        "    y_tr, y_va, y_te = y[:n1], y[n1:n2], y[n2:]\n",
        "    groups_tr, groups_va, groups_te = groups[:n1], groups[n1:n2], groups[n2:]\n",
        "\n",
        "    # Inspect group sizes in validation set\n",
        "    val_rankers = groups_va[\"ranker_id\"].to_numpy()\n",
        "    val_group_counts = Counter(val_rankers)\n",
        "\n",
        "    print(\"\\nüìã Validation group statistics:\")\n",
        "    # Save detailed group info to file\n",
        "    group_info_path = os.path.join(MODEL_DIR, \"validation_groups_info.txt\")\n",
        "    with open(group_info_path, \"w\") as f:\n",
        "        f.write(f\"Total groups: {len(val_group_counts)}\\n\\n\")\n",
        "        f.write(\"GroupID\\tSize\\tStartIdx\\tEndIdx\\n\")\n",
        "\n",
        "        group_to_rows = defaultdict(list)\n",
        "        for i, g in enumerate(val_rankers):\n",
        "            group_to_rows[g].append(i)\n",
        "\n",
        "        for group_id, indices in sorted(group_to_rows.items()):\n",
        "            start_idx = indices[0]\n",
        "            end_idx = indices[-1]\n",
        "            size = len(indices)\n",
        "            f.write(f\"{group_id}\\t{size}\\t{start_idx}\\t{end_idx}\\n\")\n",
        "\n",
        "    print(f\"üìÅ Saved validation group info to {group_info_path}\")\n",
        "\n",
        "\n",
        "    cat_dims = build_cat_dims(X, cat_features)\n",
        "    num_numeric_feats = len(num_features)\n",
        "\n",
        "    train_dataset = RankDataset(X_tr, y_tr, groups_tr, cat_features, num_features)\n",
        "    val_dataset = RankDataset(X_va, y_va, groups_va, cat_features, num_features)\n",
        "    test_dataset = RankDataset(X_te, y_te, groups_te, cat_features, num_features)\n",
        "\n",
        "    plot_group_size_distribution(train_dataset, save_path=os.path.join(MODEL_DIR, \"group_sizes.png\"))\n",
        "    print(\"üìä Group size distribution saved.\")\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True, collate_fn=collate_fn)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=4, shuffle=False, collate_fn=collate_fn)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False, collate_fn=collate_fn)\n",
        "\n",
        "    print(\"‚úÖ Data loaders created.\")\n",
        "\n",
        "    num_epochs = 10\n",
        "    num_training_steps = num_epochs * len(train_loader)\n",
        "    num_warmup_steps = int(0.1 * num_training_steps)\n",
        "\n",
        "    learning_rate = 3e-4\n",
        "\n",
        "    model = DLRankerAttention(\n",
        "        cat_dims=cat_dims,\n",
        "        num_numeric_feats=num_numeric_feats,\n",
        "        emb_dropout=0.1,\n",
        "        dropout=0.1,\n",
        "        num_heads=4,\n",
        "        num_layers=2,\n",
        "        dim_feedforward=128,\n",
        "        proj_dim=64\n",
        "    ).to(device)\n",
        "\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=0.01)\n",
        "\n",
        "    scheduler = OneCycleLR(\n",
        "        optimizer,\n",
        "        max_lr=learning_rate,\n",
        "        steps_per_epoch=len(train_loader),\n",
        "        epochs=num_epochs,\n",
        "        pct_start=0.3,\n",
        "    )\n",
        "\n",
        "    best_hitrate = 0\n",
        "    for epoch in range(num_epochs):\n",
        "        print(f\"\\n--- Epoch {epoch+1}/{num_epochs} ---\")\n",
        "        start_time = time.time()\n",
        "\n",
        "        train_loss = train_one_epoch(model, train_loader, optimizer, device, scheduler)\n",
        "        val_loss, val_hitrate, val_ndcg, val_map = validate(model, val_loader, device, min_group_size=10)\n",
        "\n",
        "        train_losses.append(train_loss)\n",
        "        val_losses.append(val_loss)\n",
        "        val_hitrates.append(val_hitrate.item())\n",
        "        val_ndcgs.append(val_ndcg.item())\n",
        "        val_maps.append(val_map.item())\n",
        "\n",
        "        current_lr = scheduler.get_last_lr()\n",
        "        learning_rates.append(current_lr[0])\n",
        "\n",
        "        elapsed = time.time() - start_time\n",
        "        print(\n",
        "            f\"Epoch {epoch+1}: \"\n",
        "            f\"Train Loss={train_loss:.4f}, \"\n",
        "            f\"Val Loss={val_loss:.4f}, \"\n",
        "            f\"HitRate@3={val_hitrate:.4f}, \"\n",
        "            f\"NDCG@3={val_ndcg:.4f}, \"\n",
        "            f\"MAP@3={val_map:.4f}, \"\n",
        "            f\"LR={current_lr[0]:.6f} \"\n",
        "            f\"({elapsed:.1f}s)\"\n",
        "        )\n",
        "\n",
        "\n",
        "        if val_loss < best_val_loss and val_hitrate > best_hitrate:\n",
        "            best_val_loss = val_loss\n",
        "            best_hitrate = val_hitrate\n",
        "            torch.save(model.state_dict(), model_path)\n",
        "            print(\"üíæ Model improved (loss ‚Üì and hitrate ‚Üë), saved.\")\n",
        "\n",
        "        if early_stopper.step(-val_loss):\n",
        "            print(\"‚õî Early stopping triggered.\")\n",
        "            break\n",
        "\n",
        "    # Plot metrics\n",
        "    epochs = list(range(1, len(train_losses) + 1))\n",
        "\n",
        "    # Plot Loss Curve\n",
        "    plt.figure()\n",
        "    plt.plot(epochs, train_losses, label=\"Train Loss\")\n",
        "    plt.plot(epochs, val_losses, label=\"Val Loss\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.title(\"Training & Validation Loss\")\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.savefig(os.path.join(MODEL_DIR, \"loss_curve.png\"))\n",
        "    plt.close()\n",
        "\n",
        "    # Plot HitRate@3\n",
        "    plt.figure()\n",
        "    plt.plot(epochs, val_hitrates, label=\"Val HitRate@3\", color=\"green\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"HitRate@3\")\n",
        "    plt.title(\"Validation HitRate@3\")\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.savefig(os.path.join(MODEL_DIR, \"hitrate_curve.png\"))\n",
        "    plt.close()\n",
        "\n",
        "    # Plot Learning Rate\n",
        "    plt.figure()\n",
        "    plt.plot(epochs, learning_rates, label=\"Learning Rate\", color=\"orange\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"LR\")\n",
        "    plt.title(\"Learning Rate Schedule\")\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.savefig(os.path.join(MODEL_DIR, \"lr_curve.png\"))\n",
        "    plt.close()\n",
        "\n",
        "    # Plot NDCG@3\n",
        "    plt.figure()\n",
        "    plt.plot(epochs, val_ndcgs, label=\"Val NDCG@3\", color=\"purple\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"NDCG@3\")\n",
        "    plt.title(\"Validation NDCG@3\")\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.savefig(os.path.join(MODEL_DIR, \"ndcg_curve.png\"))\n",
        "    plt.close()\n",
        "\n",
        "    # Plot MAP@3\n",
        "    plt.figure()\n",
        "    plt.plot(epochs, val_maps, label=\"Val MAP@3\", color=\"red\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"MAP@3\")\n",
        "    plt.title(\"Validation MAP@3\")\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.savefig(os.path.join(MODEL_DIR, \"map_curve.png\"))\n",
        "    plt.close()\n",
        "\n",
        "    print(\"üìä Saved metric plots to model/\")\n",
        "\n",
        "    # Predict test set\n",
        "    model.load_state_dict(torch.load(model_path))\n",
        "    model.eval()\n",
        "\n",
        "    val_ids = X_va[\"Id\"]\n",
        "    val_rankers = groups_va[\"ranker_id\"]\n",
        "    val_labels = y_va\n",
        "\n",
        "    all_val_scores = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for x_cat, x_num, _, lengths in tqdm(val_loader, desc=\"Predicting validation set\"):\n",
        "            x_num = x_num.to(device)\n",
        "            x_cat = {k: v.to(device) for k, v in x_cat.items()}\n",
        "            scores = model(x_cat, x_num)\n",
        "\n",
        "            for i in range(scores.size(0)):\n",
        "                l = lengths[i]\n",
        "                all_val_scores.append(scores[i, :l].cpu().numpy())\n",
        "\n",
        "    all_val_scores = np.concatenate(all_val_scores)\n",
        "\n",
        "    assert len(all_val_scores) == X_va.shape[0], \\\n",
        "        f\"Mismatch: {len(all_val_scores)} scores vs {X_va.shape[0]} rows\"\n",
        "\n",
        "    val_df = X_va.with_columns([\n",
        "        pl.Series(\"Id\", val_ids),\n",
        "        pl.Series(\"ranker_id\", val_rankers),\n",
        "        pl.Series(\"score\", all_val_scores),\n",
        "        pl.Series(\"label\", val_labels)\n",
        "    ])\n",
        "\n",
        "    val_df = val_df.with_columns(\n",
        "        pl.col(\"score\")\n",
        "        .rank(method=\"ordinal\", descending=True)\n",
        "        .over(\"ranker_id\")\n",
        "        .cast(pl.Int32)\n",
        "        .alias(\"selected\")\n",
        "    )\n",
        "\n",
        "    val_save_path = os.path.join(MODEL_DIR, \"validation_preds_dl_full.csv\")\n",
        "    val_df.write_csv(val_save_path)\n",
        "    print(f\"‚úÖ Saved full validation predictions (with features) to {val_save_path}\")\n",
        "\n",
        "    all_scores = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for x_cat, x_num, _, lengths in tqdm(test_loader, desc=\"Predicting test set\"):\n",
        "            x_num = x_num.to(device)\n",
        "            x_cat = {k: v.to(device) for k, v in x_cat.items()}\n",
        "            scores = model(x_cat, x_num)\n",
        "\n",
        "            for i in range(scores.size(0)):\n",
        "                l = lengths[i]\n",
        "                all_scores.append(scores[i, :l].cpu().numpy())\n",
        "\n",
        "    all_scores = np.concatenate(all_scores)\n",
        "\n",
        "    assert len(all_scores) == X_te.shape[0], \\\n",
        "        f\"Mismatch: {len(all_scores)} scores vs {X_te.shape[0]} rows in X_te\"\n",
        "\n",
        "    submission_df = pl.DataFrame({\n",
        "        \"Id\": test_ids,\n",
        "        \"ranker_id\": test_rankers,\n",
        "        \"score\": all_scores\n",
        "    })\n",
        "\n",
        "    submission = (\n",
        "        submission_df\n",
        "        .with_columns(\n",
        "            pl.col(\"score\")\n",
        "            .rank(method=\"ordinal\", descending=True)\n",
        "            .over(\"ranker_id\")\n",
        "            .cast(pl.Int32)\n",
        "            .alias(\"selected\")\n",
        "        )\n",
        "        .select([\"Id\", \"ranker_id\", \"score\", \"selected\"])\n",
        "    )\n",
        "\n",
        "    submission_path = os.path.join(SUBMIT_DIR, \"submission_dl_ranker.csv\")\n",
        "    submission.write_csv(submission_path)\n",
        "    print(f\"‚úÖ Submission saved to {submission_path}\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lx-UyzXMmy3o",
        "outputId": "95326b0a-93c7-43ec-b404-16d22ddd1bff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting deeprec_validate.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile deeprec_validate.py\n",
        "import os\n",
        "import time\n",
        "import random\n",
        "import torch\n",
        "import math\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import defaultdict\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "import polars as pl\n",
        "from tqdm import tqdm\n",
        "from src.feature import feature_engineering, feature_selection\n",
        "from transformers import get_scheduler\n",
        "from collections import Counter\n",
        "from torch.optim.lr_scheduler import OneCycleLR, CosineAnnealingWarmRestarts\n",
        "\n",
        "class RankDataset(Dataset):\n",
        "    def __init__(\n",
        "        self,\n",
        "        X: pl.DataFrame,\n",
        "        y: pl.Series,\n",
        "        groups: pl.DataFrame,\n",
        "        cat_features: list[str],\n",
        "        num_features: list[str],\n",
        "    ):\n",
        "        self.cat_features = cat_features\n",
        "        self.num_features = num_features\n",
        "        self.X_cat = {c: X[c].to_numpy() for c in cat_features}\n",
        "        self.X_num = X[self.num_features].to_numpy()\n",
        "        self.y = y.to_numpy()\n",
        "        self.groups = groups[\"ranker_id\"].to_numpy()\n",
        "\n",
        "        self.group_to_indices = defaultdict(list)\n",
        "        for i, g in enumerate(self.groups):\n",
        "            self.group_to_indices[g].append(i)\n",
        "        self.group_keys = list(self.group_to_indices.keys())\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.group_keys)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        g = self.group_keys[idx]\n",
        "        inds = self.group_to_indices[g]\n",
        "        length = len(inds)\n",
        "\n",
        "        x_cat = {\n",
        "            c: torch.LongTensor([\n",
        "                self.X_cat[c][i] if self.X_cat[c][i] >= 0 else 0 for i in inds\n",
        "            ])\n",
        "            for c in self.cat_features\n",
        "        }\n",
        "\n",
        "        x_num = torch.FloatTensor(self.X_num[inds])\n",
        "        y = torch.FloatTensor(self.y[inds]).reshape(-1)\n",
        "\n",
        "        return x_cat, x_num, y, length\n",
        "\n",
        "def collate_fn(batch):\n",
        "    batch_size = len(batch)\n",
        "    lengths = [b[3] for b in batch]\n",
        "    max_len = max(lengths)\n",
        "\n",
        "    padded_x_cat = {key: [] for key in batch[0][0].keys()}\n",
        "    padded_x_num = []\n",
        "    padded_y = []\n",
        "\n",
        "    num_dim = batch[0][1].shape[1]\n",
        "\n",
        "    for x_cat, x_num, y, length in batch:\n",
        "        pad_len = max_len - length\n",
        "\n",
        "        for key in padded_x_cat:\n",
        "            val = x_cat[key]\n",
        "            if pad_len > 0:\n",
        "                val = torch.cat([val, torch.zeros(pad_len, dtype=torch.long)])\n",
        "            padded_x_cat[key].append(val)\n",
        "\n",
        "        if pad_len > 0:\n",
        "            x_num = torch.cat([x_num, torch.zeros(pad_len, num_dim)])\n",
        "            y = torch.cat([y, torch.zeros(pad_len)])\n",
        "\n",
        "        padded_x_num.append(x_num)\n",
        "        padded_y.append(y)\n",
        "\n",
        "    padded_x_cat = {k: torch.stack(v) for k, v in padded_x_cat.items()}\n",
        "    padded_x_num = torch.stack(padded_x_num)\n",
        "    padded_y = torch.stack(padded_y)\n",
        "    lengths = torch.tensor(lengths, dtype=torch.long)\n",
        "\n",
        "    return padded_x_cat, padded_x_num, padded_y, lengths\n",
        "\n",
        "class SEModule(nn.Module):\n",
        "    def __init__(self, channel, reduction=4):\n",
        "        super().__init__()\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(channel, channel // reduction),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(channel // reduction, channel),\n",
        "            nn.Sigmoid(),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: [B, N, C]\n",
        "        w = self.fc(x.mean(dim=1))\n",
        "        w = w.unsqueeze(1)  # [B, 1, C]\n",
        "        return x * w\n",
        "\n",
        "\n",
        "class DLRankerAttention(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        cat_dims,\n",
        "        num_numeric_feats,\n",
        "        emb_dropout=0.1,\n",
        "        dropout=0.1,\n",
        "        num_heads=4,\n",
        "        num_layers=4,\n",
        "        dim_feedforward=128,\n",
        "        proj_dim=64,\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "        self.emb_dims = {\n",
        "            f: min(50, max(4, round(6 * math.log2(cat_dims[f] + 1)))) for f in cat_dims\n",
        "        }\n",
        "        self.embeddings = nn.ModuleDict({\n",
        "            f: nn.Embedding(cat_dims[f], self.emb_dims[f], padding_idx=0)\n",
        "            for f in cat_dims\n",
        "        })\n",
        "        self.emb_dropout = nn.Dropout(emb_dropout)\n",
        "\n",
        "        total_emb_dim = sum(self.emb_dims.values())\n",
        "        print(f\"Categorial emb dim sum: {total_emb_dim}, Numerical dim: {num_numeric_feats}\")\n",
        "\n",
        "        self.cat_proj = nn.Linear(total_emb_dim, proj_dim)\n",
        "        self.cat_transformer = nn.TransformerEncoder(\n",
        "            nn.TransformerEncoderLayer(\n",
        "                d_model=proj_dim,\n",
        "                nhead=4,\n",
        "                dim_feedforward=dim_feedforward,\n",
        "                dropout=dropout,\n",
        "                batch_first=True,\n",
        "                norm_first=True,\n",
        "            ),\n",
        "            num_layers=1,\n",
        "        )\n",
        "\n",
        "        self.num_proj_in = nn.Linear(num_numeric_feats, proj_dim)\n",
        "        self.num_transformer = nn.TransformerEncoder(\n",
        "            nn.TransformerEncoderLayer(\n",
        "                d_model=proj_dim,\n",
        "                nhead=4,\n",
        "                dim_feedforward=dim_feedforward,\n",
        "                dropout=dropout,\n",
        "                batch_first=True,\n",
        "                norm_first=True,\n",
        "            ),\n",
        "            num_layers=1,\n",
        "        )\n",
        "        self.num_se = SEModule(proj_dim)\n",
        "        self.num_proj_out = nn.Sequential(\n",
        "            nn.Linear(proj_dim, proj_dim),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(dropout),\n",
        "        )\n",
        "\n",
        "        self.cross_attn_cat2num = nn.MultiheadAttention(\n",
        "            embed_dim=proj_dim,\n",
        "            num_heads=4,\n",
        "            dropout=dropout,\n",
        "            batch_first=True,\n",
        "        )\n",
        "\n",
        "        self.transformer_layers = nn.ModuleList([\n",
        "            nn.TransformerEncoderLayer(\n",
        "                d_model=2 * proj_dim,\n",
        "                nhead=num_heads,\n",
        "                dim_feedforward=dim_feedforward,\n",
        "                dropout=dropout,\n",
        "                batch_first=True,\n",
        "                norm_first=True,\n",
        "            )\n",
        "            for _ in range(num_layers)\n",
        "        ])\n",
        "\n",
        "        # Contextual pooling ‚Üí concat global context to each item\n",
        "        self.mlp = nn.Sequential(\n",
        "            nn.Linear(2 * proj_dim + 2 * proj_dim, 128),  # context + item\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(128, 64),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(64, 1),\n",
        "        )\n",
        "\n",
        "    def forward(self, x_cat: dict, x_num: torch.Tensor, attn_mask=None):\n",
        "        B, N, _ = x_num.shape\n",
        "\n",
        "        cat_embs = torch.cat([self.embeddings[f](x_cat[f]) for f in x_cat], dim=-1)\n",
        "        cat_embs = self.emb_dropout(cat_embs)\n",
        "        cat_feat = self.cat_proj(cat_embs)\n",
        "        cat_feat = self.cat_transformer(cat_feat)\n",
        "\n",
        "        num_feat = self.num_proj_in(x_num)\n",
        "        num_feat = self.num_transformer(num_feat)\n",
        "        num_feat = self.num_se(num_feat)\n",
        "        num_feat = self.num_proj_out(num_feat)\n",
        "\n",
        "        cat_feat_attn, _ = self.cross_attn_cat2num(query=cat_feat, key=num_feat, value=num_feat)\n",
        "        cat_feat = cat_feat + cat_feat_attn\n",
        "\n",
        "        x = torch.cat([cat_feat, num_feat], dim=-1)\n",
        "\n",
        "        for layer in self.transformer_layers:\n",
        "            x = layer(x, src_key_padding_mask=attn_mask)\n",
        "\n",
        "        # üî• Contextual pooling\n",
        "        global_context = x.mean(dim=1, keepdim=True).expand(-1, N, -1)  # [B, N, 2*D]\n",
        "        x = torch.cat([x, global_context], dim=-1)  # [B, N, 4*D]\n",
        "\n",
        "        scores = self.mlp(x).squeeze(-1)\n",
        "        return scores\n",
        "\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "def listmle_loss(scores, labels, lengths):\n",
        "    batch_size = scores.size(0)\n",
        "    total_loss = torch.tensor(0.0, device=scores.device, requires_grad=True)\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "\n",
        "        _, idx = torch.sort(y, descending=True)\n",
        "        s_sorted = s[idx]\n",
        "\n",
        "        parts = (\n",
        "            torch.logsumexp(s_sorted.unsqueeze(0).expand(l, -1).triu(diagonal=0), dim=1)\n",
        "            - s_sorted\n",
        "        )\n",
        "\n",
        "        total_loss = total_loss + parts.sum()\n",
        "\n",
        "    return total_loss / batch_size\n",
        "\"\"\"\n",
        "\n",
        "def hitrate_at_k(scores, labels, lengths, k=3, min_group_size=10):\n",
        "    batch_size = scores.size(0)\n",
        "    hits = 0\n",
        "    valid_count = 0\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        if l < min_group_size:\n",
        "            continue\n",
        "        length = min(l, k)\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "        _, topk_idx = torch.topk(s, length)\n",
        "        topk_labels = y[topk_idx]\n",
        "        hits += (topk_labels > 0).any().float()\n",
        "        valid_count += 1\n",
        "    return hits / valid_count if valid_count > 0 else torch.tensor(0.0, device=scores.device)\n",
        "\n",
        "\n",
        "def ndcg_at_k(scores, labels, lengths, k=3, min_group_size=10):\n",
        "    batch_size = scores.size(0)\n",
        "    total_ndcg = 0.0\n",
        "    valid_count = 0\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        if l < min_group_size:\n",
        "            continue\n",
        "\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "\n",
        "        _, idx_pred = torch.topk(s, min(k, l))\n",
        "        _, idx_ideal = torch.topk(y, min(k, l))\n",
        "\n",
        "        dcg = (y[idx_pred] / torch.log2(torch.arange(2, 2 + len(idx_pred), device=y.device).float())).sum()\n",
        "        idcg = (y[idx_ideal] / torch.log2(torch.arange(2, 2 + len(idx_ideal), device=y.device).float())).sum()\n",
        "\n",
        "        ndcg = dcg / idcg if idcg > 0 else 0.0\n",
        "        total_ndcg += ndcg\n",
        "        valid_count += 1\n",
        "\n",
        "    return total_ndcg / valid_count if valid_count > 0 else torch.tensor(0.0, device=scores.device)\n",
        "\n",
        "\n",
        "def map_at_k(scores, labels, lengths, k=3, min_group_size=10):\n",
        "    batch_size = scores.size(0)\n",
        "    total_ap = 0.0\n",
        "    valid_count = 0\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        if l < min_group_size:\n",
        "            continue\n",
        "\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "\n",
        "        _, idx_pred = torch.topk(s, min(k, l))\n",
        "        y_true = y[idx_pred] > 0\n",
        "\n",
        "        if y_true.sum() == 0:\n",
        "            continue\n",
        "\n",
        "        precisions = [(y_true[:j+1].float().sum() / (j+1)) for j in range(len(y_true)) if y_true[j]]\n",
        "        ap = torch.stack(precisions).mean()\n",
        "        total_ap += ap\n",
        "        valid_count += 1\n",
        "\n",
        "    return total_ap / valid_count if valid_count > 0 else torch.tensor(0.0, device=scores.device)\n",
        "\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "def listnet_loss(scores, labels, lengths):\n",
        "    batch_size = scores.size(0)\n",
        "    total_loss = 0.0\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "\n",
        "        s_softmax = torch.nn.functional.log_softmax(s, dim=0)\n",
        "        y_softmax = torch.nn.functional.softmax(y, dim=0)\n",
        "\n",
        "        loss = -torch.sum(y_softmax * s_softmax)\n",
        "        total_loss += loss\n",
        "\n",
        "    return total_loss / batch_size\n",
        "\"\"\"\n",
        "\n",
        "def ranknet_loss(scores, labels, lengths):\n",
        "    batch_size = scores.size(0)\n",
        "    total_loss = 0.0\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "\n",
        "        diff_scores = s.unsqueeze(1) - s.unsqueeze(0)\n",
        "        rel = y.unsqueeze(1) > y.unsqueeze(0)\n",
        "        label_diff = rel.float()\n",
        "\n",
        "        log_sigmoid = torch.nn.functional.logsigmoid(diff_scores)\n",
        "        pair_loss = -label_diff * log_sigmoid\n",
        "\n",
        "        total_loss += pair_loss.sum()\n",
        "\n",
        "    return total_loss / batch_size\n",
        "\n",
        "def xranknet_loss(scores, labels, lengths, temperature=1.0, margin=0.2, focus_topk=3):\n",
        "    \"\"\"\n",
        "    xRankNet with emphasis on top-K items (based on labels, not scores).\n",
        "    \"\"\"\n",
        "    batch_size = scores.size(0)\n",
        "    total_loss = 0.0\n",
        "    total_pairs = 0\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        if l < 2:\n",
        "            continue\n",
        "\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "\n",
        "        # Top-K mask based on ground truth labels\n",
        "        topk = min(focus_topk, l)\n",
        "        _, topk_idx = torch.topk(y, topk)\n",
        "        topk_mask = torch.zeros_like(y, dtype=torch.bool)\n",
        "        topk_mask[topk_idx] = True\n",
        "\n",
        "        # Create pairwise difference matrices\n",
        "        score_diff = s.unsqueeze(1) - s.unsqueeze(0)\n",
        "        label_diff = y.unsqueeze(1) - y.unsqueeze(0)\n",
        "\n",
        "        # valid pair: y_i > y_j and at least one of i, j is in top-K\n",
        "        valid_pairs = (label_diff > 0) & (\n",
        "            topk_mask.unsqueeze(1) | topk_mask.unsqueeze(0)\n",
        "        )\n",
        "\n",
        "        if valid_pairs.sum() == 0:\n",
        "            continue\n",
        "\n",
        "        importance = (label_diff.abs() * valid_pairs).float()\n",
        "\n",
        "        if margin > 0.0:\n",
        "            score_diff = score_diff - margin\n",
        "\n",
        "        score_diff = score_diff / temperature\n",
        "        pairwise_loss = -F.logsigmoid(score_diff) * importance\n",
        "\n",
        "        total_loss += pairwise_loss.sum()\n",
        "        total_pairs += importance.sum()\n",
        "\n",
        "    if total_pairs == 0:\n",
        "        return torch.tensor(0.0, device=scores.device, requires_grad=True)\n",
        "\n",
        "    return total_loss / total_pairs\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "def bpr_loss(scores, labels, lengths):\n",
        "    batch_size = scores.size(0)\n",
        "    total_loss = 0.0\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "\n",
        "        pos_mask = y > 0\n",
        "        neg_mask = y <= 0\n",
        "\n",
        "        pos_scores = s[pos_mask]\n",
        "        neg_scores = s[neg_mask]\n",
        "\n",
        "        if len(pos_scores) == 0 or len(neg_scores) == 0:\n",
        "            continue\n",
        "\n",
        "        pair_diff = pos_scores.unsqueeze(1) - neg_scores.unsqueeze(0)\n",
        "        loss = -F.logsigmoid(pair_diff).mean()\n",
        "        total_loss += loss\n",
        "\n",
        "    return total_loss / batch_size\n",
        "\"\"\"\n",
        "\n",
        "\"\"\"\n",
        "def lambdarank_loss(scores, labels, lengths, eps=1e-10):\n",
        "    batch_size = scores.size(0)\n",
        "    total_loss = 0.0\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "\n",
        "        if l < 2:\n",
        "            continue\n",
        "\n",
        "        _, rank_order = torch.sort(s, descending=True)\n",
        "        ideal_order = torch.sort(y, descending=True).indices\n",
        "\n",
        "        gain = 2 ** y - 1\n",
        "        discount = torch.log2(torch.arange(2, l + 2, device=y.device).float())\n",
        "\n",
        "        ideal_dcg = (gain[ideal_order] / discount).sum()\n",
        "        if ideal_dcg < eps:\n",
        "            continue\n",
        "\n",
        "        delta_ndcg = torch.zeros((l, l), device=y.device)\n",
        "\n",
        "        for i_idx in range(l):\n",
        "            for j_idx in range(l):\n",
        "                if y[i_idx] > y[j_idx]:\n",
        "                    change = (\n",
        "                        (1.0 / torch.log2(rank_order[i_idx] + 2.0))\n",
        "                        - (1.0 / torch.log2(rank_order[j_idx] + 2.0))\n",
        "                    ).abs()\n",
        "                    delta = (2 ** y[i_idx] - 2 ** y[j_idx]).abs() * change\n",
        "                    delta_ndcg[i_idx, j_idx] = delta / ideal_dcg\n",
        "\n",
        "        score_diffs = s.unsqueeze(1) - s.unsqueeze(0)\n",
        "        lambdas = -F.logsigmoid(score_diffs) * delta_ndcg\n",
        "        total_loss += lambdas.sum()\n",
        "\n",
        "    return total_loss / batch_size\n",
        "\"\"\"\n",
        "\n",
        "def train_one_epoch(model, loader, optimizer, device, scheduler):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "\n",
        "    for x_cat, x_num, y, lengths in tqdm(loader, desc=\"Training\", leave=False):\n",
        "        x_num, y = x_num.to(device), y.to(device)\n",
        "        if not isinstance(lengths, torch.Tensor):\n",
        "            lengths = torch.tensor(lengths)\n",
        "        lengths = lengths.detach().clone().to(device)\n",
        "        x_cat = {k: v.to(device) for k, v in x_cat.items()}\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        scores = model(x_cat, x_num)\n",
        "        loss = xranknet_loss(scores, y, lengths, temperature=1.0, margin=0.0, focus_topk=3)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    return total_loss / len(loader)\n",
        "\n",
        "\n",
        "def validate(model, loader, device, min_group_size=10):\n",
        "    model.eval()\n",
        "    total_hitrate = 0\n",
        "    total_ndcg = 0\n",
        "    total_map = 0\n",
        "    total_loss = 0\n",
        "    count = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for x_cat, x_num, y, lengths in tqdm(loader, desc=\"Validating\", leave=False):\n",
        "            x_num, y = x_num.to(device), y.to(device)\n",
        "            lengths = torch.tensor(lengths).to(device)\n",
        "            x_cat = {k: v.to(device) for k, v in x_cat.items()}\n",
        "\n",
        "            scores = model(x_cat, x_num)\n",
        "\n",
        "            hitrate = hitrate_at_k(scores, y, lengths, k=3, min_group_size=min_group_size)\n",
        "            ndcg = ndcg_at_k(scores, y, lengths, k=3, min_group_size=min_group_size)\n",
        "            map3 = map_at_k(scores, y, lengths, k=3, min_group_size=min_group_size)\n",
        "            loss = xranknet_loss(scores, y, lengths, temperature=1.0, margin=0.0, focus_topk=3)\n",
        "\n",
        "            batch_size = scores.size(0)\n",
        "            total_hitrate += hitrate * batch_size\n",
        "            total_ndcg += ndcg * batch_size\n",
        "            total_map += map3 * batch_size\n",
        "            total_loss += loss.item() * batch_size\n",
        "            count += batch_size\n",
        "\n",
        "    return total_loss / count, total_hitrate / count, total_ndcg / count, total_map / count\n",
        "\n",
        "\n",
        "def build_cat_dims(X, cat_features):\n",
        "    cat_dims = {}\n",
        "    for c in cat_features:\n",
        "        max_val = X[c].max()\n",
        "        if max_val < 0:\n",
        "            max_val = 0\n",
        "        cat_dims[c] = max_val + 1\n",
        "    return cat_dims\n",
        "\n",
        "\n",
        "def normalize_numeric_features(X, numeric_features, train_mask):\n",
        "    for col in numeric_features:\n",
        "        values = X[col].to_numpy()\n",
        "        train_vals = values[train_mask]\n",
        "        mean = train_vals.mean()\n",
        "        std = train_vals.std() if train_vals.std() > 0 else 1.0\n",
        "        norm_vals = (values - mean) / std\n",
        "        X = X.with_columns(pl.Series(col, norm_vals).alias(col))\n",
        "    return X\n",
        "\n",
        "\n",
        "def load_or_prepare_data(\n",
        "    data_dir,\n",
        "    train_file=\"train.parquet\",\n",
        "    test_file=\"test.parquet\",\n",
        "    cache_file=\"feature_engineered_val.parquet\",\n",
        "):\n",
        "    cache_path = os.path.join(data_dir, cache_file)\n",
        "\n",
        "    if os.path.exists(cache_path):\n",
        "        print(f\"Loading cached feature-engineered data from {cache_path} ...\")\n",
        "        df = pl.read_parquet(cache_path)\n",
        "\n",
        "        test = pl.read_parquet(os.path.join(data_dir, test_file)).drop(\"__index_level_0__\")\n",
        "        test_ids = test[\"Id\"]\n",
        "        test_rankers = test[\"ranker_id\"]\n",
        "    else:\n",
        "        print(\"Cached file not found, processing raw data ...\")\n",
        "\n",
        "        train = pl.read_parquet(os.path.join(data_dir, train_file)).drop(\"__index_level_0__\")\n",
        "        test = (\n",
        "            pl.read_parquet(os.path.join(data_dir, test_file))\n",
        "            .drop(\"__index_level_0__\")\n",
        "            .with_columns(pl.lit(0, dtype=pl.Int64).alias(\"selected\"))\n",
        "        )\n",
        "\n",
        "        test_ids = test[\"Id\"]\n",
        "        test_rankers = test[\"ranker_id\"]\n",
        "\n",
        "        df = pl.concat((train, test))\n",
        "        df = feature_engineering(df, full=True)\n",
        "\n",
        "        df = df.with_columns(\n",
        "            [pl.col(c).fill_null(0) for c in df.select(pl.selectors.numeric()).columns] +\n",
        "            [pl.col(c).fill_null(\"missing\") for c in df.select(pl.selectors.string()).columns]\n",
        "        )\n",
        "\n",
        "        os.makedirs(data_dir, exist_ok=True)\n",
        "        df.write_parquet(cache_path)\n",
        "        print(f\"Saved feature-engineered data to {cache_path}\")\n",
        "\n",
        "    return df, test_ids, test_rankers\n",
        "\n",
        "\n",
        "def prepare_data(data_dir):\n",
        "    df, test_ids, test_rankers = load_or_prepare_data(data_dir)\n",
        "\n",
        "    id_column = df[\"Id\"]\n",
        "    X, y, groups, cat_features, num_features = feature_selection(df)\n",
        "\n",
        "    X = X.with_columns(pl.Series(\"Id\", id_column[:X.shape[0]]))\n",
        "\n",
        "    X = X.with_columns(\n",
        "        [\n",
        "            (pl.col(c).rank(\"dense\") - 1).fill_null(-1).cast(pl.Int32)\n",
        "            for c in cat_features\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    train_size = 18145372\n",
        "    train_mask = np.arange(X.height) < train_size\n",
        "    X = normalize_numeric_features(X, num_features, train_mask)\n",
        "\n",
        "    return X, y, groups, cat_features, num_features, train_size, test_ids, test_rankers\n",
        "\n",
        "\n",
        "class EarlyStopping:\n",
        "    def __init__(self, patience=3, min_delta=0.00005):\n",
        "        self.patience = patience\n",
        "        self.min_delta = min_delta\n",
        "        self.best = float(\"-inf\")\n",
        "        self.counter = 0\n",
        "\n",
        "    def step(self, metric):\n",
        "        if metric > self.best + self.min_delta:\n",
        "            self.best = metric\n",
        "            self.counter = 0\n",
        "        else:\n",
        "            self.counter += 1\n",
        "        return self.counter >= self.patience\n",
        "\n",
        "\n",
        "def plot_group_size_distribution(dataset, save_path=None):\n",
        "    group_sizes = [len(v) for v in dataset.group_to_indices.values()]\n",
        "    plt.figure()\n",
        "    plt.hist(group_sizes, bins=100, log=True)\n",
        "    plt.xlabel(\"Group size (number of items per ranker_id)\")\n",
        "    plt.ylabel(\"Frequency (log scale)\")\n",
        "    plt.title(\"Distribution of Group Sizes\")\n",
        "    plt.grid(True)\n",
        "    if save_path:\n",
        "        plt.savefig(save_path)\n",
        "    else:\n",
        "        plt.show()\n",
        "    plt.close()\n",
        "\n",
        "\n",
        "def main():\n",
        "    DATA_DIR = \"./data\"\n",
        "    MODEL_DIR = \"model\"\n",
        "    SUBMIT_DIR = \"submission\"\n",
        "\n",
        "    best_val_loss = float(\"inf\")\n",
        "    best_hitrate = 0.0\n",
        "    model_path = os.path.join(MODEL_DIR, \"best_dl_ranker.pt\")\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "    val_hitrates = []\n",
        "    val_ndcgs = []\n",
        "    val_maps = []\n",
        "    learning_rates = []\n",
        "\n",
        "    os.makedirs(MODEL_DIR, exist_ok=True)\n",
        "    os.makedirs(SUBMIT_DIR, exist_ok=True)\n",
        "\n",
        "    early_stopper = EarlyStopping(patience=3, min_delta=0.001)\n",
        "\n",
        "    X, y, groups, cat_features, num_features, train_size, test_ids, test_rankers = prepare_data(DATA_DIR)\n",
        "\n",
        "    # Fill missing values\n",
        "    float_cols = [c for c, t in zip(X.columns, X.dtypes) if t == pl.Float64]\n",
        "    for col in float_cols:\n",
        "        X = X.with_columns(\n",
        "            pl.when(pl.col(col).is_nan()).then(0).otherwise(pl.col(col)).alias(col)\n",
        "        )\n",
        "\n",
        "    n1 = 16487352\n",
        "    # n1 = 17487300\n",
        "    n2 = train_size\n",
        "\n",
        "    X_tr, X_va, X_te = X[:n1], X[n1:n2], X[n2:]\n",
        "    y_tr, y_va, y_te = y[:n1], y[n1:n2], y[n2:]\n",
        "    groups_tr, groups_va, groups_te = groups[:n1], groups[n1:n2], groups[n2:]\n",
        "\n",
        "    # Inspect group sizes in validation set\n",
        "    val_rankers = groups_va[\"ranker_id\"].to_numpy()\n",
        "    val_group_counts = Counter(val_rankers)\n",
        "\n",
        "    print(\"\\nüìã Validation group statistics:\")\n",
        "    # Save detailed group info to file\n",
        "    group_info_path = os.path.join(MODEL_DIR, \"validation_groups_info.txt\")\n",
        "    with open(group_info_path, \"w\") as f:\n",
        "        f.write(f\"Total groups: {len(val_group_counts)}\\n\\n\")\n",
        "        f.write(\"GroupID\\tSize\\tStartIdx\\tEndIdx\\n\")\n",
        "\n",
        "        group_to_rows = defaultdict(list)\n",
        "        for i, g in enumerate(val_rankers):\n",
        "            group_to_rows[g].append(i)\n",
        "\n",
        "        for group_id, indices in sorted(group_to_rows.items()):\n",
        "            start_idx = indices[0]\n",
        "            end_idx = indices[-1]\n",
        "            size = len(indices)\n",
        "            f.write(f\"{group_id}\\t{size}\\t{start_idx}\\t{end_idx}\\n\")\n",
        "\n",
        "    print(f\"üìÅ Saved validation group info to {group_info_path}\")\n",
        "\n",
        "\n",
        "    cat_dims = build_cat_dims(X, cat_features)\n",
        "    num_numeric_feats = len(num_features)\n",
        "\n",
        "    train_dataset = RankDataset(X_tr, y_tr, groups_tr, cat_features, num_features)\n",
        "    val_dataset = RankDataset(X_va, y_va, groups_va, cat_features, num_features)\n",
        "    test_dataset = RankDataset(X_te, y_te, groups_te, cat_features, num_features)\n",
        "\n",
        "    plot_group_size_distribution(train_dataset, save_path=os.path.join(MODEL_DIR, \"group_sizes.png\"))\n",
        "    print(\"üìä Group size distribution saved.\")\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True, collate_fn=collate_fn)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=4, shuffle=False, collate_fn=collate_fn)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False, collate_fn=collate_fn)\n",
        "\n",
        "    print(\"‚úÖ Data loaders created.\")\n",
        "\n",
        "    num_epochs = 10\n",
        "    num_training_steps = num_epochs * len(train_loader)\n",
        "    num_warmup_steps = int(0.1 * num_training_steps)\n",
        "\n",
        "    learning_rate = 3e-4\n",
        "\n",
        "    model = DLRankerAttention(\n",
        "        cat_dims=cat_dims,\n",
        "        num_numeric_feats=num_numeric_feats,\n",
        "        emb_dropout=0.1,\n",
        "        dropout=0.1,\n",
        "        num_heads=4,\n",
        "        num_layers=2,\n",
        "        dim_feedforward=128,\n",
        "        proj_dim=64\n",
        "    ).to(device)\n",
        "\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=0.01)\n",
        "\n",
        "    scheduler = OneCycleLR(\n",
        "        optimizer,\n",
        "        max_lr=learning_rate,\n",
        "        steps_per_epoch=len(train_loader),\n",
        "        epochs=num_epochs,\n",
        "        pct_start=0.3,\n",
        "    )\n",
        "\n",
        "    best_hitrate = 0\n",
        "    for epoch in range(num_epochs):\n",
        "        print(f\"\\n--- Epoch {epoch+1}/{num_epochs} ---\")\n",
        "        start_time = time.time()\n",
        "\n",
        "        train_loss = train_one_epoch(model, train_loader, optimizer, device, scheduler)\n",
        "        val_loss, val_hitrate, val_ndcg, val_map = validate(model, val_loader, device, min_group_size=10)\n",
        "\n",
        "        train_losses.append(train_loss)\n",
        "        val_losses.append(val_loss)\n",
        "        val_hitrates.append(val_hitrate.item())\n",
        "        val_ndcgs.append(val_ndcg.item())\n",
        "        val_maps.append(val_map.item())\n",
        "\n",
        "        current_lr = scheduler.get_last_lr()\n",
        "        learning_rates.append(current_lr[0])\n",
        "\n",
        "        elapsed = time.time() - start_time\n",
        "        print(\n",
        "            f\"Epoch {epoch+1}: \"\n",
        "            f\"Train Loss={train_loss:.4f}, \"\n",
        "            f\"Val Loss={val_loss:.4f}, \"\n",
        "            f\"HitRate@3={val_hitrate:.4f}, \"\n",
        "            f\"NDCG@3={val_ndcg:.4f}, \"\n",
        "            f\"MAP@3={val_map:.4f}, \"\n",
        "            f\"LR={current_lr[0]:.6f} \"\n",
        "            f\"({elapsed:.1f}s)\"\n",
        "        )\n",
        "\n",
        "\n",
        "        if val_loss < best_val_loss and val_hitrate > best_hitrate:\n",
        "            best_val_loss = val_loss\n",
        "            best_hitrate = val_hitrate\n",
        "            torch.save(model.state_dict(), model_path)\n",
        "            print(\"üíæ Model improved (loss ‚Üì and hitrate ‚Üë), saved.\")\n",
        "\n",
        "        if early_stopper.step(-val_loss):\n",
        "            print(\"‚õî Early stopping triggered.\")\n",
        "            break\n",
        "\n",
        "    # Plot metrics\n",
        "    epochs = list(range(1, len(train_losses) + 1))\n",
        "\n",
        "    # Plot Loss Curve\n",
        "    plt.figure()\n",
        "    plt.plot(epochs, train_losses, label=\"Train Loss\")\n",
        "    plt.plot(epochs, val_losses, label=\"Val Loss\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.title(\"Training & Validation Loss\")\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.savefig(os.path.join(MODEL_DIR, \"loss_curve.png\"))\n",
        "    plt.close()\n",
        "\n",
        "    # Plot HitRate@3\n",
        "    plt.figure()\n",
        "    plt.plot(epochs, val_hitrates, label=\"Val HitRate@3\", color=\"green\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"HitRate@3\")\n",
        "    plt.title(\"Validation HitRate@3\")\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.savefig(os.path.join(MODEL_DIR, \"hitrate_curve.png\"))\n",
        "    plt.close()\n",
        "\n",
        "    # Plot Learning Rate\n",
        "    plt.figure()\n",
        "    plt.plot(epochs, learning_rates, label=\"Learning Rate\", color=\"orange\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"LR\")\n",
        "    plt.title(\"Learning Rate Schedule\")\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.savefig(os.path.join(MODEL_DIR, \"lr_curve.png\"))\n",
        "    plt.close()\n",
        "\n",
        "    # Plot NDCG@3\n",
        "    plt.figure()\n",
        "    plt.plot(epochs, val_ndcgs, label=\"Val NDCG@3\", color=\"purple\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"NDCG@3\")\n",
        "    plt.title(\"Validation NDCG@3\")\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.savefig(os.path.join(MODEL_DIR, \"ndcg_curve.png\"))\n",
        "    plt.close()\n",
        "\n",
        "    # Plot MAP@3\n",
        "    plt.figure()\n",
        "    plt.plot(epochs, val_maps, label=\"Val MAP@3\", color=\"red\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"MAP@3\")\n",
        "    plt.title(\"Validation MAP@3\")\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.savefig(os.path.join(MODEL_DIR, \"map_curve.png\"))\n",
        "    plt.close()\n",
        "\n",
        "    print(\"üìä Saved metric plots to model/\")\n",
        "\n",
        "    # Predict test set\n",
        "    model.load_state_dict(torch.load(model_path))\n",
        "    model.eval()\n",
        "\n",
        "    val_ids = X_va[\"Id\"]\n",
        "    val_rankers = groups_va[\"ranker_id\"]\n",
        "    val_labels = y_va\n",
        "\n",
        "    all_val_scores = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for x_cat, x_num, _, lengths in tqdm(val_loader, desc=\"Predicting validation set\"):\n",
        "            x_num = x_num.to(device)\n",
        "            x_cat = {k: v.to(device) for k, v in x_cat.items()}\n",
        "            scores = model(x_cat, x_num)\n",
        "\n",
        "            for i in range(scores.size(0)):\n",
        "                l = lengths[i]\n",
        "                all_val_scores.append(scores[i, :l].cpu().numpy())\n",
        "\n",
        "    all_val_scores = np.concatenate(all_val_scores)\n",
        "\n",
        "    assert len(all_val_scores) == X_va.shape[0], \\\n",
        "        f\"Mismatch: {len(all_val_scores)} scores vs {X_va.shape[0]} rows\"\n",
        "\n",
        "    val_df = X_va.with_columns([\n",
        "        pl.Series(\"Id\", val_ids),\n",
        "        pl.Series(\"ranker_id\", val_rankers),\n",
        "        pl.Series(\"score\", all_val_scores),\n",
        "        pl.Series(\"label\", val_labels)\n",
        "    ])\n",
        "\n",
        "    val_df = val_df.with_columns(\n",
        "        pl.col(\"score\")\n",
        "        .rank(method=\"ordinal\", descending=True)\n",
        "        .over(\"ranker_id\")\n",
        "        .cast(pl.Int32)\n",
        "        .alias(\"selected\")\n",
        "    )\n",
        "\n",
        "    val_save_path = os.path.join(MODEL_DIR, \"validation_preds_dl_full.csv\")\n",
        "    val_df.write_csv(val_save_path)\n",
        "    print(f\"‚úÖ Saved full validation predictions (with features) to {val_save_path}\")\n",
        "\n",
        "    all_scores = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for x_cat, x_num, _, lengths in tqdm(test_loader, desc=\"Predicting test set\"):\n",
        "            x_num = x_num.to(device)\n",
        "            x_cat = {k: v.to(device) for k, v in x_cat.items()}\n",
        "            scores = model(x_cat, x_num)\n",
        "\n",
        "            for i in range(scores.size(0)):\n",
        "                l = lengths[i]\n",
        "                all_scores.append(scores[i, :l].cpu().numpy())\n",
        "\n",
        "    all_scores = np.concatenate(all_scores)\n",
        "\n",
        "    assert len(all_scores) == X_te.shape[0], \\\n",
        "        f\"Mismatch: {len(all_scores)} scores vs {X_te.shape[0]} rows in X_te\"\n",
        "\n",
        "    submission_df = pl.DataFrame({\n",
        "        \"Id\": test_ids,\n",
        "        \"ranker_id\": test_rankers,\n",
        "        \"score\": all_scores\n",
        "    })\n",
        "\n",
        "    submission = (\n",
        "        submission_df\n",
        "        .with_columns(\n",
        "            pl.col(\"score\")\n",
        "            .rank(method=\"ordinal\", descending=True)\n",
        "            .over(\"ranker_id\")\n",
        "            .cast(pl.Int32)\n",
        "            .alias(\"selected\")\n",
        "        )\n",
        "        .select([\"Id\", \"ranker_id\", \"score\", \"selected\"])\n",
        "    )\n",
        "\n",
        "    submission_path = os.path.join(SUBMIT_DIR, \"submission_dl_ranker.csv\")\n",
        "    submission.write_csv(submission_path)\n",
        "    print(f\"‚úÖ Submission saved to {submission_path}\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2wz5R8PkF1_G",
        "outputId": "93afc9b4-27bb-4d9e-f516-15c6eacbae57"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing deeprec_validate.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "--- Epoch 1/10 ---\n",
        "Validating:   0%|          | 0/2636 [00:00<?, ?it/s]/home/ionut/test_whisper/test2/deeprec_validate.py:515: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
        "  lengths = torch.tensor(lengths).to(device)\n",
        "Epoch 1: Train Loss=0.3199, Val Loss=0.2600, HitRate@3=0.4677, NDCG@3=0.3706, MAP@3=0.6162, LR=0.000084 (607.2s)\n",
        "üíæ Model improved (loss ‚Üì and hitrate ‚Üë), saved.\n",
        "\n",
        "--- Epoch 2/10 ---\n",
        "Epoch 2: Train Loss=0.2564, Val Loss=0.2443, HitRate@3=0.4911, NDCG@3=0.3922, MAP@3=0.6326, LR=0.000228 (605.1s)\n",
        "üíæ Model improved (loss ‚Üì and hitrate ‚Üë), saved.\n",
        "\n",
        "--- Epoch 3/10 ---\n",
        "Epoch 3: Train Loss=0.2452, Val Loss=0.2439, HitRate@3=0.4942, NDCG@3=0.3957, MAP@3=0.6396, LR=0.000300 (604.9s)\n",
        "üíæ Model improved (loss ‚Üì and hitrate ‚Üë), saved.\n",
        "\n",
        "--- Epoch 4/10 ---\n",
        "Epoch 4: Train Loss=0.2351, Val Loss=0.2313, HitRate@3=0.5130, NDCG@3=0.4129, MAP@3=0.6533, LR=0.000285 (607.4s)\n",
        "üíæ Model improved (loss ‚Üì and hitrate ‚Üë), saved.\n",
        "\n",
        "--- Epoch 5/10 ---\n",
        "Epoch 5: Train Loss=0.2225, Val Loss=0.2211, HitRate@3=0.5126, NDCG@3=0.4148, MAP@3=0.6601, LR=0.000244 (607.2s)\n",
        "\n",
        "--- Epoch 6/10 ---\n",
        "Epoch 6: Train Loss=0.2133, Val Loss=0.2222, HitRate@3=0.5161, NDCG@3=0.4155, MAP@3=0.6558, LR=0.000183 (607.9s)\n",
        "üíæ Model improved (loss ‚Üì and hitrate ‚Üë), saved."
      ],
      "metadata": {
        "id": "DRfW5VfrW82B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile deeprec_full_training.py\n",
        "import os\n",
        "import time\n",
        "import random\n",
        "import torch\n",
        "import math\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F_torch\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import defaultdict\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "import polars as pl\n",
        "from tqdm import tqdm\n",
        "from src.feature import feature_engineering, feature_selection\n",
        "from transformers import get_scheduler\n",
        "from collections import Counter\n",
        "from torch.optim.lr_scheduler import OneCycleLR\n",
        "\n",
        "class RankDataset(Dataset):\n",
        "    def __init__(\n",
        "        self,\n",
        "        X: pl.DataFrame,\n",
        "        y: pl.Series,\n",
        "        groups: pl.DataFrame,\n",
        "        cat_features: list[str],\n",
        "        num_features: list[str],\n",
        "    ):\n",
        "        self.cat_features = cat_features\n",
        "        self.num_features = num_features\n",
        "        self.X_cat = {c: X[c].to_numpy() for c in cat_features}\n",
        "        self.X_num = X[self.num_features].to_numpy()\n",
        "        self.y = y.to_numpy()\n",
        "        self.groups = groups[\"ranker_id\"].to_numpy()\n",
        "\n",
        "        self.group_to_indices = defaultdict(list)\n",
        "        for i, g in enumerate(self.groups):\n",
        "            self.group_to_indices[g].append(i)\n",
        "        self.group_keys = list(self.group_to_indices.keys())\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.group_keys)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        g = self.group_keys[idx]\n",
        "        inds = self.group_to_indices[g]\n",
        "        length = len(inds)\n",
        "\n",
        "        x_cat = {\n",
        "            c: torch.LongTensor([\n",
        "                self.X_cat[c][i] if self.X_cat[c][i] >= 0 else 0 for i in inds\n",
        "            ])\n",
        "            for c in self.cat_features\n",
        "        }\n",
        "\n",
        "        x_num = torch.FloatTensor(self.X_num[inds])\n",
        "        y = torch.FloatTensor(self.y[inds]).reshape(-1)\n",
        "\n",
        "        return x_cat, x_num, y, length\n",
        "\n",
        "def collate_fn(batch):\n",
        "    batch_size = len(batch)\n",
        "    lengths = [b[3] for b in batch]\n",
        "    max_len = max(lengths)\n",
        "\n",
        "    padded_x_cat = {key: [] for key in batch[0][0].keys()}\n",
        "    padded_x_num = []\n",
        "    padded_y = []\n",
        "\n",
        "    num_dim = batch[0][1].shape[1]\n",
        "\n",
        "    for x_cat, x_num, y, length in batch:\n",
        "        pad_len = max_len - length\n",
        "\n",
        "        for key in padded_x_cat:\n",
        "            val = x_cat[key]\n",
        "            if pad_len > 0:\n",
        "                val = torch.cat([val, torch.zeros(pad_len, dtype=torch.long)])\n",
        "            padded_x_cat[key].append(val)\n",
        "\n",
        "        if pad_len > 0:\n",
        "            x_num = torch.cat([x_num, torch.zeros(pad_len, num_dim)])\n",
        "            y = torch.cat([y, torch.zeros(pad_len)])\n",
        "\n",
        "        padded_x_num.append(x_num)\n",
        "        padded_y.append(y)\n",
        "\n",
        "    padded_x_cat = {k: torch.stack(v) for k, v in padded_x_cat.items()}\n",
        "    padded_x_num = torch.stack(padded_x_num)\n",
        "    padded_y = torch.stack(padded_y)\n",
        "    lengths = torch.tensor(lengths, dtype=torch.long)\n",
        "\n",
        "    return padded_x_cat, padded_x_num, padded_y, lengths\n",
        "\n",
        "class SEModule(nn.Module):\n",
        "    def __init__(self, channel, reduction=4):\n",
        "        super().__init__()\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(channel, channel // reduction),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(channel // reduction, channel),\n",
        "            nn.Sigmoid(),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: [B, N, C]\n",
        "        w = self.fc(x.mean(dim=1))\n",
        "        w = w.unsqueeze(1)  # [B, 1, C]\n",
        "        return x * w\n",
        "\n",
        "\n",
        "class DLRankerAttention(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        cat_dims,\n",
        "        num_numeric_feats,\n",
        "        emb_dropout=0.1,\n",
        "        dropout=0.1,\n",
        "        num_heads=4,\n",
        "        num_layers=4,\n",
        "        dim_feedforward=128,\n",
        "        proj_dim=64,\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "        self.emb_dims = {\n",
        "            f: min(50, max(4, round(6 * math.log2(cat_dims[f] + 1)))) for f in cat_dims\n",
        "        }\n",
        "        self.embeddings = nn.ModuleDict({\n",
        "            f: nn.Embedding(cat_dims[f], self.emb_dims[f], padding_idx=0)\n",
        "            for f in cat_dims\n",
        "        })\n",
        "        self.emb_dropout = nn.Dropout(emb_dropout)\n",
        "\n",
        "        total_emb_dim = sum(self.emb_dims.values())\n",
        "        print(f\"Categorial emb dim sum: {total_emb_dim}, Numerical dim: {num_numeric_feats}\")\n",
        "\n",
        "        self.cat_proj = nn.Linear(total_emb_dim, proj_dim)\n",
        "        self.cat_transformer = nn.TransformerEncoder(\n",
        "            nn.TransformerEncoderLayer(\n",
        "                d_model=proj_dim,\n",
        "                nhead=4,\n",
        "                dim_feedforward=dim_feedforward,\n",
        "                dropout=dropout,\n",
        "                batch_first=True,\n",
        "                norm_first=True,\n",
        "            ),\n",
        "            num_layers=1,\n",
        "        )\n",
        "\n",
        "        self.num_proj_in = nn.Linear(num_numeric_feats, proj_dim)\n",
        "        self.num_transformer = nn.TransformerEncoder(\n",
        "            nn.TransformerEncoderLayer(\n",
        "                d_model=proj_dim,\n",
        "                nhead=4,\n",
        "                dim_feedforward=dim_feedforward,\n",
        "                dropout=dropout,\n",
        "                batch_first=True,\n",
        "                norm_first=True,\n",
        "            ),\n",
        "            num_layers=1,\n",
        "        )\n",
        "        self.num_se = SEModule(proj_dim)\n",
        "        self.num_proj_out = nn.Sequential(\n",
        "            nn.Linear(proj_dim, proj_dim),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(dropout),\n",
        "        )\n",
        "\n",
        "        self.cross_attn_cat2num = nn.MultiheadAttention(\n",
        "            embed_dim=proj_dim,\n",
        "            num_heads=4,\n",
        "            dropout=dropout,\n",
        "            batch_first=True,\n",
        "        )\n",
        "\n",
        "        self.transformer_layers = nn.ModuleList([\n",
        "            nn.TransformerEncoderLayer(\n",
        "                d_model=2 * proj_dim,\n",
        "                nhead=num_heads,\n",
        "                dim_feedforward=dim_feedforward,\n",
        "                dropout=dropout,\n",
        "                batch_first=True,\n",
        "                norm_first=True,\n",
        "            )\n",
        "            for _ in range(num_layers)\n",
        "        ])\n",
        "\n",
        "        # Contextual pooling ‚Üí concat global context to each item\n",
        "        self.mlp = nn.Sequential(\n",
        "            nn.Linear(2 * proj_dim + 2 * proj_dim, 128),  # context + item\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(128, 64),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(64, 1),\n",
        "        )\n",
        "\n",
        "    def forward(self, x_cat: dict, x_num: torch.Tensor, attn_mask=None):\n",
        "        B, N, _ = x_num.shape\n",
        "\n",
        "        cat_embs = torch.cat([self.embeddings[f](x_cat[f]) for f in x_cat], dim=-1)\n",
        "        cat_embs = self.emb_dropout(cat_embs)\n",
        "        cat_feat = self.cat_proj(cat_embs)\n",
        "        cat_feat = self.cat_transformer(cat_feat)\n",
        "\n",
        "        num_feat = self.num_proj_in(x_num)\n",
        "        num_feat = self.num_transformer(num_feat)\n",
        "        num_feat = self.num_se(num_feat)\n",
        "        num_feat = self.num_proj_out(num_feat)\n",
        "\n",
        "        cat_feat_attn, _ = self.cross_attn_cat2num(query=cat_feat, key=num_feat, value=num_feat)\n",
        "        cat_feat = cat_feat + cat_feat_attn\n",
        "\n",
        "        x = torch.cat([cat_feat, num_feat], dim=-1)\n",
        "\n",
        "        for layer in self.transformer_layers:\n",
        "            x = layer(x, src_key_padding_mask=attn_mask)\n",
        "\n",
        "        # üî• Contextual pooling\n",
        "        global_context = x.mean(dim=1, keepdim=True).expand(-1, N, -1)  # [B, N, 2*D]\n",
        "        x = torch.cat([x, global_context], dim=-1)  # [B, N, 4*D]\n",
        "\n",
        "        scores = self.mlp(x).squeeze(-1)\n",
        "        return scores\n",
        "\n",
        "\"\"\"\n",
        "def listmle_loss(scores, labels, lengths):\n",
        "    batch_size = scores.size(0)\n",
        "    total_loss = torch.tensor(0.0, device=scores.device, requires_grad=True)\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "\n",
        "        _, idx = torch.sort(y, descending=True)\n",
        "        s_sorted = s[idx]\n",
        "\n",
        "        parts = (\n",
        "            torch.logsumexp(s_sorted.unsqueeze(0).expand(l, -1).triu(diagonal=0), dim=1)\n",
        "            - s_sorted\n",
        "        )\n",
        "\n",
        "        total_loss = total_loss + parts.sum()\n",
        "\n",
        "    return total_loss / batch_size\n",
        "\"\"\"\n",
        "\n",
        "def hitrate_at_k(scores, labels, lengths, k=3):\n",
        "    batch_size = scores.size(0)\n",
        "    hits = 0\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        length = min(l, k)\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "        _, topk_idx = torch.topk(s, length)\n",
        "        topk_labels = y[topk_idx]\n",
        "        hits += (topk_labels > 0).any().float()\n",
        "    return hits / batch_size\n",
        "\n",
        "\"\"\"\n",
        "def listnet_loss(scores, labels, lengths):\n",
        "    batch_size = scores.size(0)\n",
        "    total_loss = 0.0\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "\n",
        "        s_softmax = torch.nn.functional.log_softmax(s, dim=0)\n",
        "        y_softmax = torch.nn.functional.softmax(y, dim=0)\n",
        "\n",
        "        loss = -torch.sum(y_softmax * s_softmax)\n",
        "        total_loss += loss\n",
        "\n",
        "    return total_loss / batch_size\n",
        "\"\"\"\n",
        "\n",
        "def ranknet_loss(scores, labels, lengths):\n",
        "    batch_size = scores.size(0)\n",
        "    total_loss = 0.0\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "\n",
        "        diff_scores = s.unsqueeze(1) - s.unsqueeze(0)\n",
        "        rel = y.unsqueeze(1) > y.unsqueeze(0)\n",
        "        label_diff = rel.float()\n",
        "\n",
        "        log_sigmoid = torch.nn.functional.logsigmoid(diff_scores)\n",
        "        pair_loss = -label_diff * log_sigmoid\n",
        "\n",
        "        total_loss += pair_loss.sum()\n",
        "\n",
        "    return total_loss / batch_size\n",
        "\n",
        "def xranknet_loss(scores, labels, lengths, temperature=1.0, margin=0.2, focus_topk=3):\n",
        "    \"\"\"\n",
        "    xRankNet with emphasis on top-K items (based on labels, not scores).\n",
        "    \"\"\"\n",
        "    batch_size = scores.size(0)\n",
        "    total_loss = 0.0\n",
        "    total_pairs = 0\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        if l < 2:\n",
        "            continue\n",
        "\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "\n",
        "        # Top-K mask based on ground truth labels\n",
        "        topk = min(focus_topk, l)\n",
        "        _, topk_idx = torch.topk(y, topk)\n",
        "        topk_mask = torch.zeros_like(y, dtype=torch.bool)\n",
        "        topk_mask[topk_idx] = True\n",
        "\n",
        "        # Create pairwise difference matrices\n",
        "        score_diff = s.unsqueeze(1) - s.unsqueeze(0)\n",
        "        label_diff = y.unsqueeze(1) - y.unsqueeze(0)\n",
        "\n",
        "        # valid pair: y_i > y_j and at least one of i, j is in top-K\n",
        "        valid_pairs = (label_diff > 0) & (\n",
        "            topk_mask.unsqueeze(1) | topk_mask.unsqueeze(0)\n",
        "        )\n",
        "\n",
        "        if valid_pairs.sum() == 0:\n",
        "            continue\n",
        "\n",
        "        importance = (label_diff.abs() * valid_pairs).float()\n",
        "\n",
        "        if margin > 0.0:\n",
        "            score_diff = score_diff - margin\n",
        "\n",
        "        score_diff = score_diff / temperature\n",
        "        pairwise_loss = -F_torch.logsigmoid(score_diff) * importance\n",
        "\n",
        "        total_loss += pairwise_loss.sum()\n",
        "        total_pairs += importance.sum()\n",
        "\n",
        "    if total_pairs == 0:\n",
        "        return torch.tensor(0.0, device=scores.device, requires_grad=True)\n",
        "\n",
        "    return total_loss / total_pairs\n",
        "\n",
        "def train_one_epoch(model, loader, optimizer, device, scheduler):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "\n",
        "    for x_cat, x_num, y, lengths in tqdm(loader, desc=\"Training\", leave=False):\n",
        "        x_num, y = x_num.to(device), y.to(device)\n",
        "        if not isinstance(lengths, torch.Tensor):\n",
        "            lengths = torch.tensor(lengths)\n",
        "        lengths = lengths.detach().clone().to(device)\n",
        "        x_cat = {k: v.to(device) for k, v in x_cat.items()}\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        scores = model(x_cat, x_num)\n",
        "        loss = xranknet_loss(scores, y, lengths, temperature=1.0, margin=0.0, focus_topk=3)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    return total_loss / len(loader)\n",
        "\n",
        "\n",
        "def validate(model, loader, device):\n",
        "    model.eval()\n",
        "    total_hitrate = 0\n",
        "    total_loss = 0\n",
        "    count = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for x_cat, x_num, y, lengths in tqdm(loader, desc=\"Validating\", leave=False):\n",
        "\n",
        "            x_num, y = x_num.to(device), y.to(device)\n",
        "            lengths = torch.tensor(lengths).to(device)\n",
        "            x_cat = {k: v.to(device) for k, v in x_cat.items()}\n",
        "            scores = model(x_cat, x_num)\n",
        "\n",
        "            hitrate = hitrate_at_k(scores, y, lengths, k=3)\n",
        "            loss = xranknet_loss(scores, y, lengths, temperature=1.0, margin=0.0, focus_topk=3)\n",
        "\n",
        "            total_hitrate += hitrate * scores.size(0)\n",
        "            total_loss += loss.item() * scores.size(0)\n",
        "            count += scores.size(0)\n",
        "\n",
        "    avg_hitrate = total_hitrate / count\n",
        "    avg_loss = total_loss / count\n",
        "    return avg_loss, avg_hitrate\n",
        "\n",
        "\n",
        "def build_cat_dims(X, cat_features):\n",
        "    cat_dims = {}\n",
        "    for c in cat_features:\n",
        "        max_val = X[c].max()\n",
        "        if max_val < 0:\n",
        "            max_val = 0\n",
        "        cat_dims[c] = max_val + 1\n",
        "    return cat_dims\n",
        "\n",
        "\n",
        "def normalize_numeric_features(X, numeric_features, train_mask):\n",
        "    for col in numeric_features:\n",
        "        values = X[col].to_numpy()\n",
        "        train_vals = values[train_mask]\n",
        "        mean = train_vals.mean()\n",
        "        std = train_vals.std() if train_vals.std() > 0 else 1.0\n",
        "        norm_vals = (values - mean) / std\n",
        "        X = X.with_columns(pl.Series(col, norm_vals).alias(col))\n",
        "    return X\n",
        "\n",
        "\n",
        "def load_or_prepare_data(\n",
        "    data_dir,\n",
        "    train_file=\"train.parquet\",\n",
        "    test_file=\"test.parquet\",\n",
        "    cache_file=\"feature_engineered_val.parquet\",\n",
        "):\n",
        "    cache_path = os.path.join(data_dir, cache_file)\n",
        "\n",
        "    if os.path.exists(cache_path):\n",
        "        print(f\"Loading cached feature-engineered data from {cache_path} ...\")\n",
        "        df = pl.read_parquet(cache_path)\n",
        "\n",
        "        test = pl.read_parquet(os.path.join(data_dir, test_file)).drop(\"__index_level_0__\")\n",
        "        test_ids = test[\"Id\"]\n",
        "        test_rankers = test[\"ranker_id\"]\n",
        "    else:\n",
        "        print(\"Cached file not found, processing raw data ...\")\n",
        "\n",
        "        train = pl.read_parquet(os.path.join(data_dir, train_file)).drop(\"__index_level_0__\")\n",
        "        test = (\n",
        "            pl.read_parquet(os.path.join(data_dir, test_file))\n",
        "            .drop(\"__index_level_0__\")\n",
        "            .with_columns(pl.lit(0, dtype=pl.Int64).alias(\"selected\"))\n",
        "        )\n",
        "\n",
        "        test_ids = test[\"Id\"]\n",
        "        test_rankers = test[\"ranker_id\"]\n",
        "\n",
        "        df = pl.concat((train, test))\n",
        "        df = feature_engineering(df, full=True)\n",
        "\n",
        "        df = df.with_columns(\n",
        "            [pl.col(c).fill_null(0) for c in df.select(pl.selectors.numeric()).columns] +\n",
        "            [pl.col(c).fill_null(\"missing\") for c in df.select(pl.selectors.string()).columns]\n",
        "        )\n",
        "\n",
        "        os.makedirs(data_dir, exist_ok=True)\n",
        "        df.write_parquet(cache_path)\n",
        "        print(f\"Saved feature-engineered data to {cache_path}\")\n",
        "\n",
        "    return df, test_ids, test_rankers\n",
        "\n",
        "\n",
        "def prepare_data(data_dir):\n",
        "    df, test_ids, test_rankers = load_or_prepare_data(data_dir)\n",
        "\n",
        "    id_column = df[\"Id\"]\n",
        "    X, y, groups, cat_features, num_features = feature_selection(df)\n",
        "\n",
        "    X = X.with_columns(pl.Series(\"Id\", id_column[:X.shape[0]]))\n",
        "\n",
        "    X = X.with_columns(\n",
        "        [\n",
        "            (pl.col(c).rank(\"dense\") - 1).fill_null(-1).cast(pl.Int32)\n",
        "            for c in cat_features\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    train_size = 18145372\n",
        "    train_mask = np.arange(X.height) < train_size\n",
        "    X = normalize_numeric_features(X, num_features, train_mask)\n",
        "\n",
        "    return X, y, groups, cat_features, num_features, train_size, test_ids, test_rankers\n",
        "\n",
        "\n",
        "class EarlyStopping:\n",
        "    def __init__(self, patience=3, min_delta=0.001):\n",
        "        self.patience = patience\n",
        "        self.min_delta = min_delta\n",
        "        self.best = float(\"-inf\")\n",
        "        self.counter = 0\n",
        "\n",
        "    def step(self, metric):\n",
        "        if metric > self.best + self.min_delta:\n",
        "            self.best = metric\n",
        "            self.counter = 0\n",
        "        else:\n",
        "            self.counter += 1\n",
        "        return self.counter >= self.patience\n",
        "\n",
        "\n",
        "def plot_group_size_distribution(dataset, save_path=None):\n",
        "    group_sizes = [len(v) for v in dataset.group_to_indices.values()]\n",
        "    plt.figure()\n",
        "    plt.hist(group_sizes, bins=100, log=True)\n",
        "    plt.xlabel(\"Group size (number of items per ranker_id)\")\n",
        "    plt.ylabel(\"Frequency (log scale)\")\n",
        "    plt.title(\"Distribution of Group Sizes\")\n",
        "    plt.grid(True)\n",
        "    if save_path:\n",
        "        plt.savefig(save_path)\n",
        "    else:\n",
        "        plt.show()\n",
        "    plt.close()\n",
        "\n",
        "\n",
        "def main():\n",
        "    DATA_DIR = \"./data\"\n",
        "    MODEL_DIR = \"model\"\n",
        "    SUBMIT_DIR = \"submission\"\n",
        "\n",
        "    model_path = os.path.join(MODEL_DIR, \"best_dl_ranker.pt\")\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    train_losses = []\n",
        "    learning_rates = []\n",
        "\n",
        "    os.makedirs(MODEL_DIR, exist_ok=True)\n",
        "    os.makedirs(SUBMIT_DIR, exist_ok=True)\n",
        "\n",
        "    early_stopper = EarlyStopping(patience=3, min_delta=0.001)\n",
        "\n",
        "    X, y, groups, cat_features, num_features, train_size, test_ids, test_rankers = prepare_data(DATA_DIR)\n",
        "\n",
        "    # Fill missing values\n",
        "    float_cols = [c for c, t in zip(X.columns, X.dtypes) if t == pl.Float64]\n",
        "    for col in float_cols:\n",
        "        X = X.with_columns(\n",
        "            pl.when(pl.col(col).is_nan()).then(0).otherwise(pl.col(col)).alias(col)\n",
        "        )\n",
        "\n",
        "    n2 = train_size\n",
        "\n",
        "    X_tr, X_te = X[:n2], X[n2:]\n",
        "    y_tr, y_te = y[:n2], y[n2:]\n",
        "    groups_tr, groups_te = groups[:n2], groups[n2:]\n",
        "\n",
        "    cat_dims = build_cat_dims(X, cat_features)\n",
        "    num_numeric_feats = len(num_features)\n",
        "\n",
        "    train_dataset = RankDataset(X_tr, y_tr, groups_tr, cat_features, num_features)\n",
        "    test_dataset = RankDataset(X_te, y_te, groups_te, cat_features, num_features)\n",
        "\n",
        "    plot_group_size_distribution(train_dataset, save_path=os.path.join(MODEL_DIR, \"group_sizes.png\"))\n",
        "    print(\"üìä Group size distribution saved.\")\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True, collate_fn=collate_fn)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False, collate_fn=collate_fn)\n",
        "\n",
        "    print(\"‚úÖ Data loaders created.\")\n",
        "\n",
        "    num_epochs = 10\n",
        "    num_training_steps = num_epochs * len(train_loader)\n",
        "    num_warmup_steps = int(0.1 * num_training_steps)\n",
        "\n",
        "    learning_rate = 3e-4\n",
        "\n",
        "    model = DLRankerAttention(\n",
        "        cat_dims=cat_dims,\n",
        "        num_numeric_feats=num_numeric_feats,\n",
        "        emb_dropout=0.1,\n",
        "        dropout=0.1,\n",
        "        num_heads=4,\n",
        "        num_layers=2,\n",
        "        dim_feedforward=128,\n",
        "        proj_dim=64\n",
        "    ).to(device)\n",
        "\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=0.05)\n",
        "\n",
        "    scheduler = OneCycleLR(\n",
        "        optimizer,\n",
        "        max_lr=learning_rate,\n",
        "        steps_per_epoch=len(train_loader),\n",
        "        epochs=num_epochs,\n",
        "        pct_start=0.3,\n",
        "    )\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print(f\"\\n--- Epoch {epoch+1}/{num_epochs} ---\")\n",
        "        start_time = time.time()\n",
        "\n",
        "        train_loss = train_one_epoch(model, train_loader, optimizer, device, scheduler)\n",
        "\n",
        "        train_losses.append(train_loss)\n",
        "\n",
        "        current_lr = scheduler.get_last_lr()\n",
        "        learning_rates.append(current_lr[0])\n",
        "\n",
        "        elapsed = time.time() - start_time\n",
        "        print(\n",
        "            f\"Epoch {epoch+1}: \"\n",
        "            f\"Train Loss={train_loss:.4f}, \"\n",
        "            f\"LR={current_lr[0]:.6f} \"\n",
        "            f\"({elapsed:.1f}s)\"\n",
        "        )\n",
        "\n",
        "        torch.save(model.state_dict(), model_path)\n",
        "        print(\"üíæ Model improved (loss ‚Üì and hitrate ‚Üë), saved.\")\n",
        "\n",
        "    # Plot metrics\n",
        "    epochs = list(range(1, len(train_losses) + 1))\n",
        "\n",
        "    # Predict test set\n",
        "    model.load_state_dict(torch.load(model_path))\n",
        "    model.eval()\n",
        "    all_scores = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for x_cat, x_num, _, lengths in tqdm(test_loader, desc=\"Predicting test set\"):\n",
        "            x_num = x_num.to(device)\n",
        "            x_cat = {k: v.to(device) for k, v in x_cat.items()}\n",
        "            scores = model(x_cat, x_num)\n",
        "\n",
        "            for i in range(scores.size(0)):\n",
        "                l = lengths[i]\n",
        "                all_scores.append(scores[i, :l].cpu().numpy())\n",
        "\n",
        "    all_scores = np.concatenate(all_scores)\n",
        "\n",
        "    assert len(all_scores) == X_te.shape[0], \\\n",
        "        f\"Mismatch: {len(all_scores)} scores vs {X_te.shape[0]} rows in X_te\"\n",
        "\n",
        "    submission_df = pl.DataFrame({\n",
        "        \"Id\": test_ids,\n",
        "        \"ranker_id\": test_rankers,\n",
        "        \"score\": all_scores\n",
        "    })\n",
        "\n",
        "    submission = (\n",
        "        submission_df\n",
        "        .with_columns(\n",
        "            pl.col(\"score\")\n",
        "            .rank(method=\"ordinal\", descending=True)\n",
        "            .over(\"ranker_id\")\n",
        "            .cast(pl.Int32)\n",
        "            .alias(\"selected\")\n",
        "        )\n",
        "        .select([\"Id\", \"ranker_id\", \"selected\"])\n",
        "    )\n",
        "\n",
        "\n",
        "    submission_path = os.path.join(SUBMIT_DIR, \"submission_dl_ranker.parquet\")\n",
        "    submission.write_parquet(submission_path)\n",
        "    print(f\"‚úÖ Submission saved to {submission_path}\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JVsGsds6WbCB",
        "outputId": "3498518b-bbc5-4131-a220-faa608a64bd0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing deeprec_full_training.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2 Stage Training**"
      ],
      "metadata": {
        "id": "uKu5K3Tl2cSu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Top 10**"
      ],
      "metadata": {
        "id": "56GTFX9E2fzs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile deeprec_validate_top10.py\n",
        "import os\n",
        "import time\n",
        "import random\n",
        "import torch\n",
        "import math\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import defaultdict\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "import polars as pl\n",
        "from tqdm import tqdm\n",
        "from src.feature import feature_engineering, feature_selection\n",
        "from transformers import get_scheduler\n",
        "from collections import Counter\n",
        "from torch.optim.lr_scheduler import OneCycleLR\n",
        "\n",
        "seed = 42\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "class RankDataset(Dataset):\n",
        "    def __init__(\n",
        "        self,\n",
        "        X: pl.DataFrame,\n",
        "        y: pl.Series,\n",
        "        groups: pl.DataFrame,\n",
        "        cat_features: list[str],\n",
        "        num_features: list[str],\n",
        "    ):\n",
        "        self.cat_features = cat_features\n",
        "        self.num_features = num_features\n",
        "        self.X_cat = {c: X[c].to_numpy() for c in cat_features}\n",
        "        self.X_num = X[self.num_features].to_numpy()\n",
        "        self.y = y.to_numpy()\n",
        "        self.groups = groups[\"ranker_id\"].to_numpy()\n",
        "\n",
        "        self.group_to_indices = defaultdict(list)\n",
        "        for i, g in enumerate(self.groups):\n",
        "            self.group_to_indices[g].append(i)\n",
        "        self.group_keys = list(self.group_to_indices.keys())\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.group_keys)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        g = self.group_keys[idx]\n",
        "        inds = self.group_to_indices[g]\n",
        "        length = len(inds)\n",
        "\n",
        "        x_cat = {\n",
        "            c: torch.LongTensor([\n",
        "                self.X_cat[c][i] if self.X_cat[c][i] >= 0 else 0 for i in inds\n",
        "            ])\n",
        "            for c in self.cat_features\n",
        "        }\n",
        "\n",
        "        x_num = torch.FloatTensor(self.X_num[inds])\n",
        "        y = torch.FloatTensor(self.y[inds]).reshape(-1)\n",
        "\n",
        "        return x_cat, x_num, y, length\n",
        "\n",
        "def collate_fn(batch):\n",
        "    batch_size = len(batch)\n",
        "    lengths = [b[3] for b in batch]\n",
        "    max_len = max(lengths)\n",
        "\n",
        "    padded_x_cat = {key: [] for key in batch[0][0].keys()}\n",
        "    padded_x_num = []\n",
        "    padded_y = []\n",
        "\n",
        "    num_dim = batch[0][1].shape[1]\n",
        "\n",
        "    for x_cat, x_num, y, length in batch:\n",
        "        pad_len = max_len - length\n",
        "\n",
        "        for key in padded_x_cat:\n",
        "            val = x_cat[key]\n",
        "            if pad_len > 0:\n",
        "                val = torch.cat([val, torch.zeros(pad_len, dtype=torch.long)])\n",
        "            padded_x_cat[key].append(val)\n",
        "\n",
        "        if pad_len > 0:\n",
        "            x_num = torch.cat([x_num, torch.zeros(pad_len, num_dim)])\n",
        "            y = torch.cat([y, torch.zeros(pad_len)])\n",
        "\n",
        "        padded_x_num.append(x_num)\n",
        "        padded_y.append(y)\n",
        "\n",
        "    padded_x_cat = {k: torch.stack(v) for k, v in padded_x_cat.items()}\n",
        "    padded_x_num = torch.stack(padded_x_num)\n",
        "    padded_y = torch.stack(padded_y)\n",
        "    lengths = torch.tensor(lengths, dtype=torch.long)\n",
        "\n",
        "    return padded_x_cat, padded_x_num, padded_y, lengths\n",
        "\n",
        "class SEModule(nn.Module):\n",
        "    def __init__(self, channel, reduction=4):\n",
        "        super().__init__()\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(channel, channel // reduction),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(channel // reduction, channel),\n",
        "            nn.Sigmoid(),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: [B, N, C]\n",
        "        w = self.fc(x.mean(dim=1))\n",
        "        w = w.unsqueeze(1)  # [B, 1, C]\n",
        "        return x * w\n",
        "\n",
        "\n",
        "class FiLM(nn.Module):\n",
        "    def __init__(self, feature_dim):\n",
        "        super().__init__()\n",
        "        self.gamma = nn.Linear(feature_dim, feature_dim)\n",
        "        self.beta = nn.Linear(feature_dim, feature_dim)\n",
        "\n",
        "    def forward(self, x, cond):\n",
        "        gamma = self.gamma(cond)\n",
        "        beta = self.beta(cond)\n",
        "        return gamma * x + beta\n",
        "\n",
        "\n",
        "class DLRankerAttention(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        cat_dims,\n",
        "        num_numeric_feats,\n",
        "        emb_dropout=0.1,\n",
        "        dropout=0.1,\n",
        "        num_heads=4,\n",
        "        num_layers=2,\n",
        "        dim_feedforward=128,\n",
        "        proj_dim=64,\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "        self.emb_dims = {\n",
        "            f: min(50, max(4, round(6 * math.log2(cat_dims[f] + 1)))) for f in cat_dims\n",
        "        }\n",
        "        self.embeddings = nn.ModuleDict({\n",
        "            f: nn.Embedding(cat_dims[f], self.emb_dims[f], padding_idx=0)\n",
        "            for f in cat_dims\n",
        "        })\n",
        "        self.emb_dropout = nn.Dropout(emb_dropout)\n",
        "\n",
        "        total_emb_dim = sum(self.emb_dims.values())\n",
        "        print(f\"Categorial emb dim sum: {total_emb_dim}, Numerical dim: {num_numeric_feats}\")\n",
        "\n",
        "        self.cat_proj = nn.Linear(total_emb_dim, proj_dim)\n",
        "        self.cat_transformer = nn.TransformerEncoder(\n",
        "            nn.TransformerEncoderLayer(\n",
        "                d_model=proj_dim,\n",
        "                nhead=4,\n",
        "                dim_feedforward=dim_feedforward,\n",
        "                dropout=dropout,\n",
        "                batch_first=True,\n",
        "            ),\n",
        "            num_layers=1,\n",
        "        )\n",
        "\n",
        "        self.num_proj_in = nn.Linear(num_numeric_feats, proj_dim)\n",
        "        self.num_transformer = nn.TransformerEncoder(\n",
        "            nn.TransformerEncoderLayer(\n",
        "                d_model=proj_dim,\n",
        "                nhead=4,\n",
        "                dim_feedforward=dim_feedforward,\n",
        "                dropout=dropout,\n",
        "                batch_first=True,\n",
        "            ),\n",
        "            num_layers=1,\n",
        "        )\n",
        "        self.num_se = SEModule(proj_dim)\n",
        "        self.num_proj_out = nn.Sequential(\n",
        "            nn.Linear(proj_dim, proj_dim),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(dropout),\n",
        "        )\n",
        "\n",
        "        # üîÅ Cross-attention: cat attends to num\n",
        "        self.cross_attn_cat2num = nn.MultiheadAttention(\n",
        "            embed_dim=proj_dim,\n",
        "            num_heads=4,\n",
        "            dropout=dropout,\n",
        "            batch_first=True,\n",
        "        )\n",
        "\n",
        "        self.film = FiLM(proj_dim)  # üîß FiLM added here\n",
        "\n",
        "        self.transformer_layers = nn.ModuleList([\n",
        "            nn.TransformerEncoderLayer(\n",
        "                d_model=2 * proj_dim,\n",
        "                nhead=num_heads,\n",
        "                dim_feedforward=dim_feedforward,\n",
        "                dropout=dropout,\n",
        "                batch_first=True,\n",
        "            )\n",
        "            for _ in range(num_layers)\n",
        "        ])\n",
        "\n",
        "        self.mlp = nn.Sequential(\n",
        "            nn.Linear(2 * proj_dim, 128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(128, 64),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(64, 1),\n",
        "        )\n",
        "\n",
        "    def forward(self, x_cat: dict, x_num: torch.Tensor, attn_mask=None):\n",
        "        B, N, _ = x_num.shape  # x_num: [B, N, F_num]\n",
        "\n",
        "        # Categorical embeddings\n",
        "        cat_embs = torch.cat([self.embeddings[f](x_cat[f]) for f in x_cat], dim=-1)\n",
        "        cat_embs = self.emb_dropout(cat_embs)\n",
        "        cat_feat = self.cat_proj(cat_embs)  # [B, N, D]\n",
        "        cat_feat = self.cat_transformer(cat_feat)  # [B, N, D]\n",
        "\n",
        "        # Numeric features\n",
        "        num_feat = self.num_proj_in(x_num)\n",
        "        num_feat = self.num_transformer(num_feat)\n",
        "        num_feat = self.num_se(num_feat)\n",
        "        num_feat = self.num_proj_out(num_feat)\n",
        "\n",
        "        # üîß FiLM: condition cat_feat on num_feat\n",
        "        cat_feat = self.film(cat_feat, num_feat)\n",
        "\n",
        "        # Cross-attention: categorical features attend over numeric ones\n",
        "        cat_feat_attn, _ = self.cross_attn_cat2num(\n",
        "            query=cat_feat, key=num_feat, value=num_feat\n",
        "        )\n",
        "        cat_feat = cat_feat + cat_feat_attn  # residual connection\n",
        "\n",
        "        # Final concatenation\n",
        "        x = torch.cat([cat_feat, num_feat], dim=-1)\n",
        "\n",
        "        for layer in self.transformer_layers:\n",
        "            x = layer(x, src_key_padding_mask=attn_mask)\n",
        "\n",
        "        scores = self.mlp(x).squeeze(-1)  # [B, N]\n",
        "        return scores\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "def listmle_loss(scores, labels, lengths):\n",
        "    batch_size = scores.size(0)\n",
        "    total_loss = torch.tensor(0.0, device=scores.device, requires_grad=True)\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "\n",
        "        _, idx = torch.sort(y, descending=True)\n",
        "        s_sorted = s[idx]\n",
        "\n",
        "        parts = (\n",
        "            torch.logsumexp(s_sorted.unsqueeze(0).expand(l, -1).triu(diagonal=0), dim=1)\n",
        "            - s_sorted\n",
        "        )\n",
        "\n",
        "        total_loss = total_loss + parts.sum()\n",
        "\n",
        "    return total_loss / batch_size\n",
        "\"\"\"\n",
        "\n",
        "def hitrate_at_k(scores, labels, lengths, k=10, min_group_size=10):\n",
        "    batch_size = scores.size(0)\n",
        "    hits = 0\n",
        "    valid_count = 0\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        if l < min_group_size:\n",
        "            continue\n",
        "        length = min(l, k)\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "        _, topk_idx = torch.topk(s, length)\n",
        "        topk_labels = y[topk_idx]\n",
        "        hits += (topk_labels > 0).any().float()\n",
        "        valid_count += 1\n",
        "    return hits / valid_count if valid_count > 0 else torch.tensor(0.0, device=scores.device)\n",
        "\n",
        "\n",
        "def ndcg_at_k(scores, labels, lengths, k=10, min_group_size=10):\n",
        "    batch_size = scores.size(0)\n",
        "    total_ndcg = 0.0\n",
        "    valid_count = 0\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        if l < min_group_size:\n",
        "            continue\n",
        "\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "\n",
        "        _, idx_pred = torch.topk(s, min(k, l))\n",
        "        _, idx_ideal = torch.topk(y, min(k, l))\n",
        "\n",
        "        dcg = (y[idx_pred] / torch.log2(torch.arange(2, 2 + len(idx_pred), device=y.device).float())).sum()\n",
        "        idcg = (y[idx_ideal] / torch.log2(torch.arange(2, 2 + len(idx_ideal), device=y.device).float())).sum()\n",
        "\n",
        "        ndcg = dcg / idcg if idcg > 0 else 0.0\n",
        "        total_ndcg += ndcg\n",
        "        valid_count += 1\n",
        "\n",
        "    return total_ndcg / valid_count if valid_count > 0 else torch.tensor(0.0, device=scores.device)\n",
        "\n",
        "\n",
        "def map_at_k(scores, labels, lengths, k=10, min_group_size=10):\n",
        "    batch_size = scores.size(0)\n",
        "    total_ap = 0.0\n",
        "    valid_count = 0\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        if l < min_group_size:\n",
        "            continue\n",
        "\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "\n",
        "        _, idx_pred = torch.topk(s, min(k, l))\n",
        "        y_true = y[idx_pred] > 0\n",
        "\n",
        "        if y_true.sum() == 0:\n",
        "            continue\n",
        "\n",
        "        precisions = [(y_true[:j+1].float().sum() / (j+1)) for j in range(len(y_true)) if y_true[j]]\n",
        "        ap = torch.stack(precisions).mean()\n",
        "        total_ap += ap\n",
        "        valid_count += 1\n",
        "\n",
        "    return total_ap / valid_count if valid_count > 0 else torch.tensor(0.0, device=scores.device)\n",
        "\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "def listnet_loss(scores, labels, lengths):\n",
        "    batch_size = scores.size(0)\n",
        "    total_loss = 0.0\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "\n",
        "        s_softmax = torch.nn.functional.log_softmax(s, dim=0)\n",
        "        y_softmax = torch.nn.functional.softmax(y, dim=0)\n",
        "\n",
        "        loss = -torch.sum(y_softmax * s_softmax)\n",
        "        total_loss += loss\n",
        "\n",
        "    return total_loss / batch_size\n",
        "\"\"\"\n",
        "\n",
        "def ranknet_loss(scores, labels, lengths):\n",
        "    batch_size = scores.size(0)\n",
        "    total_loss = 0.0\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "\n",
        "        diff_scores = s.unsqueeze(1) - s.unsqueeze(0)\n",
        "        rel = y.unsqueeze(1) > y.unsqueeze(0)\n",
        "        label_diff = rel.float()\n",
        "\n",
        "        log_sigmoid = torch.nn.functional.logsigmoid(diff_scores)\n",
        "        pair_loss = -label_diff * log_sigmoid\n",
        "\n",
        "        total_loss += pair_loss.sum()\n",
        "\n",
        "    return total_loss / batch_size\n",
        "\n",
        "def xranknet_loss(scores, labels, lengths, temperature=1.0, margin=0.2, focus_topk=10):\n",
        "    \"\"\"\n",
        "    xRankNet with emphasis on top-K items (based on labels, not scores).\n",
        "    \"\"\"\n",
        "    batch_size = scores.size(0)\n",
        "    total_loss = 0.0\n",
        "    total_pairs = 0\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        if l < 2:\n",
        "            continue\n",
        "\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "\n",
        "        # Top-K mask based on ground truth labels\n",
        "        topk = min(focus_topk, l)\n",
        "        _, topk_idx = torch.topk(y, topk)\n",
        "        topk_mask = torch.zeros_like(y, dtype=torch.bool)\n",
        "        topk_mask[topk_idx] = True\n",
        "\n",
        "        # Create pairwise difference matrices\n",
        "        score_diff = s.unsqueeze(1) - s.unsqueeze(0)\n",
        "        label_diff = y.unsqueeze(1) - y.unsqueeze(0)\n",
        "\n",
        "        # valid pair: y_i > y_j and at least one of i, j is in top-K\n",
        "        valid_pairs = (label_diff > 0) & (\n",
        "            topk_mask.unsqueeze(1) | topk_mask.unsqueeze(0)\n",
        "        )\n",
        "\n",
        "        if valid_pairs.sum() == 0:\n",
        "            continue\n",
        "\n",
        "        importance = (label_diff.abs() * valid_pairs).float()\n",
        "\n",
        "        if margin > 0.0:\n",
        "            score_diff = score_diff - margin\n",
        "\n",
        "        score_diff = score_diff / temperature\n",
        "        pairwise_loss = -F.logsigmoid(score_diff) * importance\n",
        "\n",
        "        total_loss += pairwise_loss.sum()\n",
        "        total_pairs += importance.sum()\n",
        "\n",
        "    if total_pairs == 0:\n",
        "        return torch.tensor(0.0, device=scores.device, requires_grad=True)\n",
        "\n",
        "    return total_loss / total_pairs\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "def bpr_loss(scores, labels, lengths):\n",
        "    batch_size = scores.size(0)\n",
        "    total_loss = 0.0\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "\n",
        "        pos_mask = y > 0\n",
        "        neg_mask = y <= 0\n",
        "\n",
        "        pos_scores = s[pos_mask]\n",
        "        neg_scores = s[neg_mask]\n",
        "\n",
        "        if len(pos_scores) == 0 or len(neg_scores) == 0:\n",
        "            continue\n",
        "\n",
        "        pair_diff = pos_scores.unsqueeze(1) - neg_scores.unsqueeze(0)\n",
        "        loss = -F.logsigmoid(pair_diff).mean()\n",
        "        total_loss += loss\n",
        "\n",
        "    return total_loss / batch_size\n",
        "\"\"\"\n",
        "\n",
        "\"\"\"\n",
        "def lambdarank_loss(scores, labels, lengths, eps=1e-10):\n",
        "    batch_size = scores.size(0)\n",
        "    total_loss = 0.0\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "\n",
        "        if l < 2:\n",
        "            continue\n",
        "\n",
        "        _, rank_order = torch.sort(s, descending=True)\n",
        "        ideal_order = torch.sort(y, descending=True).indices\n",
        "\n",
        "        gain = 2 ** y - 1\n",
        "        discount = torch.log2(torch.arange(2, l + 2, device=y.device).float())\n",
        "\n",
        "        ideal_dcg = (gain[ideal_order] / discount).sum()\n",
        "        if ideal_dcg < eps:\n",
        "            continue\n",
        "\n",
        "        delta_ndcg = torch.zeros((l, l), device=y.device)\n",
        "\n",
        "        for i_idx in range(l):\n",
        "            for j_idx in range(l):\n",
        "                if y[i_idx] > y[j_idx]:\n",
        "                    change = (\n",
        "                        (1.0 / torch.log2(rank_order[i_idx] + 2.0))\n",
        "                        - (1.0 / torch.log2(rank_order[j_idx] + 2.0))\n",
        "                    ).abs()\n",
        "                    delta = (2 ** y[i_idx] - 2 ** y[j_idx]).abs() * change\n",
        "                    delta_ndcg[i_idx, j_idx] = delta / ideal_dcg\n",
        "\n",
        "        score_diffs = s.unsqueeze(1) - s.unsqueeze(0)\n",
        "        lambdas = -F.logsigmoid(score_diffs) * delta_ndcg\n",
        "        total_loss += lambdas.sum()\n",
        "\n",
        "    return total_loss / batch_size\n",
        "\"\"\"\n",
        "\n",
        "def train_one_epoch(model, loader, optimizer, device, scheduler):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "\n",
        "    for x_cat, x_num, y, lengths in tqdm(loader, desc=\"Training\", leave=False):\n",
        "        x_num, y = x_num.to(device), y.to(device)\n",
        "        if not isinstance(lengths, torch.Tensor):\n",
        "            lengths = torch.tensor(lengths)\n",
        "        lengths = lengths.detach().clone().to(device)\n",
        "        x_cat = {k: v.to(device) for k, v in x_cat.items()}\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        scores = model(x_cat, x_num)\n",
        "        loss = xranknet_loss(scores, y, lengths, temperature=1.0, margin=0.2, focus_topk=10)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    return total_loss / len(loader)\n",
        "\n",
        "\n",
        "def validate(model, loader, device, min_group_size=10):\n",
        "    model.eval()\n",
        "    total_hitrate = 0\n",
        "    total_ndcg = 0\n",
        "    total_map = 0\n",
        "    total_loss = 0\n",
        "    count = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for x_cat, x_num, y, lengths in tqdm(loader, desc=\"Validating\", leave=False):\n",
        "            x_num, y = x_num.to(device), y.to(device)\n",
        "            lengths = torch.tensor(lengths).to(device)\n",
        "            x_cat = {k: v.to(device) for k, v in x_cat.items()}\n",
        "\n",
        "            scores = model(x_cat, x_num)\n",
        "\n",
        "            hitrate = hitrate_at_k(scores, y, lengths, k=10, min_group_size=min_group_size)\n",
        "            ndcg = ndcg_at_k(scores, y, lengths, k=10, min_group_size=min_group_size)\n",
        "            map10 = map_at_k(scores, y, lengths, k=10, min_group_size=min_group_size)\n",
        "            loss = xranknet_loss(scores, y, lengths, temperature=1.0, margin=0.2, focus_topk=10)\n",
        "\n",
        "            batch_size = scores.size(0)\n",
        "            total_hitrate += hitrate * batch_size\n",
        "            total_ndcg += ndcg * batch_size\n",
        "            total_map += map10 * batch_size\n",
        "            total_loss += loss.item() * batch_size\n",
        "            count += batch_size\n",
        "\n",
        "    return total_loss / count, total_hitrate / count, total_ndcg / count, total_map / count\n",
        "\n",
        "\n",
        "def build_cat_dims(X, cat_features):\n",
        "    cat_dims = {}\n",
        "    for c in cat_features:\n",
        "        max_val = X[c].max()\n",
        "        if max_val < 0:\n",
        "            max_val = 0\n",
        "        cat_dims[c] = max_val + 1\n",
        "    return cat_dims\n",
        "\n",
        "\n",
        "def normalize_numeric_features(X, numeric_features, train_mask):\n",
        "    for col in numeric_features:\n",
        "        values = X[col].to_numpy()\n",
        "        train_vals = values[train_mask]\n",
        "        mean = train_vals.mean()\n",
        "        std = train_vals.std() if train_vals.std() > 0 else 1.0\n",
        "        norm_vals = (values - mean) / std\n",
        "        X = X.with_columns(pl.Series(col, norm_vals).alias(col))\n",
        "    return X\n",
        "\n",
        "\n",
        "def load_or_prepare_data(\n",
        "    data_dir,\n",
        "    train_file=\"train.parquet\",\n",
        "    test_file=\"test.parquet\",\n",
        "    cache_file=\"feature_engineered_val.parquet\",\n",
        "):\n",
        "    cache_path = os.path.join(data_dir, cache_file)\n",
        "\n",
        "    if os.path.exists(cache_path):\n",
        "        print(f\"Loading cached feature-engineered data from {cache_path} ...\")\n",
        "        df = pl.read_parquet(cache_path)\n",
        "\n",
        "        test = pl.read_parquet(os.path.join(data_dir, test_file)).drop(\"__index_level_0__\")\n",
        "        test_ids = test[\"Id\"]\n",
        "        test_rankers = test[\"ranker_id\"]\n",
        "    else:\n",
        "        print(\"Cached file not found, processing raw data ...\")\n",
        "\n",
        "        train = pl.read_parquet(os.path.join(data_dir, train_file)).drop(\"__index_level_0__\")\n",
        "        test = (\n",
        "            pl.read_parquet(os.path.join(data_dir, test_file))\n",
        "            .drop(\"__index_level_0__\")\n",
        "            .with_columns(pl.lit(0, dtype=pl.Int64).alias(\"selected\"))\n",
        "        )\n",
        "\n",
        "        test_ids = test[\"Id\"]\n",
        "        test_rankers = test[\"ranker_id\"]\n",
        "\n",
        "        df = pl.concat((train, test))\n",
        "        df = feature_engineering(df, full=True)\n",
        "\n",
        "        df = df.with_columns(\n",
        "            [pl.col(c).fill_null(0) for c in df.select(pl.selectors.numeric()).columns] +\n",
        "            [pl.col(c).fill_null(\"missing\") for c in df.select(pl.selectors.string()).columns]\n",
        "        )\n",
        "\n",
        "        os.makedirs(data_dir, exist_ok=True)\n",
        "        df.write_parquet(cache_path)\n",
        "        print(f\"Saved feature-engineered data to {cache_path}\")\n",
        "\n",
        "    return df, test_ids, test_rankers\n",
        "\n",
        "\n",
        "def prepare_data(data_dir):\n",
        "    df, test_ids, test_rankers = load_or_prepare_data(data_dir)\n",
        "\n",
        "    id_column = df[\"Id\"]\n",
        "    X, y, groups, cat_features, num_features = feature_selection(df)\n",
        "\n",
        "    X = X.with_columns(pl.Series(\"Id\", id_column[:X.shape[0]]))\n",
        "\n",
        "    X = X.with_columns(\n",
        "        [\n",
        "            (pl.col(c).rank(\"dense\") - 1).fill_null(-1).cast(pl.Int32)\n",
        "            for c in cat_features\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    train_size = 18145372\n",
        "    train_mask = np.arange(X.height) < train_size\n",
        "    X = normalize_numeric_features(X, num_features, train_mask)\n",
        "\n",
        "    return X, y, groups, cat_features, num_features, train_size, test_ids, test_rankers\n",
        "\n",
        "\n",
        "class EarlyStopping:\n",
        "    def __init__(self, patience=3, min_delta=0.00005):\n",
        "        self.patience = patience\n",
        "        self.min_delta = min_delta\n",
        "        self.best = float(\"-inf\")\n",
        "        self.counter = 0\n",
        "\n",
        "    def step(self, metric):\n",
        "        if metric > self.best + self.min_delta:\n",
        "            self.best = metric\n",
        "            self.counter = 0\n",
        "        else:\n",
        "            self.counter += 1\n",
        "        return self.counter >= self.patience\n",
        "\n",
        "def min_common_group_size_above(groups_df, threshold=10, name=\"Validation\"):\n",
        "    group_sizes = (\n",
        "        groups_df[\"ranker_id\"]\n",
        "        .value_counts()\n",
        "        .filter(pl.col(\"count\") > threshold)\n",
        "        .sort(\"count\")\n",
        "    )\n",
        "    if group_sizes.is_empty():\n",
        "        print(f\"‚ö†Ô∏è {name}: No groups larger than {threshold}.\")\n",
        "        return None\n",
        "\n",
        "    min_size = group_sizes[\"count\"][0]\n",
        "    print(f\"‚úÖ {name}: All groups larger than {threshold} have at least size {min_size}.\")\n",
        "    return min_size\n",
        "\n",
        "\n",
        "def plot_group_size_distribution(dataset, save_path=None):\n",
        "    group_sizes = [len(v) for v in dataset.group_to_indices.values()]\n",
        "    plt.figure()\n",
        "    plt.hist(group_sizes, bins=100, log=True)\n",
        "    plt.xlabel(\"Group size (number of items per ranker_id)\")\n",
        "    plt.ylabel(\"Frequency (log scale)\")\n",
        "    plt.title(\"Distribution of Group Sizes\")\n",
        "    plt.grid(True)\n",
        "    if save_path:\n",
        "        plt.savefig(save_path)\n",
        "    else:\n",
        "        plt.show()\n",
        "    plt.close()\n",
        "\n",
        "\n",
        "def main():\n",
        "    DATA_DIR = \"./data\"\n",
        "    MODEL_DIR = \"model\"\n",
        "    SUBMIT_DIR = \"submission\"\n",
        "\n",
        "    best_val_loss = float(\"inf\")\n",
        "    best_hitrate = 0.0\n",
        "    model_path = os.path.join(MODEL_DIR, \"best_dl_ranker_top10.pt\")\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "    val_hitrates = []\n",
        "    val_ndcgs = []\n",
        "    val_maps = []\n",
        "    learning_rates = []\n",
        "\n",
        "    os.makedirs(MODEL_DIR, exist_ok=True)\n",
        "    os.makedirs(SUBMIT_DIR, exist_ok=True)\n",
        "\n",
        "    early_stopper = EarlyStopping(patience=3, min_delta=0.001)\n",
        "\n",
        "    X, y, groups, cat_features, num_features, train_size, test_ids, test_rankers = prepare_data(DATA_DIR)\n",
        "\n",
        "    # Fill missing values\n",
        "    float_cols = [c for c, t in zip(X.columns, X.dtypes) if t == pl.Float64]\n",
        "    for col in float_cols:\n",
        "        X = X.with_columns(\n",
        "            pl.when(pl.col(col).is_nan()).then(0).otherwise(pl.col(col)).alias(col)\n",
        "        )\n",
        "\n",
        "    n1 = 16487352\n",
        "    # n1 = 17487300\n",
        "    n2 = train_size\n",
        "\n",
        "    X_tr, X_va, X_te = X[:n1], X[n1:n2], X[n2:]\n",
        "    y_tr, y_va, y_te = y[:n1], y[n1:n2], y[n2:]\n",
        "    groups_tr, groups_va, groups_te = groups[:n1], groups[n1:n2], groups[n2:]\n",
        "\n",
        "    min_common_group_size_above(groups_va, threshold=10, name=\"Validation\")\n",
        "    min_common_group_size_above(groups_te, threshold=10, name=\"Test\")\n",
        "\n",
        "    # Inspect group sizes in validation set\n",
        "    val_rankers = groups_va[\"ranker_id\"].to_numpy()\n",
        "    val_group_counts = Counter(val_rankers)\n",
        "\n",
        "    print(\"\\nüìã Validation group statistics:\")\n",
        "    # Save detailed group info to file\n",
        "    group_info_path = os.path.join(MODEL_DIR, \"validation_groups_info.txt\")\n",
        "    with open(group_info_path, \"w\") as f:\n",
        "        f.write(f\"Total groups: {len(val_group_counts)}\\n\\n\")\n",
        "        f.write(\"GroupID\\tSize\\tStartIdx\\tEndIdx\\n\")\n",
        "\n",
        "        group_to_rows = defaultdict(list)\n",
        "        for i, g in enumerate(val_rankers):\n",
        "            group_to_rows[g].append(i)\n",
        "\n",
        "        for group_id, indices in sorted(group_to_rows.items()):\n",
        "            start_idx = indices[0]\n",
        "            end_idx = indices[-1]\n",
        "            size = len(indices)\n",
        "            f.write(f\"{group_id}\\t{size}\\t{start_idx}\\t{end_idx}\\n\")\n",
        "\n",
        "    print(f\"üìÅ Saved validation group info to {group_info_path}\")\n",
        "\n",
        "\n",
        "    cat_dims = build_cat_dims(X, cat_features)\n",
        "    num_numeric_feats = len(num_features)\n",
        "\n",
        "    train_dataset = RankDataset(X_tr, y_tr, groups_tr, cat_features, num_features)\n",
        "    val_dataset = RankDataset(X_va, y_va, groups_va, cat_features, num_features)\n",
        "    test_dataset = RankDataset(X_te, y_te, groups_te, cat_features, num_features)\n",
        "\n",
        "    plot_group_size_distribution(train_dataset, save_path=os.path.join(MODEL_DIR, \"group_sizes.png\"))\n",
        "    print(\"üìä Group size distribution saved.\")\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True, collate_fn=collate_fn)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=4, shuffle=False, collate_fn=collate_fn)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False, collate_fn=collate_fn)\n",
        "\n",
        "    print(\"‚úÖ Data loaders created.\")\n",
        "\n",
        "    num_epochs = 10\n",
        "    num_training_steps = num_epochs * len(train_loader)\n",
        "    num_warmup_steps = int(0.1 * num_training_steps)\n",
        "\n",
        "    learning_rate = 3e-4\n",
        "\n",
        "    model = DLRankerAttention(\n",
        "        cat_dims=cat_dims,\n",
        "        num_numeric_feats=num_numeric_feats,\n",
        "        emb_dropout=0.1,\n",
        "        dropout=0.1,\n",
        "        num_heads=4,\n",
        "        num_layers=2,\n",
        "        dim_feedforward=128,\n",
        "        proj_dim=64\n",
        "    ).to(device)\n",
        "\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=0.01)\n",
        "\n",
        "    scheduler = OneCycleLR(\n",
        "        optimizer,\n",
        "        max_lr=learning_rate,\n",
        "        steps_per_epoch=len(train_loader),\n",
        "        epochs=num_epochs,\n",
        "        pct_start=0.3,\n",
        "    )\n",
        "\n",
        "    best_hitrate = 0\n",
        "    for epoch in range(num_epochs):\n",
        "        print(f\"\\n--- Epoch {epoch+1}/{num_epochs} ---\")\n",
        "        start_time = time.time()\n",
        "\n",
        "        train_loss = train_one_epoch(model, train_loader, optimizer, device, scheduler)\n",
        "        val_loss, val_hitrate, val_ndcg, val_map = validate(model, val_loader, device, min_group_size=10)\n",
        "\n",
        "        train_losses.append(train_loss)\n",
        "        val_losses.append(val_loss)\n",
        "        val_hitrates.append(val_hitrate.item())\n",
        "        val_ndcgs.append(val_ndcg.item())\n",
        "        val_maps.append(val_map.item())\n",
        "\n",
        "        current_lr = scheduler.get_last_lr()\n",
        "        learning_rates.append(current_lr[0])\n",
        "\n",
        "        elapsed = time.time() - start_time\n",
        "        print(\n",
        "            f\"Epoch {epoch+1}: \"\n",
        "            f\"Train Loss={train_loss:.4f}, \"\n",
        "            f\"Val Loss={val_loss:.4f}, \"\n",
        "            f\"HitRate@10={val_hitrate:.4f}, \"\n",
        "            f\"NDCG@10={val_ndcg:.4f}, \"\n",
        "            f\"MAP@10={val_map:.4f}, \"\n",
        "            f\"LR={current_lr[0]:.6f} \"\n",
        "            f\"({elapsed:.1f}s)\"\n",
        "        )\n",
        "\n",
        "\n",
        "        if val_loss < best_val_loss and val_hitrate > best_hitrate:\n",
        "            best_val_loss = val_loss\n",
        "            best_hitrate = val_hitrate\n",
        "            torch.save(model.state_dict(), model_path)\n",
        "            print(\"üíæ Model improved (loss ‚Üì and hitrate ‚Üë), saved.\")\n",
        "\n",
        "        if early_stopper.step(-val_loss):\n",
        "            print(\"‚õî Early stopping triggered.\")\n",
        "            break\n",
        "\n",
        "    # Plot metrics\n",
        "    epochs = list(range(1, len(train_losses) + 1))\n",
        "\n",
        "    # Plot Loss Curve\n",
        "    plt.figure()\n",
        "    plt.plot(epochs, train_losses, label=\"Train Loss\")\n",
        "    plt.plot(epochs, val_losses, label=\"Val Loss\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.title(\"Training & Validation Loss\")\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.savefig(os.path.join(MODEL_DIR, \"loss_curve.png\"))\n",
        "    plt.close()\n",
        "\n",
        "    # Plot HitRate@10\n",
        "    plt.figure()\n",
        "    plt.plot(epochs, val_hitrates, label=\"Val HitRate@10\", color=\"green\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"HitRate@10\")\n",
        "    plt.title(\"Validation HitRate@10\")\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.savefig(os.path.join(MODEL_DIR, \"hitrate_curve.png\"))\n",
        "    plt.close()\n",
        "\n",
        "    # Plot Learning Rate\n",
        "    plt.figure()\n",
        "    plt.plot(epochs, learning_rates, label=\"Learning Rate\", color=\"orange\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"LR\")\n",
        "    plt.title(\"Learning Rate Schedule\")\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.savefig(os.path.join(MODEL_DIR, \"lr_curve.png\"))\n",
        "    plt.close()\n",
        "\n",
        "    # Plot NDCG@10\n",
        "    plt.figure()\n",
        "    plt.plot(epochs, val_ndcgs, label=\"Val NDCG@10\", color=\"purple\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"NDCG@10\")\n",
        "    plt.title(\"Validation NDCG@10\")\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.savefig(os.path.join(MODEL_DIR, \"ndcg_curve.png\"))\n",
        "    plt.close()\n",
        "\n",
        "    # Plot MAP@10\n",
        "    plt.figure()\n",
        "    plt.plot(epochs, val_maps, label=\"Val MAP@10\", color=\"red\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"MAP@10\")\n",
        "    plt.title(\"Validation MAP@10\")\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.savefig(os.path.join(MODEL_DIR, \"map_curve.png\"))\n",
        "    plt.close()\n",
        "\n",
        "    print(\"üìä Saved metric plots to model/\")\n",
        "\n",
        "    model.load_state_dict(torch.load(model_path))\n",
        "    model.eval()\n",
        "\n",
        "    val_ids = X_va[\"Id\"]\n",
        "    val_rankers = groups_va[\"ranker_id\"]\n",
        "    val_labels = y_va\n",
        "\n",
        "    all_val_scores = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for x_cat, x_num, _, lengths in tqdm(val_loader, desc=\"Predicting validation set\"):\n",
        "            x_num = x_num.to(device)\n",
        "            x_cat = {k: v.to(device) for k, v in x_cat.items()}\n",
        "            scores = model(x_cat, x_num)\n",
        "\n",
        "            for i in range(scores.size(0)):\n",
        "                l = lengths[i]\n",
        "                all_val_scores.append(scores[i, :l].cpu().numpy())\n",
        "\n",
        "    all_val_scores = np.concatenate(all_val_scores)\n",
        "\n",
        "    assert len(all_val_scores) == X_va.shape[0], \\\n",
        "        f\"Mismatch: {len(all_val_scores)} scores vs {X_va.shape[0]} rows\"\n",
        "\n",
        "    val_df = X_va.with_columns([\n",
        "        pl.Series(\"Id\", val_ids),\n",
        "        pl.Series(\"ranker_id\", val_rankers),\n",
        "        pl.Series(\"score\", all_val_scores),\n",
        "        pl.Series(\"label\", val_labels)\n",
        "    ])\n",
        "\n",
        "    val_df = val_df.with_columns(\n",
        "        pl.col(\"score\")\n",
        "        .rank(method=\"ordinal\", descending=True)\n",
        "        .over(\"ranker_id\")\n",
        "        .cast(pl.Int32)\n",
        "        .alias(\"rank\")\n",
        "    )\n",
        "\n",
        "    val_top10_df = (\n",
        "        val_df\n",
        "        .filter(pl.col(\"rank\") <= 10)\n",
        "        .sort([\"ranker_id\", \"rank\"])\n",
        "    )\n",
        "\n",
        "    val_top10_path = os.path.join(MODEL_DIR, \"validation_top10_dl_full.parquet\")\n",
        "    val_top10_df.write_parquet(val_top10_path)\n",
        "    print(f\"‚úÖ Saved top-10 validation predictions (with features) to {val_top10_path}\")\n",
        "\n",
        "    original_val_cols = set(X_va.columns)\n",
        "    val_top10_cols = set(val_top10_df.columns)\n",
        "    extra_val_cols = val_top10_cols - original_val_cols\n",
        "\n",
        "    print(f\"üìå Extra columns in validation_top10_dl_full.parquet vs original validation set: {sorted(extra_val_cols)}\")\n",
        "\n",
        "    all_scores = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for x_cat, x_num, _, lengths in tqdm(test_loader, desc=\"Predicting test set\"):\n",
        "            x_num = x_num.to(device)\n",
        "            x_cat = {k: v.to(device) for k, v in x_cat.items()}\n",
        "            scores = model(x_cat, x_num)\n",
        "\n",
        "            for i in range(scores.size(0)):\n",
        "                l = lengths[i]\n",
        "                all_scores.append(scores[i, :l].cpu().numpy())\n",
        "\n",
        "    all_scores = np.concatenate(all_scores)\n",
        "\n",
        "    assert len(all_scores) == X_te.shape[0], \\\n",
        "        f\"Mismatch: {len(all_scores)} scores vs {X_te.shape[0]} rows in X_te\"\n",
        "\n",
        "    submission_df = pl.DataFrame({\n",
        "        \"Id\": test_ids,\n",
        "        \"ranker_id\": test_rankers,\n",
        "        \"score\": all_scores\n",
        "    })\n",
        "\n",
        "    submission = (\n",
        "        submission_df\n",
        "        .with_columns(\n",
        "            pl.col(\"score\")\n",
        "            .rank(method=\"ordinal\", descending=True)\n",
        "            .over(\"ranker_id\")\n",
        "            .cast(pl.Int32)\n",
        "            .alias(\"selected\")\n",
        "        )\n",
        "        .select([\"Id\", \"ranker_id\", \"score\", \"selected\"])\n",
        "    )\n",
        "\n",
        "    submission_path = os.path.join(SUBMIT_DIR, \"submission_dl_ranker.parquet\")\n",
        "    submission.write_parquet(submission_path)\n",
        "    print(f\"‚úÖ Submission saved to {submission_path}\")\n",
        "\n",
        "    submission_full = (\n",
        "        X_te.with_columns([\n",
        "            pl.Series(\"Id\", test_ids),\n",
        "            pl.Series(\"ranker_id\", test_rankers),\n",
        "            pl.Series(\"score\", all_scores)\n",
        "        ])\n",
        "        .with_columns(\n",
        "            pl.col(\"score\")\n",
        "            .rank(method=\"ordinal\", descending=True)\n",
        "            .over(\"ranker_id\")\n",
        "            .cast(pl.Int32)\n",
        "            .alias(\"rank\")\n",
        "        )\n",
        "    )\n",
        "\n",
        "    submission_top10_full = (\n",
        "        submission_full\n",
        "        .filter(pl.col(\"rank\") <= 10)\n",
        "        .sort([\"ranker_id\", \"rank\"])\n",
        "    )\n",
        "\n",
        "    submission_top10_path = os.path.join(SUBMIT_DIR, \"submission_top10_dl_full.parquet\")\n",
        "    submission_top10_full.write_parquet(submission_top10_path)\n",
        "    print(f\"‚úÖ Saved top-10 test predictions (with features) to {submission_top10_path}\")\n",
        "\n",
        "    original_test_cols = set(X_te.columns)\n",
        "    test_top10_cols = set(submission_top10_full.columns)\n",
        "    extra_test_cols = test_top10_cols - original_test_cols\n",
        "\n",
        "    print(f\"üìå Extra columns in submission_top10_dl_full.parquet vs original test set: {sorted(extra_test_cols)}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Df0CR_NS1xio",
        "outputId": "16ddf31e-abf9-40c0-9e2a-feee94c7a924"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting deeprec_validate_top10.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "--- Epoch 1/10 ---\n",
        "Validating:   0%|          | 0/2636 [00:00<?, ?it/s]/home/ionut/test_whisper/test2/deeprec_validate_top10.py:539: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
        "  lengths = torch.tensor(lengths).to(device)\n",
        "Epoch 1: Train Loss=0.3530, Val Loss=0.2840, HitRate@10=0.7228, NDCG@10=0.4645, MAP@10=0.5119, LR=0.000084 (608.1s)\n",
        "üíæ Model improved (loss ‚Üì and hitrate ‚Üë), saved.\n",
        "\n",
        "--- Epoch 2/10 ---\n",
        "Epoch 2: Train Loss=0.2876, Val Loss=0.2888, HitRate@10=0.7306, NDCG@10=0.4760, MAP@10=0.5265, LR=0.000228 (606.2s)\n",
        "\n",
        "--- Epoch 3/10 ---\n",
        "Epoch 3: Train Loss=0.2806, Val Loss=0.2776, HitRate@10=0.7306, NDCG@10=0.4809, MAP@10=0.5344, LR=0.000300 (606.5s)\n",
        "üíæ Model improved (loss ‚Üì and hitrate ‚Üë), saved.\n",
        "\n",
        "--- Epoch 4/10 ---\n",
        "Epoch 4: Train Loss=0.2670, Val Loss=0.2750, HitRate@10=0.7381, NDCG@10=0.4881, MAP@10=0.5402, LR=0.000285 (607.2s)\n",
        "üíæ Model improved (loss ‚Üì and hitrate ‚Üë), saved.\n",
        "\n",
        "--- Epoch 5/10 ---\n",
        "Epoch 5: Train Loss=0.2554, Val Loss=0.2603, HitRate@10=0.7432, NDCG@10=0.4930, MAP@10=0.5432, LR=0.000244 (606.6s)\n",
        "üíæ Model improved (loss ‚Üì and hitrate ‚Üë), saved.\n",
        "\n",
        "--- Epoch 6/10 ---\n",
        "Epoch 6: Train Loss=0.2444, Val Loss=0.2537, HitRate@10=0.7515, NDCG@10=0.4997, MAP@10=0.5447, LR=0.000183 (609.6s)\n",
        "üíæ Model improved (loss ‚Üì and hitrate ‚Üë), saved.\n",
        "\n",
        "--- Epoch 7/10 ---\n",
        "Epoch 7: Train Loss=0.2324, Val Loss=0.2449, HitRate@10=0.7517, NDCG@10=0.5001, MAP@10=0.5457, LR=0.000117 (607.2s)\n",
        "üíæ Model improved (loss ‚Üì and hitrate ‚Üë), saved.\n",
        "\n",
        "--- Epoch 8/10 ---\n",
        "Epoch 8: Train Loss=0.2214, Val Loss=0.2457, HitRate@10=0.7554, NDCG@10=0.5059, MAP@10=0.5525, LR=0.000056 (607.6s)\n",
        "\n",
        "--- Epoch 9/10 ---\n",
        "Epoch 9: Train Loss=0.2115, Val Loss=0.2382, HitRate@10=0.7572, NDCG@10=0.5082, MAP@10=0.5544, LR=0.000015 (606.2s)\n",
        "üíæ Model improved (loss ‚Üì and hitrate ‚Üë), saved.\n",
        "\n",
        "--- Epoch 10/10 ---\n",
        "Epoch 10: Train Loss=0.2058, Val Loss=0.2383, HitRate@10=0.7563, NDCG@10=0.5056, MAP@10=0.5523, LR=0.000000 (607.5s)"
      ],
      "metadata": {
        "id": "IuhP-FIr4Ale"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Top10 -> Top3**"
      ],
      "metadata": {
        "id": "703phaAecTU5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "üìå Validation set:\n",
        "  X_va shape: (1658020, 153)\n",
        "  X_va columns (153): ['corporateTariffCode', 'nationality', 'isAccess3D', 'isVip', 'legs0_segments0_cabinClass', 'legs0_segments0_arrivalTo_airport_iata', 'legs0_segments0_departureFrom_airport_iata', 'legs0_segments0_baggageAllowance_weightMeasurementType', 'legs0_segments0_marketingCarrier_code', 'legs0_segments0_operatingCarrier_code', 'legs1_segments0_cabinClass', 'legs1_segments0_arrivalTo_airport_iata', 'legs1_segments0_departureFrom_airport_iata', 'legs1_segments0_baggageAllowance_weightMeasurementType', 'legs1_segments0_marketingCarrier_code', 'legs1_segments0_operatingCarrier_code', 'pricingInfo_isAccessTP', 'miniRules0_statusInfos', 'miniRules1_statusInfos', 'sex', 'has_ff_program', 'has_corporate_tariff', 'corporate_policy_compliant', 'corporate_vip_flag', 'free_cancel', 'free_exchange', 'is_popular_route', 'contains_capitials', 'is_codeshare_leg0_seg0', 'is_codeshare_leg1_seg0', 'fee_ratio_rule0_is_missing', 'fee_ratio_rule1_is_missing', 'is_vip_freq', 'is_direct_leg0', 'is_direct_leg1', 'is_min_segments_leg0', 'is_min_segments_leg1', 'is_direct_shortest', 'legs0_departureAt_hour', 'legs0_arrivalAt_hour', 'legs1_departureAt_hour', 'legs1_arrivalAt_hour', 'legs0_departureAt_weekday', 'legs0_arrivalAt_weekday', 'legs1_departureAt_weekday', 'legs1_arrivalAt_weekday', 'legs0_departureAt_time_bin', 'legs0_arrivalAt_time_bin', 'legs1_departureAt_time_bin', 'legs1_arrivalAt_time_bin', 'legs0_dep_arr_bin_combo', 'legs0_is_business_friendly', 'legs0_is_red_eye', 'legs1_dep_arr_bin_combo', 'legs1_is_business_friendly', 'legs1_is_red_eye', 'is_short_trip', 'legs0_is_short_flight', 'legs1_is_short_flight', 'is_top3_cheapest', 'is_cheaper_than_avg', 'is_direct_cheapest', 'has_first_class', 'max_cabin_level', 'all_cabin_level_1', 'legs0_segments0_marketingCarrier_code_in_frequentFlyer', 'legs0_segments0_marketingCarrier_code_is_only_frequentFlyer', 'is_major_carrier_0_0', 'legs0_is_cross_country', 'legs0_is_cross_timezone', 'legs1_is_cross_country', 'legs1_is_cross_timezone', 'has_any_label', 'label_BestPrice', 'label_BestPriceTravelPolicy', 'label_BestPriceDirect', 'label_Convenience', 'label_MinTime', 'label_BestPriceCorporateTariff', 'outbound_route', 'return_route', 'is_exact_round_trip', 'legs0_segments0_baggageAllowance_quantity', 'legs1_segments0_baggageAllowance_quantity', 'legs0_duration', 'legs0_segments0_duration', 'legs1_duration', 'legs1_segments0_duration', 'tax_rate', 'log_taxes', 'log_price', 'duration_ratio', 'n_ff_programs', 'fee_ratio_rule0', 'fee_ratio_rule1', 'group_size_log', 'price_duration_rat', 'n_segments_leg0', 'n_segments_leg1', 'stay_duration_hours_log', 'hours_to_departure', 'price_quantile_rank', 'duration_quantile_rank', 'rank_interaction_mul', 'rank_interaction_sub', 'price_zscore_from_median', 'price_relative_to_min', 'company_ocurrence', 'company_avg_selected_price', 'company_std_selected_price', 'company_legs0_direct_ratio', 'company_legs1_direct_ratio', 'company_avg_pct', 'company_avg_dct', 'company_policy_rate', 'company_tariff_selected_count', 'company_tariff_selected_ratio', 'legs0_Carrier_code_cabin1_select_ratio', 'legs0_Carrier_code_cabin2_select_ratio', 'legs0_Carrier_code_avg_price_rank', 'legs0_Carrier_code_avg_duration_rank', 'legs0_Carrier_code_company_diversity', 'legs0_Carrier_code_user_diversity', 'legs1_Carrier_code_cabin1_select_ratio', 'legs1_Carrier_code_cabin2_select_ratio', 'legs1_Carrier_code_avg_price_rank', 'legs1_Carrier_code_avg_duration_rank', 'legs1_Carrier_code_company_diversity', 'legs1_Carrier_code_user_diversity', 'legs0_Carrier_code_log_selected_count', 'legs1_Carrier_code_log_selected_count', 'carrier_pop_prod', 'user_selected_count', 'corporateTariffCode_hotness', 'group_price_mean', 'group_price_std', 'group_price_range', 'group_dur_mean', 'group_dur_std', 'group_dur_range', 'group_n_leg_combos', 'group_option_price_rank_ratio', 'outbound_route_hotness', 'return_route_hotness', 'outbound_route_avg_price', 'outbound_route_avg_duration', 'outbound_route_policy_rate', 'outbound_route_direct_ratio', 'return_route_avg_price', 'return_route_avg_duration', 'return_route_policy_rate', 'return_route_direct_ratio', 'Id']\n",
        "  y_va shape: (1658020, 1), name: 'selected'\n",
        "  groups_va shape: (1658020, 1), columns: ['ranker_id']\n",
        "  First 3 y_va: shape: (3, 1)\n",
        "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
        "‚îÇ selected ‚îÇ\n",
        "‚îÇ ---      ‚îÇ\n",
        "‚îÇ i64      ‚îÇ\n",
        "‚ïû‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï°\n",
        "‚îÇ 0        ‚îÇ\n",
        "‚îÇ 0        ‚îÇ\n",
        "‚îÇ 0        ‚îÇ\n",
        "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
        "  First 3 groups_va:\n",
        "shape: (3, 1)\n",
        "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
        "‚îÇ ranker_id                       ‚îÇ\n",
        "‚îÇ ---                             ‚îÇ\n",
        "‚îÇ str                             ‚îÇ\n",
        "‚ïû‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï°\n",
        "‚îÇ 0ab8aa6bd4b344efb94bdf4b814f10‚Ä¶ ‚îÇ\n",
        "‚îÇ 0ab8aa6bd4b344efb94bdf4b814f10‚Ä¶ ‚îÇ\n",
        "‚îÇ 0ab8aa6bd4b344efb94bdf4b814f10‚Ä¶ ‚îÇ\n",
        "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
        "\n",
        "üìå Test set:\n",
        "  X_te shape: (6897776, 153)\n",
        "  X_te columns (153): ['corporateTariffCode', 'nationality', 'isAccess3D', 'isVip', 'legs0_segments0_cabinClass', 'legs0_segments0_arrivalTo_airport_iata', 'legs0_segments0_departureFrom_airport_iata', 'legs0_segments0_baggageAllowance_weightMeasurementType', 'legs0_segments0_marketingCarrier_code', 'legs0_segments0_operatingCarrier_code', 'legs1_segments0_cabinClass', 'legs1_segments0_arrivalTo_airport_iata', 'legs1_segments0_departureFrom_airport_iata', 'legs1_segments0_baggageAllowance_weightMeasurementType', 'legs1_segments0_marketingCarrier_code', 'legs1_segments0_operatingCarrier_code', 'pricingInfo_isAccessTP', 'miniRules0_statusInfos', 'miniRules1_statusInfos', 'sex', 'has_ff_program', 'has_corporate_tariff', 'corporate_policy_compliant', 'corporate_vip_flag', 'free_cancel', 'free_exchange', 'is_popular_route', 'contains_capitials', 'is_codeshare_leg0_seg0', 'is_codeshare_leg1_seg0', 'fee_ratio_rule0_is_missing', 'fee_ratio_rule1_is_missing', 'is_vip_freq', 'is_direct_leg0', 'is_direct_leg1', 'is_min_segments_leg0', 'is_min_segments_leg1', 'is_direct_shortest', 'legs0_departureAt_hour', 'legs0_arrivalAt_hour', 'legs1_departureAt_hour', 'legs1_arrivalAt_hour', 'legs0_departureAt_weekday', 'legs0_arrivalAt_weekday', 'legs1_departureAt_weekday', 'legs1_arrivalAt_weekday', 'legs0_departureAt_time_bin', 'legs0_arrivalAt_time_bin', 'legs1_departureAt_time_bin', 'legs1_arrivalAt_time_bin', 'legs0_dep_arr_bin_combo', 'legs0_is_business_friendly', 'legs0_is_red_eye', 'legs1_dep_arr_bin_combo', 'legs1_is_business_friendly', 'legs1_is_red_eye', 'is_short_trip', 'legs0_is_short_flight', 'legs1_is_short_flight', 'is_top3_cheapest', 'is_cheaper_than_avg', 'is_direct_cheapest', 'has_first_class', 'max_cabin_level', 'all_cabin_level_1', 'legs0_segments0_marketingCarrier_code_in_frequentFlyer', 'legs0_segments0_marketingCarrier_code_is_only_frequentFlyer', 'is_major_carrier_0_0', 'legs0_is_cross_country', 'legs0_is_cross_timezone', 'legs1_is_cross_country', 'legs1_is_cross_timezone', 'has_any_label', 'label_BestPrice', 'label_BestPriceTravelPolicy', 'label_BestPriceDirect', 'label_Convenience', 'label_MinTime', 'label_BestPriceCorporateTariff', 'outbound_route', 'return_route', 'is_exact_round_trip', 'legs0_segments0_baggageAllowance_quantity', 'legs1_segments0_baggageAllowance_quantity', 'legs0_duration', 'legs0_segments0_duration', 'legs1_duration', 'legs1_segments0_duration', 'tax_rate', 'log_taxes', 'log_price', 'duration_ratio', 'n_ff_programs', 'fee_ratio_rule0', 'fee_ratio_rule1', 'group_size_log', 'price_duration_rat', 'n_segments_leg0', 'n_segments_leg1', 'stay_duration_hours_log', 'hours_to_departure', 'price_quantile_rank', 'duration_quantile_rank', 'rank_interaction_mul', 'rank_interaction_sub', 'price_zscore_from_median', 'price_relative_to_min', 'company_ocurrence', 'company_avg_selected_price', 'company_std_selected_price', 'company_legs0_direct_ratio', 'company_legs1_direct_ratio', 'company_avg_pct', 'company_avg_dct', 'company_policy_rate', 'company_tariff_selected_count', 'company_tariff_selected_ratio', 'legs0_Carrier_code_cabin1_select_ratio', 'legs0_Carrier_code_cabin2_select_ratio', 'legs0_Carrier_code_avg_price_rank', 'legs0_Carrier_code_avg_duration_rank', 'legs0_Carrier_code_company_diversity', 'legs0_Carrier_code_user_diversity', 'legs1_Carrier_code_cabin1_select_ratio', 'legs1_Carrier_code_cabin2_select_ratio', 'legs1_Carrier_code_avg_price_rank', 'legs1_Carrier_code_avg_duration_rank', 'legs1_Carrier_code_company_diversity', 'legs1_Carrier_code_user_diversity', 'legs0_Carrier_code_log_selected_count', 'legs1_Carrier_code_log_selected_count', 'carrier_pop_prod', 'user_selected_count', 'corporateTariffCode_hotness', 'group_price_mean', 'group_price_std', 'group_price_range', 'group_dur_mean', 'group_dur_std', 'group_dur_range', 'group_n_leg_combos', 'group_option_price_rank_ratio', 'outbound_route_hotness', 'return_route_hotness', 'outbound_route_avg_price', 'outbound_route_avg_duration', 'outbound_route_policy_rate', 'outbound_route_direct_ratio', 'return_route_avg_price', 'return_route_avg_duration', 'return_route_policy_rate', 'return_route_direct_ratio', 'Id']\n",
        "  y_te shape: (6897776, 1), name: 'selected'\n",
        "  groups_te shape: (6897776, 1), columns: ['ranker_id']\n",
        "  First 3 y_te: shape: (3, 1)\n",
        "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
        "‚îÇ selected ‚îÇ\n",
        "‚îÇ ---      ‚îÇ\n",
        "‚îÇ i64      ‚îÇ\n",
        "‚ïû‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï°\n",
        "‚îÇ 0        ‚îÇ\n",
        "‚îÇ 0        ‚îÇ\n",
        "‚îÇ 0        ‚îÇ\n",
        "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
        "  First 3 groups_te:\n",
        "shape: (3, 1)\n",
        "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
        "‚îÇ ranker_id                       ‚îÇ\n",
        "‚îÇ ---                             ‚îÇ\n",
        "‚îÇ str                             ‚îÇ\n",
        "‚ïû‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï°\n",
        "‚îÇ c9373e5f772e43d593dd6ad2fa90f6‚Ä¶ ‚îÇ\n",
        "‚îÇ c9373e5f772e43d593dd6ad2fa90f6‚Ä¶ ‚îÇ\n",
        "‚îÇ c9373e5f772e43d593dd6ad2fa90f6‚Ä¶ ‚îÇ\n",
        "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò"
      ],
      "metadata": {
        "id": "1vQn540WKdM9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import polars as pl\n",
        "\n",
        "validation_path = \"./data/validation_top10_dl_full.parquet\"\n",
        "submission_path = \"./data/submission_top10_dl_full.parquet\"\n",
        "\n",
        "val_df = pl.read_parquet(validation_path)\n",
        "sub_df = pl.read_parquet(submission_path)\n",
        "\n",
        "print(\"üìã Validation set:\")\n",
        "print(f\"  shape: {val_df.shape}\")\n",
        "print(f\"  columns: {val_df.columns}\")\n",
        "\n",
        "print(\"\\nüìã Submission set:\")\n",
        "print(f\"  shape: {sub_df.shape}\")\n",
        "print(f\"  columns: {sub_df.columns}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KtEJNhHOW12x",
        "outputId": "847f5540-c0c5-489a-eb3b-66b671c30597"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing check.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "üìã Validation set:\n",
        "  shape: (97134, 157)\n",
        "  columns: ['corporateTariffCode', 'nationality', 'isAccess3D', 'isVip', 'legs0_segments0_cabinClass', 'legs0_segments0_arrivalTo_airport_iata', 'legs0_segments0_departureFrom_airport_iata', 'legs0_segments0_baggageAllowance_weightMeasurementType', 'legs0_segments0_marketingCarrier_code', 'legs0_segments0_operatingCarrier_code', 'legs1_segments0_cabinClass', 'legs1_segments0_arrivalTo_airport_iata', 'legs1_segments0_departureFrom_airport_iata', 'legs1_segments0_baggageAllowance_weightMeasurementType', 'legs1_segments0_marketingCarrier_code', 'legs1_segments0_operatingCarrier_code', 'pricingInfo_isAccessTP', 'miniRules0_statusInfos', 'miniRules1_statusInfos', 'sex', 'has_ff_program', 'has_corporate_tariff', 'corporate_policy_compliant', 'corporate_vip_flag', 'free_cancel', 'free_exchange', 'is_popular_route', 'contains_capitials', 'is_codeshare_leg0_seg0', 'is_codeshare_leg1_seg0', 'fee_ratio_rule0_is_missing', 'fee_ratio_rule1_is_missing', 'is_vip_freq', 'is_direct_leg0', 'is_direct_leg1', 'is_min_segments_leg0', 'is_min_segments_leg1', 'is_direct_shortest', 'legs0_departureAt_hour', 'legs0_arrivalAt_hour', 'legs1_departureAt_hour', 'legs1_arrivalAt_hour', 'legs0_departureAt_weekday', 'legs0_arrivalAt_weekday', 'legs1_departureAt_weekday', 'legs1_arrivalAt_weekday', 'legs0_departureAt_time_bin', 'legs0_arrivalAt_time_bin', 'legs1_departureAt_time_bin', 'legs1_arrivalAt_time_bin', 'legs0_dep_arr_bin_combo', 'legs0_is_business_friendly', 'legs0_is_red_eye', 'legs1_dep_arr_bin_combo', 'legs1_is_business_friendly', 'legs1_is_red_eye', 'is_short_trip', 'legs0_is_short_flight', 'legs1_is_short_flight', 'is_top3_cheapest', 'is_cheaper_than_avg', 'is_direct_cheapest', 'has_first_class', 'max_cabin_level', 'all_cabin_level_1', 'legs0_segments0_marketingCarrier_code_in_frequentFlyer', 'legs0_segments0_marketingCarrier_code_is_only_frequentFlyer', 'is_major_carrier_0_0', 'legs0_is_cross_country', 'legs0_is_cross_timezone', 'legs1_is_cross_country', 'legs1_is_cross_timezone', 'has_any_label', 'label_BestPrice', 'label_BestPriceTravelPolicy', 'label_BestPriceDirect', 'label_Convenience', 'label_MinTime', 'label_BestPriceCorporateTariff', 'outbound_route', 'return_route', 'is_exact_round_trip', 'legs0_segments0_baggageAllowance_quantity', 'legs1_segments0_baggageAllowance_quantity', 'legs0_duration', 'legs0_segments0_duration', 'legs1_duration', 'legs1_segments0_duration', 'tax_rate', 'log_taxes', 'log_price', 'duration_ratio', 'n_ff_programs', 'fee_ratio_rule0', 'fee_ratio_rule1', 'group_size_log', 'price_duration_rat', 'n_segments_leg0', 'n_segments_leg1', 'stay_duration_hours_log', 'hours_to_departure', 'price_quantile_rank', 'duration_quantile_rank', 'rank_interaction_mul', 'rank_interaction_sub', 'price_zscore_from_median', 'price_relative_to_min', 'company_ocurrence', 'company_avg_selected_price', 'company_std_selected_price', 'company_legs0_direct_ratio', 'company_legs1_direct_ratio', 'company_avg_pct', 'company_avg_dct', 'company_policy_rate', 'company_tariff_selected_count', 'company_tariff_selected_ratio', 'legs0_Carrier_code_cabin1_select_ratio', 'legs0_Carrier_code_cabin2_select_ratio', 'legs0_Carrier_code_avg_price_rank', 'legs0_Carrier_code_avg_duration_rank', 'legs0_Carrier_code_company_diversity', 'legs0_Carrier_code_user_diversity', 'legs1_Carrier_code_cabin1_select_ratio', 'legs1_Carrier_code_cabin2_select_ratio', 'legs1_Carrier_code_avg_price_rank', 'legs1_Carrier_code_avg_duration_rank', 'legs1_Carrier_code_company_diversity', 'legs1_Carrier_code_user_diversity', 'legs0_Carrier_code_log_selected_count', 'legs1_Carrier_code_log_selected_count', 'carrier_pop_prod', 'user_selected_count', 'corporateTariffCode_hotness', 'group_price_mean', 'group_price_std', 'group_price_range', 'group_dur_mean', 'group_dur_std', 'group_dur_range', 'group_n_leg_combos', 'group_option_price_rank_ratio', 'outbound_route_hotness', 'return_route_hotness', 'outbound_route_avg_price', 'outbound_route_avg_duration', 'outbound_route_policy_rate', 'outbound_route_direct_ratio', 'return_route_avg_price', 'return_route_avg_duration', 'return_route_policy_rate', 'return_route_direct_ratio', 'Id', 'ranker_id', 'score', 'label', 'rank']\n",
        "\n",
        "üìã Submission set:\n",
        "  shape: (410205, 156)\n",
        "  columns: ['corporateTariffCode', 'nationality', 'isAccess3D', 'isVip', 'legs0_segments0_cabinClass', 'legs0_segments0_arrivalTo_airport_iata', 'legs0_segments0_departureFrom_airport_iata', 'legs0_segments0_baggageAllowance_weightMeasurementType', 'legs0_segments0_marketingCarrier_code', 'legs0_segments0_operatingCarrier_code', 'legs1_segments0_cabinClass', 'legs1_segments0_arrivalTo_airport_iata', 'legs1_segments0_departureFrom_airport_iata', 'legs1_segments0_baggageAllowance_weightMeasurementType', 'legs1_segments0_marketingCarrier_code', 'legs1_segments0_operatingCarrier_code', 'pricingInfo_isAccessTP', 'miniRules0_statusInfos', 'miniRules1_statusInfos', 'sex', 'has_ff_program', 'has_corporate_tariff', 'corporate_policy_compliant', 'corporate_vip_flag', 'free_cancel', 'free_exchange', 'is_popular_route', 'contains_capitials', 'is_codeshare_leg0_seg0', 'is_codeshare_leg1_seg0', 'fee_ratio_rule0_is_missing', 'fee_ratio_rule1_is_missing', 'is_vip_freq', 'is_direct_leg0', 'is_direct_leg1', 'is_min_segments_leg0', 'is_min_segments_leg1', 'is_direct_shortest', 'legs0_departureAt_hour', 'legs0_arrivalAt_hour', 'legs1_departureAt_hour', 'legs1_arrivalAt_hour', 'legs0_departureAt_weekday', 'legs0_arrivalAt_weekday', 'legs1_departureAt_weekday', 'legs1_arrivalAt_weekday', 'legs0_departureAt_time_bin', 'legs0_arrivalAt_time_bin', 'legs1_departureAt_time_bin', 'legs1_arrivalAt_time_bin', 'legs0_dep_arr_bin_combo', 'legs0_is_business_friendly', 'legs0_is_red_eye', 'legs1_dep_arr_bin_combo', 'legs1_is_business_friendly', 'legs1_is_red_eye', 'is_short_trip', 'legs0_is_short_flight', 'legs1_is_short_flight', 'is_top3_cheapest', 'is_cheaper_than_avg', 'is_direct_cheapest', 'has_first_class', 'max_cabin_level', 'all_cabin_level_1', 'legs0_segments0_marketingCarrier_code_in_frequentFlyer', 'legs0_segments0_marketingCarrier_code_is_only_frequentFlyer', 'is_major_carrier_0_0', 'legs0_is_cross_country', 'legs0_is_cross_timezone', 'legs1_is_cross_country', 'legs1_is_cross_timezone', 'has_any_label', 'label_BestPrice', 'label_BestPriceTravelPolicy', 'label_BestPriceDirect', 'label_Convenience', 'label_MinTime', 'label_BestPriceCorporateTariff', 'outbound_route', 'return_route', 'is_exact_round_trip', 'legs0_segments0_baggageAllowance_quantity', 'legs1_segments0_baggageAllowance_quantity', 'legs0_duration', 'legs0_segments0_duration', 'legs1_duration', 'legs1_segments0_duration', 'tax_rate', 'log_taxes', 'log_price', 'duration_ratio', 'n_ff_programs', 'fee_ratio_rule0', 'fee_ratio_rule1', 'group_size_log', 'price_duration_rat', 'n_segments_leg0', 'n_segments_leg1', 'stay_duration_hours_log', 'hours_to_departure', 'price_quantile_rank', 'duration_quantile_rank', 'rank_interaction_mul', 'rank_interaction_sub', 'price_zscore_from_median', 'price_relative_to_min', 'company_ocurrence', 'company_avg_selected_price', 'company_std_selected_price', 'company_legs0_direct_ratio', 'company_legs1_direct_ratio', 'company_avg_pct', 'company_avg_dct', 'company_policy_rate', 'company_tariff_selected_count', 'company_tariff_selected_ratio', 'legs0_Carrier_code_cabin1_select_ratio', 'legs0_Carrier_code_cabin2_select_ratio', 'legs0_Carrier_code_avg_price_rank', 'legs0_Carrier_code_avg_duration_rank', 'legs0_Carrier_code_company_diversity', 'legs0_Carrier_code_user_diversity', 'legs1_Carrier_code_cabin1_select_ratio', 'legs1_Carrier_code_cabin2_select_ratio', 'legs1_Carrier_code_avg_price_rank', 'legs1_Carrier_code_avg_duration_rank', 'legs1_Carrier_code_company_diversity', 'legs1_Carrier_code_user_diversity', 'legs0_Carrier_code_log_selected_count', 'legs1_Carrier_code_log_selected_count', 'carrier_pop_prod', 'user_selected_count', 'corporateTariffCode_hotness', 'group_price_mean', 'group_price_std', 'group_price_range', 'group_dur_mean', 'group_dur_std', 'group_dur_range', 'group_n_leg_combos', 'group_option_price_rank_ratio', 'outbound_route_hotness', 'return_route_hotness', 'outbound_route_avg_price', 'outbound_route_avg_duration', 'outbound_route_policy_rate', 'outbound_route_direct_ratio', 'return_route_avg_price', 'return_route_avg_duration', 'return_route_policy_rate', 'return_route_direct_ratio', 'Id', 'ranker_id', 'score', 'rank']"
      ],
      "metadata": {
        "id": "TeF0HuBrXFll"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile deeprec_validate_top3.py\n",
        "import os\n",
        "import time\n",
        "import random\n",
        "import torch\n",
        "import math\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import defaultdict\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "import polars as pl\n",
        "from tqdm import tqdm\n",
        "from src.feature import feature_engineering, feature_selection\n",
        "from transformers import get_scheduler\n",
        "from collections import Counter\n",
        "from torch.optim.lr_scheduler import OneCycleLR\n",
        "\n",
        "seed = 42\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "class RankDataset(Dataset):\n",
        "    def __init__(\n",
        "        self,\n",
        "        X: pl.DataFrame,\n",
        "        y: pl.Series,\n",
        "        groups: pl.DataFrame,\n",
        "        cat_features: list[str],\n",
        "        num_features: list[str],\n",
        "    ):\n",
        "        self.cat_features = cat_features\n",
        "        self.num_features = num_features\n",
        "        self.X_cat = {c: X[c].to_numpy() for c in cat_features}\n",
        "        self.X_num = X[self.num_features].to_numpy()\n",
        "        self.y = y.to_numpy()\n",
        "        self.groups = groups[\"ranker_id\"].to_numpy()\n",
        "\n",
        "        self.group_to_indices = defaultdict(list)\n",
        "        for i, g in enumerate(self.groups):\n",
        "            self.group_to_indices[g].append(i)\n",
        "        self.group_keys = list(self.group_to_indices.keys())\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.group_keys)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        g = self.group_keys[idx]\n",
        "        inds = self.group_to_indices[g]\n",
        "        length = len(inds)\n",
        "\n",
        "        x_cat = {\n",
        "            c: torch.LongTensor([\n",
        "                self.X_cat[c][i] if self.X_cat[c][i] >= 0 else 0 for i in inds\n",
        "            ])\n",
        "            for c in self.cat_features\n",
        "        }\n",
        "\n",
        "        x_num = torch.FloatTensor(self.X_num[inds])\n",
        "        y = torch.FloatTensor(self.y[inds]).reshape(-1)\n",
        "\n",
        "        return x_cat, x_num, y, length\n",
        "\n",
        "def collate_fn(batch):\n",
        "    batch_size = len(batch)\n",
        "    lengths = [b[3] for b in batch]\n",
        "    max_len = max(lengths)\n",
        "\n",
        "    padded_x_cat = {key: [] for key in batch[0][0].keys()}\n",
        "    padded_x_num = []\n",
        "    padded_y = []\n",
        "\n",
        "    num_dim = batch[0][1].shape[1]\n",
        "\n",
        "    for x_cat, x_num, y, length in batch:\n",
        "        pad_len = max_len - length\n",
        "\n",
        "        for key in padded_x_cat:\n",
        "            val = x_cat[key]\n",
        "            if pad_len > 0:\n",
        "                val = torch.cat([val, torch.zeros(pad_len, dtype=torch.long)])\n",
        "            padded_x_cat[key].append(val)\n",
        "\n",
        "        if pad_len > 0:\n",
        "            x_num = torch.cat([x_num, torch.zeros(pad_len, num_dim)])\n",
        "            y = torch.cat([y, torch.zeros(pad_len)])\n",
        "\n",
        "        padded_x_num.append(x_num)\n",
        "        padded_y.append(y)\n",
        "\n",
        "    padded_x_cat = {k: torch.stack(v) for k, v in padded_x_cat.items()}\n",
        "    padded_x_num = torch.stack(padded_x_num)\n",
        "    padded_y = torch.stack(padded_y)\n",
        "    lengths = torch.tensor(lengths, dtype=torch.long)\n",
        "\n",
        "    return padded_x_cat, padded_x_num, padded_y, lengths\n",
        "\n",
        "class SEModule(nn.Module):\n",
        "    def __init__(self, channel, reduction=4):\n",
        "        super().__init__()\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(channel, channel // reduction),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(channel // reduction, channel),\n",
        "            nn.Sigmoid(),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: [B, N, C]\n",
        "        w = self.fc(x.mean(dim=1))\n",
        "        w = w.unsqueeze(1)  # [B, 1, C]\n",
        "        return x * w\n",
        "\n",
        "\n",
        "class FiLM(nn.Module):\n",
        "    def __init__(self, feature_dim):\n",
        "        super().__init__()\n",
        "        self.gamma = nn.Linear(feature_dim, feature_dim)\n",
        "        self.beta = nn.Linear(feature_dim, feature_dim)\n",
        "\n",
        "    def forward(self, x, cond):\n",
        "        gamma = self.gamma(cond)\n",
        "        beta = self.beta(cond)\n",
        "        return gamma * x + beta\n",
        "\n",
        "\n",
        "class DLRankerAttention(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        cat_dims,\n",
        "        num_numeric_feats,\n",
        "        emb_dropout=0.1,\n",
        "        dropout=0.1,\n",
        "        num_heads=4,\n",
        "        num_layers=2,\n",
        "        dim_feedforward=128,\n",
        "        proj_dim=64,\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "        self.emb_dims = {\n",
        "            f: min(50, max(4, round(6 * math.log2(cat_dims[f] + 1)))) for f in cat_dims\n",
        "        }\n",
        "        self.embeddings = nn.ModuleDict({\n",
        "            f: nn.Embedding(cat_dims[f], self.emb_dims[f], padding_idx=0)\n",
        "            for f in cat_dims\n",
        "        })\n",
        "        self.emb_dropout = nn.Dropout(emb_dropout)\n",
        "\n",
        "        total_emb_dim = sum(self.emb_dims.values())\n",
        "        print(f\"Categorial emb dim sum: {total_emb_dim}, Numerical dim: {num_numeric_feats}\")\n",
        "\n",
        "        self.cat_proj = nn.Linear(total_emb_dim, proj_dim)\n",
        "        self.cat_transformer = nn.TransformerEncoder(\n",
        "            nn.TransformerEncoderLayer(\n",
        "                d_model=proj_dim,\n",
        "                nhead=4,\n",
        "                dim_feedforward=dim_feedforward,\n",
        "                dropout=dropout,\n",
        "                batch_first=True,\n",
        "            ),\n",
        "            num_layers=1,\n",
        "        )\n",
        "\n",
        "        self.num_proj_in = nn.Linear(num_numeric_feats, proj_dim)\n",
        "        self.num_transformer = nn.TransformerEncoder(\n",
        "            nn.TransformerEncoderLayer(\n",
        "                d_model=proj_dim,\n",
        "                nhead=4,\n",
        "                dim_feedforward=dim_feedforward,\n",
        "                dropout=dropout,\n",
        "                batch_first=True,\n",
        "            ),\n",
        "            num_layers=1,\n",
        "        )\n",
        "        self.num_se = SEModule(proj_dim)\n",
        "        self.num_proj_out = nn.Sequential(\n",
        "            nn.Linear(proj_dim, proj_dim),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(dropout),\n",
        "        )\n",
        "\n",
        "        # üîÅ Cross-attention: cat attends to num\n",
        "        self.cross_attn_cat2num = nn.MultiheadAttention(\n",
        "            embed_dim=proj_dim,\n",
        "            num_heads=4,\n",
        "            dropout=dropout,\n",
        "            batch_first=True,\n",
        "        )\n",
        "\n",
        "        self.film = FiLM(proj_dim)  # üîß FiLM added here\n",
        "\n",
        "        self.transformer_layers = nn.ModuleList([\n",
        "            nn.TransformerEncoderLayer(\n",
        "                d_model=2 * proj_dim,\n",
        "                nhead=num_heads,\n",
        "                dim_feedforward=dim_feedforward,\n",
        "                dropout=dropout,\n",
        "                batch_first=True,\n",
        "            )\n",
        "            for _ in range(num_layers)\n",
        "        ])\n",
        "\n",
        "        self.mlp = nn.Sequential(\n",
        "            nn.Linear(2 * proj_dim, 128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(128, 64),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(64, 1),\n",
        "        )\n",
        "\n",
        "    def forward(self, x_cat: dict, x_num: torch.Tensor, attn_mask=None):\n",
        "        B, N, _ = x_num.shape  # x_num: [B, N, F_num]\n",
        "\n",
        "        # Categorical embeddings\n",
        "        cat_embs = torch.cat([self.embeddings[f](x_cat[f]) for f in x_cat], dim=-1)\n",
        "        cat_embs = self.emb_dropout(cat_embs)\n",
        "        cat_feat = self.cat_proj(cat_embs)  # [B, N, D]\n",
        "        cat_feat = self.cat_transformer(cat_feat)  # [B, N, D]\n",
        "\n",
        "        # Numeric features\n",
        "        num_feat = self.num_proj_in(x_num)\n",
        "        num_feat = self.num_transformer(num_feat)\n",
        "        num_feat = self.num_se(num_feat)\n",
        "        num_feat = self.num_proj_out(num_feat)\n",
        "\n",
        "        # üîß FiLM: condition cat_feat on num_feat\n",
        "        cat_feat = self.film(cat_feat, num_feat)\n",
        "\n",
        "        # Cross-attention: categorical features attend over numeric ones\n",
        "        cat_feat_attn, _ = self.cross_attn_cat2num(\n",
        "            query=cat_feat, key=num_feat, value=num_feat\n",
        "        )\n",
        "        cat_feat = cat_feat + cat_feat_attn  # residual connection\n",
        "\n",
        "        # Final concatenation\n",
        "        x = torch.cat([cat_feat, num_feat], dim=-1)\n",
        "\n",
        "        for layer in self.transformer_layers:\n",
        "            x = layer(x, src_key_padding_mask=attn_mask)\n",
        "\n",
        "        scores = self.mlp(x).squeeze(-1)  # [B, N]\n",
        "        return scores\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "def listmle_loss(scores, labels, lengths):\n",
        "    batch_size = scores.size(0)\n",
        "    total_loss = torch.tensor(0.0, device=scores.device, requires_grad=True)\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "\n",
        "        _, idx = torch.sort(y, descending=True)\n",
        "        s_sorted = s[idx]\n",
        "\n",
        "        parts = (\n",
        "            torch.logsumexp(s_sorted.unsqueeze(0).expand(l, -1).triu(diagonal=0), dim=1)\n",
        "            - s_sorted\n",
        "        )\n",
        "\n",
        "        total_loss = total_loss + parts.sum()\n",
        "\n",
        "    return total_loss / batch_size\n",
        "\"\"\"\n",
        "\n",
        "def hitrate_at_k(scores, labels, lengths, k=3, min_group_size=10):\n",
        "    batch_size = scores.size(0)\n",
        "    hits = 0\n",
        "    valid_count = 0\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        if l < min_group_size:\n",
        "            continue\n",
        "        length = min(l, k)\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "        _, topk_idx = torch.topk(s, length)\n",
        "        topk_labels = y[topk_idx]\n",
        "        hits += (topk_labels > 0).any().float()\n",
        "        valid_count += 1\n",
        "    return hits / valid_count if valid_count > 0 else torch.tensor(0.0, device=scores.device)\n",
        "\n",
        "\n",
        "def ndcg_at_k(scores, labels, lengths, k=3, min_group_size=10):\n",
        "    batch_size = scores.size(0)\n",
        "    total_ndcg = 0.0\n",
        "    valid_count = 0\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        if l < min_group_size:\n",
        "            continue\n",
        "\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "\n",
        "        _, idx_pred = torch.topk(s, min(k, l))\n",
        "        _, idx_ideal = torch.topk(y, min(k, l))\n",
        "\n",
        "        dcg = (y[idx_pred] / torch.log2(torch.arange(2, 2 + len(idx_pred), device=y.device).float())).sum()\n",
        "        idcg = (y[idx_ideal] / torch.log2(torch.arange(2, 2 + len(idx_ideal), device=y.device).float())).sum()\n",
        "\n",
        "        ndcg = dcg / idcg if idcg > 0 else 0.0\n",
        "        total_ndcg += ndcg\n",
        "        valid_count += 1\n",
        "\n",
        "    return total_ndcg / valid_count if valid_count > 0 else torch.tensor(0.0, device=scores.device)\n",
        "\n",
        "\n",
        "def map_at_k(scores, labels, lengths, k=3, min_group_size=10):\n",
        "    batch_size = scores.size(0)\n",
        "    total_ap = 0.0\n",
        "    valid_count = 0\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        if l < min_group_size:\n",
        "            continue\n",
        "\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "\n",
        "        _, idx_pred = torch.topk(s, min(k, l))\n",
        "        y_true = y[idx_pred] > 0\n",
        "\n",
        "        if y_true.sum() == 0:\n",
        "            continue\n",
        "\n",
        "        precisions = [(y_true[:j+1].float().sum() / (j+1)) for j in range(len(y_true)) if y_true[j]]\n",
        "        ap = torch.stack(precisions).mean()\n",
        "        total_ap += ap\n",
        "        valid_count += 1\n",
        "\n",
        "    return total_ap / valid_count if valid_count > 0 else torch.tensor(0.0, device=scores.device)\n",
        "\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "def listnet_loss(scores, labels, lengths):\n",
        "    batch_size = scores.size(0)\n",
        "    total_loss = 0.0\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "\n",
        "        s_softmax = torch.nn.functional.log_softmax(s, dim=0)\n",
        "        y_softmax = torch.nn.functional.softmax(y, dim=0)\n",
        "\n",
        "        loss = -torch.sum(y_softmax * s_softmax)\n",
        "        total_loss += loss\n",
        "\n",
        "    return total_loss / batch_size\n",
        "\"\"\"\n",
        "\n",
        "def ranknet_loss(scores, labels, lengths):\n",
        "    batch_size = scores.size(0)\n",
        "    total_loss = 0.0\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "\n",
        "        diff_scores = s.unsqueeze(1) - s.unsqueeze(0)\n",
        "        rel = y.unsqueeze(1) > y.unsqueeze(0)\n",
        "        label_diff = rel.float()\n",
        "\n",
        "        log_sigmoid = torch.nn.functional.logsigmoid(diff_scores)\n",
        "        pair_loss = -label_diff * log_sigmoid\n",
        "\n",
        "        total_loss += pair_loss.sum()\n",
        "\n",
        "    return total_loss / batch_size\n",
        "\n",
        "def xranknet_loss(scores, labels, lengths, temperature=1.0, margin=0.2, focus_topk=3):\n",
        "    \"\"\"\n",
        "    xRankNet with emphasis on top-K items (based on labels, not scores).\n",
        "    \"\"\"\n",
        "    batch_size = scores.size(0)\n",
        "    total_loss = 0.0\n",
        "    total_pairs = 0\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        if l < 2:\n",
        "            continue\n",
        "\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "\n",
        "        # Top-K mask based on ground truth labels\n",
        "        topk = min(focus_topk, l)\n",
        "        _, topk_idx = torch.topk(y, topk)\n",
        "        topk_mask = torch.zeros_like(y, dtype=torch.bool)\n",
        "        topk_mask[topk_idx] = True\n",
        "\n",
        "        # Create pairwise difference matrices\n",
        "        score_diff = s.unsqueeze(1) - s.unsqueeze(0)\n",
        "        label_diff = y.unsqueeze(1) - y.unsqueeze(0)\n",
        "\n",
        "        # valid pair: y_i > y_j and at least one of i, j is in top-K\n",
        "        valid_pairs = (label_diff > 0) & (\n",
        "            topk_mask.unsqueeze(1) | topk_mask.unsqueeze(0)\n",
        "        )\n",
        "\n",
        "        if valid_pairs.sum() == 0:\n",
        "            continue\n",
        "\n",
        "        importance = (label_diff.abs() * valid_pairs).float()\n",
        "\n",
        "        if margin > 0.0:\n",
        "            score_diff = score_diff - margin\n",
        "\n",
        "        score_diff = score_diff / temperature\n",
        "        pairwise_loss = -F.logsigmoid(score_diff) * importance\n",
        "\n",
        "        total_loss += pairwise_loss.sum()\n",
        "        total_pairs += importance.sum()\n",
        "\n",
        "    if total_pairs == 0:\n",
        "        return torch.tensor(0.0, device=scores.device, requires_grad=True)\n",
        "\n",
        "    return total_loss / total_pairs\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "def bpr_loss(scores, labels, lengths):\n",
        "    batch_size = scores.size(0)\n",
        "    total_loss = 0.0\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "\n",
        "        pos_mask = y > 0\n",
        "        neg_mask = y <= 0\n",
        "\n",
        "        pos_scores = s[pos_mask]\n",
        "        neg_scores = s[neg_mask]\n",
        "\n",
        "        if len(pos_scores) == 0 or len(neg_scores) == 0:\n",
        "            continue\n",
        "\n",
        "        pair_diff = pos_scores.unsqueeze(1) - neg_scores.unsqueeze(0)\n",
        "        loss = -F.logsigmoid(pair_diff).mean()\n",
        "        total_loss += loss\n",
        "\n",
        "    return total_loss / batch_size\n",
        "\"\"\"\n",
        "\n",
        "\"\"\"\n",
        "def lambdarank_loss(scores, labels, lengths, eps=1e-10):\n",
        "    batch_size = scores.size(0)\n",
        "    total_loss = 0.0\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "\n",
        "        if l < 2:\n",
        "            continue\n",
        "\n",
        "        _, rank_order = torch.sort(s, descending=True)\n",
        "        ideal_order = torch.sort(y, descending=True).indices\n",
        "\n",
        "        gain = 2 ** y - 1\n",
        "        discount = torch.log2(torch.arange(2, l + 2, device=y.device).float())\n",
        "\n",
        "        ideal_dcg = (gain[ideal_order] / discount).sum()\n",
        "        if ideal_dcg < eps:\n",
        "            continue\n",
        "\n",
        "        delta_ndcg = torch.zeros((l, l), device=y.device)\n",
        "\n",
        "        for i_idx in range(l):\n",
        "            for j_idx in range(l):\n",
        "                if y[i_idx] > y[j_idx]:\n",
        "                    change = (\n",
        "                        (1.0 / torch.log2(rank_order[i_idx] + 2.0))\n",
        "                        - (1.0 / torch.log2(rank_order[j_idx] + 2.0))\n",
        "                    ).abs()\n",
        "                    delta = (2 ** y[i_idx] - 2 ** y[j_idx]).abs() * change\n",
        "                    delta_ndcg[i_idx, j_idx] = delta / ideal_dcg\n",
        "\n",
        "        score_diffs = s.unsqueeze(1) - s.unsqueeze(0)\n",
        "        lambdas = -F.logsigmoid(score_diffs) * delta_ndcg\n",
        "        total_loss += lambdas.sum()\n",
        "\n",
        "    return total_loss / batch_size\n",
        "\"\"\"\n",
        "\n",
        "def train_one_epoch(model, loader, optimizer, device, scheduler):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "\n",
        "    for x_cat, x_num, y, lengths in tqdm(loader, desc=\"Training\", leave=False):\n",
        "        x_num, y = x_num.to(device), y.to(device)\n",
        "        if not isinstance(lengths, torch.Tensor):\n",
        "            lengths = torch.tensor(lengths)\n",
        "        lengths = lengths.detach().clone().to(device)\n",
        "        x_cat = {k: v.to(device) for k, v in x_cat.items()}\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        scores = model(x_cat, x_num)\n",
        "        loss = xranknet_loss(scores, y, lengths, temperature=1.0, margin=0.2, focus_topk=3)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    return total_loss / len(loader)\n",
        "\n",
        "\n",
        "def validate(model, loader, device, min_group_size=10):\n",
        "    model.eval()\n",
        "    total_hitrate = 0\n",
        "    total_ndcg = 0\n",
        "    total_map = 0\n",
        "    total_loss = 0\n",
        "    count = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for x_cat, x_num, y, lengths in tqdm(loader, desc=\"Validating\", leave=False):\n",
        "            x_num, y = x_num.to(device), y.to(device)\n",
        "            lengths = torch.tensor(lengths).to(device)\n",
        "            x_cat = {k: v.to(device) for k, v in x_cat.items()}\n",
        "\n",
        "            scores = model(x_cat, x_num)\n",
        "\n",
        "            hitrate = hitrate_at_k(scores, y, lengths, k=3, min_group_size=min_group_size)\n",
        "            ndcg = ndcg_at_k(scores, y, lengths, k=3, min_group_size=min_group_size)\n",
        "            map3 = map_at_k(scores, y, lengths, k=3, min_group_size=min_group_size)\n",
        "            loss = xranknet_loss(scores, y, lengths, temperature=1.0, margin=0.2, focus_topk=3)\n",
        "\n",
        "            batch_size = scores.size(0)\n",
        "            total_hitrate += hitrate * batch_size\n",
        "            total_ndcg += ndcg * batch_size\n",
        "            total_map += map3 * batch_size\n",
        "            total_loss += loss.item() * batch_size\n",
        "            count += batch_size\n",
        "\n",
        "    return total_loss / count, total_hitrate / count, total_ndcg / count, total_map / count\n",
        "\n",
        "\n",
        "def build_cat_dims(X, cat_features):\n",
        "    cat_dims = {}\n",
        "    for c in cat_features:\n",
        "        max_val = X[c].max()\n",
        "        if max_val < 0:\n",
        "            max_val = 0\n",
        "        cat_dims[c] = max_val + 1\n",
        "    return cat_dims\n",
        "\n",
        "\n",
        "def normalize_numeric_features(X, numeric_features, train_mask):\n",
        "    for col in numeric_features:\n",
        "        values = X[col].to_numpy()\n",
        "        train_vals = values[train_mask]\n",
        "        mean = train_vals.mean()\n",
        "        std = train_vals.std() if train_vals.std() > 0 else 1.0\n",
        "        norm_vals = (values - mean) / std\n",
        "        X = X.with_columns(pl.Series(col, norm_vals).alias(col))\n",
        "    return X\n",
        "\n",
        "\n",
        "def load_or_prepare_data(\n",
        "    data_dir,\n",
        "    train_file=\"train.parquet\",\n",
        "    test_file=\"test.parquet\",\n",
        "    cache_file=\"feature_engineered_val.parquet\",\n",
        "):\n",
        "    cache_path = os.path.join(data_dir, cache_file)\n",
        "\n",
        "    if os.path.exists(cache_path):\n",
        "        print(f\"Loading cached feature-engineered data from {cache_path} ...\")\n",
        "        df = pl.read_parquet(cache_path)\n",
        "\n",
        "        test = pl.read_parquet(os.path.join(data_dir, test_file)).drop(\"__index_level_0__\")\n",
        "        test_ids = test[\"Id\"]\n",
        "        test_rankers = test[\"ranker_id\"]\n",
        "    else:\n",
        "        print(\"Cached file not found, processing raw data ...\")\n",
        "\n",
        "        train = pl.read_parquet(os.path.join(data_dir, train_file)).drop(\"__index_level_0__\")\n",
        "        test = (\n",
        "            pl.read_parquet(os.path.join(data_dir, test_file))\n",
        "            .drop(\"__index_level_0__\")\n",
        "            .with_columns(pl.lit(0, dtype=pl.Int64).alias(\"selected\"))\n",
        "        )\n",
        "\n",
        "        test_ids = test[\"Id\"]\n",
        "        test_rankers = test[\"ranker_id\"]\n",
        "\n",
        "        df = pl.concat((train, test))\n",
        "        df = feature_engineering(df, full=True)\n",
        "\n",
        "        df = df.with_columns(\n",
        "            [pl.col(c).fill_null(0) for c in df.select(pl.selectors.numeric()).columns] +\n",
        "            [pl.col(c).fill_null(\"missing\") for c in df.select(pl.selectors.string()).columns]\n",
        "        )\n",
        "\n",
        "        os.makedirs(data_dir, exist_ok=True)\n",
        "        df.write_parquet(cache_path)\n",
        "        print(f\"Saved feature-engineered data to {cache_path}\")\n",
        "\n",
        "    return df, test_ids, test_rankers\n",
        "\n",
        "\n",
        "def prepare_data(data_dir):\n",
        "    df, test_ids, test_rankers = load_or_prepare_data(data_dir)\n",
        "\n",
        "    id_column = df[\"Id\"]\n",
        "    X, y, groups, cat_features, num_features = feature_selection(df)\n",
        "\n",
        "    X = X.with_columns(pl.Series(\"Id\", id_column[:X.shape[0]]))\n",
        "\n",
        "    X = X.with_columns(\n",
        "        [\n",
        "            (pl.col(c).rank(\"dense\") - 1).fill_null(-1).cast(pl.Int32)\n",
        "            for c in cat_features\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    train_size = 18145372\n",
        "    train_mask = np.arange(X.height) < train_size\n",
        "    X = normalize_numeric_features(X, num_features, train_mask)\n",
        "\n",
        "    return X, y, groups, cat_features, num_features, train_size, test_ids, test_rankers\n",
        "\n",
        "\n",
        "class EarlyStopping:\n",
        "    def __init__(self, patience=3, min_delta=0.00005):\n",
        "        self.patience = patience\n",
        "        self.min_delta = min_delta\n",
        "        self.best = float(\"-inf\")\n",
        "        self.counter = 0\n",
        "\n",
        "    def step(self, metric):\n",
        "        if metric > self.best + self.min_delta:\n",
        "            self.best = metric\n",
        "            self.counter = 0\n",
        "        else:\n",
        "            self.counter += 1\n",
        "        return self.counter >= self.patience\n",
        "\n",
        "\n",
        "def plot_group_size_distribution(dataset, save_path=None):\n",
        "    group_sizes = [len(v) for v in dataset.group_to_indices.values()]\n",
        "    plt.figure()\n",
        "    plt.hist(group_sizes, bins=100, log=True)\n",
        "    plt.xlabel(\"Group size (number of items per ranker_id)\")\n",
        "    plt.ylabel(\"Frequency (log scale)\")\n",
        "    plt.title(\"Distribution of Group Sizes\")\n",
        "    plt.grid(True)\n",
        "    if save_path:\n",
        "        plt.savefig(save_path)\n",
        "    else:\n",
        "        plt.show()\n",
        "    plt.close()\n",
        "\n",
        "\n",
        "def main():\n",
        "    DATA_DIR = \"./data\"\n",
        "    MODEL_DIR = \"model\"\n",
        "    SUBMIT_DIR = \"submission\"\n",
        "\n",
        "    best_val_loss = float(\"inf\")\n",
        "    best_hitrate = 0.0\n",
        "    model_path = os.path.join(MODEL_DIR, \"best_dl_ranker_top3.pt\")\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "    val_hitrates = []\n",
        "    val_ndcgs = []\n",
        "    val_maps = []\n",
        "    learning_rates = []\n",
        "\n",
        "    os.makedirs(MODEL_DIR, exist_ok=True)\n",
        "    os.makedirs(SUBMIT_DIR, exist_ok=True)\n",
        "\n",
        "    early_stopper = EarlyStopping(patience=3, min_delta=0.00005)\n",
        "\n",
        "    X, y, groups, cat_features, num_features, train_size, test_ids, test_rankers = prepare_data(DATA_DIR)\n",
        "\n",
        "    # Fill missing values\n",
        "    float_cols = [c for c, t in zip(X.columns, X.dtypes) if t == pl.Float64]\n",
        "    for col in float_cols:\n",
        "        X = X.with_columns(\n",
        "            pl.when(pl.col(col).is_nan()).then(0).otherwise(pl.col(col)).alias(col)\n",
        "        )\n",
        "\n",
        "    n1 = 16487352\n",
        "    # n1 = 17487300\n",
        "\n",
        "    X_tr = X[:n1]\n",
        "    y_tr = y[:n1]\n",
        "    groups_tr = groups[:n1]\n",
        "\n",
        "    validation_path = os.path.join(DATA_DIR, \"validation_top10_dl_full.parquet\")\n",
        "    submission_path = os.path.join(DATA_DIR, \"submission_top10_dl_full.parquet\")\n",
        "\n",
        "    val_df = pl.read_parquet(validation_path).rename({\"label\": \"selected\"})\n",
        "    test_df = pl.read_parquet(submission_path)\n",
        "\n",
        "    X_va = val_df.drop([\"selected\", \"rank\", \"score\", \"ranker_id\"])\n",
        "    y_va = val_df.select(\"selected\")\n",
        "    groups_va = val_df.select(\"ranker_id\")\n",
        "\n",
        "    X_te = test_df.drop([\"rank\", \"score\", \"ranker_id\"])\n",
        "    y_te = pl.Series(\"selected\", [0] * test_df.height)  # dummy labels\n",
        "    groups_te = test_df.select(\"ranker_id\")\n",
        "\n",
        "    val_rankers = groups_va[\"ranker_id\"].to_numpy()\n",
        "    val_group_counts = Counter(val_rankers)\n",
        "\n",
        "    print(\"\\nüìã Validation group statistics:\")\n",
        "    # Save detailed group info to file\n",
        "    group_info_path = os.path.join(MODEL_DIR, \"validation_groups_info.txt\")\n",
        "    with open(group_info_path, \"w\") as f:\n",
        "        f.write(f\"Total groups: {len(val_group_counts)}\\n\\n\")\n",
        "        f.write(\"GroupID\\tSize\\tStartIdx\\tEndIdx\\n\")\n",
        "\n",
        "        group_to_rows = defaultdict(list)\n",
        "        for i, g in enumerate(val_rankers):\n",
        "            group_to_rows[g].append(i)\n",
        "\n",
        "        for group_id, indices in sorted(group_to_rows.items()):\n",
        "            start_idx = indices[0]\n",
        "            end_idx = indices[-1]\n",
        "            size = len(indices)\n",
        "            f.write(f\"{group_id}\\t{size}\\t{start_idx}\\t{end_idx}\\n\")\n",
        "\n",
        "    print(f\"üìÅ Saved validation group info to {group_info_path}\")\n",
        "\n",
        "\n",
        "    cat_dims = build_cat_dims(X, cat_features)\n",
        "    num_numeric_feats = len(num_features)\n",
        "\n",
        "    train_dataset = RankDataset(X_tr, y_tr, groups_tr, cat_features, num_features)\n",
        "    val_dataset = RankDataset(X_va, y_va, groups_va, cat_features, num_features)\n",
        "    test_dataset = RankDataset(X_te, y_te, groups_te, cat_features, num_features)\n",
        "\n",
        "    plot_group_size_distribution(train_dataset, save_path=os.path.join(MODEL_DIR, \"group_sizes.png\"))\n",
        "    print(\"üìä Group size distribution saved.\")\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True, collate_fn=collate_fn)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=4, shuffle=False, collate_fn=collate_fn)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False, collate_fn=collate_fn)\n",
        "\n",
        "    print(\"‚úÖ Data loaders created.\")\n",
        "\n",
        "    num_epochs = 10\n",
        "    num_training_steps = num_epochs * len(train_loader)\n",
        "    num_warmup_steps = int(0.1 * num_training_steps)\n",
        "\n",
        "    learning_rate = 1e-4\n",
        "\n",
        "    model = DLRankerAttention(\n",
        "        cat_dims=cat_dims,\n",
        "        num_numeric_feats=num_numeric_feats,\n",
        "        emb_dropout=0.1,\n",
        "        dropout=0.1,\n",
        "        num_heads=4,\n",
        "        num_layers=2,\n",
        "        dim_feedforward=128,\n",
        "        proj_dim=64\n",
        "    ).to(device)\n",
        "\n",
        "    model.load_state_dict(torch.load(\"model/best_dl_ranker_top10.pt\"))\n",
        "\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=0.01)\n",
        "\n",
        "    scheduler = OneCycleLR(\n",
        "        optimizer,\n",
        "        max_lr=learning_rate,\n",
        "        steps_per_epoch=len(train_loader),\n",
        "        epochs=num_epochs,\n",
        "        pct_start=0.3,\n",
        "    )\n",
        "\n",
        "    best_hitrate = 0\n",
        "    for epoch in range(num_epochs):\n",
        "        print(f\"\\n--- Epoch {epoch+1}/{num_epochs} ---\")\n",
        "        start_time = time.time()\n",
        "\n",
        "        train_loss = train_one_epoch(model, train_loader, optimizer, device, scheduler)\n",
        "        val_loss, val_hitrate, val_ndcg, val_map = validate(model, val_loader, device, min_group_size=10)\n",
        "\n",
        "        train_losses.append(train_loss)\n",
        "        val_losses.append(val_loss)\n",
        "        val_hitrates.append(val_hitrate.item())\n",
        "        val_ndcgs.append(val_ndcg.item())\n",
        "        val_maps.append(val_map.item())\n",
        "\n",
        "        current_lr = scheduler.get_last_lr()\n",
        "        learning_rates.append(current_lr[0])\n",
        "\n",
        "        elapsed = time.time() - start_time\n",
        "        print(\n",
        "            f\"Epoch {epoch+1}: \"\n",
        "            f\"Train Loss={train_loss:.4f}, \"\n",
        "            f\"Val Loss={val_loss:.4f}, \"\n",
        "            f\"HitRate@3={val_hitrate:.4f}, \"\n",
        "            f\"NDCG@3={val_ndcg:.4f}, \"\n",
        "            f\"MAP@3={val_map:.4f}, \"\n",
        "            f\"LR={current_lr[0]:.6f} \"\n",
        "            f\"({elapsed:.1f}s)\"\n",
        "        )\n",
        "\n",
        "\n",
        "        if val_loss < best_val_loss and val_hitrate > best_hitrate:\n",
        "            best_val_loss = val_loss\n",
        "            best_hitrate = val_hitrate\n",
        "            torch.save(model.state_dict(), model_path)\n",
        "            print(\"üíæ Model improved (loss ‚Üì and hitrate ‚Üë), saved.\")\n",
        "\n",
        "        if early_stopper.step(-val_loss):\n",
        "            print(\"‚õî Early stopping triggered.\")\n",
        "            break\n",
        "\n",
        "    # Plot metrics\n",
        "    epochs = list(range(1, len(train_losses) + 1))\n",
        "\n",
        "    # Plot Loss Curve\n",
        "    plt.figure()\n",
        "    plt.plot(epochs, train_losses, label=\"Train Loss\")\n",
        "    plt.plot(epochs, val_losses, label=\"Val Loss\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.title(\"Training & Validation Loss\")\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.savefig(os.path.join(MODEL_DIR, \"loss_curve.png\"))\n",
        "    plt.close()\n",
        "\n",
        "    # Plot HitRate@3\n",
        "    plt.figure()\n",
        "    plt.plot(epochs, val_hitrates, label=\"Val HitRate@3\", color=\"green\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"HitRate@3\")\n",
        "    plt.title(\"Validation HitRate@3\")\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.savefig(os.path.join(MODEL_DIR, \"hitrate_curve.png\"))\n",
        "    plt.close()\n",
        "\n",
        "    # Plot Learning Rate\n",
        "    plt.figure()\n",
        "    plt.plot(epochs, learning_rates, label=\"Learning Rate\", color=\"orange\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"LR\")\n",
        "    plt.title(\"Learning Rate Schedule\")\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.savefig(os.path.join(MODEL_DIR, \"lr_curve.png\"))\n",
        "    plt.close()\n",
        "\n",
        "    # Plot NDCG@3\n",
        "    plt.figure()\n",
        "    plt.plot(epochs, val_ndcgs, label=\"Val NDCG@3\", color=\"purple\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"NDCG@3\")\n",
        "    plt.title(\"Validation NDCG@3\")\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.savefig(os.path.join(MODEL_DIR, \"ndcg_curve.png\"))\n",
        "    plt.close()\n",
        "\n",
        "    # Plot MAP@3\n",
        "    plt.figure()\n",
        "    plt.plot(epochs, val_maps, label=\"Val MAP@3\", color=\"red\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"MAP@3\")\n",
        "    plt.title(\"Validation MAP@3\")\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.savefig(os.path.join(MODEL_DIR, \"map_curve.png\"))\n",
        "    plt.close()\n",
        "\n",
        "    print(\"üìä Saved metric plots to model/\")\n",
        "\n",
        "    # Predict test set\n",
        "    model.load_state_dict(torch.load(model_path))\n",
        "    model.eval()\n",
        "\n",
        "    val_ids = X_va[\"Id\"]\n",
        "    val_rankers = groups_va[\"ranker_id\"]\n",
        "    val_labels = y_va\n",
        "\n",
        "    all_val_scores = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for x_cat, x_num, _, lengths in tqdm(val_loader, desc=\"Predicting validation set\"):\n",
        "            x_num = x_num.to(device)\n",
        "            x_cat = {k: v.to(device) for k, v in x_cat.items()}\n",
        "            scores = model(x_cat, x_num)\n",
        "\n",
        "            for i in range(scores.size(0)):\n",
        "                l = lengths[i]\n",
        "                all_val_scores.append(scores[i, :l].cpu().numpy())\n",
        "\n",
        "    all_val_scores = np.concatenate(all_val_scores)\n",
        "\n",
        "    assert len(all_val_scores) == X_va.shape[0], \\\n",
        "        f\"Mismatch: {len(all_val_scores)} scores vs {X_va.shape[0]} rows\"\n",
        "\n",
        "    val_df = X_va.with_columns([\n",
        "        pl.Series(\"Id\", val_ids),\n",
        "        pl.Series(\"ranker_id\", val_rankers),\n",
        "        pl.Series(\"score\", all_val_scores),\n",
        "        pl.Series(\"selected\", val_labels)\n",
        "    ])\n",
        "\n",
        "    val_df = val_df.with_columns(\n",
        "        pl.col(\"score\")\n",
        "        .rank(method=\"ordinal\", descending=True)\n",
        "        .over(\"ranker_id\")\n",
        "        .cast(pl.Int32)\n",
        "        .alias(\"selected\")\n",
        "    )\n",
        "\n",
        "    val_save_path = os.path.join(MODEL_DIR, \"validation_preds_dl_full.csv\")\n",
        "    val_df.write_csv(val_save_path)\n",
        "    print(f\"‚úÖ Saved full validation predictions (with features) to {val_save_path}\")\n",
        "\n",
        "    all_scores = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for x_cat, x_num, _, lengths in tqdm(test_loader, desc=\"Predicting test set\"):\n",
        "            x_num = x_num.to(device)\n",
        "            x_cat = {k: v.to(device) for k, v in x_cat.items()}\n",
        "            scores = model(x_cat, x_num)\n",
        "\n",
        "            for i in range(scores.size(0)):\n",
        "                l = lengths[i]\n",
        "                all_scores.append(scores[i, :l].cpu().numpy())\n",
        "\n",
        "    all_scores = np.concatenate(all_scores)\n",
        "\n",
        "    assert len(all_scores) == X_te.shape[0], \\\n",
        "        f\"Mismatch: {len(all_scores)} scores vs {X_te.shape[0]} rows in X_te\"\n",
        "\n",
        "    submission_df = pl.DataFrame({\n",
        "        \"Id\": test_ids,\n",
        "        \"ranker_id\": test_rankers,\n",
        "        \"score\": all_scores\n",
        "    })\n",
        "\n",
        "    submission = (\n",
        "        submission_df\n",
        "        .with_columns(\n",
        "            pl.col(\"score\")\n",
        "            .rank(method=\"ordinal\", descending=True)\n",
        "            .over(\"ranker_id\")\n",
        "            .cast(pl.Int32)\n",
        "            .alias(\"selected\")\n",
        "        )\n",
        "        .select([\"Id\", \"ranker_id\", \"score\", \"selected\"])\n",
        "    )\n",
        "\n",
        "    submission_path = os.path.join(SUBMIT_DIR, \"submission_dl_ranker.csv\")\n",
        "    submission.write_csv(submission_path)\n",
        "    print(f\"‚úÖ Submission saved to {submission_path}\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ifhHWx1tcVUG",
        "outputId": "98231dd2-78b5-4fe2-d90e-c43cdd8b0824"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing deeprec_validate_top3.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "--- Epoch 1/10 ---\n",
        "Validating:   0%|          | 0/2636 [00:00<?, ?it/s]/home/ionut/test_whisper/test2/deeprec_validate.py:539: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
        "  lengths = torch.tensor(lengths).to(device)\n",
        "Epoch 1: Train Loss=0.3531, Val Loss=0.5595, HitRate@3=0.4739, NDCG@3=0.3745, MAP@3=0.6289, LR=0.000084 (582.8s)\n",
        "üíæ Model improved (loss ‚Üì and hitrate ‚Üë), saved.\n",
        "\n",
        "--- Epoch 2/10 ---\n",
        "Epoch 2: Train Loss=0.2876, Val Loss=0.5293, HitRate@3=0.4840, NDCG@3=0.3802, MAP@3=0.6295, LR=0.000228 (584.8s)\n",
        "üíæ Model improved (loss ‚Üì and hitrate ‚Üë), saved.\n",
        "\n",
        "--- Epoch 3/10 ---\n",
        "Epoch 3: Train Loss=0.2799, Val Loss=0.5292, HitRate@3=0.4895, NDCG@3=0.3912, MAP@3=0.6490, LR=0.000300 (584.0s)\n",
        "üíæ Model improved (loss ‚Üì and hitrate ‚Üë), saved.\n",
        "\n",
        "--- Epoch 4/10 ---\n",
        "Epoch 4: Train Loss=0.2667, Val Loss=0.5256, HitRate@3=0.4986, NDCG@3=0.4015, MAP@3=0.6618, LR=0.000285 (583.6s)\n",
        "üíæ Model improved (loss ‚Üì and hitrate ‚Üë), saved.\n",
        "\n",
        "--- Epoch 5/10 ---\n",
        "Epoch 5: Train Loss=0.2553, Val Loss=0.5082, HitRate@3=0.5038, NDCG@3=0.4005, MAP@3=0.6500, LR=0.000244 (582.9s)\n",
        "üíæ Model improved (loss ‚Üì and hitrate ‚Üë), saved.\n",
        "\n",
        "--- Epoch 6/10 ---\n",
        "Epoch 6: Train Loss=0.2443, Val Loss=0.5007, HitRate@3=0.5086, NDCG@3=0.4131, MAP@3=0.6719, LR=0.000183 (585.2s)\n",
        "üíæ Model improved (loss ‚Üì and hitrate ‚Üë), saved.\n",
        "\n",
        "--- Epoch 7/10 ---\n",
        "Epoch 7: Train Loss=0.2330, Val Loss=0.5043, HitRate@3=0.5092, NDCG@3=0.4076, MAP@3=0.6608, LR=0.000117 (584.1s)\n",
        "\n",
        "--- Epoch 8/10 ---\n",
        "Epoch 8: Train Loss=0.2229, Val Loss=0.5002, HitRate@3=0.5070, NDCG@3=0.4075, MAP@3=0.6635, LR=0.000056 (586.0s)\n",
        "\n",
        "--- Epoch 9/10 ---\n",
        "Epoch 9: Train Loss=0.2135, Val Loss=0.5007, HitRate@3=0.5111, NDCG@3=0.4104, MAP@3=0.6620, LR=0.000015 (582.4s)\n",
        "üíæ Model improved (loss ‚Üì and hitrate ‚Üë), saved."
      ],
      "metadata": {
        "id": "2wqFG8wWkk8i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Get back features**"
      ],
      "metadata": {
        "id": "d_L8L_DcCkcH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from feature_specs import get_all_feature_lists\n",
        "\n",
        "# Ob»õine listele\n",
        "_, _, exclude = get_all_feature_lists()\n",
        "\n",
        "# EliminƒÉ duplicate »ôi sorteazƒÉ\n",
        "exclude_unique_sorted = sorted(set(exclude))\n",
        "\n",
        "# Afi»ôeazƒÉ numƒÉrul total »ôi feature-urile excluse\n",
        "print(f\"NumƒÉr total de feature-uri excluse: {len(exclude_unique_sorted)}\\n\")\n",
        "print(\"Lista feature-urilor excluse:\")\n",
        "for feat in exclude_unique_sorted:\n",
        "    print(feat)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hQOC6Zfy2KrL",
        "outputId": "0cad91f9-1abf-47d7-f906-d898c33ee6cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NumƒÉr total de feature-uri excluse: 102\n",
            "\n",
            "Lista feature-urilor excluse:\n",
            "Id\n",
            "both_direct\n",
            "carrier_pop_prod\n",
            "corporateTariffCode_duration_rank_mean\n",
            "corporateTariffCode_price_rank_mean\n",
            "frequentFlyer\n",
            "geo_distance_km\n",
            "group_size\n",
            "is_expensive_outlier\n",
            "is_last_minute_booking\n",
            "is_min_segments\n",
            "is_popular_flight\n",
            "is_shortest_duration\n",
            "l0_seg\n",
            "leg_dur_interaction_ratio\n",
            "legs0_arrivalAt\n",
            "legs0_arrivalAt_business_time\n",
            "legs0_departureAt\n",
            "legs0_departureAt_business_time\n",
            "legs0_segments0_marketingCarrier_code_avg_dep_hour\n",
            "legs0_segments0_marketingCarrier_code_ff_and_economic\n",
            "legs0_segments0_marketingCarrier_code_selected_rank_bin\n",
            "legs0_segments0_marketingCarrier_code_selection_rate\n",
            "legs0_segments0_seatsAvailable\n",
            "legs0_segments1_duration\n",
            "legs0_segments1_seatsAvailable\n",
            "legs0_segments2_aircraft_code\n",
            "legs0_segments2_arrivalTo_airport_city_iata\n",
            "legs0_segments2_arrivalTo_airport_iata\n",
            "legs0_segments2_baggageAllowance_quantity\n",
            "legs0_segments2_baggageAllowance_weightMeasurementType\n",
            "legs0_segments2_cabinClass\n",
            "legs0_segments2_departureFrom_airport_iata\n",
            "legs0_segments2_duration\n",
            "legs0_segments2_flightNumber\n",
            "legs0_segments2_marketingCarrier_code\n",
            "legs0_segments2_operatingCarrier_code\n",
            "legs0_segments2_seatsAvailable\n",
            "legs0_segments3_aircraft_code\n",
            "legs0_segments3_arrivalTo_airport_city_iata\n",
            "legs0_segments3_arrivalTo_airport_iata\n",
            "legs0_segments3_baggageAllowance_quantity\n",
            "legs0_segments3_baggageAllowance_weightMeasurementType\n",
            "legs0_segments3_cabinClass\n",
            "legs0_segments3_departureFrom_airport_iata\n",
            "legs0_segments3_duration\n",
            "legs0_segments3_flightNumber\n",
            "legs0_segments3_marketingCarrier_code\n",
            "legs0_segments3_operatingCarrier_code\n",
            "legs0_segments3_seatsAvailable\n",
            "legs1_arrivalAt\n",
            "legs1_arrivalAt_business_time\n",
            "legs1_departureAt\n",
            "legs1_departureAt_business_time\n",
            "legs1_segments0_marketingCarrier_code_selected_rank_bin\n",
            "legs1_segments0_marketingCarrier_code_selection_rate\n",
            "legs1_segments0_seatsAvailable\n",
            "legs1_segments1_duration\n",
            "legs1_segments1_seatsAvailable\n",
            "legs1_segments2_aircraft_code\n",
            "legs1_segments2_arrivalTo_airport_city_iata\n",
            "legs1_segments2_arrivalTo_airport_iata\n",
            "legs1_segments2_baggageAllowance_quantity\n",
            "legs1_segments2_baggageAllowance_weightMeasurementType\n",
            "legs1_segments2_cabinClass\n",
            "legs1_segments2_departureFrom_airport_iata\n",
            "legs1_segments2_duration\n",
            "legs1_segments2_flightNumber\n",
            "legs1_segments2_marketingCarrier_code\n",
            "legs1_segments2_operatingCarrier_code\n",
            "legs1_segments2_seatsAvailable\n",
            "legs1_segments3_aircraft_code\n",
            "legs1_segments3_arrivalTo_airport_city_iata\n",
            "legs1_segments3_arrivalTo_airport_iata\n",
            "legs1_segments3_baggageAllowance_quantity\n",
            "legs1_segments3_baggageAllowance_weightMeasurementType\n",
            "legs1_segments3_cabinClass\n",
            "legs1_segments3_departureFrom_airport_iata\n",
            "legs1_segments3_duration\n",
            "legs1_segments3_flightNumber\n",
            "legs1_segments3_marketingCarrier_code\n",
            "legs1_segments3_operatingCarrier_code\n",
            "legs1_segments3_seatsAvailable\n",
            "miniRules0_monetaryAmount\n",
            "miniRules0_percentage\n",
            "miniRules1_monetaryAmount\n",
            "miniRules1_percentage\n",
            "price_distance_mul\n",
            "price_per_tax\n",
            "pricingInfo_passengerCount\n",
            "profileId\n",
            "rank_interaction_ratio\n",
            "rank_interaction_sum\n",
            "ranker_id\n",
            "requestDate\n",
            "selected\n",
            "selected_direct_ratio\n",
            "stay_duration_bin\n",
            "stay_duration_hours\n",
            "taxes\n",
            "totalPrice\n",
            "total_duration\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile combine.py\n",
        "import polars as pl\n",
        "\n",
        "cols_to_copy = [\n",
        "    \"corporateTariffCode_duration_rank_mean\",\n",
        "    \"corporateTariffCode_price_rank_mean\",\n",
        "    \"miniRules0_percentage\",\n",
        "    \"miniRules1_percentage\",\n",
        "    \"miniRules0_monetaryAmount\",\n",
        "    \"miniRules1_monetaryAmount\",\n",
        "    \"taxes\",\n",
        "    \"totalPrice\",\n",
        "    \"group_size\",\n",
        "    \"price_per_tax\",\n",
        "    \"l0_seg\",\n",
        "    \"rank_interaction_ratio\",\n",
        "    \"rank_interaction_sum\",\n",
        "    \"leg_dur_interaction_ratio\",\n",
        "    \"selected_direct_ratio\",\n",
        "    \"legs0_segments0_marketingCarrier_code_avg_dep_hour\",\n",
        "    \"legs0_segments0_marketingCarrier_code_selection_rate\",\n",
        "    \"legs1_segments0_marketingCarrier_code_selection_rate\",\n",
        "    \"carrier_pop_prod\"\n",
        "]\n",
        "\n",
        "# Cite»ôte fi»ôierele\n",
        "f1 = pl.read_parquet(\"feature_engineered_val.parquet\")\n",
        "f2 = pl.read_parquet(\"features.parquet\").select(cols_to_copy)\n",
        "\n",
        "# Verificare rapidƒÉ\n",
        "assert f1.height == f2.height, \"‚ö†Ô∏è Fi»ôierele nu au acela»ôi numƒÉr de r√¢nduri!\"\n",
        "\n",
        "# CombinƒÉ orizontal\n",
        "f_new = f1.hstack(f2)\n",
        "\n",
        "# SalveazƒÉ\n",
        "f_new.write_parquet(\"feature_engineered_val_new.parquet\")\n",
        "print(\"‚úÖ Coloane adƒÉugate prin hstack.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9d7BwgDVBEhT",
        "outputId": "733bad99-3442-4dfa-d2a1-802e47b0544b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting combine.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile deeprec_validate.py\n",
        "import os\n",
        "import time\n",
        "import random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F_torch\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import defaultdict\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "import polars as pl\n",
        "from tqdm import tqdm\n",
        "from src.feature import feature_engineering, feature_selection\n",
        "from transformers import get_scheduler\n",
        "from collections import Counter\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "class RankDataset(Dataset):\n",
        "    def __init__(\n",
        "        self,\n",
        "        X: pl.DataFrame,\n",
        "        y: pl.Series,\n",
        "        groups: pl.DataFrame,\n",
        "        cat_features: list[str],\n",
        "        num_features: list[str],\n",
        "    ):\n",
        "        self.cat_features = cat_features\n",
        "        self.num_features = num_features\n",
        "        self.X_cat = {c: X[c].to_numpy() for c in cat_features}\n",
        "        self.X_num = X[self.num_features].to_numpy()\n",
        "        self.y = y.to_numpy()\n",
        "        self.groups = groups[\"ranker_id\"].to_numpy()\n",
        "\n",
        "        self.group_to_indices = defaultdict(list)\n",
        "        for i, g in enumerate(self.groups):\n",
        "            self.group_to_indices[g].append(i)\n",
        "        self.group_keys = list(self.group_to_indices.keys())\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.group_keys)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        g = self.group_keys[idx]\n",
        "        inds = self.group_to_indices[g]\n",
        "        length = len(inds)\n",
        "\n",
        "        x_cat = {\n",
        "            c: torch.LongTensor([\n",
        "                self.X_cat[c][i] if self.X_cat[c][i] >= 0 else 0 for i in inds\n",
        "            ])\n",
        "            for c in self.cat_features\n",
        "        }\n",
        "\n",
        "        x_num = torch.FloatTensor(self.X_num[inds])\n",
        "        y = torch.FloatTensor(self.y[inds]).reshape(-1)\n",
        "\n",
        "        return x_cat, x_num, y, length\n",
        "\n",
        "def collate_fn(batch):\n",
        "    batch = [b for b in batch if b[3] >= 2]\n",
        "    if len(batch) == 0:\n",
        "        return None\n",
        "\n",
        "    batch_size = len(batch)\n",
        "    lengths = [b[3] for b in batch]\n",
        "    max_len = max(lengths)\n",
        "\n",
        "    padded_x_cat = {key: [] for key in batch[0][0].keys()}\n",
        "    padded_x_num = []\n",
        "    padded_y = []\n",
        "\n",
        "    num_dim = batch[0][1].shape[1]\n",
        "\n",
        "    for x_cat, x_num, y, length in batch:\n",
        "        pad_len = max_len - length\n",
        "\n",
        "        for key in padded_x_cat:\n",
        "            val = x_cat[key]\n",
        "            if pad_len > 0:\n",
        "                val = torch.cat([val, torch.zeros(pad_len, dtype=torch.long)])\n",
        "            padded_x_cat[key].append(val)\n",
        "\n",
        "        if pad_len > 0:\n",
        "            x_num = torch.cat([x_num, torch.zeros(pad_len, num_dim)])\n",
        "            y = torch.cat([y, torch.zeros(pad_len)])\n",
        "\n",
        "        padded_x_num.append(x_num)\n",
        "        padded_y.append(y)\n",
        "\n",
        "    padded_x_cat = {k: torch.stack(v) for k, v in padded_x_cat.items()}\n",
        "    padded_x_num = torch.stack(padded_x_num)\n",
        "    padded_y = torch.stack(padded_y)\n",
        "    lengths = torch.tensor(lengths, dtype=torch.long)\n",
        "\n",
        "    return padded_x_cat, padded_x_num, padded_y, lengths\n",
        "\n",
        "\n",
        "class FiBiDLRanker(nn.Module):\n",
        "    def __init__(self, cat_dims, num_numeric_feats, emb_dim=64, hidden=[512, 256, 128, 64], reduction=4, use_senet=True):\n",
        "        super().__init__()\n",
        "        self.cat_fields = list(cat_dims.keys())\n",
        "        self.emb_dim = emb_dim\n",
        "        self.num_fields = len(self.cat_fields)\n",
        "        self.use_senet = use_senet\n",
        "\n",
        "        # Embedding layers\n",
        "        self.embeddings = nn.ModuleDict({\n",
        "            f: nn.Embedding(cat_dims[f], emb_dim, padding_idx=0) for f in self.cat_fields\n",
        "        })\n",
        "        self.linear_cat = nn.ModuleDict({\n",
        "            f: nn.Embedding(cat_dims[f], 1, padding_idx=0) for f in self.cat_fields\n",
        "        })\n",
        "        self.linear_num = nn.Linear(num_numeric_feats, 1)\n",
        "\n",
        "        for emb in list(self.embeddings.values()) + list(self.linear_cat.values()):\n",
        "            nn.init.xavier_uniform_(emb.weight)\n",
        "        nn.init.xavier_uniform_(self.linear_num.weight)\n",
        "\n",
        "        # SENet (with LayerNorm)\n",
        "        if self.use_senet:\n",
        "            self.se_fc1 = nn.Linear(self.num_fields * emb_dim, self.num_fields * emb_dim // reduction)\n",
        "            self.se_ln1 = nn.LayerNorm(self.num_fields * emb_dim // reduction)\n",
        "            self.se_dropout = nn.Dropout(0.1)\n",
        "            self.se_fc2 = nn.Linear(self.num_fields * emb_dim // reduction, self.num_fields * emb_dim)\n",
        "\n",
        "        # Bilinear layer (shared)\n",
        "        self.bilinear = nn.Linear(emb_dim, emb_dim, bias=False)\n",
        "\n",
        "        # MLP (using LayerNorm instead of BatchNorm)\n",
        "        input_dim = emb_dim + num_numeric_feats\n",
        "        layers = []\n",
        "        for h in hidden:\n",
        "            layers.append(nn.Linear(input_dim, h))\n",
        "            layers.append(nn.LayerNorm(h))     # replaced BatchNorm1d with LayerNorm\n",
        "            layers.append(nn.ReLU())\n",
        "            layers.append(nn.Dropout(0.2))\n",
        "            input_dim = h\n",
        "        self.mlp = nn.Sequential(*layers)\n",
        "        self.output = nn.Linear(input_dim, 1)\n",
        "\n",
        "    def senet(self, embs):\n",
        "        B, F, D = embs.shape\n",
        "        z = embs.view(B, -1)  # Flatten [B, F*D]\n",
        "        a = self.se_fc1(z)    # Linear\n",
        "        a = self.se_ln1(a)    # LayerNorm instead of BatchNorm\n",
        "        a = F_torch.relu(a)\n",
        "        a = self.se_dropout(a)\n",
        "        s = torch.sigmoid(self.se_fc2(a)).view(B, F, D)\n",
        "        return embs * s\n",
        "\n",
        "    def bilinear_interaction(self, embs):\n",
        "        transformed = self.bilinear(embs)\n",
        "        interaction = (embs * transformed).mean(dim=1)\n",
        "        return interaction\n",
        "\n",
        "    def forward(self, x_cat, x_num):\n",
        "        B, G = x_num.shape[:2]\n",
        "        F, D = self.num_fields, self.emb_dim\n",
        "\n",
        "        # Embeddings [B, G, F, D]\n",
        "        embs = torch.stack([self.embeddings[f](x_cat[f]) for f in self.cat_fields], dim=2)\n",
        "\n",
        "        # Linear output\n",
        "        linear_cat_sum = torch.stack([\n",
        "            self.linear_cat[f](x_cat[f]).squeeze(-1) for f in self.cat_fields\n",
        "        ], dim=0).sum(dim=0)\n",
        "        linear_num_out = self.linear_num(x_num).squeeze(-1)\n",
        "        linear_out = linear_cat_sum + linear_num_out  # [B, G]\n",
        "\n",
        "        # Feature interactions\n",
        "        embs = embs.view(B * G, F, D)\n",
        "        if self.use_senet:\n",
        "            embs = self.senet(embs)\n",
        "        bi = self.bilinear_interaction(embs)  # [B*G, D]\n",
        "\n",
        "        # Deep part\n",
        "        x_num_flat = x_num.view(B * G, -1)\n",
        "        deep_input = torch.cat([bi, x_num_flat], dim=1)\n",
        "        deep_out = self.mlp(deep_input)\n",
        "        scores = self.output(deep_out).view(B, G)\n",
        "\n",
        "        return scores + linear_out  # final output\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "def listmle_loss(scores, labels, lengths):\n",
        "    batch_size = scores.size(0)\n",
        "    total_loss = torch.tensor(0.0, device=scores.device, requires_grad=True)\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "\n",
        "        _, idx = torch.sort(y, descending=True)\n",
        "        s_sorted = s[idx]\n",
        "\n",
        "        parts = (\n",
        "            torch.logsumexp(s_sorted.unsqueeze(0).expand(l, -1).triu(diagonal=0), dim=1)\n",
        "            - s_sorted\n",
        "        )\n",
        "\n",
        "        total_loss = total_loss + parts.sum()\n",
        "\n",
        "    return total_loss / batch_size\n",
        "\"\"\"\n",
        "\n",
        "def hitrate_at_k(scores, labels, lengths, k=3, min_group_size=10):\n",
        "    batch_size = scores.size(0)\n",
        "    hits = 0\n",
        "    valid_count = 0\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        if l < min_group_size:\n",
        "            continue\n",
        "        length = min(l, k)\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "        _, topk_idx = torch.topk(s, length)\n",
        "        topk_labels = y[topk_idx]\n",
        "        hits += (topk_labels > 0).any().float()\n",
        "        valid_count += 1\n",
        "    return hits / valid_count if valid_count > 0 else torch.tensor(0.0, device=scores.device)\n",
        "\n",
        "\n",
        "def ndcg_at_k(scores, labels, lengths, k=3, min_group_size=10):\n",
        "    batch_size = scores.size(0)\n",
        "    total_ndcg = 0.0\n",
        "    valid_count = 0\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        if l < min_group_size:\n",
        "            continue\n",
        "\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "\n",
        "        _, idx_pred = torch.topk(s, min(k, l))\n",
        "        _, idx_ideal = torch.topk(y, min(k, l))\n",
        "\n",
        "        dcg = (y[idx_pred] / torch.log2(torch.arange(2, 2 + len(idx_pred), device=y.device).float())).sum()\n",
        "        idcg = (y[idx_ideal] / torch.log2(torch.arange(2, 2 + len(idx_ideal), device=y.device).float())).sum()\n",
        "\n",
        "        ndcg = dcg / idcg if idcg > 0 else 0.0\n",
        "        total_ndcg += ndcg\n",
        "        valid_count += 1\n",
        "\n",
        "    return total_ndcg / valid_count if valid_count > 0 else torch.tensor(0.0, device=scores.device)\n",
        "\n",
        "\n",
        "def map_at_k(scores, labels, lengths, k=3, min_group_size=10):\n",
        "    batch_size = scores.size(0)\n",
        "    total_ap = 0.0\n",
        "    valid_count = 0\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        if l < min_group_size:\n",
        "            continue\n",
        "\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "\n",
        "        _, idx_pred = torch.topk(s, min(k, l))\n",
        "        y_true = y[idx_pred] > 0\n",
        "\n",
        "        if y_true.sum() == 0:\n",
        "            continue\n",
        "\n",
        "        precisions = [(y_true[:j+1].float().sum() / (j+1)) for j in range(len(y_true)) if y_true[j]]\n",
        "        ap = torch.stack(precisions).mean()\n",
        "        total_ap += ap\n",
        "        valid_count += 1\n",
        "\n",
        "    return total_ap / valid_count if valid_count > 0 else torch.tensor(0.0, device=scores.device)\n",
        "\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "def listnet_loss(scores, labels, lengths):\n",
        "    batch_size = scores.size(0)\n",
        "    total_loss = 0.0\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "\n",
        "        s_softmax = torch.nn.functional.log_softmax(s, dim=0)\n",
        "        y_softmax = torch.nn.functional.softmax(y, dim=0)\n",
        "\n",
        "        loss = -torch.sum(y_softmax * s_softmax)\n",
        "        total_loss += loss\n",
        "\n",
        "    return total_loss / batch_size\n",
        "\"\"\"\n",
        "\n",
        "def ranknet_loss(scores, labels, lengths):\n",
        "    batch_size = scores.size(0)\n",
        "    total_loss = 0.0\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "\n",
        "        diff_scores = s.unsqueeze(1) - s.unsqueeze(0)\n",
        "        rel = y.unsqueeze(1) > y.unsqueeze(0)\n",
        "        label_diff = rel.float()\n",
        "\n",
        "        log_sigmoid = torch.nn.functional.logsigmoid(diff_scores)\n",
        "        pair_loss = -label_diff * log_sigmoid\n",
        "\n",
        "        total_loss += pair_loss.sum()\n",
        "\n",
        "    return total_loss / batch_size\n",
        "\n",
        "def xranknet_loss(scores, labels, lengths, temperature=1.0, margin=0.2, focus_topk=3):\n",
        "    \"\"\"\n",
        "    xRankNet with emphasis on top-K items (based on labels, not scores).\n",
        "    \"\"\"\n",
        "    batch_size = scores.size(0)\n",
        "    total_loss = 0.0\n",
        "    total_pairs = 0\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        if l < 2:\n",
        "            continue\n",
        "\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "\n",
        "        # Top-K mask based on ground truth labels\n",
        "        topk = min(focus_topk, l)\n",
        "        _, topk_idx = torch.topk(y, topk)\n",
        "        topk_mask = torch.zeros_like(y, dtype=torch.bool)\n",
        "        topk_mask[topk_idx] = True\n",
        "\n",
        "        # Create pairwise difference matrices\n",
        "        score_diff = s.unsqueeze(1) - s.unsqueeze(0)\n",
        "        label_diff = y.unsqueeze(1) - y.unsqueeze(0)\n",
        "\n",
        "        # valid pair: y_i > y_j and at least one of i, j is in top-K\n",
        "        valid_pairs = (label_diff > 0) & (\n",
        "            topk_mask.unsqueeze(1) | topk_mask.unsqueeze(0)\n",
        "        )\n",
        "\n",
        "        if valid_pairs.sum() == 0:\n",
        "            continue\n",
        "\n",
        "        importance = (label_diff.abs() * valid_pairs).float()\n",
        "\n",
        "        if margin > 0.0:\n",
        "            score_diff = score_diff - margin\n",
        "\n",
        "        score_diff = score_diff / temperature\n",
        "        pairwise_loss = -F_torch.logsigmoid(score_diff) * importance\n",
        "\n",
        "        total_loss += pairwise_loss.sum()\n",
        "        total_pairs += importance.sum()\n",
        "\n",
        "    if total_pairs == 0:\n",
        "        return torch.tensor(0.0, device=scores.device, requires_grad=True)\n",
        "\n",
        "    return total_loss / total_pairs\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "def bpr_loss(scores, labels, lengths):\n",
        "    batch_size = scores.size(0)\n",
        "    total_loss = 0.0\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "\n",
        "        pos_mask = y > 0\n",
        "        neg_mask = y <= 0\n",
        "\n",
        "        pos_scores = s[pos_mask]\n",
        "        neg_scores = s[neg_mask]\n",
        "\n",
        "        if len(pos_scores) == 0 or len(neg_scores) == 0:\n",
        "            continue\n",
        "\n",
        "        pair_diff = pos_scores.unsqueeze(1) - neg_scores.unsqueeze(0)\n",
        "        loss = -F.logsigmoid(pair_diff).mean()\n",
        "        total_loss += loss\n",
        "\n",
        "    return total_loss / batch_size\n",
        "\"\"\"\n",
        "\n",
        "\"\"\"\n",
        "def lambdarank_loss(scores, labels, lengths, eps=1e-10):\n",
        "    batch_size = scores.size(0)\n",
        "    total_loss = 0.0\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "\n",
        "        if l < 2:\n",
        "            continue\n",
        "\n",
        "        _, rank_order = torch.sort(s, descending=True)\n",
        "        ideal_order = torch.sort(y, descending=True).indices\n",
        "\n",
        "        gain = 2 ** y - 1\n",
        "        discount = torch.log2(torch.arange(2, l + 2, device=y.device).float())\n",
        "\n",
        "        ideal_dcg = (gain[ideal_order] / discount).sum()\n",
        "        if ideal_dcg < eps:\n",
        "            continue\n",
        "\n",
        "        delta_ndcg = torch.zeros((l, l), device=y.device)\n",
        "\n",
        "        for i_idx in range(l):\n",
        "            for j_idx in range(l):\n",
        "                if y[i_idx] > y[j_idx]:\n",
        "                    change = (\n",
        "                        (1.0 / torch.log2(rank_order[i_idx] + 2.0))\n",
        "                        - (1.0 / torch.log2(rank_order[j_idx] + 2.0))\n",
        "                    ).abs()\n",
        "                    delta = (2 ** y[i_idx] - 2 ** y[j_idx]).abs() * change\n",
        "                    delta_ndcg[i_idx, j_idx] = delta / ideal_dcg\n",
        "\n",
        "        score_diffs = s.unsqueeze(1) - s.unsqueeze(0)\n",
        "        lambdas = -F.logsigmoid(score_diffs) * delta_ndcg\n",
        "        total_loss += lambdas.sum()\n",
        "\n",
        "    return total_loss / batch_size\n",
        "\"\"\"\n",
        "\n",
        "def train_one_epoch(model, loader, optimizer, device, scheduler):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "    valid_batches = 0\n",
        "\n",
        "    for batch in tqdm(loader, desc=\"Training\", leave=False):\n",
        "        if batch is None:\n",
        "            continue\n",
        "\n",
        "        x_cat, x_num, y, lengths = batch\n",
        "\n",
        "        x_num, y = x_num.to(device), y.to(device)\n",
        "        lengths = lengths.to(device)\n",
        "        x_cat = {k: v.to(device) for k, v in x_cat.items()}\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        scores = model(x_cat, x_num)\n",
        "        loss = xranknet_loss(scores, y, lengths, temperature=1.0, margin=0.2, focus_topk=3)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        valid_batches += 1\n",
        "\n",
        "    return total_loss / valid_batches if valid_batches > 0 else float(\"inf\")\n",
        "\n",
        "\n",
        "\n",
        "def validate(model, loader, device, min_group_size=10):\n",
        "    model.eval()\n",
        "    total_hitrate = 0\n",
        "    total_ndcg = 0\n",
        "    total_map = 0\n",
        "    total_loss = 0\n",
        "    count = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for x_cat, x_num, y, lengths in tqdm(loader, desc=\"Validating\", leave=False):\n",
        "            x_num, y = x_num.to(device), y.to(device)\n",
        "            lengths = torch.tensor(lengths).to(device)\n",
        "            x_cat = {k: v.to(device) for k, v in x_cat.items()}\n",
        "\n",
        "            scores = model(x_cat, x_num)\n",
        "\n",
        "            hitrate = hitrate_at_k(scores, y, lengths, k=3, min_group_size=min_group_size)\n",
        "            ndcg = ndcg_at_k(scores, y, lengths, k=3, min_group_size=min_group_size)\n",
        "            map3 = map_at_k(scores, y, lengths, k=3, min_group_size=min_group_size)\n",
        "            loss = xranknet_loss(scores, y, lengths, temperature=1.0, margin=0.2, focus_topk=3)\n",
        "\n",
        "            batch_size = scores.size(0)\n",
        "            total_hitrate += hitrate * batch_size\n",
        "            total_ndcg += ndcg * batch_size\n",
        "            total_map += map3 * batch_size\n",
        "            total_loss += loss.item() * batch_size\n",
        "            count += batch_size\n",
        "\n",
        "    return total_loss / count, total_hitrate / count, total_ndcg / count, total_map / count\n",
        "\n",
        "\n",
        "def build_cat_dims(X, cat_features):\n",
        "    cat_dims = {}\n",
        "    for c in cat_features:\n",
        "        max_val = X[c].max()\n",
        "        if max_val < 0:\n",
        "            max_val = 0\n",
        "        cat_dims[c] = max_val + 1\n",
        "    return cat_dims\n",
        "\n",
        "\n",
        "def normalize_numeric_features(X, numeric_features, train_mask):\n",
        "    for col in numeric_features:\n",
        "        values = X[col].to_numpy()\n",
        "        train_vals = values[train_mask]\n",
        "        mean = train_vals.mean()\n",
        "        std = train_vals.std() if train_vals.std() > 0 else 1.0\n",
        "        norm_vals = (values - mean) / std\n",
        "        X = X.with_columns(pl.Series(col, norm_vals).alias(col))\n",
        "    return X\n",
        "\n",
        "def apply_pca(X, numeric_features, train_mask, explained_variance=0.975):\n",
        "    train_data = X[numeric_features].to_numpy()[train_mask]\n",
        "    full_data = X[numeric_features].to_numpy()\n",
        "\n",
        "    pca = PCA(n_components=explained_variance, svd_solver='full')\n",
        "    pca.fit(train_data)\n",
        "    transformed = pca.transform(full_data)\n",
        "\n",
        "    print(f\"üìê PCA: {len(numeric_features)} features ‚Üí {transformed.shape[1]} components (explained variance ‚â• {explained_variance})\")\n",
        "\n",
        "    pca_feature_names = [f'pca_{i}' for i in range(transformed.shape[1])]\n",
        "    X_pca = pl.DataFrame(transformed, schema=pca_feature_names)\n",
        "\n",
        "    X = X.drop(numeric_features)\n",
        "    X = pl.concat([X, X_pca], how=\"horizontal\")\n",
        "\n",
        "    return X, pca_feature_names\n",
        "\n",
        "def load_or_prepare_data(\n",
        "    data_dir,\n",
        "    train_file=\"train.parquet\",\n",
        "    test_file=\"test.parquet\",\n",
        "    cache_file=\"feature_engineered_val.parquet\",\n",
        "):\n",
        "    cache_path = os.path.join(data_dir, cache_file)\n",
        "\n",
        "    if os.path.exists(cache_path):\n",
        "        print(f\"Loading cached feature-engineered data from {cache_path} ...\")\n",
        "        df = pl.read_parquet(cache_path)\n",
        "\n",
        "        test = pl.read_parquet(os.path.join(data_dir, test_file)).drop(\"__index_level_0__\")\n",
        "        test_ids = test[\"Id\"]\n",
        "        test_rankers = test[\"ranker_id\"]\n",
        "    else:\n",
        "        print(\"Cached file not found, processing raw data ...\")\n",
        "\n",
        "        train = pl.read_parquet(os.path.join(data_dir, train_file)).drop(\"__index_level_0__\")\n",
        "        test = (\n",
        "            pl.read_parquet(os.path.join(data_dir, test_file))\n",
        "            .drop(\"__index_level_0__\")\n",
        "            .with_columns(pl.lit(0, dtype=pl.Int64).alias(\"selected\"))\n",
        "        )\n",
        "\n",
        "        test_ids = test[\"Id\"]\n",
        "        test_rankers = test[\"ranker_id\"]\n",
        "\n",
        "        df = pl.concat((train, test))\n",
        "        df = feature_engineering(df, full=True)\n",
        "\n",
        "        df = df.with_columns(\n",
        "            [pl.col(c).fill_null(0) for c in df.select(pl.selectors.numeric()).columns] +\n",
        "            [pl.col(c).fill_null(\"missing\") for c in df.select(pl.selectors.string()).columns]\n",
        "        )\n",
        "\n",
        "        os.makedirs(data_dir, exist_ok=True)\n",
        "        df.write_parquet(cache_path)\n",
        "        print(f\"Saved feature-engineered data to {cache_path}\")\n",
        "\n",
        "    return df, test_ids, test_rankers\n",
        "\n",
        "\n",
        "def prepare_data(data_dir):\n",
        "    df, test_ids, test_rankers = load_or_prepare_data(data_dir)\n",
        "\n",
        "    id_column = df[\"Id\"]\n",
        "    X, y, groups, cat_features, num_features = feature_selection(df)\n",
        "\n",
        "    X = X.with_columns(pl.Series(\"Id\", id_column[:X.shape[0]]))\n",
        "\n",
        "    X = X.with_columns(\n",
        "        [\n",
        "            (pl.col(c).rank(\"dense\") - 1).fill_null(-1).cast(pl.Int32)\n",
        "            for c in cat_features\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    train_size = 18145372\n",
        "    train_mask = np.arange(X.height) < train_size\n",
        "\n",
        "    for col in num_features:\n",
        "        nans = X.select(pl.col(col).is_nan().sum()).item()\n",
        "        if nans > 0:\n",
        "            print(f\"‚ö†Ô∏è Found {nans} NaNs in column '{col}', filling with 0.\")\n",
        "            X = X.with_columns(\n",
        "                pl.when(pl.col(col).is_nan()).then(0).otherwise(pl.col(col)).alias(col)\n",
        "            )\n",
        "\n",
        "    X = normalize_numeric_features(X, num_features, train_mask)\n",
        "    X, pca_features = apply_pca(X, num_features, train_mask, explained_variance=0.98)\n",
        "    num_features = pca_features\n",
        "\n",
        "    return X, y, groups, cat_features, num_features, train_size, test_ids, test_rankers\n",
        "\n",
        "\n",
        "\n",
        "class EarlyStopping:\n",
        "    def __init__(self, patience=3, min_delta=0.00005):\n",
        "        self.patience = patience\n",
        "        self.min_delta = min_delta\n",
        "        self.best = float(\"-inf\")\n",
        "        self.counter = 0\n",
        "\n",
        "    def step(self, metric):\n",
        "        if metric > self.best + self.min_delta:\n",
        "            self.best = metric\n",
        "            self.counter = 0\n",
        "        else:\n",
        "            self.counter += 1\n",
        "        return self.counter >= self.patience\n",
        "\n",
        "\n",
        "def plot_group_size_distribution(dataset, save_path=None):\n",
        "    group_sizes = [len(v) for v in dataset.group_to_indices.values()]\n",
        "    plt.figure()\n",
        "    plt.hist(group_sizes, bins=100, log=True)\n",
        "    plt.xlabel(\"Group size (number of items per ranker_id)\")\n",
        "    plt.ylabel(\"Frequency (log scale)\")\n",
        "    plt.title(\"Distribution of Group Sizes\")\n",
        "    plt.grid(True)\n",
        "    if save_path:\n",
        "        plt.savefig(save_path)\n",
        "    else:\n",
        "        plt.show()\n",
        "    plt.close()\n",
        "\n",
        "\n",
        "def main():\n",
        "    DATA_DIR = \"./data\"\n",
        "    SUBMIT_DIR = \"submission\"\n",
        "    os.makedirs(SUBMIT_DIR, exist_ok=True)\n",
        "\n",
        "    learning_rates_to_try = [1e-3, 7e-4, 5e-4]\n",
        "\n",
        "    for lr in learning_rates_to_try:\n",
        "        run_name = f\"lr_{lr:.0e}\".replace(\"-\", \"\")\n",
        "        MODEL_DIR = f\"model_{run_name}\"\n",
        "        os.makedirs(MODEL_DIR, exist_ok=True)\n",
        "\n",
        "        print(f\"\\n\\nüöÄ Starting training with learning rate = {lr}\\nSaved to: {MODEL_DIR}\")\n",
        "\n",
        "        best_val_loss = float(\"inf\")\n",
        "        best_hitrate = 0.0\n",
        "        model_path = os.path.join(MODEL_DIR, \"best_dl_ranker.pt\")\n",
        "\n",
        "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "        train_losses = []\n",
        "        val_losses = []\n",
        "        val_hitrates = []\n",
        "        val_ndcgs = []\n",
        "        val_maps = []\n",
        "        learning_rates = []\n",
        "\n",
        "        os.makedirs(MODEL_DIR, exist_ok=True)\n",
        "        os.makedirs(SUBMIT_DIR, exist_ok=True)\n",
        "\n",
        "        early_stopper = EarlyStopping(patience=3, min_delta=0.00005)\n",
        "\n",
        "        X, y, groups, cat_features, num_features, train_size, test_ids, test_rankers = prepare_data(DATA_DIR)\n",
        "\n",
        "        # Fill missing values\n",
        "        float_cols = [c for c, t in zip(X.columns, X.dtypes) if t == pl.Float64]\n",
        "        for col in float_cols:\n",
        "            X = X.with_columns(\n",
        "                pl.when(pl.col(col).is_nan()).then(0).otherwise(pl.col(col)).alias(col)\n",
        "            )\n",
        "\n",
        "        n1 = 16487352\n",
        "        # n1 = 17487300\n",
        "        n2 = train_size\n",
        "\n",
        "        X_tr, X_va, X_te = X[:n1], X[n1:n2], X[n2:]\n",
        "        y_tr, y_va, y_te = y[:n1], y[n1:n2], y[n2:]\n",
        "        groups_tr, groups_va, groups_te = groups[:n1], groups[n1:n2], groups[n2:]\n",
        "\n",
        "        # Inspect group sizes in validation set\n",
        "        val_rankers = groups_va[\"ranker_id\"].to_numpy()\n",
        "        val_group_counts = Counter(val_rankers)\n",
        "\n",
        "        print(\"\\nüìã Validation group statistics:\")\n",
        "        # Save detailed group info to file\n",
        "        group_info_path = os.path.join(MODEL_DIR, \"validation_groups_info.txt\")\n",
        "        with open(group_info_path, \"w\") as f:\n",
        "            f.write(f\"Total groups: {len(val_group_counts)}\\n\\n\")\n",
        "            f.write(\"GroupID\\tSize\\tStartIdx\\tEndIdx\\n\")\n",
        "\n",
        "            group_to_rows = defaultdict(list)\n",
        "            for i, g in enumerate(val_rankers):\n",
        "                group_to_rows[g].append(i)\n",
        "\n",
        "            for group_id, indices in sorted(group_to_rows.items()):\n",
        "                start_idx = indices[0]\n",
        "                end_idx = indices[-1]\n",
        "                size = len(indices)\n",
        "                f.write(f\"{group_id}\\t{size}\\t{start_idx}\\t{end_idx}\\n\")\n",
        "\n",
        "        print(f\"üìÅ Saved validation group info to {group_info_path}\")\n",
        "\n",
        "\n",
        "        cat_dims = build_cat_dims(X, cat_features)\n",
        "        num_numeric_feats = len(num_features)\n",
        "\n",
        "        train_dataset = RankDataset(X_tr, y_tr, groups_tr, cat_features, num_features)\n",
        "        val_dataset = RankDataset(X_va, y_va, groups_va, cat_features, num_features)\n",
        "        test_dataset = RankDataset(X_te, y_te, groups_te, cat_features, num_features)\n",
        "\n",
        "        plot_group_size_distribution(train_dataset, save_path=os.path.join(MODEL_DIR, \"group_sizes.png\"))\n",
        "        print(\"üìä Group size distribution saved.\")\n",
        "\n",
        "        train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True, collate_fn=collate_fn)\n",
        "        val_loader = DataLoader(val_dataset, batch_size=4, shuffle=False, collate_fn=collate_fn)\n",
        "        test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False, collate_fn=collate_fn)\n",
        "\n",
        "        print(\"‚úÖ Data loaders created.\")\n",
        "\n",
        "        num_epochs = 10\n",
        "        num_training_steps = num_epochs * len(train_loader)\n",
        "        num_warmup_steps = int(0.1 * num_training_steps)\n",
        "\n",
        "        model = FiBiDLRanker(\n",
        "            cat_dims=cat_dims,\n",
        "            num_numeric_feats=num_numeric_feats,\n",
        "            emb_dim=32,\n",
        "            hidden=[512, 256, 128, 64]\n",
        "        ).to(device)\n",
        "\n",
        "        optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=0.01)\n",
        "\n",
        "        scheduler = get_scheduler(\n",
        "            \"linear\",\n",
        "            optimizer=optimizer,\n",
        "            num_warmup_steps=num_warmup_steps,\n",
        "            num_training_steps=num_training_steps\n",
        "        )\n",
        "\n",
        "        best_hitrate = 0\n",
        "        for epoch in range(num_epochs):\n",
        "            print(f\"\\n--- Epoch {epoch+1}/{num_epochs} ---\")\n",
        "            start_time = time.time()\n",
        "\n",
        "            train_loss = train_one_epoch(model, train_loader, optimizer, device, scheduler)\n",
        "            val_loss, val_hitrate, val_ndcg, val_map = validate(model, val_loader, device, min_group_size=10)\n",
        "\n",
        "            train_losses.append(train_loss)\n",
        "            val_losses.append(val_loss)\n",
        "            val_hitrates.append(val_hitrate.item())\n",
        "            val_ndcgs.append(val_ndcg.item())\n",
        "            val_maps.append(val_map.item())\n",
        "\n",
        "            current_lr = scheduler.get_last_lr()\n",
        "            learning_rates.append(current_lr[0])\n",
        "\n",
        "            elapsed = time.time() - start_time\n",
        "            print(\n",
        "                f\"Epoch {epoch+1}: \"\n",
        "                f\"Train Loss={train_loss:.4f}, \"\n",
        "                f\"Val Loss={val_loss:.4f}, \"\n",
        "                f\"HitRate@3={val_hitrate:.4f}, \"\n",
        "                f\"NDCG@3={val_ndcg:.4f}, \"\n",
        "                f\"MAP@3={val_map:.4f}, \"\n",
        "                f\"LR={current_lr[0]:.6f} \"\n",
        "                f\"({elapsed:.1f}s)\"\n",
        "            )\n",
        "\n",
        "\n",
        "            if val_loss < best_val_loss and val_hitrate > best_hitrate:\n",
        "                best_val_loss = val_loss\n",
        "                best_hitrate = val_hitrate\n",
        "                torch.save(model.state_dict(), model_path)\n",
        "                print(\"üíæ Model improved (loss ‚Üì and hitrate ‚Üë), saved.\")\n",
        "\n",
        "            if early_stopper.step(-val_loss):\n",
        "                print(\"‚õî Early stopping triggered.\")\n",
        "                break\n",
        "\n",
        "        # Plot metrics\n",
        "        epochs = list(range(1, len(train_losses) + 1))\n",
        "\n",
        "        # Plot Loss Curve\n",
        "        plt.figure()\n",
        "        plt.plot(epochs, train_losses, label=\"Train Loss\")\n",
        "        plt.plot(epochs, val_losses, label=\"Val Loss\")\n",
        "        plt.xlabel(\"Epoch\")\n",
        "        plt.ylabel(\"Loss\")\n",
        "        plt.title(\"Training & Validation Loss\")\n",
        "        plt.legend()\n",
        "        plt.grid(True)\n",
        "        plt.savefig(os.path.join(MODEL_DIR, \"loss_curve.png\"))\n",
        "        plt.close()\n",
        "\n",
        "        # Plot HitRate@3\n",
        "        plt.figure()\n",
        "        plt.plot(epochs, val_hitrates, label=\"Val HitRate@3\", color=\"green\")\n",
        "        plt.xlabel(\"Epoch\")\n",
        "        plt.ylabel(\"HitRate@3\")\n",
        "        plt.title(\"Validation HitRate@3\")\n",
        "        plt.legend()\n",
        "        plt.grid(True)\n",
        "        plt.savefig(os.path.join(MODEL_DIR, \"hitrate_curve.png\"))\n",
        "        plt.close()\n",
        "\n",
        "        # Plot Learning Rate\n",
        "        plt.figure()\n",
        "        plt.plot(epochs, learning_rates, label=\"Learning Rate\", color=\"orange\")\n",
        "        plt.xlabel(\"Epoch\")\n",
        "        plt.ylabel(\"LR\")\n",
        "        plt.title(\"Learning Rate Schedule\")\n",
        "        plt.legend()\n",
        "        plt.grid(True)\n",
        "        plt.savefig(os.path.join(MODEL_DIR, \"lr_curve.png\"))\n",
        "        plt.close()\n",
        "\n",
        "        # Plot NDCG@3\n",
        "        plt.figure()\n",
        "        plt.plot(epochs, val_ndcgs, label=\"Val NDCG@3\", color=\"purple\")\n",
        "        plt.xlabel(\"Epoch\")\n",
        "        plt.ylabel(\"NDCG@3\")\n",
        "        plt.title(\"Validation NDCG@3\")\n",
        "        plt.legend()\n",
        "        plt.grid(True)\n",
        "        plt.savefig(os.path.join(MODEL_DIR, \"ndcg_curve.png\"))\n",
        "        plt.close()\n",
        "\n",
        "        # Plot MAP@3\n",
        "        plt.figure()\n",
        "        plt.plot(epochs, val_maps, label=\"Val MAP@3\", color=\"red\")\n",
        "        plt.xlabel(\"Epoch\")\n",
        "        plt.ylabel(\"MAP@3\")\n",
        "        plt.title(\"Validation MAP@3\")\n",
        "        plt.legend()\n",
        "        plt.grid(True)\n",
        "        plt.savefig(os.path.join(MODEL_DIR, \"map_curve.png\"))\n",
        "        plt.close()\n",
        "\n",
        "        print(\"üìä Saved metric plots to model/\")\n",
        "\n",
        "        # Predict test set\n",
        "        model.load_state_dict(torch.load(model_path))\n",
        "        model.eval()\n",
        "\n",
        "        val_ids = X_va[\"Id\"]\n",
        "        val_rankers = groups_va[\"ranker_id\"]\n",
        "        val_labels = y_va\n",
        "\n",
        "        all_val_scores = []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for x_cat, x_num, _, lengths in tqdm(val_loader, desc=\"Predicting validation set\"):\n",
        "                x_num = x_num.to(device)\n",
        "                x_cat = {k: v.to(device) for k, v in x_cat.items()}\n",
        "                scores = model(x_cat, x_num)\n",
        "\n",
        "                for i in range(scores.size(0)):\n",
        "                    l = lengths[i]\n",
        "                    all_val_scores.append(scores[i, :l].cpu().numpy())\n",
        "\n",
        "        all_val_scores = np.concatenate(all_val_scores)\n",
        "\n",
        "        assert len(all_val_scores) == X_va.shape[0], \\\n",
        "            f\"Mismatch: {len(all_val_scores)} scores vs {X_va.shape[0]} rows\"\n",
        "\n",
        "        val_df = X_va.with_columns([\n",
        "            pl.Series(\"Id\", val_ids),\n",
        "            pl.Series(\"ranker_id\", val_rankers),\n",
        "            pl.Series(\"score\", all_val_scores),\n",
        "            pl.Series(\"label\", val_labels)\n",
        "        ])\n",
        "\n",
        "        val_df = val_df.with_columns(\n",
        "            pl.col(\"score\")\n",
        "            .rank(method=\"ordinal\", descending=True)\n",
        "            .over(\"ranker_id\")\n",
        "            .cast(pl.Int32)\n",
        "            .alias(\"selected\")\n",
        "        )\n",
        "\n",
        "        val_save_path = os.path.join(MODEL_DIR, \"validation_preds_dl_full.csv\")\n",
        "        val_df.write_csv(val_save_path)\n",
        "        print(f\"‚úÖ Saved full validation predictions (with features) to {val_save_path}\")\n",
        "\n",
        "        all_scores = []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for x_cat, x_num, _, lengths in tqdm(test_loader, desc=\"Predicting test set\"):\n",
        "                x_num = x_num.to(device)\n",
        "                x_cat = {k: v.to(device) for k, v in x_cat.items()}\n",
        "                scores = model(x_cat, x_num)\n",
        "\n",
        "                for i in range(scores.size(0)):\n",
        "                    l = lengths[i]\n",
        "                    all_scores.append(scores[i, :l].cpu().numpy())\n",
        "\n",
        "        all_scores = np.concatenate(all_scores)\n",
        "\n",
        "        assert len(all_scores) == X_te.shape[0], \\\n",
        "            f\"Mismatch: {len(all_scores)} scores vs {X_te.shape[0]} rows in X_te\"\n",
        "\n",
        "        submission_df = pl.DataFrame({\n",
        "            \"Id\": test_ids,\n",
        "            \"ranker_id\": test_rankers,\n",
        "            \"score\": all_scores\n",
        "        })\n",
        "\n",
        "        submission = (\n",
        "            submission_df\n",
        "            .with_columns(\n",
        "                pl.col(\"score\")\n",
        "                .rank(method=\"ordinal\", descending=True)\n",
        "                .over(\"ranker_id\")\n",
        "                .cast(pl.Int32)\n",
        "                .alias(\"selected\")\n",
        "            )\n",
        "            .select([\"Id\", \"ranker_id\", \"score\", \"selected\"])\n",
        "        )\n",
        "\n",
        "        submission_path = os.path.join(SUBMIT_DIR, \"submission_dl_ranker.csv\")\n",
        "        submission.write_csv(submission_path)\n",
        "        print(f\"‚úÖ Submission saved to {submission_path}\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Js4LUdtCvq5",
        "outputId": "0a61138f-fe76-4516-b4e4-05c99cae2cbd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting deeprec_validate.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Legs0/Legs1 Separation**"
      ],
      "metadata": {
        "id": "gQZSry9zgVBz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile deeprec_validate.py\n",
        "import os\n",
        "import time\n",
        "import random\n",
        "import torch\n",
        "import math\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import defaultdict\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "import polars as pl\n",
        "from tqdm import tqdm\n",
        "from src.feature import feature_engineering, feature_selection\n",
        "from transformers import get_scheduler\n",
        "from collections import Counter\n",
        "\n",
        "SEED = 42\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed(SEED)\n",
        "torch.cuda.manual_seed_all(SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "\n",
        "class RankDataset(Dataset):\n",
        "    def __init__(\n",
        "        self,\n",
        "        X: pl.DataFrame,\n",
        "        y: pl.Series,\n",
        "        groups: pl.DataFrame,\n",
        "        cat_features: list[str],\n",
        "        num_features: list[str],\n",
        "    ):\n",
        "        self.cat_features = cat_features\n",
        "        self.num_features = num_features\n",
        "        self.X_cat = {c: X[c].to_numpy() for c in cat_features}\n",
        "        self.X_num = X[self.num_features].to_numpy()\n",
        "        self.y = y.to_numpy()\n",
        "        self.groups = groups[\"ranker_id\"].to_numpy()\n",
        "\n",
        "        self.group_to_indices = defaultdict(list)\n",
        "        for i, g in enumerate(self.groups):\n",
        "            self.group_to_indices[g].append(i)\n",
        "        self.group_keys = list(self.group_to_indices.keys())\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.group_keys)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        g = self.group_keys[idx]\n",
        "        inds = self.group_to_indices[g]\n",
        "        length = len(inds)\n",
        "\n",
        "        x_cat = {\n",
        "            c: torch.LongTensor([\n",
        "                self.X_cat[c][i] if self.X_cat[c][i] >= 0 else 0 for i in inds\n",
        "            ])\n",
        "            for c in self.cat_features\n",
        "        }\n",
        "\n",
        "        x_num = torch.FloatTensor(self.X_num[inds])\n",
        "        y = torch.FloatTensor(self.y[inds]).reshape(-1)\n",
        "\n",
        "        return x_cat, x_num, y, length\n",
        "\n",
        "def collate_fn(batch):\n",
        "    batch_size = len(batch)\n",
        "    lengths = [b[3] for b in batch]\n",
        "    max_len = max(lengths)\n",
        "\n",
        "    padded_x_cat = {key: [] for key in batch[0][0].keys()}\n",
        "    padded_x_num = []\n",
        "    padded_y = []\n",
        "\n",
        "    num_dim = batch[0][1].shape[1]\n",
        "\n",
        "    for x_cat, x_num, y, length in batch:\n",
        "        pad_len = max_len - length\n",
        "\n",
        "        for key in padded_x_cat:\n",
        "            val = x_cat[key]\n",
        "            if pad_len > 0:\n",
        "                val = torch.cat([val, torch.zeros(pad_len, dtype=torch.long)])\n",
        "            padded_x_cat[key].append(val)\n",
        "\n",
        "        if pad_len > 0:\n",
        "            x_num = torch.cat([x_num, torch.zeros(pad_len, num_dim)])\n",
        "            y = torch.cat([y, torch.zeros(pad_len)])\n",
        "\n",
        "        padded_x_num.append(x_num)\n",
        "        padded_y.append(y)\n",
        "\n",
        "    padded_x_cat = {k: torch.stack(v) for k, v in padded_x_cat.items()}\n",
        "    padded_x_num = torch.stack(padded_x_num)\n",
        "    padded_y = torch.stack(padded_y)\n",
        "    lengths = torch.tensor(lengths, dtype=torch.long)\n",
        "\n",
        "    return padded_x_cat, padded_x_num, padded_y, lengths\n",
        "\n",
        "class DLRanker(nn.Module):\n",
        "    def __init__(self, cat_dims, num_numeric_feats, emb_dim=64, hidden=[512, 256, 128, 64]):\n",
        "        super().__init__()\n",
        "\n",
        "        self.embeddings = nn.ModuleDict({\n",
        "            f: nn.Embedding(cat_dims[f], emb_dim, padding_idx=0) for f in cat_dims\n",
        "        })\n",
        "        self.linear_cat = nn.ModuleDict({\n",
        "            f: nn.Embedding(cat_dims[f], 1, padding_idx=0) for f in cat_dims\n",
        "        })\n",
        "\n",
        "        for emb in list(self.embeddings.values()) + list(self.linear_cat.values()):\n",
        "            nn.init.xavier_uniform_(emb.weight)\n",
        "\n",
        "        self.linear_num = nn.Linear(num_numeric_feats, 1)\n",
        "        nn.init.xavier_uniform_(self.linear_num.weight)\n",
        "\n",
        "        input_dim = emb_dim * len(cat_dims) + num_numeric_feats\n",
        "        layers = []\n",
        "        for h in hidden:\n",
        "            layers.append(nn.Linear(input_dim, h))\n",
        "            layers.append(nn.BatchNorm1d(h))\n",
        "            layers.append(nn.ReLU())\n",
        "            layers.append(nn.Dropout(0.1))\n",
        "            input_dim = h\n",
        "        self.mlp = nn.Sequential(*layers)\n",
        "        self.output = nn.Linear(input_dim, 1)\n",
        "\n",
        "    def forward(self, x_cat, x_num):\n",
        "        batch_size, group_size = x_num.shape[:2]\n",
        "\n",
        "        linear_cat_sum = torch.stack([\n",
        "            self.linear_cat[f](x_cat[f]).squeeze(-1)\n",
        "            for f in self.linear_cat\n",
        "        ], dim=0).sum(dim=0)\n",
        "\n",
        "        linear_num_out = self.linear_num(x_num).squeeze(-1)\n",
        "        linear_out = linear_cat_sum + linear_num_out\n",
        "\n",
        "        embs = torch.stack([\n",
        "            self.embeddings[f](x_cat[f]) for f in self.embeddings\n",
        "        ], dim=2)\n",
        "\n",
        "        sum_emb = embs.sum(dim=2)\n",
        "        sum_emb_square = sum_emb ** 2\n",
        "        square_emb_sum = (embs ** 2).sum(dim=2)\n",
        "        fm_out = 0.0\n",
        "        # fm_out = 0.5 * (sum_emb_square - square_emb_sum).sum(dim=2)\n",
        "\n",
        "        embs_cat = embs.reshape(batch_size * group_size, -1)\n",
        "        x_num_flat = x_num.reshape(batch_size * group_size, -1)\n",
        "        deep_input = torch.cat([embs_cat, x_num_flat], dim=1)\n",
        "        deep_out = self.mlp(deep_input)\n",
        "        deep_out = self.output(deep_out).view(batch_size, group_size)\n",
        "\n",
        "        return linear_out + fm_out + deep_out\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "def listmle_loss(scores, labels, lengths):\n",
        "    batch_size = scores.size(0)\n",
        "    total_loss = torch.tensor(0.0, device=scores.device, requires_grad=True)\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "\n",
        "        _, idx = torch.sort(y, descending=True)\n",
        "        s_sorted = s[idx]\n",
        "\n",
        "        parts = (\n",
        "            torch.logsumexp(s_sorted.unsqueeze(0).expand(l, -1).triu(diagonal=0), dim=1)\n",
        "            - s_sorted\n",
        "        )\n",
        "\n",
        "        total_loss = total_loss + parts.sum()\n",
        "\n",
        "    return total_loss / batch_size\n",
        "\"\"\"\n",
        "\n",
        "def hitrate_at_k(scores, labels, lengths, k=3, min_group_size=10):\n",
        "    batch_size = scores.size(0)\n",
        "    hits = 0\n",
        "    valid_count = 0\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        if l < min_group_size:\n",
        "            continue\n",
        "        length = min(l, k)\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "        _, topk_idx = torch.topk(s, length)\n",
        "        topk_labels = y[topk_idx]\n",
        "        hits += (topk_labels > 0).any().float()\n",
        "        valid_count += 1\n",
        "    return hits / valid_count if valid_count > 0 else torch.tensor(0.0, device=scores.device)\n",
        "\n",
        "\n",
        "def ndcg_at_k(scores, labels, lengths, k=3, min_group_size=10):\n",
        "    batch_size = scores.size(0)\n",
        "    total_ndcg = 0.0\n",
        "    valid_count = 0\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        if l < min_group_size:\n",
        "            continue\n",
        "\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "\n",
        "        _, idx_pred = torch.topk(s, min(k, l))\n",
        "        _, idx_ideal = torch.topk(y, min(k, l))\n",
        "\n",
        "        dcg = (y[idx_pred] / torch.log2(torch.arange(2, 2 + len(idx_pred), device=y.device).float())).sum()\n",
        "        idcg = (y[idx_ideal] / torch.log2(torch.arange(2, 2 + len(idx_ideal), device=y.device).float())).sum()\n",
        "\n",
        "        ndcg = dcg / idcg if idcg > 0 else 0.0\n",
        "        total_ndcg += ndcg\n",
        "        valid_count += 1\n",
        "\n",
        "    return total_ndcg / valid_count if valid_count > 0 else torch.tensor(0.0, device=scores.device)\n",
        "\n",
        "\n",
        "def map_at_k(scores, labels, lengths, k=3, min_group_size=10):\n",
        "    batch_size = scores.size(0)\n",
        "    total_ap = 0.0\n",
        "    valid_count = 0\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        if l < min_group_size:\n",
        "            continue\n",
        "\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "\n",
        "        _, idx_pred = torch.topk(s, min(k, l))\n",
        "        y_true = y[idx_pred] > 0\n",
        "\n",
        "        if y_true.sum() == 0:\n",
        "            continue\n",
        "\n",
        "        precisions = [(y_true[:j+1].float().sum() / (j+1)) for j in range(len(y_true)) if y_true[j]]\n",
        "        ap = torch.stack(precisions).mean()\n",
        "        total_ap += ap\n",
        "        valid_count += 1\n",
        "\n",
        "    return total_ap / valid_count if valid_count > 0 else torch.tensor(0.0, device=scores.device)\n",
        "\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "def listnet_loss(scores, labels, lengths):\n",
        "    batch_size = scores.size(0)\n",
        "    total_loss = 0.0\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "\n",
        "        s_softmax = torch.nn.functional.log_softmax(s, dim=0)\n",
        "        y_softmax = torch.nn.functional.softmax(y, dim=0)\n",
        "\n",
        "        loss = -torch.sum(y_softmax * s_softmax)\n",
        "        total_loss += loss\n",
        "\n",
        "    return total_loss / batch_size\n",
        "\"\"\"\n",
        "\n",
        "def ranknet_loss(scores, labels, lengths):\n",
        "    batch_size = scores.size(0)\n",
        "    total_loss = 0.0\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "\n",
        "        diff_scores = s.unsqueeze(1) - s.unsqueeze(0)\n",
        "        rel = y.unsqueeze(1) > y.unsqueeze(0)\n",
        "        label_diff = rel.float()\n",
        "\n",
        "        log_sigmoid = torch.nn.functional.logsigmoid(diff_scores)\n",
        "        pair_loss = -label_diff * log_sigmoid\n",
        "\n",
        "        total_loss += pair_loss.sum()\n",
        "\n",
        "    return total_loss / batch_size\n",
        "\n",
        "def xranknet_loss(scores, labels, lengths, temperature=1.0, margin=0.2, focus_topk=3):\n",
        "    \"\"\"\n",
        "    xRankNet with emphasis on top-K items (based on labels, not scores).\n",
        "    \"\"\"\n",
        "    batch_size = scores.size(0)\n",
        "    total_loss = 0.0\n",
        "    total_pairs = 0\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        if l < 2:\n",
        "            continue\n",
        "\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "\n",
        "        # Top-K mask based on ground truth labels\n",
        "        topk = min(focus_topk, l)\n",
        "        _, topk_idx = torch.topk(y, topk)\n",
        "        topk_mask = torch.zeros_like(y, dtype=torch.bool)\n",
        "        topk_mask[topk_idx] = True\n",
        "\n",
        "        # Create pairwise difference matrices\n",
        "        score_diff = s.unsqueeze(1) - s.unsqueeze(0)\n",
        "        label_diff = y.unsqueeze(1) - y.unsqueeze(0)\n",
        "\n",
        "        # valid pair: y_i > y_j and at least one of i, j is in top-K\n",
        "        valid_pairs = (label_diff > 0) & (\n",
        "            topk_mask.unsqueeze(1) | topk_mask.unsqueeze(0)\n",
        "        )\n",
        "\n",
        "        if valid_pairs.sum() == 0:\n",
        "            continue\n",
        "\n",
        "        importance = (label_diff.abs() * valid_pairs).float()\n",
        "\n",
        "        if margin > 0.0:\n",
        "            score_diff = score_diff - margin\n",
        "\n",
        "        score_diff = score_diff / temperature\n",
        "        pairwise_loss = -F.logsigmoid(score_diff) * importance\n",
        "\n",
        "        total_loss += pairwise_loss.sum()\n",
        "        total_pairs += importance.sum()\n",
        "\n",
        "    if total_pairs == 0:\n",
        "        return torch.tensor(0.0, device=scores.device, requires_grad=True)\n",
        "\n",
        "    return total_loss / total_pairs\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "def bpr_loss(scores, labels, lengths):\n",
        "    batch_size = scores.size(0)\n",
        "    total_loss = 0.0\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "\n",
        "        pos_mask = y > 0\n",
        "        neg_mask = y <= 0\n",
        "\n",
        "        pos_scores = s[pos_mask]\n",
        "        neg_scores = s[neg_mask]\n",
        "\n",
        "        if len(pos_scores) == 0 or len(neg_scores) == 0:\n",
        "            continue\n",
        "\n",
        "        pair_diff = pos_scores.unsqueeze(1) - neg_scores.unsqueeze(0)\n",
        "        loss = -F.logsigmoid(pair_diff).mean()\n",
        "        total_loss += loss\n",
        "\n",
        "    return total_loss / batch_size\n",
        "\"\"\"\n",
        "\n",
        "\"\"\"\n",
        "def lambdarank_loss(scores, labels, lengths, eps=1e-10):\n",
        "    batch_size = scores.size(0)\n",
        "    total_loss = 0.0\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        l = lengths[i]\n",
        "        s = scores[i][:l]\n",
        "        y = labels[i][:l]\n",
        "\n",
        "        if l < 2:\n",
        "            continue\n",
        "\n",
        "        _, rank_order = torch.sort(s, descending=True)\n",
        "        ideal_order = torch.sort(y, descending=True).indices\n",
        "\n",
        "        gain = 2 ** y - 1\n",
        "        discount = torch.log2(torch.arange(2, l + 2, device=y.device).float())\n",
        "\n",
        "        ideal_dcg = (gain[ideal_order] / discount).sum()\n",
        "        if ideal_dcg < eps:\n",
        "            continue\n",
        "\n",
        "        delta_ndcg = torch.zeros((l, l), device=y.device)\n",
        "\n",
        "        for i_idx in range(l):\n",
        "            for j_idx in range(l):\n",
        "                if y[i_idx] > y[j_idx]:\n",
        "                    change = (\n",
        "                        (1.0 / torch.log2(rank_order[i_idx] + 2.0))\n",
        "                        - (1.0 / torch.log2(rank_order[j_idx] + 2.0))\n",
        "                    ).abs()\n",
        "                    delta = (2 ** y[i_idx] - 2 ** y[j_idx]).abs() * change\n",
        "                    delta_ndcg[i_idx, j_idx] = delta / ideal_dcg\n",
        "\n",
        "        score_diffs = s.unsqueeze(1) - s.unsqueeze(0)\n",
        "        lambdas = -F.logsigmoid(score_diffs) * delta_ndcg\n",
        "        total_loss += lambdas.sum()\n",
        "\n",
        "    return total_loss / batch_size\n",
        "\"\"\"\n",
        "\n",
        "def train_one_epoch(model, loader, optimizer, device, scheduler):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "\n",
        "    for x_cat, x_num, y, lengths in tqdm(loader, desc=\"Training\", leave=False):\n",
        "        x_num, y = x_num.to(device), y.to(device)\n",
        "        if not isinstance(lengths, torch.Tensor):\n",
        "            lengths = torch.tensor(lengths)\n",
        "        lengths = lengths.detach().clone().to(device)\n",
        "        x_cat = {k: v.to(device) for k, v in x_cat.items()}\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        scores = model(x_cat, x_num)\n",
        "        loss = xranknet_loss(scores, y, lengths, temperature=1.0, margin=0.0, focus_topk=3)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    return total_loss / len(loader)\n",
        "\n",
        "\n",
        "def validate(model, loader, device, min_group_size=10):\n",
        "    model.eval()\n",
        "    total_hitrate = 0\n",
        "    total_ndcg = 0\n",
        "    total_map = 0\n",
        "    total_loss = 0\n",
        "    count = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for x_cat, x_num, y, lengths in tqdm(loader, desc=\"Validating\", leave=False):\n",
        "            x_num, y = x_num.to(device), y.to(device)\n",
        "            lengths = torch.tensor(lengths).to(device)\n",
        "            x_cat = {k: v.to(device) for k, v in x_cat.items()}\n",
        "\n",
        "            scores = model(x_cat, x_num)\n",
        "\n",
        "            hitrate = hitrate_at_k(scores, y, lengths, k=3, min_group_size=min_group_size)\n",
        "            ndcg = ndcg_at_k(scores, y, lengths, k=3, min_group_size=min_group_size)\n",
        "            map3 = map_at_k(scores, y, lengths, k=3, min_group_size=min_group_size)\n",
        "            loss = xranknet_loss(scores, y, lengths, temperature=1.0, margin=0.0, focus_topk=3)\n",
        "\n",
        "            batch_size = scores.size(0)\n",
        "            total_hitrate += hitrate * batch_size\n",
        "            total_ndcg += ndcg * batch_size\n",
        "            total_map += map3 * batch_size\n",
        "            total_loss += loss.item() * batch_size\n",
        "            count += batch_size\n",
        "\n",
        "    return total_loss / count, total_hitrate / count, total_ndcg / count, total_map / count\n",
        "\n",
        "\n",
        "def build_cat_dims(X, cat_features):\n",
        "    cat_dims = {}\n",
        "    for c in cat_features:\n",
        "        max_val = X[c].max()\n",
        "        if max_val < 0:\n",
        "            max_val = 0\n",
        "        cat_dims[c] = max_val + 1\n",
        "    return cat_dims\n",
        "\n",
        "\n",
        "def normalize_numeric_features(X, numeric_features, train_mask):\n",
        "    for col in numeric_features:\n",
        "        values = X[col].to_numpy()\n",
        "        train_vals = values[train_mask]\n",
        "        mean = train_vals.mean()\n",
        "        std = train_vals.std() if train_vals.std() > 0 else 1.0\n",
        "        norm_vals = (values - mean) / std\n",
        "        X = X.with_columns(pl.Series(col, norm_vals).alias(col))\n",
        "    return X\n",
        "\n",
        "\n",
        "def load_or_prepare_data(\n",
        "    data_dir,\n",
        "    train_file=\"train.parquet\",\n",
        "    test_file=\"test.parquet\",\n",
        "    cache_file=\"feature_engineered_val.parquet\",\n",
        "):\n",
        "    cache_path = os.path.join(data_dir, cache_file)\n",
        "\n",
        "    if os.path.exists(cache_path):\n",
        "        print(f\"Loading cached feature-engineered data from {cache_path} ...\")\n",
        "        df = pl.read_parquet(cache_path)\n",
        "\n",
        "        test = pl.read_parquet(os.path.join(data_dir, test_file)).drop(\"__index_level_0__\")\n",
        "        test_ids = test[\"Id\"]\n",
        "        test_rankers = test[\"ranker_id\"]\n",
        "    else:\n",
        "        print(\"Cached file not found, processing raw data ...\")\n",
        "\n",
        "        train = pl.read_parquet(os.path.join(data_dir, train_file)).drop(\"__index_level_0__\")\n",
        "        test = (\n",
        "            pl.read_parquet(os.path.join(data_dir, test_file))\n",
        "            .drop(\"__index_level_0__\")\n",
        "            .with_columns(pl.lit(0, dtype=pl.Int64).alias(\"selected\"))\n",
        "        )\n",
        "\n",
        "        test_ids = test[\"Id\"]\n",
        "        test_rankers = test[\"ranker_id\"]\n",
        "\n",
        "        df = pl.concat((train, test))\n",
        "        df = feature_engineering(df, full=True)\n",
        "\n",
        "        df = df.with_columns(\n",
        "            [pl.col(c).fill_null(0) for c in df.select(pl.selectors.numeric()).columns] +\n",
        "            [pl.col(c).fill_null(\"missing\") for c in df.select(pl.selectors.string()).columns]\n",
        "        )\n",
        "\n",
        "        os.makedirs(data_dir, exist_ok=True)\n",
        "        df.write_parquet(cache_path)\n",
        "        print(f\"Saved feature-engineered data to {cache_path}\")\n",
        "\n",
        "    return df, test_ids, test_rankers\n",
        "\n",
        "\n",
        "def prepare_data(data_dir):\n",
        "    df, test_ids, test_rankers = load_or_prepare_data(data_dir)\n",
        "\n",
        "    id_column = df[\"Id\"]\n",
        "    X, y, groups, cat_features, num_features = feature_selection(df)\n",
        "\n",
        "    X = X.with_columns(pl.Series(\"Id\", id_column[:X.shape[0]]))\n",
        "\n",
        "    X = X.with_columns(\n",
        "        [\n",
        "            (pl.col(c).rank(\"dense\") - 1).fill_null(-1).cast(pl.Int32)\n",
        "            for c in cat_features\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    train_size = 18145372\n",
        "    train_mask = np.arange(X.height) < train_size\n",
        "    X = normalize_numeric_features(X, num_features, train_mask)\n",
        "\n",
        "    return X, y, groups, cat_features, num_features, train_size, test_ids, test_rankers\n",
        "\n",
        "\n",
        "class EarlyStopping:\n",
        "    def __init__(self, patience=3, min_delta=0.00005):\n",
        "        self.patience = patience\n",
        "        self.min_delta = min_delta\n",
        "        self.best = float(\"-inf\")\n",
        "        self.counter = 0\n",
        "\n",
        "    def step(self, metric):\n",
        "        if metric > self.best + self.min_delta:\n",
        "            self.best = metric\n",
        "            self.counter = 0\n",
        "        else:\n",
        "            self.counter += 1\n",
        "        return self.counter >= self.patience\n",
        "\n",
        "\n",
        "def plot_group_size_distribution(dataset, save_path=None):\n",
        "    group_sizes = [len(v) for v in dataset.group_to_indices.values()]\n",
        "    plt.figure()\n",
        "    plt.hist(group_sizes, bins=100, log=True)\n",
        "    plt.xlabel(\"Group size (number of items per ranker_id)\")\n",
        "    plt.ylabel(\"Frequency (log scale)\")\n",
        "    plt.title(\"Distribution of Group Sizes\")\n",
        "    plt.grid(True)\n",
        "    if save_path:\n",
        "        plt.savefig(save_path)\n",
        "    else:\n",
        "        plt.show()\n",
        "    plt.close()\n",
        "\n",
        "def split_by_is_one_way(\n",
        "    X: pl.DataFrame, y: pl.Series, groups: pl.DataFrame, value: int\n",
        ") -> tuple[pl.DataFrame, pl.Series, pl.DataFrame]:\n",
        "    \"\"\"\n",
        "    Returns (X_sub, y_sub, groups_sub) where is_one_way == value (0 or 1).\n",
        "    \"\"\"\n",
        "    mask = (X[\"is_one_way\"] == value)\n",
        "    return X.filter(mask), y.filter(mask), groups.filter(mask)\n",
        "\n",
        "# Keep only columns that do NOT contain \"legs1\" or \"leg1\"\n",
        "def drop_leg_cols(df: pl.DataFrame) -> pl.DataFrame:\n",
        "    cols_to_keep = [c for c in df.columns if \"legs1\" not in c and \"leg1\" not in c]\n",
        "    return df.select(cols_to_keep)\n",
        "\n",
        "def main():\n",
        "    DATA_DIR = \"./data\"\n",
        "    MODEL_DIR = \"model\"\n",
        "    SUBMIT_DIR = \"submission\"\n",
        "\n",
        "    best_val_loss = float(\"inf\")\n",
        "    best_hitrate = 0.0\n",
        "    model_path = os.path.join(MODEL_DIR, \"best_dl_ranker.pt\")\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "    val_hitrates = []\n",
        "    val_ndcgs = []\n",
        "    val_maps = []\n",
        "    learning_rates = []\n",
        "\n",
        "    os.makedirs(MODEL_DIR, exist_ok=True)\n",
        "    os.makedirs(SUBMIT_DIR, exist_ok=True)\n",
        "\n",
        "    early_stopper = EarlyStopping(patience=3, min_delta=0.001)\n",
        "\n",
        "    X, y, groups, cat_features, num_features, train_size, test_ids, test_rankers = prepare_data(DATA_DIR)\n",
        "\n",
        "    # Fill missing values\n",
        "    float_cols = [c for c, t in zip(X.columns, X.dtypes) if t == pl.Float64]\n",
        "    for col in float_cols:\n",
        "        X = X.with_columns(\n",
        "            pl.when(pl.col(col).is_nan()).then(0).otherwise(pl.col(col)).alias(col)\n",
        "        )\n",
        "\n",
        "    n1 = 16487352\n",
        "    # n1 = 17487300\n",
        "    n2 = train_size\n",
        "\n",
        "    X_tr, X_va, X_te = X[:n1], X[n1:n2], X[n2:]\n",
        "    y_tr, y_va, y_te = y[:n1], y[n1:n2], y[n2:]\n",
        "    groups_tr, groups_va, groups_te = groups[:n1], groups[n1:n2], groups[n2:]\n",
        "\n",
        "    print(\"\\nüìä Distribution of is_one_way in the training set:\")\n",
        "    print(X_tr[\"is_one_way\"].value_counts().sort(\"is_one_way\"))\n",
        "\n",
        "    print(\"\\nüìä Distribution of is_one_way in the validation set:\")\n",
        "    print(X_va[\"is_one_way\"].value_counts().sort(\"is_one_way\"))\n",
        "\n",
        "    print(\"\\nüìä Distribution of is_one_way in the test set:\")\n",
        "    print(X_te[\"is_one_way\"].value_counts().sort(\"is_one_way\"))\n",
        "\n",
        "    X_tr_1, y_tr_1, groups_tr_1 = split_by_is_one_way(X_tr, y_tr, groups_tr, 1)\n",
        "    X_tr_0, y_tr_0, groups_tr_0 = split_by_is_one_way(X_tr, y_tr, groups_tr, 0)\n",
        "\n",
        "    X_va_1, y_va_1, groups_va_1 = split_by_is_one_way(X_va, y_va, groups_va, 1)\n",
        "    X_va_0, y_va_0, groups_va_0 = split_by_is_one_way(X_va, y_va, groups_va, 0)\n",
        "\n",
        "    X_te_1, y_te_1, groups_te_1 = split_by_is_one_way(X_te, y_te, groups_te, 1)\n",
        "    X_te_0, y_te_0, groups_te_0 = split_by_is_one_way(X_te, y_te, groups_te, 0)\n",
        "\n",
        "    # To use\n",
        "    # X_tr_to_use = drop_leg_cols(X_tr_1)\n",
        "    # y_tr_to_use, groups_tr_to_use = y_tr_1, groups_tr_1\n",
        "\n",
        "    # X_va_to_use = drop_leg_cols(X_va_1)\n",
        "    # y_va_to_use, groups_va_to_use = y_va_1, groups_va_1\n",
        "\n",
        "    # X_te_to_use = drop_leg_cols(X_te_1)\n",
        "    # y_te_to_use, groups_te_to_use = y_te_1, groups_te_1\n",
        "\n",
        "    # To use\n",
        "    # X_tr_to_use, y_tr_to_use, groups_tr_to_use = X_tr_1, y_tr_1, groups_tr_1\n",
        "    # X_va_to_use, y_va_to_use, groups_va_to_use = X_va_1, y_va_1, groups_va_1\n",
        "    # X_te_to_use, y_te_to_use, groups_te_to_use = X_te_1, y_te_1, groups_te_1\n",
        "\n",
        "    # To use\n",
        "    X_tr_to_use, y_tr_to_use, groups_tr_to_use = X_tr_0, y_tr_0, groups_tr_0\n",
        "    X_va_to_use, y_va_to_use, groups_va_to_use = X_va_0, y_va_0, groups_va_0\n",
        "    X_te_to_use, y_te_to_use, groups_te_to_use = X_te_0, y_te_0, groups_te_0\n",
        "\n",
        "    # Inspect group sizes in validation set\n",
        "    val_rankers = groups_va_to_use[\"ranker_id\"].to_numpy()\n",
        "    val_group_counts = Counter(val_rankers)\n",
        "\n",
        "    print(\"\\nüìã Validation group statistics:\")\n",
        "    # Save detailed group info to file\n",
        "    group_info_path = os.path.join(MODEL_DIR, \"validation_groups_info.txt\")\n",
        "    with open(group_info_path, \"w\") as f:\n",
        "        f.write(f\"Total groups: {len(val_group_counts)}\\n\\n\")\n",
        "        f.write(\"GroupID\\tSize\\tStartIdx\\tEndIdx\\n\")\n",
        "\n",
        "        group_to_rows = defaultdict(list)\n",
        "        for i, g in enumerate(val_rankers):\n",
        "            group_to_rows[g].append(i)\n",
        "\n",
        "        for group_id, indices in sorted(group_to_rows.items()):\n",
        "            start_idx = indices[0]\n",
        "            end_idx = indices[-1]\n",
        "            size = len(indices)\n",
        "            f.write(f\"{group_id}\\t{size}\\t{start_idx}\\t{end_idx}\\n\")\n",
        "\n",
        "    print(f\"üìÅ Saved validation group info to {group_info_path}\")\n",
        "\n",
        "    cat_dims = build_cat_dims(X, cat_features)\n",
        "    num_numeric_feats = len(num_features)\n",
        "\n",
        "    train_dataset = RankDataset(X_tr_to_use, y_tr_to_use, groups_tr_to_use, cat_features, num_features)\n",
        "    val_dataset = RankDataset(X_va_to_use, y_va_to_use, groups_va_to_use, cat_features, num_features)\n",
        "    test_dataset = RankDataset(X_te_to_use, y_te_to_use, groups_te_to_use, cat_features, num_features)\n",
        "\n",
        "    plot_group_size_distribution(train_dataset, save_path=os.path.join(MODEL_DIR, \"group_sizes.png\"))\n",
        "    print(\"üìä Group size distribution saved.\")\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True, collate_fn=collate_fn)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False, collate_fn=collate_fn)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, collate_fn=collate_fn)\n",
        "\n",
        "    print(\"‚úÖ Data loaders created.\")\n",
        "\n",
        "    num_epochs = 10\n",
        "    num_training_steps = num_epochs * len(train_loader)\n",
        "    num_warmup_steps = int(0.1 * num_training_steps)\n",
        "\n",
        "    learning_rate = 1e-3\n",
        "\n",
        "    model = DLRanker(cat_dims, num_numeric_feats).to(device)\n",
        "\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=0.01)\n",
        "\n",
        "    scheduler = get_scheduler(\n",
        "        \"linear\",\n",
        "        optimizer=optimizer,\n",
        "        num_warmup_steps=num_warmup_steps,\n",
        "        num_training_steps=num_training_steps\n",
        "    )\n",
        "\n",
        "    best_hitrate = 0\n",
        "    for epoch in range(num_epochs):\n",
        "        print(f\"\\n--- Epoch {epoch+1}/{num_epochs} ---\")\n",
        "        start_time = time.time()\n",
        "\n",
        "        train_loss = train_one_epoch(model, train_loader, optimizer, device, scheduler)\n",
        "        val_loss, val_hitrate, val_ndcg, val_map = validate(model, val_loader, device, min_group_size=10)\n",
        "\n",
        "        train_losses.append(train_loss)\n",
        "        val_losses.append(val_loss)\n",
        "        val_hitrates.append(val_hitrate.item())\n",
        "        val_ndcgs.append(val_ndcg.item())\n",
        "        val_maps.append(val_map.item())\n",
        "\n",
        "        current_lr = scheduler.get_last_lr()\n",
        "        learning_rates.append(current_lr[0])\n",
        "\n",
        "        elapsed = time.time() - start_time\n",
        "        print(\n",
        "            f\"Epoch {epoch+1}: \"\n",
        "            f\"Train Loss={train_loss:.4f}, \"\n",
        "            f\"Val Loss={val_loss:.4f}, \"\n",
        "            f\"HitRate@3={val_hitrate:.4f}, \"\n",
        "            f\"NDCG@3={val_ndcg:.4f}, \"\n",
        "            f\"MAP@3={val_map:.4f}, \"\n",
        "            f\"LR={current_lr[0]:.6f} \"\n",
        "            f\"({elapsed:.1f}s)\"\n",
        "        )\n",
        "\n",
        "\n",
        "        if val_loss < best_val_loss and val_hitrate > best_hitrate:\n",
        "            best_val_loss = val_loss\n",
        "            best_hitrate = val_hitrate\n",
        "            torch.save(model.state_dict(), model_path)\n",
        "            print(\"üíæ Model improved (loss ‚Üì and hitrate ‚Üë), saved.\")\n",
        "\n",
        "        if early_stopper.step(-val_loss):\n",
        "            print(\"‚õî Early stopping triggered.\")\n",
        "            break\n",
        "\n",
        "    # Plot metrics\n",
        "    epochs = list(range(1, len(train_losses) + 1))\n",
        "\n",
        "    # Plot Loss Curve\n",
        "    plt.figure()\n",
        "    plt.plot(epochs, train_losses, label=\"Train Loss\")\n",
        "    plt.plot(epochs, val_losses, label=\"Val Loss\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.title(\"Training & Validation Loss\")\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.savefig(os.path.join(MODEL_DIR, \"loss_curve.png\"))\n",
        "    plt.close()\n",
        "\n",
        "    # Plot HitRate@3\n",
        "    plt.figure()\n",
        "    plt.plot(epochs, val_hitrates, label=\"Val HitRate@3\", color=\"green\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"HitRate@3\")\n",
        "    plt.title(\"Validation HitRate@3\")\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.savefig(os.path.join(MODEL_DIR, \"hitrate_curve.png\"))\n",
        "    plt.close()\n",
        "\n",
        "    # Plot Learning Rate\n",
        "    plt.figure()\n",
        "    plt.plot(epochs, learning_rates, label=\"Learning Rate\", color=\"orange\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"LR\")\n",
        "    plt.title(\"Learning Rate Schedule\")\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.savefig(os.path.join(MODEL_DIR, \"lr_curve.png\"))\n",
        "    plt.close()\n",
        "\n",
        "    # Plot NDCG@3\n",
        "    plt.figure()\n",
        "    plt.plot(epochs, val_ndcgs, label=\"Val NDCG@3\", color=\"purple\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"NDCG@3\")\n",
        "    plt.title(\"Validation NDCG@3\")\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.savefig(os.path.join(MODEL_DIR, \"ndcg_curve.png\"))\n",
        "    plt.close()\n",
        "\n",
        "    # Plot MAP@3\n",
        "    plt.figure()\n",
        "    plt.plot(epochs, val_maps, label=\"Val MAP@3\", color=\"red\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"MAP@3\")\n",
        "    plt.title(\"Validation MAP@3\")\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.savefig(os.path.join(MODEL_DIR, \"map_curve.png\"))\n",
        "    plt.close()\n",
        "\n",
        "    print(\"üìä Saved metric plots to model/\")\n",
        "\n",
        "    # Predict test set\n",
        "    model.load_state_dict(torch.load(model_path))\n",
        "    model.eval()\n",
        "\n",
        "    val_ids = X_va_to_use[\"Id\"]\n",
        "    val_rankers = groups_va_to_use[\"ranker_id\"]\n",
        "    val_labels = y_va_to_use\n",
        "\n",
        "    all_val_scores = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for x_cat, x_num, _, lengths in tqdm(val_loader, desc=\"Predicting validation set\"):\n",
        "            x_num = x_num.to(device)\n",
        "            x_cat = {k: v.to(device) for k, v in x_cat.items()}\n",
        "            scores = model(x_cat, x_num)\n",
        "\n",
        "            for i in range(scores.size(0)):\n",
        "                l = lengths[i]\n",
        "                all_val_scores.append(scores[i, :l].cpu().numpy())\n",
        "\n",
        "    all_val_scores = np.concatenate(all_val_scores)\n",
        "\n",
        "    assert len(all_val_scores) == X_va_to_use.shape[0], \\\n",
        "        f\"Mismatch: {len(all_val_scores)} scores vs {X_va_to_use.shape[0]} rows\"\n",
        "\n",
        "    val_df = X_va_to_use.with_columns([\n",
        "        pl.Series(\"Id\", val_ids),\n",
        "        pl.Series(\"ranker_id\", val_rankers),\n",
        "        pl.Series(\"score\", all_val_scores),\n",
        "        pl.Series(\"label\", val_labels)\n",
        "    ])\n",
        "\n",
        "    val_df = val_df.with_columns(\n",
        "        pl.col(\"score\")\n",
        "        .rank(method=\"ordinal\", descending=True)\n",
        "        .over(\"ranker_id\")\n",
        "        .cast(pl.Int32)\n",
        "        .alias(\"selected\")\n",
        "    )\n",
        "\n",
        "    val_save_path = os.path.join(MODEL_DIR, \"validation_preds_dl_full.parquet\")\n",
        "    val_df.write_parquet(val_save_path)\n",
        "    print(f\"‚úÖ Saved full validation predictions (with features) to {val_save_path}\")\n",
        "\n",
        "    all_scores = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for x_cat, x_num, _, lengths in tqdm(test_loader, desc=\"Predicting test set\"):\n",
        "            x_num = x_num.to(device)\n",
        "            x_cat = {k: v.to(device) for k, v in x_cat.items()}\n",
        "            scores = model(x_cat, x_num)\n",
        "\n",
        "            for i in range(scores.size(0)):\n",
        "                l = lengths[i]\n",
        "                all_scores.append(scores[i, :l].cpu().numpy())\n",
        "\n",
        "    all_scores = np.concatenate(all_scores)\n",
        "\n",
        "    # Find the rows in the full test set where we actually made predictions\n",
        "    # (assuming test_loader is built from X_te filtered by is_one_way == 1/0)\n",
        "    mask_one_way = (X_te[\"is_one_way\"].to_numpy() == 0)\n",
        "    idx_one_way = np.where(mask_one_way)[0]\n",
        "\n",
        "    assert len(all_scores) == len(idx_one_way), \\\n",
        "        f\"Mismatch: {len(all_scores)} predictions vs {len(idx_one_way)} one-way rows\"\n",
        "\n",
        "    # Initialize scores for the entire test set as NaN and fill only predicted rows\n",
        "    all_scores_full = np.full(len(test_ids), np.nan, dtype=np.float32)\n",
        "    all_scores_full[idx_one_way] = all_scores\n",
        "\n",
        "    # Build the full submission dataframe; add a stable row index to preserve original order\n",
        "    row_idx = pl.Series(\"row_idx\", np.arange(len(test_ids), dtype=np.int64))\n",
        "\n",
        "    submission_df = pl.DataFrame({\n",
        "        \"row_idx\": row_idx,\n",
        "        \"Id\": test_ids,\n",
        "        \"ranker_id\": test_rankers,\n",
        "        \"score\": all_scores_full,\n",
        "    })\n",
        "\n",
        "    # Compute 'selected' only where a score exists; keep others at 0 (or another default)\n",
        "    submission_df = submission_df.with_columns(\n",
        "        pl.when(pl.col(\"score\").is_not_null())\n",
        "          .then(\n",
        "              pl.col(\"score\")\n",
        "              .rank(method=\"ordinal\", descending=True)\n",
        "              .over(\"ranker_id\")\n",
        "              .cast(pl.Int32)\n",
        "          )\n",
        "          .otherwise(0)\n",
        "          .alias(\"selected\")\n",
        "    )\n",
        "\n",
        "    # Ensure original order by row_idx, then select final columns\n",
        "    submission = (\n",
        "        submission_df\n",
        "        .sort(\"row_idx\")       # keeps original Id order\n",
        "        .select([\"Id\", \"ranker_id\", \"score\", \"selected\"])\n",
        "    )\n",
        "\n",
        "    submission_path = os.path.join(SUBMIT_DIR, \"submission_dl_ranker.parquet\")\n",
        "    submission.write_parquet(submission_path)\n",
        "    print(f\"‚úÖ Submission saved to {submission_path}\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dW-Gc6G_a2Hl",
        "outputId": "657d3dbd-6377-4af2-9375-4724c928cd52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting deeprec_validate.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "is_one_way = 1, with legs_1 columns"
      ],
      "metadata": {
        "id": "xYyuflmI0RCA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "--- Epoch 1/10 ---\n",
        "Validating:   0%|          | 0/332 [00:00<?, ?it/s]/home/ionut/test_whisper/test2/deeprec_validate.py:446: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
        "  lengths = torch.tensor(lengths).to(device)\n",
        "Epoch 1: Train Loss=0.3710, Val Loss=0.3602, HitRate@3=0.4649, NDCG@3=0.3531, MAP@3=0.6646, LR=0.001000 (292.6s)\n",
        "üíæ Model improved (loss ‚Üì and hitrate ‚Üë), saved.\n",
        "\n",
        "--- Epoch 2/10 ---\n",
        "Epoch 2: Train Loss=0.3145, Val Loss=0.3105, HitRate@3=0.5272, NDCG@3=0.4234, MAP@3=0.7303, LR=0.000889 (292.2s)\n",
        "üíæ Model improved (loss ‚Üì and hitrate ‚Üë), saved.\n",
        "\n",
        "--- Epoch 3/10 ---\n",
        "Epoch 3: Train Loss=0.2890, Val Loss=0.2891, HitRate@3=0.5440, NDCG@3=0.4394, MAP@3=0.7309, LR=0.000778 (292.0s)\n",
        "üíæ Model improved (loss ‚Üì and hitrate ‚Üë), saved.\n",
        "\n",
        "--- Epoch 4/10 ---\n",
        "Epoch 4: Train Loss=0.2730, Val Loss=0.2990, HitRate@3=0.5272, NDCG@3=0.4176, MAP@3=0.7124, LR=0.000667 (293.3s)\n",
        "\n",
        "--- Epoch 5/10 ---\n",
        "Epoch 5: Train Loss=0.2596, Val Loss=0.2897, HitRate@3=0.5543, NDCG@3=0.4514, MAP@3=0.7424, LR=0.000556 (292.6s)\n",
        "\n",
        "--- Epoch 6/10 ---\n",
        "Epoch 6: Train Loss=0.2486, Val Loss=0.2816, HitRate@3=0.5537, NDCG@3=0.4523, MAP@3=0.7458, LR=0.000444 (292.4s)\n",
        "üíæ Model improved (loss ‚Üì and hitrate ‚Üë), saved.\n",
        "\n",
        "--- Epoch 7/10 ---\n",
        "Epoch 7: Train Loss=0.2357, Val Loss=0.2850, HitRate@3=0.5543, NDCG@3=0.4512, MAP@3=0.7415, LR=0.000333 (291.8s)\n",
        "\n",
        "--- Epoch 8/10 ---\n",
        "Epoch 8: Train Loss=0.2241, Val Loss=0.2806, HitRate@3=0.5533, NDCG@3=0.4501, MAP@3=0.7414, LR=0.000222 (292.3s)\n",
        "\n",
        "--- Epoch 9/10 ---\n",
        "Epoch 9: Train Loss=0.2142, Val Loss=0.2806, HitRate@3=0.5545, NDCG@3=0.4516, MAP@3=0.7430, LR=0.000111 (292.7s)\n",
        "üíæ Model improved (loss ‚Üì and hitrate ‚Üë), saved.\n",
        "\n",
        "--- Epoch 10/10 ---\n",
        "Epoch 10: Train Loss=0.2030, Val Loss=0.2857, HitRate@3=0.5501, NDCG@3=0.4476, MAP@3=0.7420, LR=0.000000 (292.1s)"
      ],
      "metadata": {
        "id": "THAI2gPu0QOe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile check.py\n",
        "import pyarrow.parquet as pq\n",
        "\n",
        "# Function to extract column names from a parquet file\n",
        "def get_columns(filename):\n",
        "    schema = pq.read_schema(filename)\n",
        "    return schema.names\n",
        "\n",
        "# Get columns\n",
        "cols_full = get_columns(\"feateng_full.parquet\")\n",
        "cols_not_full = get_columns(\"feateng_not_full.parquet\")\n",
        "\n",
        "# Filter columns containing 'legs0' and 'legs1'\n",
        "legs0_full = [col for col in cols_full if \"legs0\" in col]\n",
        "legs1_full = [col for col in cols_full if \"legs1\" in col]\n",
        "legs0_not_full = [col for col in cols_not_full if \"legs0\" in col]\n",
        "legs1_not_full = [col for col in cols_not_full if \"legs1\" in col]\n",
        "\n",
        "# Save results to a text file\n",
        "with open(\"columns_info.txt\", \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(\"Columns in feateng_full.parquet:\\n\")\n",
        "    f.write(\", \".join(cols_full) + \"\\n\\n\")\n",
        "\n",
        "    f.write(\"Columns in feateng_not_full.parquet:\\n\")\n",
        "    f.write(\", \".join(cols_not_full) + \"\\n\\n\")\n",
        "\n",
        "    f.write(\"Columns in feateng_full containing 'legs0':\\n\")\n",
        "    f.write(\", \".join(legs0_full) + \"\\n\")\n",
        "\n",
        "    f.write(\"Columns in feateng_full containing 'legs1':\\n\")\n",
        "    f.write(\", \".join(legs1_full) + \"\\n\\n\")\n",
        "\n",
        "    f.write(\"Columns in feateng_not_full containing 'legs0':\\n\")\n",
        "    f.write(\", \".join(legs0_not_full) + \"\\n\")\n",
        "\n",
        "    f.write(\"Columns in feateng_not_full containing 'legs1':\\n\")\n",
        "    f.write(\", \".join(legs1_not_full) + \"\\n\")\n",
        "\n",
        "print(\"File 'columns_info.txt' has been saved.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H4VbvtyngYB6",
        "outputId": "0f9e94a7-30c8-4287-d5ca-92c0909da579"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting check.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile create_legs0_only.py\n",
        "import pyarrow.parquet as pq\n",
        "import pandas as pd\n",
        "\n",
        "# Step 1: Read only the schema (no data yet)\n",
        "schema = pq.read_schema(\"feateng_not_full.parquet\")\n",
        "all_columns = schema.names\n",
        "\n",
        "# Step 2: Keep only columns that DO NOT contain 'legs1'\n",
        "columns_to_keep = [col for col in all_columns if \"legs1\" not in col]\n",
        "\n",
        "# Step 3: Load only these columns from the file\n",
        "df_not_full_legs0_only = pd.read_parquet(\"feateng_not_full.parquet\", columns=columns_to_keep)\n",
        "\n",
        "# Step 4: Save the new dataset\n",
        "df_not_full_legs0_only.to_parquet(\"feateng_not_full_legs0_only.parquet\", index=False)\n",
        "\n",
        "print(f\"Saved 'feateng_not_full_legs0_only.parquet' with {len(columns_to_keep)} columns.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y19mhFeXj019",
        "outputId": "1f83eaa4-af5d-44f3-e581-1ac6b76cd4af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting create_legs0_only.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Ensemble**"
      ],
      "metadata": {
        "id": "IMPtcQCq33sN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import polars as pl\n",
        "import os\n",
        "\n",
        "def compute_confidence(df: pl.DataFrame) -> pl.DataFrame:\n",
        "    df = df.with_columns([\n",
        "        pl.len().over(\"ranker_id\").alias(\"group_size\")\n",
        "    ])\n",
        "\n",
        "    df = df.with_columns([\n",
        "        (1.0 - ((pl.col(\"selected\") - 1) / (pl.col(\"group_size\") - 1 + 1e-8))).alias(\"confidence\")\n",
        "    ])\n",
        "\n",
        "    return df.drop(\"group_size\")\n",
        "\n",
        "def process_file(input_path: str):\n",
        "    print(f\"üîÑ Processing: {input_path}\")\n",
        "\n",
        "    if input_path.endswith(\".csv\"):\n",
        "        df = pl.read_csv(input_path)\n",
        "    elif input_path.endswith(\".parquet\"):\n",
        "        df = pl.read_parquet(input_path)\n",
        "    else:\n",
        "        print(f\"‚ö†Ô∏è Skipping unsupported file: {input_path}\")\n",
        "        return\n",
        "\n",
        "    df_conf = compute_confidence(df)\n",
        "\n",
        "    base, ext = os.path.splitext(input_path)\n",
        "    if base.endswith(\"_with_confidence\"):\n",
        "        output_path = f\"{base}.csv\"\n",
        "    else:\n",
        "        output_path = f\"{base}_with_confidence.csv\"\n",
        "\n",
        "    df_conf.write_csv(output_path)\n",
        "    print(f\"‚úÖ Saved: {output_path}\\n\")\n",
        "\n",
        "\n",
        "\n",
        "def main():\n",
        "    files = [\n",
        "        \"submission_20250721083807_0.52244.parquet\",\n",
        "        \"submission_20250724032338_0.51345.parquet\",\n",
        "        \"submission_20250725083055_0.52391.parquet\",\n",
        "        \"submission_20250727084025_0.52795.parquet\",\n",
        "        \"submission_20250802074816_0.52603.parquet\",\n",
        "        \"submission_20250804001151_0.51244.parquet\",\n",
        "        \"submission_20250807032439_0.52538.parquet\",\n",
        "        \"submission_dl_ranker_0.48755.parquet\"\n",
        "    ]\n",
        "\n",
        "    for file in files:\n",
        "        if os.path.exists(file):\n",
        "            process_file(file)\n",
        "        else:\n",
        "            print(f\"‚ùå File not found: {file}\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QToY7ux_35Gj",
        "outputId": "aeb74c82-d0e8-465c-8a55-05a51c7e2c16"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîÑ Processing: submission_20250721083807_0.52244.parquet\n",
            "‚úÖ Saved: submission_20250721083807_0.52244_with_confidence.csv\n",
            "\n",
            "üîÑ Processing: submission_20250724032338_0.51345.parquet\n",
            "‚úÖ Saved: submission_20250724032338_0.51345_with_confidence.csv\n",
            "\n",
            "üîÑ Processing: submission_20250725083055_0.52391.parquet\n",
            "‚úÖ Saved: submission_20250725083055_0.52391_with_confidence.csv\n",
            "\n",
            "üîÑ Processing: submission_20250727084025_0.52795.parquet\n",
            "‚úÖ Saved: submission_20250727084025_0.52795_with_confidence.csv\n",
            "\n",
            "üîÑ Processing: submission_20250802074816_0.52603.parquet\n",
            "‚úÖ Saved: submission_20250802074816_0.52603_with_confidence.csv\n",
            "\n",
            "üîÑ Processing: submission_20250804001151_0.51244.parquet\n",
            "‚úÖ Saved: submission_20250804001151_0.51244_with_confidence.csv\n",
            "\n",
            "üîÑ Processing: submission_20250807032439_0.52538.parquet\n",
            "‚úÖ Saved: submission_20250807032439_0.52538_with_confidence.csv\n",
            "\n",
            "üîÑ Processing: submission_dl_ranker_0.48755.parquet\n",
            "‚úÖ Saved: submission_dl_ranker_0.48755_with_confidence.csv\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import polars as pl\n",
        "import os\n",
        "\n",
        "def compute_confidence(df: pl.DataFrame, alpha: float = 0.7, k: int = 5) -> pl.DataFrame:\n",
        "    # group size for each ranker_id\n",
        "    df = df.with_columns([\n",
        "        pl.len().over(\"ranker_id\").alias(\"group_size\")\n",
        "    ])\n",
        "\n",
        "    # 1) base score based on position within the group (max for selected = 1)\n",
        "    base_conf = 1.0 - ((pl.col(\"selected\") - 1) / (pl.col(\"group_size\") - 1 + 1e-8))\n",
        "    df = df.with_columns(base_conf.alias(\"confidence\"))\n",
        "\n",
        "    # 2) RRF score normalized to [0, 1]\n",
        "    rrf_max = 1.0 / (k + 1)  # RRF value for selected = 1\n",
        "    df = df.with_columns(\n",
        "        ((1.0 / (k + pl.col(\"selected\"))) / rrf_max).alias(\"rrf_score\")\n",
        "    )\n",
        "\n",
        "    # 3) convex combination between base score and RRF\n",
        "    df = df.with_columns(\n",
        "        (alpha * pl.col(\"confidence\") + (1 - alpha) * pl.col(\"rrf_score\")).alias(\"confidence\")\n",
        "    )\n",
        "\n",
        "    # keep 'selected'; remove only temporary columns\n",
        "    return df.drop([\"group_size\", \"rrf_score\"])\n",
        "\n",
        "def process_file(input_path: str, alpha: float = 0.7, k: int = 5):\n",
        "    print(f\"üîÑ Processing: {input_path}\")\n",
        "\n",
        "    if input_path.endswith(\".csv\"):\n",
        "        df = pl.read_csv(input_path)\n",
        "    elif input_path.endswith(\".parquet\"):\n",
        "        df = pl.read_parquet(input_path)\n",
        "    else:\n",
        "        print(f\"‚ö†Ô∏è Skipping unsupported file: {input_path}\")\n",
        "        return\n",
        "\n",
        "    df_conf = compute_confidence(df, alpha=alpha, k=k)\n",
        "\n",
        "    base, ext = os.path.splitext(input_path)\n",
        "    if base.endswith(\"_with_confidence\"):\n",
        "        output_path = f\"{base}.csv\"\n",
        "    else:\n",
        "        output_path = f\"{base}_with_confidence.csv\"\n",
        "\n",
        "    df_conf.write_csv(output_path)\n",
        "    print(f\"‚úÖ Saved: {output_path}\\n\")\n",
        "\n",
        "\n",
        "def main():\n",
        "    files = [\n",
        "        \"submission_20250721083807_0.52244.parquet\",\n",
        "        \"submission_20250724032338_0.51345.parquet\",\n",
        "        \"submission_20250725083055_0.52391.parquet\",\n",
        "        \"submission_20250727084025_0.52795.parquet\",\n",
        "        \"submission_20250802074816_0.52603.parquet\",\n",
        "        \"submission_20250804001151_0.51244.parquet\",\n",
        "        \"submission_20250807032439_0.52538.parquet\",\n",
        "        \"submission_dl_ranker_0.48755.parquet\"\n",
        "    ]\n",
        "\n",
        "    alpha = 0.7\n",
        "    k = 5\n",
        "\n",
        "    for file in files:\n",
        "        if os.path.exists(file):\n",
        "            process_file(file, alpha=alpha, k=k)\n",
        "        else:\n",
        "            print(f\"‚ùå File not found: {file}\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s9QmMhHXDQ6_",
        "outputId": "ea6dd1fa-bd2c-4ed0-a233-adf68e1d6b50"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîÑ Processing: submission_20250721083807_0.52244.parquet\n",
            "‚úÖ Saved: submission_20250721083807_0.52244_with_confidence.csv\n",
            "\n",
            "üîÑ Processing: submission_20250724032338_0.51345.parquet\n",
            "‚úÖ Saved: submission_20250724032338_0.51345_with_confidence.csv\n",
            "\n",
            "üîÑ Processing: submission_20250725083055_0.52391.parquet\n",
            "‚úÖ Saved: submission_20250725083055_0.52391_with_confidence.csv\n",
            "\n",
            "üîÑ Processing: submission_20250727084025_0.52795.parquet\n",
            "‚úÖ Saved: submission_20250727084025_0.52795_with_confidence.csv\n",
            "\n",
            "üîÑ Processing: submission_20250802074816_0.52603.parquet\n",
            "‚úÖ Saved: submission_20250802074816_0.52603_with_confidence.csv\n",
            "\n",
            "üîÑ Processing: submission_20250804001151_0.51244.parquet\n",
            "‚úÖ Saved: submission_20250804001151_0.51244_with_confidence.csv\n",
            "\n",
            "üîÑ Processing: submission_20250807032439_0.52538.parquet\n",
            "‚úÖ Saved: submission_20250807032439_0.52538_with_confidence.csv\n",
            "\n",
            "üîÑ Processing: submission_dl_ranker_0.48755.parquet\n",
            "‚úÖ Saved: submission_dl_ranker_0.48755_with_confidence.csv\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import polars as pl\n",
        "import glob\n",
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "def load_submission_with_confidence(filepath):\n",
        "    df = pl.read_csv(filepath)\n",
        "    if \"selected\" in df.columns:\n",
        "        df = df.drop(\"selected\")\n",
        "    return df\n",
        "\n",
        "def compute_entropy(probabilities):\n",
        "    p = np.clip(probabilities, 1e-9, 1.0)\n",
        "    return -np.sum(p * np.log(p))\n",
        "\n",
        "def pca_svd(X, n_components):\n",
        "    \"\"\"\n",
        "    X: (n_samples, n_models) already standardized by columns.\n",
        "    Returns:\n",
        "      scores  : (n_samples, n_components)  = X @ Vt_k.T\n",
        "      loadings: (n_models,  n_components)  = Vt_k.T\n",
        "      recon   : (n_samples, n_models) reconstructed from the first components\n",
        "    \"\"\"\n",
        "    # SVD on standardized X (centering + scaling should be done beforehand)\n",
        "    # Note: np.linalg.svd returns Vt with shape (n_models, n_models)\n",
        "    U, S, Vt = np.linalg.svd(X, full_matrices=False)\n",
        "    Vt_k = Vt[:n_components, :]               # (k, n_models)\n",
        "    scores = X @ Vt_k.T                        # (n_samples, k)\n",
        "    recon  = scores @ Vt_k                     # (n_samples, n_models)\n",
        "    loadings = Vt_k.T                          # (n_models, k)\n",
        "    return scores, loadings, recon\n",
        "\n",
        "def main():\n",
        "    # Find all files matching *_with_confidence.csv\n",
        "    filepaths = glob.glob(\"submission_*_*_with_confidence.csv\")\n",
        "\n",
        "    dfs = []\n",
        "    confidence_col_names = []\n",
        "\n",
        "    for filepath in filepaths:\n",
        "        match = re.search(r\"submission_.*_([\\d.]+)_with_confidence\\.csv\", filepath)\n",
        "        if match:\n",
        "            score = match.group(1)\n",
        "            df = load_submission_with_confidence(filepath)\n",
        "            confidence_col = f\"confidence_{score}\"\n",
        "            df = df.with_columns(pl.col(\"confidence\").alias(confidence_col)).drop(\"confidence\")\n",
        "            confidence_col_names.append(confidence_col)\n",
        "            dfs.append(df)\n",
        "\n",
        "    if not dfs:\n",
        "        print(\"‚ùå No valid submission files found.\")\n",
        "        return\n",
        "\n",
        "    # Join on Id + ranker_id\n",
        "    df_combined = dfs[0]\n",
        "    for df in dfs[1:]:\n",
        "        df_combined = df_combined.join(df, on=[\"Id\", \"ranker_id\"])\n",
        "\n",
        "    # Confidence matrix (n_samples x n_models)\n",
        "    X_df = df_combined.select(confidence_col_names).to_pandas()\n",
        "    # Replace NaN with column mean\n",
        "    X_df = X_df.apply(lambda col: col.fillna(col.mean()), axis=0)\n",
        "    X = X_df.values.astype(float)\n",
        "\n",
        "    # Standardize columns (center and scale) for PCA\n",
        "    col_means = X.mean(axis=0, keepdims=True)\n",
        "    col_stds  = X.std(axis=0, ddof=1, keepdims=True)\n",
        "    col_stds[col_stds == 0.0] = 1.0  # protection against zero std\n",
        "    X_std = (X - col_means) / col_stds\n",
        "\n",
        "    # PCA parameters + Spearman calculation mode\n",
        "    k_pca = 5\n",
        "    spearman_mode = \"residual\"  # \"residual\" (recommended) | \"loadings\" | \"scores\"\n",
        "\n",
        "    # PCA via SVD\n",
        "    scores, loadings, recon = pca_svd(X_std, n_components=k_pca)\n",
        "\n",
        "    if spearman_mode == \"residual\":\n",
        "        # Idiosyncratic signal (after removing the first k components)\n",
        "        X_resid = X_std - recon\n",
        "        corr_df = pd.DataFrame(X_resid, columns=confidence_col_names).corr(method=\"spearman\")\n",
        "        print(f\"üìä Spearman between models on RESIDUALS after PCA (k={k_pca}):\")\n",
        "    elif spearman_mode == \"loadings\":\n",
        "        # Spearman correlation between each model's loadings on the first k components\n",
        "        load_df = pd.DataFrame(loadings, index=confidence_col_names,\n",
        "                               columns=[f\"PC{i+1}\" for i in range(k_pca)])\n",
        "        corr_df = load_df.T.corr(method=\"spearman\")\n",
        "        print(f\"üìä Spearman between models on PCA LOADINGS (first {k_pca}):\")\n",
        "    elif spearman_mode == \"scores\":\n",
        "        # Spearman correlation between models viewed through the PCA scores\n",
        "        # (correlate reconstructed model columns from the first k components)\n",
        "        X_k = recon  # common signal from the first components\n",
        "        corr_df = pd.DataFrame(X_k, columns=confidence_col_names).corr(method=\"spearman\")\n",
        "        print(f\"üìä Spearman between models on PCA SCORES (first {k_pca}):\")\n",
        "    else:\n",
        "        raise ValueError(\"Invalid spearman_mode. Choose: 'residual' | 'loadings' | 'scores'.\")\n",
        "\n",
        "    print(corr_df)\n",
        "\n",
        "    # Uniqueness based on 1 - average correlation (exclude diagonal = 1)\n",
        "    mean_corr = corr_df.apply(lambda row: (row.sum() - 1) / (len(row) - 1), axis=1)\n",
        "    model_uniqueness = 1 - mean_corr\n",
        "    uniqueness_weights = model_uniqueness / model_uniqueness.sum()\n",
        "\n",
        "    # Entropy for each confidence column (on raw scores, not standardized)\n",
        "    entropies = []\n",
        "    for col in confidence_col_names:\n",
        "        probs = df_combined[col].to_numpy()\n",
        "        probs = np.nan_to_num(probs, nan=np.nanmean(probs))\n",
        "        total = np.sum(probs)\n",
        "        if total <= 0:\n",
        "            # stable fallback\n",
        "            probs = np.full_like(probs, 1.0 / len(probs), dtype=float)\n",
        "        else:\n",
        "            probs = probs / total\n",
        "        entropies.append(compute_entropy(probs))\n",
        "\n",
        "    entropy_weights = np.array(entropies, dtype=float)\n",
        "    entropy_weights /= entropy_weights.sum()\n",
        "\n",
        "    # Combine weights: uniqueness (post-PCA) + entropy (informativeness)\n",
        "    alpha = 0.65  # more emphasis on uniqueness\n",
        "    combined_weights = alpha * uniqueness_weights.values + (1 - alpha) * entropy_weights\n",
        "    combined_weights = combined_weights / combined_weights.sum()\n",
        "\n",
        "    print(\"\\n‚öñÔ∏è Final ensemble weights (uniqueness + entropy):\")\n",
        "    for col, weight in zip(confidence_col_names, combined_weights):\n",
        "        print(f\"{col}: {weight:.4f}\")\n",
        "\n",
        "    # Weighted ensemble on confidence\n",
        "    weighted_conf = sum(\n",
        "        df_combined[col].fill_null(0) * weight\n",
        "        for col, weight in zip(confidence_col_names, combined_weights)\n",
        "    )\n",
        "    df_combined = df_combined.with_columns(weighted_conf.alias(\"ensemble_confidence\"))\n",
        "\n",
        "    # Ranking per group (ranker_id) by ensemble_confidence\n",
        "    df_ranked = df_combined.with_columns(\n",
        "        pl.col(\"ensemble_confidence\")\n",
        "        .rank(\"ordinal\", descending=True)\n",
        "        .over(\"ranker_id\")\n",
        "        .cast(pl.Int32)\n",
        "        .alias(\"selected\")\n",
        "    )\n",
        "\n",
        "    final_submission = df_ranked.select([\"Id\", \"ranker_id\", \"selected\"])\n",
        "\n",
        "    print(\"\\n‚úÖ Sample of final submission:\")\n",
        "    print(final_submission.head())\n",
        "\n",
        "    final_submission.write_parquet(\"submission_ensemble.parquet\")\n",
        "    print(\"\\nüíæ Saved as: submission_ensemble.parquet\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YLKD_plSt-3C",
        "outputId": "c70d30ef-6b8b-45da-dfa4-94a63092b18e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìä Spearman between models on RESIDUALS after PCA (k=5):\n",
            "                    confidence_0.51244  confidence_0.52795  \\\n",
            "confidence_0.51244            1.000000           -0.871089   \n",
            "confidence_0.52795           -0.871089            1.000000   \n",
            "confidence_0.52603            0.049608           -0.366223   \n",
            "confidence_0.52538            0.678231           -0.507004   \n",
            "confidence_0.48755           -0.036545            0.287423   \n",
            "confidence_0.51345           -0.463710            0.119839   \n",
            "confidence_0.52244           -0.239497           -0.023314   \n",
            "confidence_0.52391            0.297432           -0.020860   \n",
            "\n",
            "                    confidence_0.52603  confidence_0.52538  \\\n",
            "confidence_0.51244            0.049608            0.678231   \n",
            "confidence_0.52795           -0.366223           -0.507004   \n",
            "confidence_0.52603            1.000000           -0.487018   \n",
            "confidence_0.52538           -0.487018            1.000000   \n",
            "confidence_0.48755           -0.023417           -0.371223   \n",
            "confidence_0.51345            0.222213           -0.180638   \n",
            "confidence_0.52244           -0.012474            0.168526   \n",
            "confidence_0.52391           -0.017873           -0.100784   \n",
            "\n",
            "                    confidence_0.48755  confidence_0.51345  \\\n",
            "confidence_0.51244           -0.036545           -0.463710   \n",
            "confidence_0.52795            0.287423            0.119839   \n",
            "confidence_0.52603           -0.023417            0.222213   \n",
            "confidence_0.52538           -0.371223           -0.180638   \n",
            "confidence_0.48755            1.000000           -0.769280   \n",
            "confidence_0.51345           -0.769280            1.000000   \n",
            "confidence_0.52244           -0.939308            0.903305   \n",
            "confidence_0.52391            0.912422           -0.934220   \n",
            "\n",
            "                    confidence_0.52244  confidence_0.52391  \n",
            "confidence_0.51244           -0.239497            0.297432  \n",
            "confidence_0.52795           -0.023314           -0.020860  \n",
            "confidence_0.52603           -0.012474           -0.017873  \n",
            "confidence_0.52538            0.168526           -0.100784  \n",
            "confidence_0.48755           -0.939308            0.912422  \n",
            "confidence_0.51345            0.903305           -0.934220  \n",
            "confidence_0.52244            1.000000           -0.995983  \n",
            "confidence_0.52391           -0.995983            1.000000  \n",
            "\n",
            "‚öñÔ∏è Final ensemble weights (uniqueness + entropy):\n",
            "confidence_0.51244: 0.1215\n",
            "confidence_0.52795: 0.1296\n",
            "confidence_0.52603: 0.1220\n",
            "confidence_0.52538: 0.1237\n",
            "confidence_0.48755: 0.1251\n",
            "confidence_0.51345: 0.1268\n",
            "confidence_0.52244: 0.1271\n",
            "confidence_0.52391: 0.1243\n",
            "\n",
            "‚úÖ Sample of final submission:\n",
            "shape: (5, 3)\n",
            "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
            "‚îÇ Id       ‚îÜ ranker_id                       ‚îÜ selected ‚îÇ\n",
            "‚îÇ ---      ‚îÜ ---                             ‚îÜ ---      ‚îÇ\n",
            "‚îÇ i64      ‚îÜ str                             ‚îÜ i32      ‚îÇ\n",
            "‚ïû‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï°\n",
            "‚îÇ 18144679 ‚îÜ c9373e5f772e43d593dd6ad2fa90f6‚Ä¶ ‚îÜ 4        ‚îÇ\n",
            "‚îÇ 18144680 ‚îÜ c9373e5f772e43d593dd6ad2fa90f6‚Ä¶ ‚îÜ 21       ‚îÇ\n",
            "‚îÇ 18144681 ‚îÜ c9373e5f772e43d593dd6ad2fa90f6‚Ä¶ ‚îÜ 259      ‚îÇ\n",
            "‚îÇ 18144682 ‚îÜ c9373e5f772e43d593dd6ad2fa90f6‚Ä¶ ‚îÜ 16       ‚îÇ\n",
            "‚îÇ 18144683 ‚îÜ c9373e5f772e43d593dd6ad2fa90f6‚Ä¶ ‚îÜ 57       ‚îÇ\n",
            "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
            "\n",
            "üíæ Saved as: submission_ensemble.parquet\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import polars as pl\n",
        "import os\n",
        "\n",
        "def compute_confidence(df: pl.DataFrame, alpha: float = 0.7, k: int = 5) -> pl.DataFrame:\n",
        "    # mƒÉrimea grupului pentru fiecare ranker_id\n",
        "    df = df.with_columns([\n",
        "        pl.len().over(\"ranker_id\").alias(\"group_size\")\n",
        "    ])\n",
        "\n",
        "    # 1) scorul de bazƒÉ pe pozi»õie √Æn cadrul grupului (maxim pentru selected=1)\n",
        "    base_conf = 1.0 - ((pl.col(\"selected\") - 1) / (pl.col(\"group_size\") - 1 + 1e-8))\n",
        "    df = df.with_columns(base_conf.alias(\"confidence\"))\n",
        "\n",
        "    # 2) scorul RRF normalizat la [0, 1]\n",
        "    rrf_max = 1.0 / (k + 1)  # valoarea RRF pentru selected=1\n",
        "    df = df.with_columns(\n",
        "        ((1.0 / (k + pl.col(\"selected\"))) / rrf_max).alias(\"rrf_score\")\n",
        "    )\n",
        "\n",
        "    # 3) combina»õie convexƒÉ √Æntre scorul de bazƒÉ »ôi RRF\n",
        "    df = df.with_columns(\n",
        "        (alpha * pl.col(\"confidence\") + (1 - alpha) * pl.col(\"rrf_score\")).alias(\"confidence\")\n",
        "    )\n",
        "\n",
        "    # pƒÉstrƒÉm 'selected'; curƒÉ»õƒÉm doar coloanele temporare\n",
        "    return df.drop([\"group_size\", \"rrf_score\"])\n",
        "\n",
        "def process_file(input_path: str, alpha: float = 0.7, k: int = 5):\n",
        "    print(f\"üîÑ Processing: {input_path}\")\n",
        "\n",
        "    if input_path.endswith(\".csv\"):\n",
        "        df = pl.read_csv(input_path)\n",
        "    elif input_path.endswith(\".parquet\"):\n",
        "        df = pl.read_parquet(input_path)\n",
        "    else:\n",
        "        print(f\"‚ö†Ô∏è Skipping unsupported file: {input_path}\")\n",
        "        return\n",
        "\n",
        "    df_conf = compute_confidence(df, alpha=alpha, k=k)\n",
        "\n",
        "    base, ext = os.path.splitext(input_path)\n",
        "    if base.endswith(\"_with_confidence\"):\n",
        "        output_path = f\"{base}.csv\"\n",
        "    else:\n",
        "        output_path = f\"{base}_with_confidence.csv\"\n",
        "\n",
        "    df_conf.write_csv(output_path)\n",
        "    print(f\"‚úÖ Saved: {output_path}\\n\")\n",
        "\n",
        "\n",
        "def main():\n",
        "    files = [\n",
        "        \"submission_ensemble_xgb.parquet\",\n",
        "        \"submission_ensemble_lgb.parquet\"\n",
        "    ]\n",
        "\n",
        "    alpha = 0.7\n",
        "    k = 5\n",
        "\n",
        "    for file in files:\n",
        "        if os.path.exists(file):\n",
        "            process_file(file, alpha=alpha, k=k)\n",
        "        else:\n",
        "            print(f\"‚ùå File not found: {file}\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HWmAyfhSF9XB",
        "outputId": "4a98d53c-290d-4a59-fc84-1aab9da0b8bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîÑ Processing: submission_ensemble_xgb.parquet\n",
            "‚úÖ Saved: submission_ensemble_xgb_with_confidence.csv\n",
            "\n",
            "üîÑ Processing: submission_ensemble_lgb.parquet\n",
            "‚úÖ Saved: submission_ensemble_lgb_with_confidence.csv\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import polars as pl\n",
        "from pathlib import Path\n",
        "\n",
        "# ---------------------\n",
        "# FILES TO ENSEMBLE\n",
        "# ---------------------\n",
        "INPUT_FILES = [\n",
        "    \"submission_0.51822_with_confidence.csv\",\n",
        "    \"submission_dl_ranker_with_confidence.csv\",\n",
        "    \"submission_0.52244_with_confidence.csv\"\n",
        "]\n",
        "\n",
        "OUTPUT_FILE = \"submission_ensemble.parquet\"\n",
        "\n",
        "# ---------------------\n",
        "# LOAD & CONCAT\n",
        "# ---------------------\n",
        "dfs = []\n",
        "\n",
        "for path in INPUT_FILES:\n",
        "    if not Path(path).exists():\n",
        "        raise FileNotFoundError(f\"‚ùå File not found: {path}\")\n",
        "\n",
        "    df = pl.read_csv(path).drop(\"selected\", strict=False)  # drop selected if exists\n",
        "    if \"confidence\" not in df.columns:\n",
        "        raise ValueError(f\"‚ö†Ô∏è Missing 'confidence' column in {path}\")\n",
        "\n",
        "    dfs.append(df)\n",
        "\n",
        "# ---------------------\n",
        "# ENSEMBLE LOGIC\n",
        "# ---------------------\n",
        "# Concatenate and aggregate confidence per Id + ranker_id\n",
        "df_combined = (\n",
        "    pl.concat(dfs)\n",
        "    .group_by([\"Id\", \"ranker_id\"])\n",
        "    .agg(pl.sum(\"confidence\").alias(\"confidence_sum\"))\n",
        ")\n",
        "\n",
        "# Rank within each ranker_id\n",
        "df_ranked = (\n",
        "    df_combined.with_columns([\n",
        "        pl.col(\"confidence_sum\")\n",
        "        .rank(method=\"ordinal\", descending=True)\n",
        "        .over(\"ranker_id\")\n",
        "        .cast(pl.Int32)\n",
        "        .alias(\"selected\")\n",
        "    ])\n",
        ")\n",
        "\n",
        "# Load original ordering from first file\n",
        "df_original = pl.read_csv(INPUT_FILES[0]).select([\"Id\", \"ranker_id\"])\n",
        "\n",
        "# Join and keep only relevant columns\n",
        "final_submission = (\n",
        "    df_original.join(\n",
        "        df_ranked.select([\"Id\", \"ranker_id\", \"selected\"]),\n",
        "        on=[\"Id\", \"ranker_id\"],\n",
        "        how=\"left\"\n",
        "    )\n",
        ")\n",
        "\n",
        "# ---------------------\n",
        "# SAVE\n",
        "# ---------------------\n",
        "final_submission.write_parquet(OUTPUT_FILE)\n",
        "print(f\"‚úÖ Ensemble saved as {OUTPUT_FILE}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y97Zcxgj-0zO",
        "outputId": "a140cbd0-6c28-4fda-e59b-5df54a2278bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Ensemble saved as submission_ensemble.parquet\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Boosting**"
      ],
      "metadata": {
        "id": "4_RrbFccPWyS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import polars as pl\n",
        "from pathlib import Path\n",
        "\n",
        "# ---------------------\n",
        "# CONFIG\n",
        "# ---------------------\n",
        "V1 = \"submission_dl_ranker_0.48755_with_confidence.csv\"\n",
        "V2 = \"submission_dl_ranker_0.49242_with_confidence.csv\"\n",
        "OUTPUT_FILE = \"submission_dl_ranker_weighted_boosted_normalized.csv\"\n",
        "\n",
        "WEIGHT_V1 = 0.65\n",
        "WEIGHT_V2 = 0.35\n",
        "BOOST_IF_EQUAL = 1.2\n",
        "EPSILON = 1e-8  # pentru comparare »ôi normalizare\n",
        "\n",
        "# ---------------------\n",
        "# LOAD FILES\n",
        "# ---------------------\n",
        "def load_conf_df(path: str) -> pl.DataFrame:\n",
        "    if not Path(path).exists():\n",
        "        raise FileNotFoundError(f\"‚ùå File not found: {path}\")\n",
        "    df = pl.read_csv(path) if path.endswith(\".csv\") else pl.read_parquet(path)\n",
        "    if \"confidence\" not in df.columns:\n",
        "        raise ValueError(f\"‚ö†Ô∏è Missing 'confidence' column in {path}\")\n",
        "    return df.drop(\"selected\", strict=False)\n",
        "\n",
        "df_v1 = load_conf_df(V1).rename({\"confidence\": \"confidence_v1\"})\n",
        "df_v2 = load_conf_df(V2).rename({\"confidence\": \"confidence_v2\"})\n",
        "\n",
        "# ---------------------\n",
        "# JOIN FILES\n",
        "# ---------------------\n",
        "df_joined = df_v1.join(df_v2, on=[\"Id\", \"ranker_id\"], how=\"inner\")\n",
        "\n",
        "# ---------------------\n",
        "# DETERMINE BOOST FLAG (before weighting)\n",
        "# ---------------------\n",
        "df_with_flag = df_joined.with_columns([\n",
        "    ((pl.col(\"confidence_v1\") - pl.col(\"confidence_v2\")).abs() < EPSILON).alias(\"apply_boost\")\n",
        "])\n",
        "\n",
        "# ---------------------\n",
        "# COMPUTE WEIGHTED CONFIDENCE + APPLY BOOST\n",
        "# ---------------------\n",
        "df_weighted = df_with_flag.with_columns([\n",
        "    (WEIGHT_V1 * pl.col(\"confidence_v1\") + WEIGHT_V2 * pl.col(\"confidence_v2\")).alias(\"base_confidence\")\n",
        "])\n",
        "\n",
        "df_boosted = df_weighted.with_columns([\n",
        "    pl.when(pl.col(\"apply_boost\"))\n",
        "    .then(pl.col(\"base_confidence\") * BOOST_IF_EQUAL)\n",
        "    .otherwise(pl.col(\"base_confidence\"))\n",
        "    .alias(\"confidence\")\n",
        "])\n",
        "\n",
        "# ---------------------\n",
        "# NORMALIZE CONFIDENCE TO [0, 1]\n",
        "# ---------------------\n",
        "min_conf, max_conf = df_boosted.select([\n",
        "    pl.col(\"confidence\").min().alias(\"min\"),\n",
        "    pl.col(\"confidence\").max().alias(\"max\")\n",
        "]).row(0)\n",
        "\n",
        "df_normalized = df_boosted.with_columns([\n",
        "    ((pl.col(\"confidence\") - min_conf) / (max_conf - min_conf + EPSILON)).alias(\"confidence_normalized\")\n",
        "])\n",
        "\n",
        "# ---------------------\n",
        "# SELECT & SAVE\n",
        "# ---------------------\n",
        "df_output = df_normalized.select([\"Id\", \"ranker_id\", \"confidence_normalized\"]).rename({\"confidence_normalized\": \"confidence\"})\n",
        "df_output.write_csv(OUTPUT_FILE)\n",
        "\n",
        "print(f\"‚úÖ Weighted, boosted, and normalized confidence saved to {OUTPUT_FILE}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "agOc-q8jaMmw",
        "outputId": "3559f1f0-229c-41a6-8465-41ed9e24b64e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Weighted, boosted, and normalized confidence saved to submission_dl_ranker_weighted_boosted_normalized.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import polars as pl\n",
        "from pathlib import Path\n",
        "\n",
        "# ---------------------\n",
        "# FILES\n",
        "# ---------------------\n",
        "V1 = \"submission_ensemble_0.53108_with_confidence.csv\"\n",
        "V2 = \"submission_ensemble_0.53135_with_confidence.csv\"\n",
        "OUTPUT_FILE = \"submission_ensemble_boosted.parquet\"\n",
        "\n",
        "# ---------------------\n",
        "# LOAD FILES\n",
        "# ---------------------\n",
        "def load_conf_df(path: str) -> pl.DataFrame:\n",
        "    if not Path(path).exists():\n",
        "        raise FileNotFoundError(f\"‚ùå File not found: {path}\")\n",
        "    df = pl.read_csv(path) if path.endswith(\".csv\") else pl.read_parquet(path)\n",
        "    if \"confidence\" not in df.columns:\n",
        "        raise ValueError(f\"‚ö†Ô∏è Missing 'confidence' column in {path}\")\n",
        "    return df.drop(\"selected\", strict=False)\n",
        "\n",
        "df_v1 = load_conf_df(V1)\n",
        "df_v2 = load_conf_df(V2)\n",
        "\n",
        "# ---------------------\n",
        "# BUILD top6 per ranker_id\n",
        "# ---------------------\n",
        "def build_top6_map(df: pl.DataFrame) -> dict[str, set[str]]:\n",
        "    ranked = (\n",
        "        df.with_columns(\n",
        "            pl.col(\"confidence\")\n",
        "            .rank(\"ordinal\", descending=True)\n",
        "            .over(\"ranker_id\")\n",
        "            .alias(\"rank\")\n",
        "        )\n",
        "        .filter(pl.col(\"rank\") <= 6)\n",
        "        .group_by(\"ranker_id\")\n",
        "        .agg(pl.col(\"Id\").alias(\"top6\"))\n",
        "    )\n",
        "    return {row[\"ranker_id\"]: set(row[\"top6\"]) for row in ranked.iter_rows(named=True)}\n",
        "\n",
        "top6_v1 = build_top6_map(df_v1)\n",
        "top6_v2 = build_top6_map(df_v2)\n",
        "\n",
        "# ---------------------\n",
        "# COMBINE v1 + v2 WITH BOOST ONLY FOR SHARED TOP6 IDs\n",
        "# ---------------------\n",
        "df_v1v2 = pl.concat([df_v1, df_v2])\n",
        "df_grouped = (\n",
        "    df_v1v2\n",
        "    .group_by([\"Id\", \"ranker_id\"])\n",
        "    .agg(pl.sum(\"confidence\").alias(\"conf_sum\"))\n",
        ")\n",
        "\n",
        "boosted_rows = []\n",
        "for row in df_grouped.iter_rows(named=True):\n",
        "    id_, ranker_id, conf = row[\"Id\"], row[\"ranker_id\"], row[\"conf_sum\"]\n",
        "    top1 = top6_v1.get(ranker_id, set())\n",
        "    top2 = top6_v2.get(ranker_id, set())\n",
        "    shared_top6 = top1 & top2\n",
        "\n",
        "    if id_ in shared_top6:\n",
        "        n_shared = len(shared_top6)\n",
        "        boost = 1.5 if n_shared >= 6 else 1.4 if n_shared >= 4 else 1.3\n",
        "    else:\n",
        "        boost = 1.0\n",
        "\n",
        "    boosted_rows.append({\n",
        "        \"Id\": id_,\n",
        "        \"ranker_id\": ranker_id,\n",
        "        \"confidence\": conf * boost\n",
        "    })\n",
        "\n",
        "df_boosted = pl.DataFrame(boosted_rows)\n",
        "\n",
        "# ---------------------\n",
        "# RANK\n",
        "# ---------------------\n",
        "df_ranked = df_boosted.with_columns([\n",
        "    pl.col(\"confidence\")\n",
        "    .rank(method=\"ordinal\", descending=True)\n",
        "    .over(\"ranker_id\")\n",
        "    .cast(pl.Int32)\n",
        "    .alias(\"selected\")\n",
        "])\n",
        "\n",
        "# ---------------------\n",
        "# RESTORE ORIGINAL ORDER\n",
        "# ---------------------\n",
        "df_original = df_v1.select([\"Id\", \"ranker_id\"])\n",
        "final_submission = df_original.join(\n",
        "    df_ranked.select([\"Id\", \"ranker_id\", \"selected\"]),\n",
        "    on=[\"Id\", \"ranker_id\"],\n",
        "    how=\"left\"\n",
        ")\n",
        "\n",
        "# ---------------------\n",
        "# SAVE\n",
        "# ---------------------\n",
        "final_submission.write_parquet(OUTPUT_FILE)\n",
        "print(f\"‚úÖ Boosted ensemble (Top6) saved to {OUTPUT_FILE}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kcALhJJwPGjt",
        "outputId": "e6f5d38e-020c-4358-ebb9-99b84df1f9f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Boosted ensemble (Top6) saved to submission_ensemble_boosted.parquet\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import polars as pl\n",
        "from pathlib import Path\n",
        "\n",
        "# ---------------------\n",
        "# FILES\n",
        "# ---------------------\n",
        "V1 = \"submission_ensemble_0.53007_with_confidence.csv\"\n",
        "V2 = \"submission_ensemble_0.53108_with_confidence.csv\"\n",
        "OUTPUT_FILE = \"submission_ensemble_boosted.parquet\"\n",
        "\n",
        "# ---------------------\n",
        "# LOAD FILES\n",
        "# ---------------------\n",
        "def load_conf_df(path: str) -> pl.DataFrame:\n",
        "    if not Path(path).exists():\n",
        "        raise FileNotFoundError(f\"‚ùå File not found: {path}\")\n",
        "    df = pl.read_csv(path) if path.endswith(\".csv\") else pl.read_parquet(path)\n",
        "    if \"confidence\" not in df.columns:\n",
        "        raise ValueError(f\"‚ö†Ô∏è Missing 'confidence' column in {path}\")\n",
        "    return df.drop(\"selected\", strict=False)\n",
        "\n",
        "df_v1 = load_conf_df(V1)\n",
        "df_v2 = load_conf_df(V2)\n",
        "\n",
        "# ---------------------\n",
        "# BUILD top5 per ranker_id\n",
        "# ---------------------\n",
        "def build_top5_map(df: pl.DataFrame) -> dict[str, set[str]]:\n",
        "    ranked = (\n",
        "        df.with_columns(\n",
        "            pl.col(\"confidence\")\n",
        "            .rank(\"ordinal\", descending=True)\n",
        "            .over(\"ranker_id\")\n",
        "            .alias(\"rank\")\n",
        "        )\n",
        "        .filter(pl.col(\"rank\") <= 5)\n",
        "        .group_by(\"ranker_id\")\n",
        "        .agg(pl.col(\"Id\").alias(\"top5\"))\n",
        "    )\n",
        "    return {row[\"ranker_id\"]: set(row[\"top5\"]) for row in ranked.iter_rows(named=True)}\n",
        "\n",
        "top5_v1 = build_top5_map(df_v1)\n",
        "top5_v2 = build_top5_map(df_v2)\n",
        "\n",
        "# ---------------------\n",
        "# COMBINE v1 + v2 WITH BOOST ONLY FOR SHARED TOP5 IDs\n",
        "# ---------------------\n",
        "df_v1v2 = pl.concat([df_v1, df_v2])\n",
        "df_grouped = (\n",
        "    df_v1v2\n",
        "    .group_by([\"Id\", \"ranker_id\"])\n",
        "    .agg(pl.sum(\"confidence\").alias(\"conf_sum\"))\n",
        ")\n",
        "\n",
        "boosted_rows = []\n",
        "for row in df_grouped.iter_rows(named=True):\n",
        "    id_, ranker_id, conf = row[\"Id\"], row[\"ranker_id\"], row[\"conf_sum\"]\n",
        "    shared_top5 = top5_v1.get(ranker_id, set()) & top5_v2.get(ranker_id, set())\n",
        "\n",
        "    # Apply a fixed boost of 1.5 only if the current ID is in shared top5\n",
        "    boost = 1.4 if id_ in shared_top5 else 1.0\n",
        "\n",
        "    boosted_rows.append({\n",
        "        \"Id\": id_,\n",
        "        \"ranker_id\": ranker_id,\n",
        "        \"confidence\": conf * boost\n",
        "    })\n",
        "\n",
        "df_boosted = pl.DataFrame(boosted_rows)\n",
        "\n",
        "# ---------------------\n",
        "# RANK\n",
        "# ---------------------\n",
        "df_ranked = df_boosted.with_columns([\n",
        "    pl.col(\"confidence\")\n",
        "    .rank(method=\"ordinal\", descending=True)\n",
        "    .over(\"ranker_id\")\n",
        "    .cast(pl.Int32)\n",
        "    .alias(\"selected\")\n",
        "])\n",
        "\n",
        "# ---------------------\n",
        "# RESTORE ORIGINAL ORDER\n",
        "# ---------------------\n",
        "df_original = df_v1.select([\"Id\", \"ranker_id\"])\n",
        "final_submission = df_original.join(\n",
        "    df_ranked.select([\"Id\", \"ranker_id\", \"selected\"]),\n",
        "    on=[\"Id\", \"ranker_id\"],\n",
        "    how=\"left\"\n",
        ")\n",
        "\n",
        "# ---------------------\n",
        "# SAVE\n",
        "# ---------------------\n",
        "final_submission.write_parquet(OUTPUT_FILE)\n",
        "print(f\"‚úÖ Boosted ensemble (Top5 shared, boost=1.5) saved to {OUTPUT_FILE}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lDWH9zabifCm",
        "outputId": "f918efb2-bd89-47b4-84c5-66bb4945a963"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Boosted ensemble (Top5 shared, boost=1.5) saved to submission_ensemble_boosted.parquet\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile boosting.py\n",
        "import polars as pl\n",
        "from pathlib import Path\n",
        "from collections import defaultdict\n",
        "\n",
        "# ---------------------\n",
        "# FILES\n",
        "# ---------------------\n",
        "V1 = \"submission_0.51822_with_confidence.csv\"\n",
        "V2 = \"submission_0.52244_with_confidence.csv\"\n",
        "V3 = \"submission_dl_ranker_with_confidence.csv\"\n",
        "OUTPUT_FILE = \"submission_ensemble_boosted.parquet\"\n",
        "\n",
        "# ---------------------\n",
        "# LOAD FILES\n",
        "# ---------------------\n",
        "def load_conf_df(path: str) -> pl.DataFrame:\n",
        "    if not Path(path).exists():\n",
        "        raise FileNotFoundError(f\"‚ùå File not found: {path}\")\n",
        "    df = pl.read_csv(path).drop(\"selected\", strict=False)\n",
        "    if \"confidence\" not in df.columns:\n",
        "        raise ValueError(f\"‚ö†Ô∏è Missing 'confidence' column in {path}\")\n",
        "    return df\n",
        "\n",
        "df_v1 = load_conf_df(V1)\n",
        "df_v2 = load_conf_df(V2)\n",
        "df_v3 = load_conf_df(V3)\n",
        "\n",
        "# ---------------------\n",
        "# BUILD top3 per ranker_id\n",
        "# ---------------------\n",
        "def build_top3_map(df: pl.DataFrame) -> dict[str, set[str]]:\n",
        "    ranked = (\n",
        "        df.with_columns(\n",
        "            pl.col(\"confidence\").rank(\"ordinal\", descending=True).over(\"ranker_id\").alias(\"rank\")\n",
        "        )\n",
        "        .filter(pl.col(\"rank\") <= 3)\n",
        "        .group_by(\"ranker_id\")\n",
        "        .agg(pl.col(\"Id\").alias(\"top3\"))\n",
        "    )\n",
        "    return {row[\"ranker_id\"]: set(row[\"top3\"]) for row in ranked.iter_rows(named=True)}\n",
        "\n",
        "top3_v1 = build_top3_map(df_v1)\n",
        "top3_v2 = build_top3_map(df_v2)\n",
        "\n",
        "# ---------------------\n",
        "# COMBINE v1 + v2 WITH BOOST ONLY FOR SHARED TOP3 IDs\n",
        "# ---------------------\n",
        "df_v1v2 = pl.concat([df_v1, df_v2])\n",
        "df_grouped = (\n",
        "    df_v1v2\n",
        "    .group_by([\"Id\", \"ranker_id\"])\n",
        "    .agg(pl.sum(\"confidence\").alias(\"conf_v1v2\"))\n",
        ")\n",
        "\n",
        "boosted_rows = []\n",
        "\n",
        "for row in df_grouped.iter_rows(named=True):\n",
        "    id_, ranker_id, conf = row[\"Id\"], row[\"ranker_id\"], row[\"conf_v1v2\"]\n",
        "    top1 = top3_v1.get(ranker_id, set())\n",
        "    top2 = top3_v2.get(ranker_id, set())\n",
        "    shared_top3 = top1 & top2\n",
        "\n",
        "    if id_ in shared_top3:\n",
        "        if len(shared_top3) == 3:\n",
        "            boost = 1.5\n",
        "        elif len(shared_top3) == 2:\n",
        "            boost = 1.4\n",
        "        elif len(shared_top3) == 1:\n",
        "            boost = 1.3\n",
        "        else:\n",
        "            boost = 1.0\n",
        "    else:\n",
        "        boost = 1.0\n",
        "\n",
        "    boosted_rows.append({\n",
        "        \"Id\": id_,\n",
        "        \"ranker_id\": ranker_id,\n",
        "        \"confidence\": conf * boost\n",
        "    })\n",
        "\n",
        "df_boosted_v1v2 = pl.DataFrame(boosted_rows)\n",
        "\n",
        "# ---------------------\n",
        "# ADD dl_ranker (v3)\n",
        "# ---------------------\n",
        "df_final_conf = (\n",
        "    pl.concat([df_boosted_v1v2, df_v3])\n",
        "    .group_by([\"Id\", \"ranker_id\"])\n",
        "    .agg(pl.sum(\"confidence\").alias(\"confidence_sum\"))\n",
        ")\n",
        "\n",
        "# ---------------------\n",
        "# RANK\n",
        "# ---------------------\n",
        "df_ranked = (\n",
        "    df_final_conf.with_columns([\n",
        "        pl.col(\"confidence_sum\")\n",
        "        .rank(method=\"ordinal\", descending=True)\n",
        "        .over(\"ranker_id\")\n",
        "        .cast(pl.Int32)\n",
        "        .alias(\"selected\")\n",
        "    ])\n",
        ")\n",
        "\n",
        "# ---------------------\n",
        "# RESTORE ORIGINAL ORDER\n",
        "# ---------------------\n",
        "df_original = df_v1.select([\"Id\", \"ranker_id\"])\n",
        "final_submission = (\n",
        "    df_original.join(\n",
        "        df_ranked.select([\"Id\", \"ranker_id\", \"selected\"]),\n",
        "        on=[\"Id\", \"ranker_id\"],\n",
        "        how=\"left\"\n",
        "    )\n",
        ")\n",
        "\n",
        "# ---------------------\n",
        "# SAVE\n",
        "# ---------------------\n",
        "final_submission.write_parquet(OUTPUT_FILE)\n",
        "print(f\"‚úÖ Boosted ensemble saved to {OUTPUT_FILE}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G7T_kP69zvdy",
        "outputId": "4b7a57c5-4902-4074-de3a-abcd811df9fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting boosting.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile boosting.py\n",
        "import polars as pl\n",
        "from pathlib import Path\n",
        "\n",
        "# ---------------------\n",
        "# FILES\n",
        "# ---------------------\n",
        "V1 = \"submission_0.51822_with_confidence.csv\"\n",
        "V2 = \"submission_0.52244_with_confidence.csv\"\n",
        "V3 = \"submission_dl_ranker_with_confidence.csv\"\n",
        "OUTPUT_FILE = \"submission_ensemble_boosted.parquet\"\n",
        "\n",
        "# ---------------------\n",
        "# LOAD FILES\n",
        "# ---------------------\n",
        "def load_conf_df(path: str) -> pl.DataFrame:\n",
        "    if not Path(path).exists():\n",
        "        raise FileNotFoundError(f\"‚ùå File not found: {path}\")\n",
        "    df = pl.read_csv(path).drop(\"selected\", strict=False)\n",
        "    if \"confidence\" not in df.columns:\n",
        "        raise ValueError(f\"‚ö†Ô∏è Missing 'confidence' column in {path}\")\n",
        "    return df\n",
        "\n",
        "df_v1 = load_conf_df(V1)\n",
        "df_v2 = load_conf_df(V2)\n",
        "df_v3 = load_conf_df(V3)\n",
        "\n",
        "# ---------------------\n",
        "# BUILD top3 per ranker_id\n",
        "# ---------------------\n",
        "def build_top3_map(df: pl.DataFrame) -> dict[str, set[str]]:\n",
        "    ranked = (\n",
        "        df.with_columns(\n",
        "            pl.col(\"confidence\").rank(\"ordinal\", descending=True).over(\"ranker_id\").alias(\"rank\")\n",
        "        )\n",
        "        .filter(pl.col(\"rank\") <= 3)\n",
        "        .group_by(\"ranker_id\")\n",
        "        .agg(pl.col(\"Id\").alias(\"top3\"))\n",
        "    )\n",
        "    return {row[\"ranker_id\"]: set(row[\"top3\"]) for row in ranked.iter_rows(named=True)}\n",
        "\n",
        "top3_v1 = build_top3_map(df_v1)\n",
        "top3_v2 = build_top3_map(df_v2)\n",
        "top3_v3 = build_top3_map(df_v3)\n",
        "\n",
        "# ---------------------\n",
        "# COMBINE ALL FILES\n",
        "# ---------------------\n",
        "df_all = pl.concat([df_v1, df_v2, df_v3])\n",
        "df_grouped = (\n",
        "    df_all\n",
        "    .group_by([\"Id\", \"ranker_id\"])\n",
        "    .agg(pl.sum(\"confidence\").alias(\"confidence_sum\"))\n",
        ")\n",
        "\n",
        "# ---------------------\n",
        "# APPLY BOOSTING STRATEGY\n",
        "# ---------------------\n",
        "boosted_rows = []\n",
        "\n",
        "for row in df_grouped.iter_rows(named=True):\n",
        "    id_, ranker_id, conf_sum = row[\"Id\"], row[\"ranker_id\"], row[\"confidence_sum\"]\n",
        "\n",
        "    top1 = top3_v1.get(ranker_id, set())\n",
        "    top2 = top3_v2.get(ranker_id, set())\n",
        "    top3 = top3_v3.get(ranker_id, set())\n",
        "\n",
        "    # All three top3 are identical\n",
        "    if top1 == top2 == top3 and id_ in top1:\n",
        "        boost = 2.0\n",
        "    else:\n",
        "        shared_all = top1 & top2 & top3\n",
        "        if len(shared_all) == 2 and id_ in shared_all:\n",
        "            boost = 1.8\n",
        "        elif len(shared_all) == 1 and id_ in shared_all:\n",
        "            boost = 1.7\n",
        "        else:\n",
        "            # fallback: use old logic between v1 and v2 only\n",
        "            shared_v1v2 = top1 & top2\n",
        "            if id_ in shared_v1v2:\n",
        "                if len(shared_v1v2) == 3:\n",
        "                    boost = 1.6\n",
        "                elif len(shared_v1v2) == 2:\n",
        "                    boost = 1.5\n",
        "                elif len(shared_v1v2) == 1:\n",
        "                    boost = 1.4\n",
        "                else:\n",
        "                    boost = 1.0\n",
        "            else:\n",
        "                boost = 1.0\n",
        "\n",
        "    boosted_rows.append({\n",
        "        \"Id\": id_,\n",
        "        \"ranker_id\": ranker_id,\n",
        "        \"confidence\": conf_sum * boost\n",
        "    })\n",
        "\n",
        "df_boosted = pl.DataFrame(boosted_rows)\n",
        "\n",
        "# ---------------------\n",
        "# RANK\n",
        "# ---------------------\n",
        "df_ranked = (\n",
        "    df_boosted.with_columns([\n",
        "        pl.col(\"confidence\")\n",
        "        .rank(method=\"ordinal\", descending=True)\n",
        "        .over(\"ranker_id\")\n",
        "        .cast(pl.Int32)\n",
        "        .alias(\"selected\")\n",
        "    ])\n",
        ")\n",
        "\n",
        "# ---------------------\n",
        "# RESTORE ORIGINAL ORDER\n",
        "# ---------------------\n",
        "df_original = df_v1.select([\"Id\", \"ranker_id\"])\n",
        "final_submission = (\n",
        "    df_original.join(\n",
        "        df_ranked.select([\"Id\", \"ranker_id\", \"selected\"]),\n",
        "        on=[\"Id\", \"ranker_id\"],\n",
        "        how=\"left\"\n",
        "    )\n",
        ")\n",
        "\n",
        "# ---------------------\n",
        "# SAVE\n",
        "# ---------------------\n",
        "final_submission.write_parquet(OUTPUT_FILE)\n",
        "print(f\"‚úÖ Boosted ensemble saved to {OUTPUT_FILE}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iE9ZwbPCOCXP",
        "outputId": "932b84f6-8413-42c4-ffef-25ecf5a4d711"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing boosting.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Spearman**"
      ],
      "metadata": {
        "id": "suJEFLBLPaZh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import polars as pl\n",
        "import glob\n",
        "import re\n",
        "import numpy as np\n",
        "\n",
        "def load_submission_with_confidence(filepath):\n",
        "    df = pl.read_csv(filepath)\n",
        "    if \"selected\" in df.columns:\n",
        "        df = df.drop(\"selected\")\n",
        "    return df\n",
        "\n",
        "def main():\n",
        "    # CƒÉutƒÉm toate fi»ôierele CSV cu _with_confidence\n",
        "    filepaths = glob.glob(\"submission_*_*_with_confidence.csv\")\n",
        "\n",
        "    dfs = []\n",
        "    confidence_col_names = []\n",
        "\n",
        "    for filepath in filepaths:\n",
        "        # Extragem scorul exact din numele fi»ôierului\n",
        "        match = re.search(r\"submission_.*_([\\d.]+)_with_confidence\\.csv\", filepath)\n",
        "        if match:\n",
        "            score = match.group(1)\n",
        "            score_str = score  # nu mai normalizƒÉm scorul\n",
        "            df = load_submission_with_confidence(filepath)\n",
        "            confidence_col = f\"confidence_{score_str}\"\n",
        "            df = df.with_columns(pl.col(\"confidence\").alias(confidence_col)).drop(\"confidence\")\n",
        "            confidence_col_names.append(confidence_col)\n",
        "            dfs.append(df)\n",
        "\n",
        "    if not dfs:\n",
        "        print(\"‚ùå Nu s-au gƒÉsit fi»ôiere valide.\")\n",
        "        return\n",
        "\n",
        "    # CombinƒÉm toate datele pe baza Id + ranker_id\n",
        "    df_combined = dfs[0]\n",
        "    for df in dfs[1:]:\n",
        "        df_combined = df_combined.join(df, on=[\"Id\", \"ranker_id\"])\n",
        "\n",
        "    # CalculƒÉm corela»õia Spearman\n",
        "    corr_df = df_combined.select(confidence_col_names).to_pandas().corr(method=\"spearman\")\n",
        "    print(\"üìä Corela»õie Spearman √Æntre modele:\")\n",
        "    print(corr_df)\n",
        "\n",
        "    # CalculƒÉm unicitatea modelelor »ôi ponderile\n",
        "    mean_corr = corr_df.apply(lambda row: (row.sum() - 1) / (len(row) - 1), axis=1)\n",
        "    model_uniqueness = 1 - mean_corr\n",
        "    weights = model_uniqueness / model_uniqueness.sum()\n",
        "\n",
        "    print(\"\\n‚öñÔ∏è Ponderi calculate:\")\n",
        "    for col, weight in zip(confidence_col_names, weights.values):\n",
        "        print(f\"{col}: {weight:.4f}\")\n",
        "\n",
        "    # Ensemble ponderat\n",
        "    weighted_conf = sum(\n",
        "        df_combined[col].fill_null(0) * weight\n",
        "        for col, weight in zip(confidence_col_names, weights.values)\n",
        "    )\n",
        "\n",
        "    df_combined = df_combined.with_columns(weighted_conf.alias(\"ensemble_confidence\"))\n",
        "\n",
        "    # RankƒÉm √Æn func»õie de ensemble_confidence\n",
        "    df_ranked = df_combined.with_columns(\n",
        "        pl.col(\"ensemble_confidence\")\n",
        "        .rank(\"ordinal\", descending=True)\n",
        "        .over(\"ranker_id\")\n",
        "        .cast(pl.Int32)\n",
        "        .alias(\"selected\")\n",
        "    )\n",
        "\n",
        "    # Rezultatul final\n",
        "    final_submission = df_ranked.select([\"Id\", \"ranker_id\", \"selected\"])\n",
        "\n",
        "    print(\"\\n‚úÖ Exemplu din rezultatul final:\")\n",
        "    print(final_submission.head())\n",
        "\n",
        "    final_submission.write_csv(\"submission_ensemble.csv\")\n",
        "    print(\"\\nüíæ Salvare completƒÉ: submission_ensemble.csv\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uD5SKEMnf-cc",
        "outputId": "32913531-3ef7-42ed-f0d3-671f204a8668"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìä Corela»õie Spearman √Æntre modele:\n",
            "                    confidence_0.52474  confidence_0.49380  \\\n",
            "confidence_0.52474            1.000000            0.894615   \n",
            "confidence_0.49380            0.894615            1.000000   \n",
            "confidence_0.52795            0.979722            0.895570   \n",
            "confidence_0.51345            0.935174            0.897351   \n",
            "confidence_0.52391            0.958787            0.897411   \n",
            "confidence_0.51244            0.949075            0.898176   \n",
            "confidence_0.52603            0.982708            0.896322   \n",
            "confidence_0.52244            0.958957            0.899752   \n",
            "\n",
            "                    confidence_0.52795  confidence_0.51345  \\\n",
            "confidence_0.52474            0.979722            0.935174   \n",
            "confidence_0.49380            0.895570            0.897351   \n",
            "confidence_0.52795            1.000000            0.937831   \n",
            "confidence_0.51345            0.937831            1.000000   \n",
            "confidence_0.52391            0.961404            0.949847   \n",
            "confidence_0.51244            0.954461            0.944147   \n",
            "confidence_0.52603            0.982173            0.935918   \n",
            "confidence_0.52244            0.956795            0.948437   \n",
            "\n",
            "                    confidence_0.52391  confidence_0.51244  \\\n",
            "confidence_0.52474            0.958787            0.949075   \n",
            "confidence_0.49380            0.897411            0.898176   \n",
            "confidence_0.52795            0.961404            0.954461   \n",
            "confidence_0.51345            0.949847            0.944147   \n",
            "confidence_0.52391            1.000000            0.936022   \n",
            "confidence_0.51244            0.936022            1.000000   \n",
            "confidence_0.52603            0.962633            0.951352   \n",
            "confidence_0.52244            0.973582            0.932722   \n",
            "\n",
            "                    confidence_0.52603  confidence_0.52244  \n",
            "confidence_0.52474            0.982708            0.958957  \n",
            "confidence_0.49380            0.896322            0.899752  \n",
            "confidence_0.52795            0.982173            0.956795  \n",
            "confidence_0.51345            0.935918            0.948437  \n",
            "confidence_0.52391            0.962633            0.973582  \n",
            "confidence_0.51244            0.951352            0.932722  \n",
            "confidence_0.52603            1.000000            0.957188  \n",
            "confidence_0.52244            0.957188            1.000000  \n",
            "\n",
            "‚öñÔ∏è Ponderi calculate:\n",
            "confidence_0.52474: 0.1020\n",
            "confidence_0.49380: 0.2156\n",
            "confidence_0.52795: 0.0993\n",
            "confidence_0.51345: 0.1350\n",
            "confidence_0.52391: 0.1078\n",
            "confidence_0.51244: 0.1298\n",
            "confidence_0.52603: 0.0992\n",
            "confidence_0.52244: 0.1114\n",
            "\n",
            "‚úÖ Exemplu din rezultatul final:\n",
            "shape: (5, 3)\n",
            "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
            "‚îÇ Id       ‚îÜ ranker_id                       ‚îÜ selected ‚îÇ\n",
            "‚îÇ ---      ‚îÜ ---                             ‚îÜ ---      ‚îÇ\n",
            "‚îÇ i64      ‚îÜ str                             ‚îÜ i32      ‚îÇ\n",
            "‚ïû‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï°\n",
            "‚îÇ 18144679 ‚îÜ c9373e5f772e43d593dd6ad2fa90f6‚Ä¶ ‚îÜ 2        ‚îÇ\n",
            "‚îÇ 18144680 ‚îÜ c9373e5f772e43d593dd6ad2fa90f6‚Ä¶ ‚îÜ 16       ‚îÇ\n",
            "‚îÇ 18144681 ‚îÜ c9373e5f772e43d593dd6ad2fa90f6‚Ä¶ ‚îÜ 263      ‚îÇ\n",
            "‚îÇ 18144682 ‚îÜ c9373e5f772e43d593dd6ad2fa90f6‚Ä¶ ‚îÜ 23       ‚îÇ\n",
            "‚îÇ 18144683 ‚îÜ c9373e5f772e43d593dd6ad2fa90f6‚Ä¶ ‚îÜ 40       ‚îÇ\n",
            "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
            "\n",
            "üíæ Salvare completƒÉ: submission_ensemble.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import polars as pl\n",
        "import glob\n",
        "import re\n",
        "import numpy as np\n",
        "\n",
        "def load_submission_with_confidence(filepath):\n",
        "    df = pl.read_csv(filepath)\n",
        "    if \"selected\" in df.columns:\n",
        "        df = df.drop(\"selected\")\n",
        "    return df\n",
        "\n",
        "def compute_entropy(probabilities):\n",
        "    p = np.clip(probabilities, 1e-9, 1.0)\n",
        "    return -np.sum(p * np.log(p))\n",
        "\n",
        "def main():\n",
        "    # Find all submission files with confidence\n",
        "    filepaths = glob.glob(\"submission_*_*_with_confidence.csv\")\n",
        "\n",
        "    dfs = []\n",
        "    confidence_col_names = []\n",
        "\n",
        "    for filepath in filepaths:\n",
        "        match = re.search(r\"submission_.*_([\\d.]+)_with_confidence\\.csv\", filepath)\n",
        "        if match:\n",
        "            score = match.group(1)\n",
        "            df = load_submission_with_confidence(filepath)\n",
        "            confidence_col = f\"confidence_{score}\"\n",
        "            df = df.with_columns(pl.col(\"confidence\").alias(confidence_col)).drop(\"confidence\")\n",
        "            confidence_col_names.append(confidence_col)\n",
        "            dfs.append(df)\n",
        "\n",
        "    if not dfs:\n",
        "        print(\"‚ùå No valid submission files found.\")\n",
        "        return\n",
        "\n",
        "    # Join all dataframes on Id + ranker_id\n",
        "    df_combined = dfs[0]\n",
        "    for df in dfs[1:]:\n",
        "        df_combined = df_combined.join(df, on=[\"Id\", \"ranker_id\"])\n",
        "\n",
        "    # Spearman correlation between confidence columns\n",
        "    corr_df = df_combined.select(confidence_col_names).to_pandas().corr(method=\"spearman\")\n",
        "    print(\"üìä Spearman correlation between models:\")\n",
        "    print(corr_df)\n",
        "\n",
        "    # Uniqueness based on 1 - average Spearman correlation\n",
        "    mean_corr = corr_df.apply(lambda row: (row.sum() - 1) / (len(row) - 1), axis=1)\n",
        "    model_uniqueness = 1 - mean_corr\n",
        "    uniqueness_weights = model_uniqueness / model_uniqueness.sum()\n",
        "\n",
        "    # Entropy of each confidence column (as measure of uncertainty/informativeness)\n",
        "    entropies = []\n",
        "    for col in confidence_col_names:\n",
        "        probs = df_combined[col].to_numpy()\n",
        "        probs = probs / np.sum(probs)\n",
        "        entropies.append(compute_entropy(probs))\n",
        "\n",
        "    entropy_weights = np.array(entropies)\n",
        "    entropy_weights /= entropy_weights.sum()\n",
        "\n",
        "    # Combine uniqueness and entropy into final weights\n",
        "    alpha = 0.75  # higher = more weight on uniqueness\n",
        "    combined_weights = alpha * uniqueness_weights.values + (1 - alpha) * entropy_weights\n",
        "    combined_weights /= combined_weights.sum()\n",
        "\n",
        "    print(\"\\n‚öñÔ∏è Final ensemble weights (uniqueness + entropy):\")\n",
        "    for col, weight in zip(confidence_col_names, combined_weights):\n",
        "        print(f\"{col}: {weight:.4f}\")\n",
        "\n",
        "    # Weighted ensemble of confidence scores\n",
        "    weighted_conf = sum(\n",
        "        df_combined[col].fill_null(0) * weight\n",
        "        for col, weight in zip(confidence_col_names, combined_weights)\n",
        "    )\n",
        "\n",
        "    df_combined = df_combined.with_columns(weighted_conf.alias(\"ensemble_confidence\"))\n",
        "\n",
        "    # Ranking based on ensemble confidence\n",
        "    df_ranked = df_combined.with_columns(\n",
        "        pl.col(\"ensemble_confidence\")\n",
        "        .rank(\"ordinal\", descending=True)\n",
        "        .over(\"ranker_id\")\n",
        "        .cast(pl.Int32)\n",
        "        .alias(\"selected\")\n",
        "    )\n",
        "\n",
        "    final_submission = df_ranked.select([\"Id\", \"ranker_id\", \"selected\"])\n",
        "\n",
        "    print(\"\\n‚úÖ Sample of final submission:\")\n",
        "    print(final_submission.head())\n",
        "\n",
        "    final_submission.write_parquet(\"submission_ensemble.parquet\")\n",
        "    print(\"\\nüíæ Saved as: submission_ensemble.parquet\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wb-mn1OM8wcl",
        "outputId": "60f5f287-7ec4-4033-cc9b-69830fc4e444"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìä Spearman correlation between models:\n",
            "                    confidence_0.52795  confidence_0.51345  \\\n",
            "confidence_0.52795            1.000000            0.939309   \n",
            "confidence_0.51345            0.939309            1.000000   \n",
            "confidence_0.51244            0.955373            0.945280   \n",
            "confidence_0.52391            0.962294            0.950659   \n",
            "confidence_0.48755            0.891861            0.902773   \n",
            "confidence_0.52244            0.957935            0.949373   \n",
            "confidence_0.49755            0.875167            0.883281   \n",
            "confidence_0.52538            0.979736            0.935733   \n",
            "\n",
            "                    confidence_0.51244  confidence_0.52391  \\\n",
            "confidence_0.52795            0.955373            0.962294   \n",
            "confidence_0.51345            0.945280            0.950659   \n",
            "confidence_0.51244            1.000000            0.937243   \n",
            "confidence_0.52391            0.937243            1.000000   \n",
            "confidence_0.48755            0.886153            0.899695   \n",
            "confidence_0.52244            0.934095            0.973914   \n",
            "confidence_0.49755            0.883789            0.879274   \n",
            "confidence_0.52538            0.949621            0.958893   \n",
            "\n",
            "                    confidence_0.48755  confidence_0.52244  \\\n",
            "confidence_0.52795            0.891861            0.957935   \n",
            "confidence_0.51345            0.902773            0.949373   \n",
            "confidence_0.51244            0.886153            0.934095   \n",
            "confidence_0.52391            0.899695            0.973914   \n",
            "confidence_0.48755            1.000000            0.904576   \n",
            "confidence_0.52244            0.904576            1.000000   \n",
            "confidence_0.49755            0.902571            0.881633   \n",
            "confidence_0.52538            0.891378            0.957988   \n",
            "\n",
            "                    confidence_0.49755  confidence_0.52538  \n",
            "confidence_0.52795            0.875167            0.979736  \n",
            "confidence_0.51345            0.883281            0.935733  \n",
            "confidence_0.51244            0.883789            0.949621  \n",
            "confidence_0.52391            0.879274            0.958893  \n",
            "confidence_0.48755            0.902571            0.891378  \n",
            "confidence_0.52244            0.881633            0.957988  \n",
            "confidence_0.49755            1.000000            0.877003  \n",
            "confidence_0.52538            0.877003            1.000000  \n",
            "\n",
            "‚öñÔ∏è Final ensemble weights (uniqueness + entropy):\n",
            "confidence_0.52795: 0.1076\n",
            "confidence_0.51345: 0.1172\n",
            "confidence_0.51244: 0.1198\n",
            "confidence_0.52391: 0.1075\n",
            "confidence_0.48755: 0.1568\n",
            "confidence_0.52244: 0.1080\n",
            "confidence_0.49755: 0.1736\n",
            "confidence_0.52538: 0.1096\n",
            "\n",
            "‚úÖ Sample of final submission:\n",
            "shape: (5, 3)\n",
            "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
            "‚îÇ Id       ‚îÜ ranker_id                       ‚îÜ selected ‚îÇ\n",
            "‚îÇ ---      ‚îÜ ---                             ‚îÜ ---      ‚îÇ\n",
            "‚îÇ i64      ‚îÜ str                             ‚îÜ i32      ‚îÇ\n",
            "‚ïû‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï°\n",
            "‚îÇ 18144679 ‚îÜ c9373e5f772e43d593dd6ad2fa90f6‚Ä¶ ‚îÜ 4        ‚îÇ\n",
            "‚îÇ 18144680 ‚îÜ c9373e5f772e43d593dd6ad2fa90f6‚Ä¶ ‚îÜ 41       ‚îÇ\n",
            "‚îÇ 18144681 ‚îÜ c9373e5f772e43d593dd6ad2fa90f6‚Ä¶ ‚îÜ 256      ‚îÇ\n",
            "‚îÇ 18144682 ‚îÜ c9373e5f772e43d593dd6ad2fa90f6‚Ä¶ ‚îÜ 36       ‚îÇ\n",
            "‚îÇ 18144683 ‚îÜ c9373e5f772e43d593dd6ad2fa90f6‚Ä¶ ‚îÜ 62       ‚îÇ\n",
            "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
            "\n",
            "üíæ Saved as: submission_ensemble.parquet\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile ensemble_cos_sim.py\n",
        "import polars as pl\n",
        "import glob\n",
        "import re\n",
        "import numpy as np\n",
        "from numpy.linalg import norm\n",
        "\n",
        "def load_submission_with_confidence(filepath: str) -> pl.DataFrame:\n",
        "    df = pl.read_csv(filepath)\n",
        "    if \"selected\" in df.columns:\n",
        "        df = df.drop(\"selected\")\n",
        "    return df\n",
        "\n",
        "def cos_sim(a: np.ndarray, b: np.ndarray) -> float:\n",
        "    # Guard against NaN/Inf and zero vectors\n",
        "    a = np.nan_to_num(a, nan=0.0, posinf=0.0, neginf=0.0)\n",
        "    b = np.nan_to_num(b, nan=0.0, posinf=0.0, neginf=0.0)\n",
        "    na = norm(a) + 1e-12\n",
        "    nb = norm(b) + 1e-12\n",
        "    return float(np.dot(a, b) / (na * nb))\n",
        "\n",
        "def main():\n",
        "    # Find all *_with_confidence.csv files\n",
        "    filepaths = glob.glob(\"submission_*_*_with_confidence.csv\")\n",
        "\n",
        "    dfs = []\n",
        "    confidence_col_names = []\n",
        "\n",
        "    for filepath in filepaths:\n",
        "        # extract numeric label for column naming\n",
        "        match = re.search(r\"submission_.*_([\\d.]+)_with_confidence\\.csv\", filepath)\n",
        "        if not match:\n",
        "            # skip files without a numeric score in the name (keeps original behavior)\n",
        "            continue\n",
        "\n",
        "        score = match.group(1)\n",
        "        df = load_submission_with_confidence(filepath)\n",
        "        if \"confidence\" not in df.columns:\n",
        "            continue\n",
        "\n",
        "        confidence_col = f\"confidence_{score}\"\n",
        "        df = df.with_columns(pl.col(\"confidence\").alias(confidence_col)).drop(\"confidence\")\n",
        "        confidence_col_names.append(confidence_col)\n",
        "        dfs.append(df)\n",
        "\n",
        "    if not dfs:\n",
        "        print(\"‚ùå No valid submission files found.\")\n",
        "        return\n",
        "\n",
        "    # Join on Id + ranker_id\n",
        "    df_combined = dfs[0]\n",
        "    for df in dfs[1:]:\n",
        "        df_combined = df_combined.join(df, on=[\"Id\", \"ranker_id\"])\n",
        "\n",
        "    # === Cosine-uniqueness weights (label-free) ===\n",
        "    cols_np = []\n",
        "    for c in confidence_col_names:\n",
        "        x = df_combined[c].to_numpy()\n",
        "        x = np.nan_to_num(x, nan=0.0, posinf=0.0, neginf=0.0)\n",
        "        cols_np.append(x)\n",
        "\n",
        "    m = len(cols_np)\n",
        "    if m == 1:\n",
        "        combined_weights = np.array([1.0])\n",
        "        print(\"\\nüìå Only one model detected ‚Üí weight = 1.0\")\n",
        "    else:\n",
        "        uniq = []\n",
        "        for i in range(m):\n",
        "            sims = [abs(cos_sim(cols_np[i], cols_np[j])) for j in range(m) if j != i]\n",
        "            avg_sim = np.mean(sims) if sims else 0.0\n",
        "            uniq.append(max(0.0, 1.0 - avg_sim))  # uniqueness ‚àà [0,1]\n",
        "        uniq = np.array(uniq, dtype=float)\n",
        "        s = uniq.sum()\n",
        "        combined_weights = (uniq / s) if s > 0 and np.isfinite(s) else (np.ones(m) / m)\n",
        "\n",
        "    print(\"\\n‚öñÔ∏è Final ensemble weights (cosine-uniqueness):\")\n",
        "    for col, w in zip(confidence_col_names, combined_weights):\n",
        "        print(f\"{col}: {w:.4f}\")\n",
        "\n",
        "    # Weighted ensemble of confidence scores\n",
        "    weighted_conf = sum(\n",
        "        df_combined[col].fill_null(0) * weight\n",
        "        for col, weight in zip(confidence_col_names, combined_weights)\n",
        "    )\n",
        "\n",
        "    df_combined = df_combined.with_columns(weighted_conf.alias(\"ensemble_confidence\"))\n",
        "\n",
        "    # Ranking by ensemble_confidence within each ranker_id\n",
        "    df_ranked = df_combined.with_columns(\n",
        "        pl.col(\"ensemble_confidence\")\n",
        "        .rank(\"ordinal\", descending=True)\n",
        "        .over(\"ranker_id\")\n",
        "        .cast(pl.Int32)\n",
        "        .alias(\"selected\")\n",
        "    )\n",
        "\n",
        "    final_submission = df_ranked.select([\"Id\", \"ranker_id\", \"selected\"])\n",
        "\n",
        "    print(\"\\n‚úÖ Sample of final submission:\")\n",
        "    print(final_submission.head())\n",
        "\n",
        "    final_submission.write_parquet(\"submission_ensemble.parquet\")\n",
        "    print(\"\\nüíæ Saved as: submission_ensemble.parquet\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "82pKXphUJAkJ",
        "outputId": "cc73cd68-7755-4971-cf0f-7d45b0770c4e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing ensemble_cos_sim.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import polars as pl\n",
        "import glob\n",
        "import re\n",
        "import numpy as np\n",
        "from numpy.linalg import norm, svd\n",
        "\n",
        "# === Helpers ===\n",
        "\n",
        "def load_submission_with_confidence(filepath: str) -> pl.DataFrame:\n",
        "    df = pl.read_csv(filepath)\n",
        "    if \"selected\" in df.columns:\n",
        "        df = df.drop(\"selected\")\n",
        "    return df\n",
        "\n",
        "def cos_sim(a: np.ndarray, b: np.ndarray) -> float:\n",
        "    a = np.nan_to_num(a, nan=0.0, posinf=0.0, neginf=0.0)\n",
        "    b = np.nan_to_num(b, nan=0.0, posinf=0.0, neginf=0.0)\n",
        "    na = norm(a) + 1e-12\n",
        "    nb = norm(b) + 1e-12\n",
        "    return float(np.dot(a, b) / (na * nb))\n",
        "\n",
        "def compute_entropy(probabilities: np.ndarray) -> float:\n",
        "    # Scores are already normalized to [0,1]; ensure they sum to 1\n",
        "    p = np.nan_to_num(probabilities, nan=0.0, posinf=0.0, neginf=0.0)\n",
        "    s = p.sum()\n",
        "    if s <= 0 or not np.isfinite(s):\n",
        "        p = np.ones_like(p) / len(p)\n",
        "    else:\n",
        "        p = p / s\n",
        "    p = np.clip(p, 1e-12, 1.0)\n",
        "    return float(-np.sum(p * np.log(p)))\n",
        "\n",
        "# === Main ===\n",
        "def main():\n",
        "    # 1) Load all *_with_confidence.csv files with a numeric score in the name\n",
        "    filepaths = glob.glob(\"submission_*_*_with_confidence.csv\")\n",
        "\n",
        "    dfs = []\n",
        "    confidence_col_names = []\n",
        "    for filepath in filepaths:\n",
        "        m = re.search(r\"submission_.*_([\\d.]+)_with_confidence\\.csv\", filepath)\n",
        "        if not m:\n",
        "            continue\n",
        "        score = m.group(1)\n",
        "        df = load_submission_with_confidence(filepath)\n",
        "        if \"confidence\" not in df.columns:\n",
        "            continue\n",
        "        colname = f\"confidence_{score}\"\n",
        "        df = df.with_columns(pl.col(\"confidence\").alias(colname)).drop(\"confidence\")\n",
        "        confidence_col_names.append(colname)\n",
        "        dfs.append(df)\n",
        "\n",
        "    if not dfs:\n",
        "        print(\"‚ùå No valid files found.\")\n",
        "        return\n",
        "\n",
        "    # 2) Join on Id and ranker_id\n",
        "    df_combined = dfs[0]\n",
        "    for df in dfs[1:]:\n",
        "        df_combined = df_combined.join(df, on=[\"Id\", \"ranker_id\"])\n",
        "\n",
        "    # 3) Matrix X (n x m) from original columns\n",
        "    X = df_combined.select(confidence_col_names).to_numpy()\n",
        "    X = np.nan_to_num(X, nan=0.0, posinf=0.0, neginf=0.0)\n",
        "    n, m = X.shape\n",
        "\n",
        "    # 4) Cosine-uniqueness blend ‚Üí new column 'blend_cos'\n",
        "    if m == 1:\n",
        "        w_cos = np.array([1.0])\n",
        "    else:\n",
        "        uniq = []\n",
        "        for i in range(m):\n",
        "            sims = [abs(cos_sim(X[:, i], X[:, j])) for j in range(m) if j != i]\n",
        "            avg_sim = np.mean(sims) if sims else 0.0\n",
        "            uniq.append(max(0.0, 1.0 - avg_sim))\n",
        "        uniq = np.array(uniq, dtype=float)\n",
        "        s = uniq.sum()\n",
        "        w_cos = (uniq / s) if s > 0 and np.isfinite(s) else np.ones(m) / m\n",
        "\n",
        "    blend_cos = X @ w_cos  # true blend across all models\n",
        "    df_combined = df_combined.with_columns(pl.Series(\"blend_cos\", blend_cos))\n",
        "\n",
        "    # 5) PCA consensus (PC1) ‚Üí new column 'pc1_consensus'\n",
        "    # standardize columns before SVD\n",
        "    X_std = (X - X.mean(axis=0)) / (X.std(axis=0) + 1e-12)\n",
        "    U, Svals, Vt = svd(X_std, full_matrices=False)\n",
        "    v1 = Vt[0]                 # PC1 loadings (m,)\n",
        "    pc1_scores = X_std @ v1    # PC1 score per row\n",
        "    # optional: align sign with mean score direction\n",
        "    sign = np.sign(np.corrcoef(pc1_scores, X_std.mean(axis=1))[0, 1] + 1e-12)\n",
        "    pc1_scores *= sign\n",
        "    df_combined = df_combined.with_columns(pl.Series(\"pc1_consensus\", pc1_scores))\n",
        "\n",
        "    # 6) Columns to use for weighting\n",
        "    ensemble_cols = confidence_col_names + [\"blend_cos\", \"pc1_consensus\"]\n",
        "\n",
        "    # 7) Spearman correlation across all columns (original + new)\n",
        "    corr_df = df_combined.select(ensemble_cols).to_pandas().corr(method=\"spearman\").fillna(0.0)\n",
        "    print(\"üìä Spearman correlation (original + blend_cos + pc1_consensus):\")\n",
        "    print(corr_df)\n",
        "\n",
        "    # 8) Uniqueness weights from Spearman: 1 - average off-diagonal correlation\n",
        "    ncols = corr_df.shape[0]\n",
        "    if ncols == 1:\n",
        "        w_uni = np.array([1.0])\n",
        "    else:\n",
        "        mean_corr = (corr_df.sum(axis=1) - 1.0) / max(ncols - 1, 1)\n",
        "        uniqueness = 1.0 - mean_corr.values\n",
        "        su = uniqueness.sum()\n",
        "        w_uni = (uniqueness / su) if su > 0 and np.isfinite(su) else np.ones(ncols) / ncols\n",
        "\n",
        "    # 9) Entropy-based weights (ensure each column sums to 1 before H)\n",
        "    entropies = []\n",
        "    for c in ensemble_cols:\n",
        "        entropies.append(compute_entropy(df_combined[c].to_numpy()))\n",
        "    entropies = np.array(entropies, dtype=float)\n",
        "    se = entropies.sum()\n",
        "    w_ent = (entropies / se) if se > 0 and np.isfinite(se) else np.ones_like(entropies) / len(entropies)\n",
        "\n",
        "    # 10) Final weights (alpha toward uniqueness)\n",
        "    alpha = 0.75\n",
        "    w_final = alpha * w_uni + (1 - alpha) * w_ent\n",
        "    sf = w_final.sum()\n",
        "    w_final = (w_final / sf) if sf > 0 and np.isfinite(sf) else np.ones_like(w_final) / len(w_final)\n",
        "\n",
        "    print(\"\\n‚öñÔ∏è Final weights (including the new columns):\")\n",
        "    for col, w in zip(ensemble_cols, w_final):\n",
        "        print(f\"{col}: {w:.4f}\")\n",
        "\n",
        "    # 11) Final ensemble score\n",
        "    ensemble_conf = sum(\n",
        "        df_combined[c].fill_null(0) * w\n",
        "        for c, w in zip(ensemble_cols, w_final)\n",
        "    )\n",
        "    df_combined = df_combined.with_columns(ensemble_conf.alias(\"ensemble_confidence\"))\n",
        "\n",
        "    # 12) Rank within each ranker_id\n",
        "    df_ranked = df_combined.with_columns(\n",
        "        pl.col(\"ensemble_confidence\")\n",
        "        .rank(\"ordinal\", descending=True)\n",
        "        .over(\"ranker_id\")\n",
        "        .cast(pl.Int32)\n",
        "        .alias(\"selected\")\n",
        "    )\n",
        "\n",
        "    final_submission = df_ranked.select([\"Id\", \"ranker_id\", \"selected\"])\n",
        "\n",
        "    print(\"\\n‚úÖ Sample of final submission:\")\n",
        "    print(final_submission.head())\n",
        "\n",
        "    final_submission.write_parquet(\"submission_ensemble.parquet\")\n",
        "    print(\"\\nüíæ Saved as: submission_ensemble.parquet\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Trgly7IwMNj3",
        "outputId": "c08253c6-8e86-41a9-fbfe-a4cb286863d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìä Spearman correlation (original + blend_cos + pc1_consensus):\n",
            "                    confidence_0.48755  confidence_0.52244  \\\n",
            "confidence_0.48755            1.000000            0.904576   \n",
            "confidence_0.52244            0.904576            1.000000   \n",
            "confidence_0.52603            0.892817            0.958322   \n",
            "confidence_0.51244            0.886153            0.934095   \n",
            "confidence_0.51345            0.902773            0.949373   \n",
            "confidence_0.52391            0.899695            0.973914   \n",
            "confidence_0.52538            0.891378            0.957988   \n",
            "confidence_0.52795            0.891861            0.957935   \n",
            "blend_cos                     0.946820            0.977914   \n",
            "pc1_consensus                 0.932055            0.980414   \n",
            "\n",
            "                    confidence_0.52603  confidence_0.51244  \\\n",
            "confidence_0.48755            0.892817            0.886153   \n",
            "confidence_0.52244            0.958322            0.934095   \n",
            "confidence_0.52603            1.000000            0.952257   \n",
            "confidence_0.51244            0.952257            1.000000   \n",
            "confidence_0.51345            0.937384            0.945280   \n",
            "confidence_0.52391            0.963522            0.937243   \n",
            "confidence_0.52538            0.981877            0.949621   \n",
            "confidence_0.52795            0.982414            0.955373   \n",
            "blend_cos                     0.979537            0.968884   \n",
            "pc1_consensus                 0.984664            0.970554   \n",
            "\n",
            "                    confidence_0.51345  confidence_0.52391  \\\n",
            "confidence_0.48755            0.902773            0.899695   \n",
            "confidence_0.52244            0.949373            0.973914   \n",
            "confidence_0.52603            0.937384            0.963522   \n",
            "confidence_0.51244            0.945280            0.937243   \n",
            "confidence_0.51345            1.000000            0.950659   \n",
            "confidence_0.52391            0.950659            1.000000   \n",
            "confidence_0.52538            0.935733            0.958893   \n",
            "confidence_0.52795            0.939309            0.962294   \n",
            "blend_cos                     0.971273            0.978481   \n",
            "pc1_consensus                 0.970541            0.981814   \n",
            "\n",
            "                    confidence_0.52538  confidence_0.52795  blend_cos  \\\n",
            "confidence_0.48755            0.891378            0.891861   0.946820   \n",
            "confidence_0.52244            0.957988            0.957935   0.977914   \n",
            "confidence_0.52603            0.981877            0.982414   0.979537   \n",
            "confidence_0.51244            0.949621            0.955373   0.968884   \n",
            "confidence_0.51345            0.935733            0.939309   0.971273   \n",
            "confidence_0.52391            0.958893            0.962294   0.978481   \n",
            "confidence_0.52538            1.000000            0.979736   0.977834   \n",
            "confidence_0.52795            0.979736            1.000000   0.979580   \n",
            "blend_cos                     0.977834            0.979580   1.000000   \n",
            "pc1_consensus                 0.982898            0.984702   0.998977   \n",
            "\n",
            "                    pc1_consensus  \n",
            "confidence_0.48755       0.932055  \n",
            "confidence_0.52244       0.980414  \n",
            "confidence_0.52603       0.984664  \n",
            "confidence_0.51244       0.970554  \n",
            "confidence_0.51345       0.970541  \n",
            "confidence_0.52391       0.981814  \n",
            "confidence_0.52538       0.982898  \n",
            "confidence_0.52795       0.984702  \n",
            "blend_cos                0.998977  \n",
            "pc1_consensus            1.000000  \n",
            "\n",
            "‚öñÔ∏è Final weights (including the new columns):\n",
            "confidence_0.48755: 0.1799\n",
            "confidence_0.52244: 0.1002\n",
            "confidence_0.52603: 0.0933\n",
            "confidence_0.51244: 0.1171\n",
            "confidence_0.51345: 0.1166\n",
            "confidence_0.52391: 0.0980\n",
            "confidence_0.52538: 0.0963\n",
            "confidence_0.52795: 0.0933\n",
            "blend_cos: 0.0672\n",
            "pc1_consensus: 0.0381\n",
            "\n",
            "‚úÖ Sample of final submission:\n",
            "shape: (5, 3)\n",
            "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
            "‚îÇ Id       ‚îÜ ranker_id                       ‚îÜ selected ‚îÇ\n",
            "‚îÇ ---      ‚îÜ ---                             ‚îÜ ---      ‚îÇ\n",
            "‚îÇ i64      ‚îÜ str                             ‚îÜ i32      ‚îÇ\n",
            "‚ïû‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï°\n",
            "‚îÇ 18144679 ‚îÜ c9373e5f772e43d593dd6ad2fa90f6‚Ä¶ ‚îÜ 4        ‚îÇ\n",
            "‚îÇ 18144680 ‚îÜ c9373e5f772e43d593dd6ad2fa90f6‚Ä¶ ‚îÜ 27       ‚îÇ\n",
            "‚îÇ 18144681 ‚îÜ c9373e5f772e43d593dd6ad2fa90f6‚Ä¶ ‚îÜ 260      ‚îÇ\n",
            "‚îÇ 18144682 ‚îÜ c9373e5f772e43d593dd6ad2fa90f6‚Ä¶ ‚îÜ 12       ‚îÇ\n",
            "‚îÇ 18144683 ‚îÜ c9373e5f772e43d593dd6ad2fa90f6‚Ä¶ ‚îÜ 57       ‚îÇ\n",
            "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
            "\n",
            "üíæ Saved as: submission_ensemble.parquet\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import polars as pl\n",
        "import glob\n",
        "import re\n",
        "import numpy as np\n",
        "\n",
        "def load_submission_with_confidence(filepath: str) -> pl.DataFrame:\n",
        "    df = pl.read_csv(filepath)\n",
        "    # Drop 'selected' if present ‚Äî we only need Id, ranker_id, confidence-like column\n",
        "    if \"selected\" in df.columns:\n",
        "        df = df.drop(\"selected\")\n",
        "    return df\n",
        "\n",
        "def compute_entropy(probabilities: np.ndarray) -> float:\n",
        "    p = np.clip(probabilities, 1e-9, 1.0)\n",
        "    return float(-np.sum(p * np.log(p)))\n",
        "\n",
        "def main():\n",
        "    # -------- 1) Load all submissions that contain per-item confidence --------\n",
        "    filepaths = glob.glob(\"submission_*_*_with_confidence.csv\")\n",
        "\n",
        "    dfs = []\n",
        "    confidence_col_names = []\n",
        "\n",
        "    for filepath in filepaths:\n",
        "        # Extract a score token from filename, e.g. ..._0.52795_with_confidence.csv\n",
        "        match = re.search(r\"submission_.*_([\\d.]+)_with_confidence\\.csv\", filepath)\n",
        "        if match:\n",
        "            score = match.group(1)\n",
        "            df = load_submission_with_confidence(filepath)\n",
        "            # Rename 'confidence' to a unique column per model\n",
        "            conf_col = f\"confidence_{score}\"\n",
        "            df = df.with_columns(pl.col(\"confidence\").alias(conf_col)).drop(\"confidence\")\n",
        "            confidence_col_names.append(conf_col)\n",
        "            dfs.append(df)\n",
        "\n",
        "    if not dfs:\n",
        "        print(\"‚ùå No valid submission files found.\")\n",
        "        return\n",
        "\n",
        "    # -------- 2) Join on (Id, ranker_id) to align items across models --------\n",
        "    df_combined = dfs[0]\n",
        "    for df in dfs[1:]:\n",
        "        df_combined = df_combined.join(df, on=[\"Id\", \"ranker_id\"])\n",
        "\n",
        "    # -------- 3) Compute model-to-model Spearman (global, on confidence) --------\n",
        "    corr_df = df_combined.select(confidence_col_names).to_pandas().corr(method=\"spearman\")\n",
        "    print(\"üìä Spearman correlation between models:\")\n",
        "    print(corr_df)\n",
        "\n",
        "    # Uniqueness weight: 1 - average Spearman correlation (row-wise, excluding diagonal)\n",
        "    mean_corr = corr_df.apply(lambda row: (row.sum() - 1) / (len(row) - 1), axis=1)\n",
        "    model_uniqueness = 1 - mean_corr\n",
        "    uniqueness_weights = model_uniqueness / model_uniqueness.sum()\n",
        "\n",
        "    # -------- 4) Entropy per model (global) as informativeness proxy --------\n",
        "    entropies = []\n",
        "    for col in confidence_col_names:\n",
        "        probs = df_combined[col].to_numpy()\n",
        "        probs = probs / np.sum(probs)\n",
        "        entropies.append(compute_entropy(probs))\n",
        "\n",
        "    entropy_weights = np.array(entropies, dtype=float)\n",
        "    entropy_weights /= entropy_weights.sum()\n",
        "\n",
        "    # -------- 5) Combine weights (same strategy as before) --------\n",
        "    alpha = 0.7  # higher -> more weight on uniqueness\n",
        "    combined_weights = alpha * uniqueness_weights.values + (1 - alpha) * entropy_weights\n",
        "    combined_weights /= combined_weights.sum()\n",
        "\n",
        "    print(\"\\n‚öñÔ∏è Final ensemble weights (uniqueness + entropy):\")\n",
        "    for col, w in zip(confidence_col_names, combined_weights):\n",
        "        print(f\"{col}: {w:.4f}\")\n",
        "\n",
        "    # -------- 6) Weighted confidence ensemble (same as before) --------\n",
        "    weighted_conf = sum(\n",
        "        df_combined[col].fill_null(0) * w\n",
        "        for col, w in zip(confidence_col_names, combined_weights)\n",
        "    )\n",
        "    df_combined = df_combined.with_columns(weighted_conf.alias(\"ensemble_confidence\"))\n",
        "\n",
        "    # -------- 7) Top-K agreement boosting (K=3) --------\n",
        "    # Agreement = fraction of models that place the item in Top-K of its group\n",
        "    K = 3           # Top-K window\n",
        "    lam = 0.2      # boost strength (try 0.1‚Äì0.3)\n",
        "    cap = 0.25     # maximum additional boost (25%)\n",
        "\n",
        "    # Build per-model ranks and binary Top-K votes per group\n",
        "    vote_cols = []\n",
        "    df_boost = df_combined.clone()\n",
        "    for c in confidence_col_names:\n",
        "        rank_col = f\"rank_{c}\"\n",
        "        vote_col = f\"vote_{c}\"\n",
        "        df_boost = df_boost.with_columns(\n",
        "            pl.col(c).rank(\"ordinal\", descending=True).over(\"ranker_id\").alias(rank_col)\n",
        "        ).with_columns(\n",
        "            (pl.col(rank_col) <= K).cast(pl.Float64).alias(vote_col)\n",
        "        )\n",
        "        vote_cols.append(vote_col)\n",
        "\n",
        "    # Agreement (vote_rate): fraction of models with rank <= K\n",
        "    M = float(len(confidence_col_names))\n",
        "    df_boost = df_boost.with_columns(\n",
        "        (sum(pl.col(v) for v in vote_cols) / M).alias(\"agreement\")\n",
        "    )\n",
        "\n",
        "    # Boost factor: 1 + lam * agreement, clamped to [1, 1 + cap]\n",
        "    df_boost = df_boost.with_columns(\n",
        "        (1.0 + lam * pl.col(\"agreement\")).clip(1.0, 1.0 + cap).alias(\"boost\")\n",
        "    )\n",
        "\n",
        "    # Apply boost to ensemble confidence\n",
        "    df_boost = df_boost.with_columns(\n",
        "        (pl.col(\"ensemble_confidence\") * pl.col(\"boost\")).alias(\"ensemble_confidence_boosted\")\n",
        "    )\n",
        "\n",
        "    # -------- 8) Final ranking per group (using boosted score) --------\n",
        "    df_ranked = df_boost.with_columns(\n",
        "        pl.col(\"ensemble_confidence_boosted\")\n",
        "        .rank(\"ordinal\", descending=True)\n",
        "        .over(\"ranker_id\")\n",
        "        .cast(pl.Int32)\n",
        "        .alias(\"selected\")\n",
        "    )\n",
        "\n",
        "    final_submission = df_ranked.select([\"Id\", \"ranker_id\", \"selected\"])\n",
        "\n",
        "    print(\"\\n‚úÖ Sample of final submission:\")\n",
        "    print(final_submission.head())\n",
        "\n",
        "    final_submission.write_parquet(\"submission_ensemble.parquet\")\n",
        "    print(\"\\nüíæ Saved as: submission_ensemble.parquet\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fKzDzzDuj4Z_",
        "outputId": "20463fbf-3abb-48d4-c792-a45193fe7963"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìä Spearman correlation between models:\n",
            "                    confidence_0.52795  confidence_0.51244  \\\n",
            "confidence_0.52795            1.000000            0.955373   \n",
            "confidence_0.51244            0.955373            1.000000   \n",
            "confidence_0.52244            0.957935            0.934095   \n",
            "confidence_0.48755            0.891861            0.886153   \n",
            "\n",
            "                    confidence_0.52244  confidence_0.48755  \n",
            "confidence_0.52795            0.957935            0.891861  \n",
            "confidence_0.51244            0.934095            0.886153  \n",
            "confidence_0.52244            1.000000            0.904576  \n",
            "confidence_0.48755            0.904576            1.000000  \n",
            "\n",
            "‚öñÔ∏è Final ensemble weights (uniqueness + entropy):\n",
            "confidence_0.52795: 0.2201\n",
            "confidence_0.51244: 0.2421\n",
            "confidence_0.52244: 0.2265\n",
            "confidence_0.48755: 0.3114\n",
            "\n",
            "‚úÖ Sample of final submission:\n",
            "shape: (5, 3)\n",
            "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
            "‚îÇ Id       ‚îÜ ranker_id                       ‚îÜ selected ‚îÇ\n",
            "‚îÇ ---      ‚îÜ ---                             ‚îÜ ---      ‚îÇ\n",
            "‚îÇ i64      ‚îÜ str                             ‚îÜ i32      ‚îÇ\n",
            "‚ïû‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï°\n",
            "‚îÇ 18144679 ‚îÜ c9373e5f772e43d593dd6ad2fa90f6‚Ä¶ ‚îÜ 4        ‚îÇ\n",
            "‚îÇ 18144680 ‚îÜ c9373e5f772e43d593dd6ad2fa90f6‚Ä¶ ‚îÜ 42       ‚îÇ\n",
            "‚îÇ 18144681 ‚îÜ c9373e5f772e43d593dd6ad2fa90f6‚Ä¶ ‚îÜ 254      ‚îÇ\n",
            "‚îÇ 18144682 ‚îÜ c9373e5f772e43d593dd6ad2fa90f6‚Ä¶ ‚îÜ 13       ‚îÇ\n",
            "‚îÇ 18144683 ‚îÜ c9373e5f772e43d593dd6ad2fa90f6‚Ä¶ ‚îÜ 71       ‚îÇ\n",
            "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
            "\n",
            "üíæ Saved as: submission_ensemble.parquet\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile ensemble.py\n",
        "import polars as pl\n",
        "import glob\n",
        "import re\n",
        "import numpy as np\n",
        "\n",
        "def load_submission_with_confidence(filepath: str, alpha: float = 0.7, k: int = 5) -> pl.DataFrame:\n",
        "    df = pl.read_csv(filepath)\n",
        "\n",
        "    if \"selected\" in df.columns:\n",
        "        rrf_max = 1.0 / (k + 1)\n",
        "        df = df.with_columns(\n",
        "            ((1.0 / (k + pl.col(\"selected\"))) / rrf_max).alias(\"rrf_score\")\n",
        "        )\n",
        "        df = df.with_columns(\n",
        "            (alpha * pl.col(\"confidence\") + (1 - alpha) * pl.col(\"rrf_score\")).alias(\"confidence\")\n",
        "        )\n",
        "        df = df.drop([\"selected\", \"rrf_score\"])\n",
        "\n",
        "    return df\n",
        "\n",
        "def compute_entropy(probabilities: np.ndarray) -> float:\n",
        "    p = np.clip(probabilities, 1e-9, 1.0)\n",
        "    return float(-np.sum(p * np.log(p)))\n",
        "\n",
        "def main():\n",
        "    # -------- 1) Load all submissions that contain per-item confidence --------\n",
        "    filepaths = glob.glob(\"submission_*_*_with_confidence.csv\")\n",
        "\n",
        "    dfs = []\n",
        "    confidence_col_names = []\n",
        "\n",
        "    for filepath in filepaths:\n",
        "        # Extract a score token from filename, e.g. ..._0.52795_with_confidence.csv\n",
        "        match = re.search(r\"submission_.*_([\\d.]+)_with_confidence\\.csv\", filepath)\n",
        "        if match:\n",
        "            score = match.group(1)\n",
        "            df = load_submission_with_confidence(filepath, alpha=0.7, k=5)\n",
        "            conf_col = f\"confidence_{score}\"\n",
        "            df = df.with_columns(pl.col(\"confidence\").alias(conf_col)).drop(\"confidence\")\n",
        "            confidence_col_names.append(conf_col)\n",
        "            dfs.append(df)\n",
        "\n",
        "    if not dfs:\n",
        "        print(\"‚ùå No valid submission files found.\")\n",
        "        return\n",
        "\n",
        "    # -------- 2) Join on (Id, ranker_id) to align items across models --------\n",
        "    df_combined = dfs[0]\n",
        "    for df in dfs[1:]:\n",
        "        df_combined = df_combined.join(df, on=[\"Id\", \"ranker_id\"])\n",
        "\n",
        "    # -------- 3) Compute model-to-model Spearman (global, on confidence) --------\n",
        "    corr_df = df_combined.select(confidence_col_names).to_pandas().corr(method=\"spearman\")\n",
        "    print(\"üìä Spearman correlation between models:\")\n",
        "    print(corr_df)\n",
        "\n",
        "    # Uniqueness weight: 1 - average Spearman correlation (row-wise, excluding diagonal)\n",
        "    mean_corr = corr_df.apply(lambda row: (row.sum() - 1) / (len(row) - 1), axis=1)\n",
        "    model_uniqueness = 1 - mean_corr\n",
        "    uniqueness_weights = model_uniqueness / model_uniqueness.sum()\n",
        "\n",
        "    # -------- 4) Entropy per model (global) as informativeness proxy --------\n",
        "    entropies = []\n",
        "    for col in confidence_col_names:\n",
        "        probs = df_combined[col].to_numpy()\n",
        "        probs = probs / np.sum(probs)\n",
        "        entropies.append(compute_entropy(probs))\n",
        "\n",
        "    entropy_weights = np.array(entropies, dtype=float)\n",
        "    entropy_weights /= entropy_weights.sum()\n",
        "\n",
        "    # -------- 5) Combine weights (same strategy as before) --------\n",
        "    alpha = 0.75  # higher -> more weight on uniqueness\n",
        "    combined_weights = alpha * uniqueness_weights.values + (1 - alpha) * entropy_weights\n",
        "    combined_weights /= combined_weights.sum()\n",
        "\n",
        "    print(\"\\n‚öñÔ∏è Final ensemble weights (uniqueness + entropy):\")\n",
        "    for col, w in zip(confidence_col_names, combined_weights):\n",
        "        print(f\"{col}: {w:.4f}\")\n",
        "\n",
        "    # -------- 6) Weighted confidence ensemble --------\n",
        "    weighted_conf = sum(\n",
        "        df_combined[col].fill_null(0) * w\n",
        "        for col, w in zip(confidence_col_names, combined_weights)\n",
        "    )\n",
        "    df_combined = df_combined.with_columns(weighted_conf.alias(\"ensemble_confidence\"))\n",
        "\n",
        "    # -------- 7) Top-K agreement boosting (K=3) --------\n",
        "    K = 3\n",
        "    lam = 0.35\n",
        "    cap = 0.45\n",
        "\n",
        "    vote_cols = []\n",
        "    df_boost = df_combined.clone()\n",
        "    for c in confidence_col_names:\n",
        "        rank_col = f\"rank_{c}\"\n",
        "        vote_col = f\"vote_{c}\"\n",
        "        df_boost = df_boost.with_columns(\n",
        "            pl.col(c).rank(\"ordinal\", descending=True).over(\"ranker_id\").alias(rank_col)\n",
        "        ).with_columns(\n",
        "            (pl.col(rank_col) <= K).cast(pl.Float64).alias(vote_col)\n",
        "        )\n",
        "        vote_cols.append(vote_col)\n",
        "\n",
        "    M = float(len(confidence_col_names))\n",
        "    df_boost = df_boost.with_columns(\n",
        "        (sum(pl.col(v) for v in vote_cols) / M).alias(\"agreement\")\n",
        "    )\n",
        "\n",
        "    df_boost = df_boost.with_columns(\n",
        "        (1.0 + lam * pl.col(\"agreement\")).clip(1.0, 1.0 + cap).alias(\"boost\")\n",
        "    )\n",
        "\n",
        "    df_boost = df_boost.with_columns(\n",
        "        (pl.col(\"ensemble_confidence\") * pl.col(\"boost\")).alias(\"ensemble_confidence_boosted\")\n",
        "    )\n",
        "\n",
        "    # -------- 8) Final ranking --------\n",
        "    df_ranked = df_boost.with_columns(\n",
        "        pl.col(\"ensemble_confidence_boosted\")\n",
        "        .rank(\"ordinal\", descending=True)\n",
        "        .over(\"ranker_id\")\n",
        "        .cast(pl.Int32)\n",
        "        .alias(\"selected\")\n",
        "    )\n",
        "\n",
        "    final_submission = df_ranked.select([\"Id\", \"ranker_id\", \"selected\"])\n",
        "\n",
        "    print(\"\\n‚úÖ Sample of final submission:\")\n",
        "    print(final_submission.head())\n",
        "\n",
        "    final_submission.write_parquet(\"submission_ensemble.parquet\")\n",
        "    print(\"\\nüíæ Saved as: submission_ensemble.parquet\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xzQra1UHXwpz",
        "outputId": "4005fd18-ace3-40f7-a351-383dc48ff565"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing ensemble.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "import os\n",
        "import re\n",
        "import glob\n",
        "import numpy as np\n",
        "import polars as pl\n",
        "import pandas as pd\n",
        "\n",
        "# =========================\n",
        "# ======== Config =========\n",
        "# =========================\n",
        "\n",
        "# Raw submissions to aggregate (Id, ranker_id, selected)\n",
        "RAW_SUBMISSIONS = [\n",
        "    \"submission_20250721083807_0.52244.parquet\",\n",
        "    \"submission_20250724032338_0.51345.parquet\",\n",
        "    \"submission_20250725083055_0.52391.parquet\",\n",
        "    \"submission_20250727084025_0.52795.parquet\",\n",
        "    \"submission_20250802074816_0.52603.parquet\",\n",
        "    \"submission_20250804001151_0.51244.parquet\",\n",
        "    \"submission_20250807032439_0.52538.parquet\",\n",
        "    \"submission_dl_ranker_0.48755.parquet\",\n",
        "]\n",
        "\n",
        "# Which aggregators to compute and blend\n",
        "USE_RRF      = True\n",
        "USE_BORDA    = True\n",
        "USE_SOFTMAX  = True\n",
        "\n",
        "# RRF and Softmax parameters\n",
        "RRF_K = 5\n",
        "TAU   = 0.7\n",
        "\n",
        "# Blend the aggregators with min-variance weights? (else pick one by name)\n",
        "BLEND_AGGREGATORS = True\n",
        "# If not blending, choose one: \"rrf\" | \"borda\" | \"softmax\"\n",
        "SINGLE_AGGREGATOR = \"rrf\"\n",
        "\n",
        "# Correlation shrinkage for min-variance meta-weights\n",
        "CORR_SHRINKAGE_LAMBDA = 0.2\n",
        "\n",
        "# Normalize final score per group before ranking?\n",
        "NORMALIZE_FINAL_PER_GROUP = True\n",
        "\n",
        "# Deterministic tie-break by Id?\n",
        "DETERMINISTIC_TIE_BREAK = True\n",
        "\n",
        "# Output\n",
        "OUTPUT_PARQUET = \"submission_ensemble_rank_agg.parquet\"\n",
        "SAVE_AGG_WEIGHTS = True   # save aggregator weights if blending\n",
        "\n",
        "# =========================\n",
        "# ===== Utilities =========\n",
        "# =========================\n",
        "\n",
        "def mv_weights_from_corr(corr: np.ndarray, lam: float = 0.2) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Minimum-variance weights from correlation matrix (with shrinkage).\n",
        "    w ‚àù Œ£^{-1} 1 , normalized to sum to 1, forced non-negative.\n",
        "    \"\"\"\n",
        "    p = corr.shape[0]\n",
        "    corr_shr = (1 - lam) * corr + lam * np.eye(p)\n",
        "    inv = np.linalg.pinv(corr_shr)\n",
        "    ones = np.ones((p, 1))\n",
        "    denom = (ones.T @ inv @ ones)[0, 0]\n",
        "    denom = float(denom)\n",
        "    if denom <= 0:\n",
        "        return np.ones(p) / p\n",
        "    w = (inv @ ones) / denom\n",
        "    w = w.ravel()\n",
        "    w = np.clip(w, 0, None)\n",
        "    s = w.sum()\n",
        "    return w / s if s > 0 else np.ones(p) / p\n",
        "\n",
        "def safe_minmax_norm(expr: pl.Expr, over_col: str) -> pl.Expr:\n",
        "    \"\"\"Groupwise min-max normalize, safe for constant groups.\"\"\"\n",
        "    e_min = expr.min().over(over_col)\n",
        "    e_max = expr.max().over(over_col)\n",
        "    return (expr - e_min) / (e_max - e_min + 1e-12)\n",
        "\n",
        "def read_submission(path: str) -> pl.DataFrame:\n",
        "    \"\"\"Read a submission (parquet or csv) with columns Id, ranker_id, selected.\"\"\"\n",
        "    if path.endswith(\".parquet\"):\n",
        "        return pl.read_parquet(path)\n",
        "    elif path.endswith(\".csv\"):\n",
        "        return pl.read_csv(path)\n",
        "    else:\n",
        "        raise ValueError(f\"Unsupported file: {path}\")\n",
        "\n",
        "# =========================\n",
        "# === Rank Aggregators ====\n",
        "# =========================\n",
        "\n",
        "def agg_rrf(df: pl.DataFrame, rank_cols: list[str], rrf_k: int) -> pl.Expr:\n",
        "    \"\"\"RRF: sum_i 1 / (k + rank_i).\"\"\"\n",
        "    expr = None\n",
        "    for c in rank_cols:\n",
        "        term = 1.0 / (rrf_k + pl.col(c))\n",
        "        expr = term if expr is None else (expr + term)\n",
        "    return expr.alias(\"agg_rrf\")\n",
        "\n",
        "def agg_borda(df: pl.DataFrame, rank_cols: list[str]) -> pl.Expr:\n",
        "    \"\"\"\n",
        "    Borda (normalized): for each model, points = (max_rank + 1 - rank),\n",
        "    then sum points, then (optionally) normalize per group later.\n",
        "    We approximate max_rank per group via the max across rank columns.\n",
        "    \"\"\"\n",
        "    # max rank across models per row (same within a group but computed rowwise)\n",
        "    max_rank_row = None\n",
        "    for c in rank_cols:\n",
        "        max_rank_row = pl.max_horizontal(pl.col(c)) if max_rank_row is None else pl.max_horizontal(max_rank_row, pl.col(c))\n",
        "    # sum points\n",
        "    expr = None\n",
        "    for c in rank_cols:\n",
        "        points_c = (max_rank_row + 1 - pl.col(c))\n",
        "        expr = points_c if expr is None else (expr + points_c)\n",
        "    return expr.alias(\"agg_borda\")\n",
        "\n",
        "def agg_softmax(df: pl.DataFrame, rank_cols: list[str], tau: float) -> pl.Expr:\n",
        "    \"\"\"Softmax over ranks: sum_i exp(-rank_i / tau).\"\"\"\n",
        "    expr = None\n",
        "    for c in rank_cols:\n",
        "        term = (-pl.col(c) / tau).exp()\n",
        "        expr = term if expr is None else (expr + term)\n",
        "    return expr.alias(\"agg_softmax\")\n",
        "\n",
        "# =========================\n",
        "# ========= Main ==========\n",
        "# =========================\n",
        "\n",
        "def main():\n",
        "    # 1) Read all raw submissions and rename their 'selected' to a per-model column\n",
        "    dfs = []\n",
        "    model_cols = []\n",
        "    for path in RAW_SUBMISSIONS:\n",
        "        if not os.path.exists(path):\n",
        "            print(f\"‚ùå File not found: {path}\")\n",
        "            continue\n",
        "        df = read_submission(path)\n",
        "        # derive a tag from filename to name the column\n",
        "        m = re.search(r\"submission_.*?_(\\d+\\.\\d+)\\.(?:parquet|csv)$\", os.path.basename(path))\n",
        "        tag = m.group(1) if m else os.path.splitext(os.path.basename(path))[0]\n",
        "        colname = f\"rank_{tag}\"\n",
        "        # keep only necessary cols; rename 'selected' -> colname\n",
        "        df = df.select([\"Id\", \"ranker_id\", \"selected\"]).rename({\"selected\": colname})\n",
        "        dfs.append(df)\n",
        "        model_cols.append(colname)\n",
        "\n",
        "    if not dfs:\n",
        "        print(\"‚ùå No valid raw submissions found.\")\n",
        "        return\n",
        "\n",
        "    # 2) Join all on (Id, ranker_id)\n",
        "    df = dfs[0]\n",
        "    for d in dfs[1:]:\n",
        "        df = df.join(d, on=[\"Id\", \"ranker_id\"], how=\"inner\")\n",
        "\n",
        "    # 3) Compute aggregators (as expressions), then materialize\n",
        "    agg_exprs = []\n",
        "    agg_names = []\n",
        "\n",
        "    if USE_RRF:\n",
        "        agg_exprs.append(agg_rrf(df, model_cols, RRF_K))\n",
        "        agg_names.append(\"agg_rrf\")\n",
        "\n",
        "    if USE_BORDA:\n",
        "        agg_exprs.append(agg_borda(df, model_cols))\n",
        "        agg_names.append(\"agg_borda\")\n",
        "\n",
        "    if USE_SOFTMAX:\n",
        "        agg_exprs.append(agg_softmax(df, model_cols, TAU))\n",
        "        agg_names.append(\"agg_softmax\")\n",
        "\n",
        "    if not agg_exprs:\n",
        "        print(\"‚ùå No aggregators selected.\")\n",
        "        return\n",
        "\n",
        "    df = df.with_columns(agg_exprs)\n",
        "\n",
        "    # 4) Optionally blend aggregators with min-variance weights (computed from Spearman corr)\n",
        "    if BLEND_AGGREGATORS and len(agg_names) > 1:\n",
        "        # Normalize each aggregator per group so scales are compatible\n",
        "        norm_cols = []\n",
        "        for name in agg_names:\n",
        "            norm_col = f\"{name}_norm\"\n",
        "            df = df.with_columns(safe_minmax_norm(pl.col(name), \"ranker_id\").alias(norm_col))\n",
        "            norm_cols.append(norm_col)\n",
        "\n",
        "        # Correlation across all rows (Spearman) between normalized aggregators\n",
        "        pdf = df.select(norm_cols).to_pandas()\n",
        "        corr_df = pdf.corr(method=\"spearman\")\n",
        "        print(\"üìä Spearman between aggregators:\\n\", corr_df, \"\\n\")\n",
        "\n",
        "        corr = corr_df.values\n",
        "        w = mv_weights_from_corr(corr, lam=CORR_SHRINKAGE_LAMBDA)\n",
        "\n",
        "        if SAVE_AGG_WEIGHTS:\n",
        "            pd.Series(w, index=agg_names, name=\"weight\").to_csv(\"agg_blend_weights.csv\", header=True)\n",
        "            print(\"üìù Saved aggregator blend weights to agg_blend_weights.csv\")\n",
        "\n",
        "        # Blend: sum_j w_j * norm_agg_j\n",
        "        blended_expr = None\n",
        "        for name, norm_col, ww in zip(agg_names, norm_cols, w):\n",
        "            term = pl.col(norm_col) * float(ww)\n",
        "            blended_expr = term if blended_expr is None else (blended_expr + term)\n",
        "\n",
        "        df = df.with_columns(blended_expr.alias(\"ensemble_score\"))\n",
        "\n",
        "    else:\n",
        "        # Use a single aggregator\n",
        "        pick = SINGLE_AGGREGATOR.lower()\n",
        "        if pick not in {\"rrf\", \"borda\", \"softmax\"}:\n",
        "            raise ValueError(\"SINGLE_AGGREGATOR must be one of: 'rrf', 'borda', 'softmax'\")\n",
        "        pick_col = f\"agg_{pick}\"\n",
        "        if pick_col not in df.columns:\n",
        "            raise ValueError(f\"Aggregator {pick_col} not computed; enable it or change SINGLE_AGGREGATOR.\")\n",
        "        df = df.with_columns(pl.col(pick_col).alias(\"ensemble_score\"))\n",
        "\n",
        "    # 5) Optional final groupwise normalization\n",
        "    if NORMALIZE_FINAL_PER_GROUP:\n",
        "        df = df.with_columns(\n",
        "            safe_minmax_norm(pl.col(\"ensemble_score\"), \"ranker_id\").alias(\"ensemble_score\")\n",
        "        )\n",
        "\n",
        "    # 6) Final ranking within each ranker_id\n",
        "    if DETERMINISTIC_TIE_BREAK:\n",
        "        df = (\n",
        "            df.sort([\"ranker_id\", \"ensemble_score\", \"Id\"], descending=[False, True, False])\n",
        "              .with_columns(\n",
        "                  pl.col(\"ensemble_score\")\n",
        "                  .rank(\"ordinal\", descending=True)\n",
        "                  .over(\"ranker_id\")\n",
        "                  .cast(pl.Int32)\n",
        "                  .alias(\"selected\")\n",
        "              )\n",
        "        )\n",
        "    else:\n",
        "        df = df.with_columns(\n",
        "            pl.col(\"ensemble_score\")\n",
        "            .rank(\"ordinal\", descending=True)\n",
        "            .over(\"ranker_id\")\n",
        "            .cast(pl.Int32)\n",
        "            .alias(\"selected\")\n",
        "        )\n",
        "\n",
        "    final_submission = df.select([\"Id\", \"ranker_id\", \"selected\"])\n",
        "    print(\"‚úÖ Sample final submission:\")\n",
        "    print(final_submission.head())\n",
        "\n",
        "    final_submission.write_parquet(OUTPUT_PARQUET)\n",
        "    print(f\"üíæ Saved as: {OUTPUT_PARQUET}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lmJm1TEUEEda",
        "outputId": "d43a201f-8c3f-4b15-acb9-d15504ca2ab1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìä Spearman between aggregators:\n",
            "                   agg_rrf_norm  agg_borda_norm  agg_softmax_norm\n",
            "agg_rrf_norm          1.000000        0.253933          0.917329\n",
            "agg_borda_norm        0.253933        1.000000          0.161572\n",
            "agg_softmax_norm      0.917329        0.161572          1.000000 \n",
            "\n",
            "üìù Saved aggregator blend weights to agg_blend_weights.csv\n",
            "‚úÖ Sample final submission:\n",
            "shape: (5, 3)\n",
            "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
            "‚îÇ Id       ‚îÜ ranker_id                       ‚îÜ selected ‚îÇ\n",
            "‚îÇ ---      ‚îÜ ---                             ‚îÜ ---      ‚îÇ\n",
            "‚îÇ i64      ‚îÜ str                             ‚îÜ i32      ‚îÇ\n",
            "‚ïû‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï°\n",
            "‚îÇ 18952395 ‚îÜ 0001b08669de43deb3606f6764f1b4‚Ä¶ ‚îÜ 1        ‚îÇ\n",
            "‚îÇ 18952394 ‚îÜ 0001b08669de43deb3606f6764f1b4‚Ä¶ ‚îÜ 2        ‚îÇ\n",
            "‚îÇ 18952396 ‚îÜ 0001b08669de43deb3606f6764f1b4‚Ä¶ ‚îÜ 3        ‚îÇ\n",
            "‚îÇ 24082569 ‚îÜ 0002979a2bf046d99d0ddc79e924cf‚Ä¶ ‚îÜ 1        ‚îÇ\n",
            "‚îÇ 24082567 ‚îÜ 0002979a2bf046d99d0ddc79e924cf‚Ä¶ ‚îÜ 2        ‚îÇ\n",
            "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
            "üíæ Saved as: submission_ensemble_rank_agg.parquet\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import polars as pl\n",
        "\n",
        "# Cite»ôte fi»ôierul CSV\n",
        "df = pl.read_csv(\"submission_ensemble.csv\")\n",
        "\n",
        "# Scrie fi»ôierul √Æn format Parquet\n",
        "df.write_parquet(\"submission_ensemble.parquet\")\n",
        "\n",
        "print(\"üíæ Conversie completƒÉ: submission_ensemble.parquet\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V2ORSf1JiMEx",
        "outputId": "e2e196b5-d46f-41ad-b994-3175e8be64b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üíæ Conversie completƒÉ: submission_ensemble.parquet\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import polars as pl\n",
        "\n",
        "def load_submission_with_confidence(tag):\n",
        "    df = pl.read_parquet(f\"./ensemble/submission_{tag}_with_confidence.parquet\").drop(\n",
        "        \"selected\"\n",
        "    )\n",
        "\n",
        "    return df\n",
        "\n",
        "dfs = []\n",
        "\n",
        "timetag_score = {\n",
        "    # \"20250716132706\": [0, 0.51381],\n",
        "    # \"20250718083308\": [0, 0.51822],\n",
        "    # \"20250719002505\": [0, 0.51859],\n",
        "    # \"20250720003111\": [0, \"0.50693/lgb\"],\n",
        "    \"20250721025740\": [0, 0.51960],\n",
        "    \"20250722050939\": [1, 0.52070],\n",
        "    \"20250721083807\": [1, 0.52244],\n",
        "    \"20250724032338\": [1, \"0.51345/lgb\"],\n",
        "    # \"20250725040223\": [1, 0.52309],\n",
        "    \"20250725083055\": [1, 0.52391],\n",
        "    \"20250727084025\": [1, 0.52795],\n",
        "    \"20250728094305\": [1, 0.52492],\n",
        "    \"20250729084249\": [1, 0.51822],\n",
        "    # \"dl_ranker\": [1, 0.48755],\n",
        "    \"0.49242\": [1, 0.49242],\n",
        "}\n",
        "\n",
        "for timetag, score_list in timetag_score.items():\n",
        "    df = load_submission_with_confidence(timetag)\n",
        "    weight, score = score_list\n",
        "    df = df.with_columns(\n",
        "        (pl.col(\"confidence\")).alias(f\"confidence_{score}\")\n",
        "    ).drop(\"confidence\")\n",
        "    dfs.append(df)\n",
        "\n",
        "df_combined = dfs[0]\n",
        "for i in range(1, len(dfs)):\n",
        "    df_combined = df_combined.join(dfs[i], on=[\"Id\", \"ranker_id\"])\n",
        "\n",
        "print(df_combined)"
      ],
      "metadata": {
        "id": "0i9DtnIAPdiA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "confidence_cols = [col for col in df_combined.columns if col.startswith(\"confidence\")]\n",
        "corr_df = df_combined.select(confidence_cols).to_pandas().corr(method=\"spearman\")\n",
        "print(corr_df)"
      ],
      "metadata": {
        "id": "LZTzgm_CPf2h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mean_corr = corr_df.apply(lambda row: (row.sum() - 1) / (len(row) - 1), axis=1)\n",
        "\n",
        "model_uniqueness = 1 - mean_corr\n",
        "\n",
        "weights = model_uniqueness / model_uniqueness.sum()\n",
        "print(weights)"
      ],
      "metadata": {
        "id": "SgbV1lZfPg7g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "weighted_conf = sum(\n",
        "    df_combined[f].fill_null(0) * w\n",
        "    for f, w in zip(confidence_cols, weights.values)\n",
        ")\n",
        "\n",
        "df_combined = df_combined.with_columns(weighted_conf.alias(\"ensemble_confidence\"))"
      ],
      "metadata": {
        "id": "Yamjjd5_PiE4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_ranked = df_combined.with_columns(\n",
        "    [\n",
        "        pl.col(\"ensemble_confidence\")\n",
        "        .rank(method=\"ordinal\", descending=True)\n",
        "        .over(\"ranker_id\")\n",
        "        .cast(pl.Int32)\n",
        "        .alias(\"selected\")\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Load original order from one of the submissions\n",
        "df_original = dfs[0].select([\"Id\", \"ranker_id\"])\n",
        "\n",
        "# Join and keep only required columns in original order\n",
        "final_submission = df_original.join(\n",
        "    df_ranked.select([\"Id\", \"ranker_id\", \"selected\"]),\n",
        "    on=[\"Id\", \"ranker_id\"],\n",
        "    how=\"left\",\n",
        ")\n",
        "print(final_submission.head())"
      ],
      "metadata": {
        "id": "hSvW3GYsPjF_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import polars as pl\n",
        "import os\n",
        "\n",
        "# üéØ Weights for each model\n",
        "weights = {\n",
        "    \"confidence_0.52244\":       0.108858,\n",
        "    \"confidence_0.51345/lgb\":   0.131961,\n",
        "    \"confidence_0.52391\":       0.106060,\n",
        "    \"confidence_0.52795\":       0.099680,\n",
        "    \"confidence_0.52603\":       0.099481,\n",
        "    \"confidence_0.52474\":       0.102036,\n",
        "    \"confidence_0.51244/lgb\":   0.132210,\n",
        "    \"confidence_0.48755/0.49242\":       0.219714,\n",
        "}\n",
        "\n",
        "\n",
        "# üìÅ Input files mapped to confidence column names\n",
        "file_to_confcol = {\n",
        "    \"submission_20250721083807_0.52244_with_confidence.csv\": \"confidence_0.52244\",\n",
        "    \"submission_20250724032338_0.51345_with_confidence.csv\": \"confidence_0.51345/lgb\",\n",
        "    \"submission_20250725083055_0.52391_with_confidence.csv\": \"confidence_0.52391\",\n",
        "    \"submission_20250727084025_0.52795_with_confidence.csv\": \"confidence_0.52795\",\n",
        "    \"submission_20250802074816_0.52603_with_confidence.csv\": \"confidence_0.52603\",\n",
        "    \"submission_20250803063026_0.52474_with_confidence.csv\": \"confidence_0.52474\",\n",
        "    \"submission_20250804001151_0.51244_with_confidence.csv\": \"confidence_0.51244/lgb\",\n",
        "    \"submission_dl_ranker_weighted_boosted_normalized.csv\": \"confidence_0.48755/0.49242\"\n",
        "}\n",
        "\n",
        "# üì• Load and rename confidence columns\n",
        "dfs = []\n",
        "for file, colname in file_to_confcol.items():\n",
        "    if not os.path.exists(file):\n",
        "        print(f\"‚ùå File not found: {file}\")\n",
        "        continue\n",
        "    df = pl.read_csv(file)\n",
        "    if \"selected\" in df.columns:\n",
        "        df = df.drop(\"selected\")\n",
        "    df = df.with_columns(pl.col(\"confidence\").alias(colname)).drop(\"confidence\")\n",
        "    dfs.append(df)\n",
        "\n",
        "# üîó Join all DataFrames\n",
        "df_combined = dfs[0]\n",
        "for df in dfs[1:]:\n",
        "    df_combined = df_combined.join(df, on=[\"Id\", \"ranker_id\"])\n",
        "\n",
        "# üßÆ Compute ensemble confidence\n",
        "confidence_cols = list(weights.keys())\n",
        "df_combined = df_combined.with_columns(\n",
        "    sum(df_combined[col] * weights[col] for col in confidence_cols).alias(\"ensemble_confidence\")\n",
        ")\n",
        "\n",
        "# üèÅ Rank and save result\n",
        "df_output = df_combined.with_columns(\n",
        "    pl.col(\"ensemble_confidence\")\n",
        "    .rank(\"ordinal\", descending=True)\n",
        "    .over(\"ranker_id\")\n",
        "    .cast(pl.Int32)\n",
        "    .alias(\"selected\")\n",
        ").select([\"Id\", \"ranker_id\", \"selected\"])\n",
        "\n",
        "df_output.write_parquet(\"submission_weighted_ensemble.parquet\")\n",
        "print(\"üì¶ Saved unboosted ensemble ‚Üí submission_weighted_ensemble.parquet\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zJcUGwqHa3SJ",
        "outputId": "c551f784-6867-4b20-994d-11de21552e8a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üì¶ Saved unboosted ensemble ‚Üí submission_weighted_ensemble.parquet\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import polars as pl\n",
        "import os\n",
        "from collections import Counter, defaultdict\n",
        "\n",
        "# üéØ Weights for each model\n",
        "weights = {\n",
        "    \"confidence_0.51960\": 0.089680,\n",
        "    \"confidence_0.52070\": 0.087749,\n",
        "    \"confidence_0.52244\": 0.089308,\n",
        "    \"confidence_0.51345/lgb\": 0.129152,\n",
        "    \"confidence_0.52391\": 0.093028,\n",
        "    \"confidence_0.52795\": 0.097278,\n",
        "    \"confidence_0.52492\": 0.094761,\n",
        "    \"confidence_0.51822\": 0.101181,\n",
        "    \"confidence_0.48755\": 0.217863,\n",
        "}\n",
        "\n",
        "# üìÅ Input files mapped to confidence column names\n",
        "file_to_confcol = {\n",
        "    \"submission_20250721025740_0.51960_with_confidence.csv\": \"confidence_0.51960\",\n",
        "    \"submission_20250722050939_0.52070_with_confidence.csv\": \"confidence_0.52070\",\n",
        "    \"submission_20250721083807_0.52244_with_confidence.csv\": \"confidence_0.52244\",\n",
        "    \"submission_20250724032338_0.51345_with_confidence.csv\": \"confidence_0.51345/lgb\",\n",
        "    \"submission_20250725083055_0.52391_with_confidence.csv\": \"confidence_0.52391\",\n",
        "    \"submission_20250727084025_0.52795_with_confidence.csv\": \"confidence_0.52795\",\n",
        "    \"submission_20250728094305_0.52492_with_confidence.csv\": \"confidence_0.52492\",\n",
        "    \"submission_20250729084249_0.51822_with_confidence.csv\": \"confidence_0.51822\",\n",
        "    \"submission_dl_ranker_0.48755_with_confidence.csv\": \"confidence_0.48755\",\n",
        "}\n",
        "\n",
        "# üöÄ Boost factors based on frequency in top 3 across models\n",
        "boost_map = {\n",
        "    2: 1.30,\n",
        "    3: 1.40,\n",
        "    4: 1.45,\n",
        "    5: 1.50,\n",
        "    6: 1.55,\n",
        "    7: 1.60,\n",
        "    8: 1.65,\n",
        "    9: 1.70,\n",
        "}\n",
        "\n",
        "# üì• Load CSVs and rename confidence column\n",
        "dfs = []\n",
        "for file, colname in file_to_confcol.items():\n",
        "    if not os.path.exists(file):\n",
        "        print(f\"‚ùå File not found: {file}\")\n",
        "        continue\n",
        "    df = pl.read_csv(file)\n",
        "    if \"selected\" in df.columns:\n",
        "        df = df.drop(\"selected\")\n",
        "    df = df.with_columns(pl.col(\"confidence\").alias(colname)).drop(\"confidence\")\n",
        "    dfs.append(df)\n",
        "\n",
        "# üîó Join all dataframes on Id and ranker_id\n",
        "df_combined = dfs[0]\n",
        "for df in dfs[1:]:\n",
        "    df_combined = df_combined.join(df, on=[\"Id\", \"ranker_id\"])\n",
        "\n",
        "confidence_cols = list(weights.keys())\n",
        "\n",
        "# üßÆ Compute ensemble confidence (before boosting)\n",
        "df_combined = df_combined.with_columns(\n",
        "    sum(df_combined[col] * weights[col] for col in confidence_cols).alias(\"ensemble_confidence\")\n",
        ")\n",
        "\n",
        "# üíæ Save unboosted version\n",
        "df_combined.with_columns(\n",
        "    pl.col(\"ensemble_confidence\")\n",
        "    .rank(\"ordinal\", descending=True)\n",
        "    .over(\"ranker_id\")\n",
        "    .cast(pl.Int32)\n",
        "    .alias(\"selected\")\n",
        ").select([\"Id\", \"ranker_id\", \"selected\"]).write_parquet(\"submission_weighted_ensemble_unboosted.parquet\")\n",
        "\n",
        "print(\"üì¶ Saved unboosted ensemble ‚Üí submission_weighted_ensemble_unboosted.parquet\")\n",
        "\n",
        "# üöÄ Compute dynamic boost factors: (ranker_id, Id) ‚Üí boost_factor\n",
        "boosted_records = []\n",
        "boost_counts = defaultdict(int)\n",
        "\n",
        "# üîÑ Group data by ranker_id just once\n",
        "for group in df_combined.partition_by(\"ranker_id\"):\n",
        "    ranker_id_val = group[\"ranker_id\"][0]\n",
        "    top_ids_counter = Counter()\n",
        "\n",
        "    for col in confidence_cols:\n",
        "        top3_ids = (\n",
        "            group.select([\"Id\", col])\n",
        "            .sort(by=col, descending=True)\n",
        "            .head(3)\n",
        "            .get_column(\"Id\")\n",
        "            .to_list()\n",
        "        )\n",
        "        top_ids_counter.update(top3_ids)\n",
        "\n",
        "    for id_, freq in top_ids_counter.items():\n",
        "        if freq >= 2:\n",
        "            factor = boost_map.get(freq, 1.0)\n",
        "            boosted_records.append((ranker_id_val, id_, factor))\n",
        "            boost_counts[factor] += 1\n",
        "\n",
        "# üìå Create boost DataFrame\n",
        "df_boost = pl.DataFrame(boosted_records, schema=[\"ranker_id\", \"Id\", \"boost_factor\"])\n",
        "\n",
        "# üß™ Apply boost to ensemble_confidence\n",
        "df_boosted = df_combined.join(df_boost, on=[\"ranker_id\", \"Id\"], how=\"left\").with_columns(\n",
        "    (pl.col(\"ensemble_confidence\") * pl.col(\"boost_factor\").fill_null(1.0)).alias(\"ensemble_confidence\")\n",
        ")\n",
        "\n",
        "# üèÅ Compute final ranking after boosting\n",
        "df_boosted = df_boosted.with_columns(\n",
        "    pl.col(\"ensemble_confidence\")\n",
        "    .rank(\"ordinal\", descending=True)\n",
        "    .over(\"ranker_id\")\n",
        "    .cast(pl.Int32)\n",
        "    .alias(\"selected\")\n",
        ")\n",
        "\n",
        "df_boosted.select([\"Id\", \"ranker_id\", \"selected\"]).write_parquet(\"submission_weighted_ensemble_boosted.parquet\")\n",
        "print(\"‚úÖ Saved boosted ensemble ‚Üí submission_weighted_ensemble_boosted.parquet\")\n",
        "\n",
        "# üìä Boost summary\n",
        "print(\"\\nüìä Boosting summary (number of boosted Ids):\")\n",
        "for factor in sorted(boost_counts):\n",
        "    print(f\"√ó{factor:.2f} ‚Üí {boost_counts[factor]} rows\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SZD8uYMYZ9vn",
        "outputId": "b66e5eae-4676-4a5c-b62c-515962348636"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üì¶ Saved unboosted ensemble ‚Üí submission_weighted_ensemble_unboosted.parquet\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-718624286.py:104: DataOrientationWarning: Row orientation inferred during DataFrame construction. Explicitly specify the orientation by passing `orient=\"row\"` to silence this warning.\n",
            "  df_boost = pl.DataFrame(boosted_records, schema=[\"ranker_id\", \"Id\", \"boost_factor\"])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Saved boosted ensemble ‚Üí submission_weighted_ensemble_boosted.parquet\n",
            "\n",
            "üìä Boosting summary (numƒÉr de Id-uri boost-uite):\n",
            "√ó1.30 ‚Üí 25938 rows\n",
            "√ó1.40 ‚Üí 17318 rows\n",
            "√ó1.45 ‚Üí 14032 rows\n",
            "√ó1.50 ‚Üí 12435 rows\n",
            "√ó1.55 ‚Üí 11609 rows\n",
            "√ó1.60 ‚Üí 13422 rows\n",
            "√ó1.65 ‚Üí 19900 rows\n",
            "√ó1.70 ‚Üí 64719 rows\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import polars as pl\n",
        "import os\n",
        "from collections import Counter, defaultdict\n",
        "\n",
        "# üì• √éncarcƒÉ fi»ôierele *_with_confidence.csv\n",
        "files = [f for f in os.listdir() if f.endswith(\"_with_confidence.csv\")]\n",
        "\n",
        "dfs = []\n",
        "for file in files:\n",
        "    score_tag = os.path.splitext(file)[0]  # ex: submission_20250721025740_0.51960_with_confidence\n",
        "    df = pl.read_csv(file).rename({\"confidence\": f\"confidence_{score_tag}\"})\n",
        "    dfs.append(df)\n",
        "\n",
        "# üîó CombinƒÉ toate pe Id »ôi ranker_id\n",
        "df_combined = dfs[0]\n",
        "for df in dfs[1:]:\n",
        "    df_combined = df_combined.join(df, on=[\"Id\", \"ranker_id\"])\n",
        "\n",
        "# üß† Coloanele cu confidence\n",
        "confidence_cols = [col for col in df_combined.columns if col.startswith(\"confidence_\")]\n",
        "\n",
        "# üìä CalculeazƒÉ corela»õie Spearman √Æntre modele\n",
        "corr_df = df_combined.select(confidence_cols).to_pandas().corr(method=\"spearman\")\n",
        "\n",
        "# üéØ DerivƒÉ ponderea pe baza unicita»õii (1 - corela»õia medie)\n",
        "mean_corr = corr_df.apply(lambda row: (row.sum() - 1) / (len(row) - 1), axis=1)\n",
        "model_uniqueness = 1 - mean_corr\n",
        "weights = model_uniqueness / model_uniqueness.sum()\n",
        "\n",
        "# üßÆ Agregare ponderatƒÉ\n",
        "weighted_conf = sum(\n",
        "    df_combined[col].fill_null(0) * weight\n",
        "    for col, weight in zip(confidence_cols, weights.values)\n",
        ")\n",
        "\n",
        "df_combined = df_combined.with_columns(weighted_conf.alias(\"ensemble_confidence\"))\n",
        "\n",
        "# üèÅ Clasament final fƒÉrƒÉ boost\n",
        "df_ranked = df_combined.with_columns(\n",
        "    pl.col(\"ensemble_confidence\")\n",
        "    .rank(\"ordinal\", descending=True)\n",
        "    .over(\"ranker_id\")\n",
        "    .cast(pl.Int32)\n",
        "    .alias(\"selected\")\n",
        ")\n",
        "\n",
        "# üíæ SalveazƒÉ rezultatul fƒÉrƒÉ boost\n",
        "df_ranked.select([\"Id\", \"ranker_id\", \"selected\"]).write_parquet(\"submission_spearman_unboosted.parquet\")\n",
        "print(\"‚úÖ Salvat fƒÉrƒÉ boosting: submission_spearman_unboosted.parquet\")\n",
        "\n",
        "# üöÄ Boosting bazat pe frecven»õa √Æn top 3\n",
        "boost_map = {\n",
        "    2: 1.20, 3: 1.25, 4: 1.35, 5: 1.40,\n",
        "    6: 1.45, 7: 1.50, 8: 1.55, 9: 1.60,\n",
        "    10: 1.65, 11: 1.70\n",
        "}\n",
        "boosted_records = []\n",
        "boost_counts = defaultdict(int)\n",
        "\n",
        "for group in df_combined.partition_by(\"ranker_id\"):\n",
        "    ranker_id_val = group[\"ranker_id\"][0]\n",
        "    top_ids_counter = Counter()\n",
        "\n",
        "    for col in confidence_cols:\n",
        "        top3_ids = (\n",
        "            group.select([\"Id\", col])\n",
        "            .sort(col, descending=True)\n",
        "            .head(3)\n",
        "            .get_column(\"Id\")\n",
        "            .to_list()\n",
        "        )\n",
        "        top_ids_counter.update(top3_ids)\n",
        "\n",
        "    for id_, freq in top_ids_counter.items():\n",
        "        if freq >= 2:\n",
        "            factor = boost_map.get(freq, 1.0)\n",
        "            boosted_records.append((ranker_id_val, id_, factor))\n",
        "            boost_counts[factor] += 1\n",
        "\n",
        "df_boost = pl.DataFrame(boosted_records, schema=[\"ranker_id\", \"Id\", \"boost_factor\"])\n",
        "\n",
        "# üìà AplicƒÉ boosting\n",
        "df_boosted = df_combined.join(df_boost, on=[\"ranker_id\", \"Id\"], how=\"left\").with_columns(\n",
        "    (pl.col(\"ensemble_confidence\") * pl.col(\"boost_factor\").fill_null(1.0)).alias(\"ensemble_confidence\")\n",
        ")\n",
        "\n",
        "df_boosted = df_boosted.with_columns(\n",
        "    pl.col(\"ensemble_confidence\")\n",
        "    .rank(\"ordinal\", descending=True)\n",
        "    .over(\"ranker_id\")\n",
        "    .cast(pl.Int32)\n",
        "    .alias(\"selected\")\n",
        ")\n",
        "\n",
        "df_boosted.select([\"Id\", \"ranker_id\", \"selected\"]).write_parquet(\"submission_spearman_boosted.parquet\")\n",
        "print(\"‚úÖ Salvat cu boosting: submission_spearman_boosted.parquet\")\n",
        "\n",
        "# üìä Rezumat boosting\n",
        "print(\"\\nüìä Boosting summary:\")\n",
        "for factor in sorted(boost_counts):\n",
        "    print(f\"√ó{factor:.2f} ‚Üí {boost_counts[factor]} rows\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 608
        },
        "id": "zFP5YD33PxDD",
        "outputId": "a01ea7ce-eeb0-4d7e-fba3-1765b68bdd35"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "DuplicateError",
          "evalue": "column with name 'selected_right' already exists\n\nYou may want to try:\n- renaming the column prior to joining\n- using the `suffix` parameter to specify a suffix different to the default one ('_right')\n\nResolved plan until failure:\n\n\t---> FAILED HERE RESOLVING 'sink' <---\nDF [\"Id\", \"ranker_id\", \"selected\", \"confidence_submission_20250727084025_0.52795_with_confidence\"]; PROJECT */4 COLUMNS",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mDuplicateError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1173060755.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mdf_combined\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdfs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdfs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mdf_combined\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_combined\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Id\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ranker_id\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m# üß† Coloanele cu confidence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/polars/_utils/deprecation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m                 \u001b[0mold_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__qualname__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mversion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m             )\n\u001b[0;32m--> 114\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__signature__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/polars/dataframe/frame.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, other, on, how, left_on, right_on, suffix, validate, nulls_equal, coalesce, maintain_order)\u001b[0m\n\u001b[1;32m   7762\u001b[0m                 \u001b[0mmaintain_order\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmaintain_order\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7763\u001b[0m             )\n\u001b[0;32m-> 7764\u001b[0;31m             \u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_eager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   7765\u001b[0m         )\n\u001b[1;32m   7766\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/polars/_utils/deprecation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"engine\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"old-streaming\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__signature__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/polars/lazyframe/frame.py\u001b[0m in \u001b[0;36mcollect\u001b[0;34m(self, type_coercion, _type_check, predicate_pushdown, projection_pushdown, simplify_expression, slice_pushdown, comm_subplan_elim, comm_subexpr_elim, cluster_with_columns, collapse_joins, no_optimization, engine, background, _check_order, _eager, **_kwargs)\u001b[0m\n\u001b[1;32m   2186\u001b[0m         \u001b[0;31m# Only for testing purposes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2187\u001b[0m         \u001b[0mcallback\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"post_opt_callback\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2188\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrap_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mldf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2190\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0moverload\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mDuplicateError\u001b[0m: column with name 'selected_right' already exists\n\nYou may want to try:\n- renaming the column prior to joining\n- using the `suffix` parameter to specify a suffix different to the default one ('_right')\n\nResolved plan until failure:\n\n\t---> FAILED HERE RESOLVING 'sink' <---\nDF [\"Id\", \"ranker_id\", \"selected\", \"confidence_submission_20250727084025_0.52795_with_confidence\"]; PROJECT */4 COLUMNS"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**PCA**"
      ],
      "metadata": {
        "id": "IXH993g5PkJY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import polars as pl\n",
        "import numpy as np\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "\n",
        "def load_submission_with_confidence(tag):\n",
        "    df = pl.read_parquet(f\"./ensemble/submission_{tag}_with_confidence.parquet\").drop(\n",
        "        \"selected\"\n",
        "    )\n",
        "    return df\n",
        "\n",
        "\n",
        "# Timetag and corresponding public scores (used for column names and optional interpretation)\n",
        "timetag_score = {\n",
        "    \"20250721025740\": [0, 0.51960],\n",
        "    \"20250722050939\": [1, 0.52070],\n",
        "    \"20250721083807\": [1, 0.52244],\n",
        "    \"20250724032338\": [1, \"0.51345/lgb\"],\n",
        "    \"20250725083055\": [1, 0.52391],\n",
        "    \"20250727084025\": [1, 0.52795],\n",
        "    \"20250728094305\": [1, 0.52492],\n",
        "    \"20250729084249\": [1, 0.51822],\n",
        "    \"0.49242\": [1, 0.49242],\n",
        "}\n",
        "\n",
        "# Load and rename confidence columns from each model\n",
        "dfs = []\n",
        "for timetag, score_list in timetag_score.items():\n",
        "    df = load_submission_with_confidence(timetag)\n",
        "    _, score = score_list\n",
        "    df = df.with_columns(pl.col(\"confidence\").alias(f\"confidence_{score}\")).drop(\n",
        "        \"confidence\"\n",
        "    )\n",
        "    dfs.append(df)\n",
        "\n",
        "# Join all submissions on Id and ranker_id\n",
        "df_combined = dfs[0]\n",
        "for i in range(1, len(dfs)):\n",
        "    df_combined = df_combined.join(dfs[i], on=[\"Id\", \"ranker_id\"])\n",
        "\n",
        "# Extract confidence columns\n",
        "confidence_cols = [col for col in df_combined.columns if col.startswith(\"confidence\")]\n",
        "X = df_combined.select(confidence_cols).to_numpy()\n",
        "pca = PCA(n_components=1)\n",
        "pc1_scores = pca.fit_transform(X).flatten()\n",
        "\n",
        "# Add ensemble confidence based on PCA projection\n",
        "df_combined = df_combined.with_columns(pl.Series(\"ensemble_confidence\", pc1_scores))\n",
        "\n",
        "# Rank each item within its group (ranker_id) based on ensemble confidence\n",
        "df_ranked = df_combined.with_columns(\n",
        "    pl.col(\"ensemble_confidence\")\n",
        "    .rank(method=\"ordinal\", descending=True)\n",
        "    .over(\"ranker_id\")\n",
        "    .cast(pl.Int32)\n",
        "    .alias(\"selected\")\n",
        ")\n",
        "# Restore original ordering and format final submission\n",
        "df_original = dfs[0].select([\"Id\", \"ranker_id\"])\n",
        "final_submission = df_original.join(\n",
        "    df_ranked.select([\"Id\", \"ranker_id\", \"selected\"]),\n",
        "    on=[\"Id\", \"ranker_id\"],\n",
        "    how=\"left\",\n",
        ")\n",
        "\n",
        "# Display the top rows of the final submission\n",
        "print(final_submission.head())\n",
        "\n",
        "# Print each model's contribution to the PCA component\n",
        "print(\"\\nPCA component weights per model:\")\n",
        "for col_name, weight in zip(confidence_cols, pca.components_[0]):\n",
        "    print(f\"{col_name}: {weight:.4f}\")"
      ],
      "metadata": {
        "id": "ZqW1sRVUPlZp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_submission.write_parquet(\"submission_ensemble_pca.parquet\")"
      ],
      "metadata": {
        "id": "yvTfB1ddQAh7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import polars as pl\n",
        "import numpy as np\n",
        "from sklearn.decomposition import PCA\n",
        "import glob\n",
        "\n",
        "def load_confidence_csv(path):\n",
        "    df = pl.read_csv(path).select([\"Id\", \"ranker_id\", \"confidence\"])\n",
        "    return df\n",
        "\n",
        "def main():\n",
        "    # CautƒÉ toate fi»ôierele *_with_confidence.csv\n",
        "    confidence_files = sorted(glob.glob(\"*_with_confidence.csv\"))\n",
        "    print(f\"üìÅ Found {len(confidence_files)} confidence files.\")\n",
        "\n",
        "    if not confidence_files:\n",
        "        print(\"‚ùå No confidence files found.\")\n",
        "        return\n",
        "\n",
        "    # √éncarcƒÉ »ôi redenume»ôte coloanele de confidence\n",
        "    dfs = []\n",
        "    for f in confidence_files:\n",
        "        tag = os.path.splitext(os.path.basename(f))[0].replace(\"_with_confidence\", \"\")\n",
        "        df = load_confidence_csv(f)\n",
        "        df = df.rename({\"confidence\": f\"confidence_{tag}\"})\n",
        "        dfs.append(df)\n",
        "\n",
        "    # CombinƒÉ toate pe Id »ôi ranker_id\n",
        "    df_combined = dfs[0]\n",
        "    for df in dfs[1:]:\n",
        "        df_combined = df_combined.join(df, on=[\"Id\", \"ranker_id\"])\n",
        "\n",
        "    # AplicƒÉ PCA pe scorurile de confidence\n",
        "    confidence_cols = [col for col in df_combined.columns if col.startswith(\"confidence\")]\n",
        "    X = df_combined.select(confidence_cols).to_numpy()\n",
        "    pca = PCA(n_components=1)\n",
        "    pc1_scores = pca.fit_transform(X).flatten()\n",
        "\n",
        "    # AdaugƒÉ ensemble confidence »ôi selecteazƒÉ\n",
        "    df_combined = df_combined.with_columns(pl.Series(\"ensemble_confidence\", pc1_scores))\n",
        "    df_ranked = df_combined.with_columns(\n",
        "        pl.col(\"ensemble_confidence\")\n",
        "        .rank(method=\"ordinal\", descending=True)\n",
        "        .over(\"ranker_id\")\n",
        "        .cast(pl.Int32)\n",
        "        .alias(\"selected\")\n",
        "    )\n",
        "\n",
        "    # Format final\n",
        "    final_submission = df_ranked.select([\"Id\", \"ranker_id\", \"selected\"])\n",
        "    final_submission.write_parquet(\"submission_ensemble_pca.parquet\")\n",
        "    print(\"‚úÖ Saved PCA ensemble to submission_ensemble_pca.parquet\")\n",
        "\n",
        "    # Afi»ôeazƒÉ contribu»õia fiecƒÉrui model\n",
        "    print(\"\\nüìä PCA weights per model:\")\n",
        "    for name, weight in zip(confidence_cols, pca.components_[0]):\n",
        "        print(f\"{name}: {weight:.4f}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    import os\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aZgYOfmjRPAk",
        "outputId": "e7c3e8b8-0d6b-42fb-b111-5f2395740910"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìÅ Found 8 confidence files.\n",
            "‚úÖ Saved PCA ensemble to submission_ensemble_pca.csv\n",
            "\n",
            "üìä PCA weights per model:\n",
            "confidence_submission_20250724032338_0.51345: 0.3525\n",
            "confidence_submission_20250725040223_0.52309: 0.3580\n",
            "confidence_submission_20250725083055_0.52391: 0.3580\n",
            "confidence_submission_20250727084025_0.52795: 0.3586\n",
            "confidence_submission_20250728094305_0.52492: 0.3589\n",
            "confidence_submission_20250729084249_0.51822: 0.3581\n",
            "confidence_submission_dl_ranker_0.48755: 0.3404\n",
            "confidence_submission_dl_ranker_0.49242: 0.3433\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import polars as pl\n",
        "import numpy as np\n",
        "from sklearn.decomposition import PCA\n",
        "import glob\n",
        "import os\n",
        "\n",
        "def load_confidence_csv(path):\n",
        "    df = pl.read_csv(path).select([\"Id\", \"ranker_id\", \"confidence\"])\n",
        "    return df\n",
        "\n",
        "def main():\n",
        "    # CautƒÉ toate fi»ôierele *_with_confidence.csv\n",
        "    confidence_files = sorted(glob.glob(\"*_with_confidence.csv\"))\n",
        "    print(f\"üìÅ Found {len(confidence_files)} confidence files.\")\n",
        "\n",
        "    if not confidence_files:\n",
        "        print(\"‚ùå No confidence files found.\")\n",
        "        return\n",
        "\n",
        "    # √éncarcƒÉ »ôi redenume»ôte coloanele de confidence\n",
        "    dfs = []\n",
        "    for f in confidence_files:\n",
        "        tag = os.path.splitext(os.path.basename(f))[0].replace(\"_with_confidence\", \"\")\n",
        "        df = load_confidence_csv(f)\n",
        "        df = df.rename({\"confidence\": f\"confidence_{tag}\"})\n",
        "        dfs.append(df)\n",
        "\n",
        "    # CombinƒÉ toate pe Id »ôi ranker_id\n",
        "    df_combined = dfs[0]\n",
        "    for df in dfs[1:]:\n",
        "        df_combined = df_combined.join(df, on=[\"Id\", \"ranker_id\"])\n",
        "\n",
        "    # Extrage matricea de confidence\n",
        "    confidence_cols = [col for col in df_combined.columns if col.startswith(\"confidence\")]\n",
        "    X = df_combined.select(confidence_cols).to_numpy()\n",
        "\n",
        "    # --- PAS 1: CalculeazƒÉ corela»õia Spearman ---\n",
        "    corr_df = df_combined.select(confidence_cols).to_pandas().corr(method=\"spearman\")\n",
        "    mean_corr = corr_df.apply(lambda row: (row.sum() - 1) / (len(row) - 1), axis=1)\n",
        "    model_uniqueness = 1 - mean_corr\n",
        "    weights_spearman = model_uniqueness / model_uniqueness.sum()\n",
        "\n",
        "    print(\"\\nüîç Spearman-based weights:\")\n",
        "    for col, w in zip(confidence_cols, weights_spearman):\n",
        "        print(f\"{col}: {w:.4f}\")\n",
        "\n",
        "    # --- PAS 2: AplicƒÉ PCA pe scorurile de confidence ponderate ---\n",
        "    X_weighted = X * weights_spearman.values  # Broadcast pe coloane\n",
        "    pca = PCA(n_components=1)\n",
        "    pc1_scores = pca.fit_transform(X_weighted).flatten()\n",
        "\n",
        "    # AdaugƒÉ ensemble confidence »ôi selecteazƒÉ\n",
        "    df_combined = df_combined.with_columns(pl.Series(\"ensemble_confidence\", pc1_scores))\n",
        "    df_ranked = df_combined.with_columns(\n",
        "        pl.col(\"ensemble_confidence\")\n",
        "        .rank(method=\"ordinal\", descending=True)\n",
        "        .over(\"ranker_id\")\n",
        "        .cast(pl.Int32)\n",
        "        .alias(\"selected\")\n",
        "    )\n",
        "\n",
        "    # Format final\n",
        "    final_submission = df_ranked.select([\"Id\", \"ranker_id\", \"selected\"])\n",
        "    final_submission.write_parquet(\"submission_ensemble_spearman_pca.parquet\")\n",
        "    print(\"‚úÖ Saved Spearman+PCA ensemble to submission_ensemble_spearman_pca.parquet\")\n",
        "\n",
        "    # Afi»ôeazƒÉ contribu»õia fiecƒÉrui model √Æn PC1\n",
        "    print(\"\\nüìä PCA component weights after Spearman weighting:\")\n",
        "    for name, weight in zip(confidence_cols, pca.components_[0]):\n",
        "        print(f\"{name}: {weight:.4f}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iaIuZyjRSfXc",
        "outputId": "28beca05-f9c7-4fb0-8a4e-c915319792a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìÅ Found 8 confidence files.\n",
            "\n",
            "üîç Spearman-based weights:\n",
            "confidence_submission_20250724032338_0.51345: 0.1303\n",
            "confidence_submission_20250725040223_0.52309: 0.0999\n",
            "confidence_submission_20250725083055_0.52391: 0.1001\n",
            "confidence_submission_20250727084025_0.52795: 0.0968\n",
            "confidence_submission_20250728094305_0.52492: 0.0947\n",
            "confidence_submission_20250729084249_0.51822: 0.0995\n",
            "confidence_submission_dl_ranker_0.48755: 0.1974\n",
            "confidence_submission_dl_ranker_0.49242: 0.1813\n",
            "‚úÖ Saved Spearman+PCA ensemble to submission_ensemble_spearman_pca.parquet\n",
            "\n",
            "üìä PCA component weights after Spearman weighting:\n",
            "confidence_submission_20250724032338_0.51345: 0.3517\n",
            "confidence_submission_20250725040223_0.52309: 0.2712\n",
            "confidence_submission_20250725083055_0.52391: 0.2718\n",
            "confidence_submission_20250727084025_0.52795: 0.2629\n",
            "confidence_submission_20250728094305_0.52492: 0.2577\n",
            "confidence_submission_20250729084249_0.51822: 0.2701\n",
            "confidence_submission_dl_ranker_0.48755: 0.5317\n",
            "confidence_submission_dl_ranker_0.49242: 0.4876\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Advanced Ensemble Methods**"
      ],
      "metadata": {
        "id": "o45SFw-bw3iR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import polars as pl\n",
        "import os\n",
        "\n",
        "def compute_confidence(df: pl.DataFrame, alpha: float = 0.7, k: int = 5) -> pl.DataFrame:\n",
        "    # mƒÉrimea grupului pentru fiecare ranker_id\n",
        "    df = df.with_columns([\n",
        "        pl.len().over(\"ranker_id\").alias(\"group_size\")\n",
        "    ])\n",
        "\n",
        "    # 1) scorul de bazƒÉ pe pozi»õie √Æn cadrul grupului (maxim pentru selected=1)\n",
        "    base_conf = 1.0 - ((pl.col(\"selected\") - 1) / (pl.col(\"group_size\") - 1 + 1e-8))\n",
        "    df = df.with_columns(base_conf.alias(\"confidence\"))\n",
        "\n",
        "    # 2) scorul RRF normalizat la [0, 1]\n",
        "    rrf_max = 1.0 / (k + 1)  # valoarea RRF pentru selected=1\n",
        "    df = df.with_columns(\n",
        "        ((1.0 / (k + pl.col(\"selected\"))) / rrf_max).alias(\"rrf_score\")\n",
        "    )\n",
        "\n",
        "    # 3) combina»õie convexƒÉ √Æntre scorul de bazƒÉ »ôi RRF\n",
        "    df = df.with_columns(\n",
        "        (alpha * pl.col(\"confidence\") + (1 - alpha) * pl.col(\"rrf_score\")).alias(\"confidence\")\n",
        "    )\n",
        "\n",
        "    # pƒÉstrƒÉm 'selected'; curƒÉ»õƒÉm doar coloanele temporare\n",
        "    return df.drop([\"group_size\", \"rrf_score\"])\n",
        "\n",
        "def process_file(input_path: str, alpha: float = 0.7, k: int = 5):\n",
        "    print(f\"üîÑ Processing: {input_path}\")\n",
        "\n",
        "    if input_path.endswith(\".csv\"):\n",
        "        df = pl.read_csv(input_path)\n",
        "    elif input_path.endswith(\".parquet\"):\n",
        "        df = pl.read_parquet(input_path)\n",
        "    else:\n",
        "        print(f\"‚ö†Ô∏è Skipping unsupported file: {input_path}\")\n",
        "        return\n",
        "\n",
        "    df_conf = compute_confidence(df, alpha=alpha, k=k)\n",
        "\n",
        "    base, ext = os.path.splitext(input_path)\n",
        "    if base.endswith(\"_with_confidence\"):\n",
        "        output_path = f\"{base}.csv\"\n",
        "    else:\n",
        "        output_path = f\"{base}_with_confidence.csv\"\n",
        "\n",
        "    df_conf.write_csv(output_path)\n",
        "    print(f\"‚úÖ Saved: {output_path}\\n\")\n",
        "\n",
        "\n",
        "def main():\n",
        "    files = [\n",
        "        \"submission_20250721083807_0.52244.parquet\",\n",
        "        \"submission_20250724032338_0.51345.parquet\",\n",
        "        \"submission_20250725083055_0.52391.parquet\",\n",
        "        \"submission_20250727084025_0.52795.parquet\",\n",
        "        \"submission_20250802074816_0.52603.parquet\",\n",
        "        \"submission_20250804001151_0.51244.parquet\",\n",
        "        \"submission_20250807032439_0.52538.parquet\",\n",
        "        \"submission_dl_ranker_0.48755.parquet\"\n",
        "    ]\n",
        "\n",
        "    alpha = 0.7\n",
        "    k = 5\n",
        "\n",
        "    for file in files:\n",
        "        if os.path.exists(file):\n",
        "            process_file(file, alpha=alpha, k=k)\n",
        "        else:\n",
        "            print(f\"‚ùå File not found: {file}\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "D8eJgjTaw56H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile ensemble.py\n",
        "# %%\n",
        "# Rank-based ensemble (no \"confidence\" scores):\n",
        "# 1) rank -> percentile within each ranker_id group (1 for rank=1)\n",
        "# 2) van der Waerden normal-scores: z = Phi^{-1}(percentile)\n",
        "# 3) SML (leading eigenvector on correlations), zero diagonal\n",
        "# 4) Shrink weights within clusters of highly correlated models\n",
        "# 5) Aggregate and re-rank per ranker_id\n",
        "\n",
        "import polars as pl\n",
        "import numpy as np\n",
        "import re\n",
        "from numpy.linalg import eigh\n",
        "\n",
        "EPS = 1e-12\n",
        "\n",
        "FILES = [\n",
        "    \"submission_20250721083807_0.52244.parquet\",\n",
        "    \"submission_20250724032338_0.51345.parquet\",\n",
        "    \"submission_20250725083055_0.52391.parquet\",\n",
        "    \"submission_20250727084025_0.52795.parquet\",\n",
        "    \"submission_20250802074816_0.52603.parquet\",\n",
        "    \"submission_20250804001151_0.51244.parquet\",\n",
        "    \"submission_20250807032439_0.52538.parquet\",\n",
        "    \"submission_dl_ranker_0.48755.parquet\",\n",
        "]\n",
        "\n",
        "# ---------- helpers ----------\n",
        "def load_rank_file(fp: str) -> pl.DataFrame:\n",
        "    \"\"\"Load a rank file and keep only the necessary columns.\"\"\"\n",
        "    return pl.read_parquet(fp).select([\"Id\", \"ranker_id\", \"selected\"])\n",
        "\n",
        "def pct_from_rank(df: pl.DataFrame, col: str = \"selected\") -> pl.DataFrame:\n",
        "    \"\"\"\n",
        "    Convert ranks to descending percentiles:\n",
        "    percentile = 1 for rank=1, close to 0 for the worst rank in the group.\n",
        "    \"\"\"\n",
        "    return (\n",
        "        df.with_columns(pl.len().over(\"ranker_id\").alias(\"n_in_group\"))\n",
        "          .with_columns(\n",
        "              (1.0 - (pl.col(col) - 1) / (pl.col(\"n_in_group\") - 1 + 1e-9)).alias(\"percentile\")\n",
        "          )\n",
        "          .drop(\"n_in_group\")\n",
        "    )\n",
        "\n",
        "# ---- robust inverse normal CDF (Acklam approximation) ----\n",
        "def _phi_inv(p: np.ndarray) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Numerically stable approximation of the inverse standard normal CDF Œ¶‚Åª¬π(p).\n",
        "    (Peter John Acklam's rational approximation)\n",
        "    \"\"\"\n",
        "    p = np.asarray(p, dtype=float)\n",
        "    a = [-3.969683028665376e+01, 2.209460984245205e+02, -2.759285104469687e+02,\n",
        "         1.383577518672690e+02, -3.066479806614716e+01, 2.506628277459239e+00]\n",
        "    b = [-5.447609879822406e+01, 1.615858368580409e+02, -1.556989798598866e+02,\n",
        "         6.680131188771972e+01, -1.328068155288572e+01]\n",
        "    c = [-7.784894002430293e-03, -3.223964580411365e-01, -2.400758277161838e+00,\n",
        "         -2.549732539343734e+00, 4.374664141464968e+00, 2.938163982698783e+00]\n",
        "    d = [7.784695709041462e-03, 3.224671290700398e-01, 2.445134137142996e+00, 3.754408661907416e+00]\n",
        "    plow, phigh = 0.02425, 1 - 0.02425\n",
        "    x = np.empty_like(p, dtype=float)\n",
        "\n",
        "    mask = p < plow\n",
        "    if np.any(mask):\n",
        "        q = np.sqrt(-2 * np.log(p[mask]))\n",
        "        x[mask] = (((((c[0]*q + c[1])*q + c[2])*q + c[3])*q + c[4])*q + c[5]) / \\\n",
        "                   ((((d[0]*q + d[1])*q + d[2])*q + d[3])*q + 1)\n",
        "\n",
        "    mask = (p >= plow) & (p <= phigh)\n",
        "    if np.any(mask):\n",
        "        q = p[mask] - 0.5\n",
        "        r = q * q\n",
        "        x[mask] = (((((a[0]*r + a[1])*r + a[2])*r + a[3])*r + a[4])*r + a[5]) * q / \\\n",
        "                   (((((b[0]*r + b[1])*r + b[2])*r + b[3])*r + b[4])*r + 1)\n",
        "\n",
        "    mask = p > phigh\n",
        "    if np.any(mask):\n",
        "        q = np.sqrt(-2 * np.log(1 - p[mask]))\n",
        "        x[mask] = -(((((c[0]*q + c[1])*q + c[2])*q + c[3])*q + c[4])*q + c[5]) / \\\n",
        "                    ((((d[0]*q + d[1])*q + d[2])*q + d[3])*q + 1)\n",
        "    return x\n",
        "\n",
        "def normal_score(u: np.ndarray) -> np.ndarray:\n",
        "    \"\"\"van der Waerden normal scores via Œ¶‚Åª¬π(u) using a robust approximation.\"\"\"\n",
        "    u = np.clip(u, 1e-6, 1 - 1e-6)\n",
        "    return _phi_inv(u)\n",
        "\n",
        "def zscore_cols(M: np.ndarray) -> np.ndarray:\n",
        "    \"\"\"Column-wise z-score standardization.\"\"\"\n",
        "    mu = M.mean(axis=0, keepdims=True)\n",
        "    sd = M.std(axis=0, ddof=1, keepdims=True)\n",
        "    sd = np.where(sd < 1e-8, 1.0, sd)\n",
        "    return (M - mu) / sd\n",
        "\n",
        "def leading_eigvec_sym(C: np.ndarray) -> np.ndarray:\n",
        "    \"\"\"Return the leading eigenvector of a symmetric matrix (positive-oriented).\"\"\"\n",
        "    _, vecs = eigh(C)\n",
        "    v = vecs[:, -1]\n",
        "    return v if v.mean() >= 0 else -v\n",
        "\n",
        "def cluster_by_corr(R: np.ndarray, thr: float = 0.92):\n",
        "    \"\"\"Greedy clustering of models with high absolute correlation (|corr| >= thr).\"\"\"\n",
        "    m = R.shape[0]\n",
        "    seen = np.zeros(m, dtype=bool)\n",
        "    clusters = []\n",
        "    for i in range(m):\n",
        "        if seen[i]:\n",
        "            continue\n",
        "        grp = [i]\n",
        "        seen[i] = True\n",
        "        for j in range(i + 1, m):\n",
        "            if not seen[j] and abs(R[i, j]) >= thr:\n",
        "                grp.append(j)\n",
        "                seen[j] = True\n",
        "        clusters.append(grp)\n",
        "    return clusters\n",
        "\n",
        "def shrink_within_clusters(w: np.ndarray, clusters, alpha=0.5):\n",
        "    \"\"\"Blend weights with the cluster mean to avoid double-counting similar models.\"\"\"\n",
        "    w2 = w.copy()\n",
        "    for grp in clusters:\n",
        "        if len(grp) <= 1:\n",
        "            continue\n",
        "        mu = w[grp].mean()\n",
        "        for k in grp:\n",
        "            w2[k] = alpha * mu + (1 - alpha) * w[k]\n",
        "    s = w2.sum()\n",
        "    return (w2 / s) if s > 0 else (np.ones_like(w2) / len(w2))\n",
        "\n",
        "# ---------- main ----------\n",
        "def main():\n",
        "    # 1) Load files and create percentile columns per model (drop 'selected' to avoid join collisions)\n",
        "    dfs, colnames = [], []\n",
        "    for fp in FILES:\n",
        "        try:\n",
        "            df = load_rank_file(fp)\n",
        "        except Exception as e:\n",
        "            print(f\"‚ö†Ô∏è Skipping (cannot read): {fp} ({e})\")\n",
        "            continue\n",
        "\n",
        "        m = re.search(r\"_([\\d.]+)\\.parquet$\", fp)\n",
        "        tag = m.group(1) if m else re.sub(r\"\\W+\", \"\", fp.split(\"/\")[-1])\n",
        "\n",
        "        df_pct = (\n",
        "            pct_from_rank(df, col=\"selected\")\n",
        "            .select([\"Id\", \"ranker_id\", pl.col(\"percentile\").alias(f\"pct_{tag}\")])\n",
        "        )\n",
        "        dfs.append(df_pct)\n",
        "        colnames.append(f\"pct_{tag}\")\n",
        "\n",
        "    if not dfs:\n",
        "        print(\"‚ùå No valid rank files found.\")\n",
        "        return\n",
        "\n",
        "    # 2) Join on Id + ranker_id\n",
        "    base = dfs[0]\n",
        "    for d in dfs[1:]:\n",
        "        base = base.join(d, on=[\"Id\", \"ranker_id\"])\n",
        "\n",
        "    # 3) Process each ranker_id separately\n",
        "    out = []\n",
        "    for g in base.partition_by(\"ranker_id\", as_dict=False, maintain_order=True):\n",
        "        P = np.column_stack([g[c].to_numpy() for c in colnames])  # (n, m) percentiles\n",
        "        n, m = P.shape\n",
        "\n",
        "        # 3a) normal-scores + standardization\n",
        "        Z = np.column_stack([normal_score(P[:, j]) for j in range(m)])\n",
        "        if (m == 1) or (n < 3) or (not np.all(np.isfinite(Z))):\n",
        "            w = np.ones(m) / m\n",
        "        else:\n",
        "            L = zscore_cols(Z)\n",
        "            if not np.all(np.isfinite(L)):\n",
        "                w = np.ones(m) / m\n",
        "            else:\n",
        "                # Correlation on standardized variables; zero diagonal for classic SML\n",
        "                C = (L.T @ L) / max(1, n - 1)\n",
        "                np.fill_diagonal(C, 0.0)\n",
        "                if not np.all(np.isfinite(C)):\n",
        "                    w = np.ones(m) / m\n",
        "                else:\n",
        "                    v = np.maximum(leading_eigvec_sym(C), 0) + EPS\n",
        "                    w = v / v.sum()\n",
        "                    # Shrink in clusters of highly correlated models\n",
        "                    R = np.corrcoef(L.T)\n",
        "                    R[~np.isfinite(R)] = 0.0\n",
        "                    clusters = cluster_by_corr(R, thr=0.92)\n",
        "                    w = shrink_within_clusters(w, clusters, alpha=0.5)\n",
        "\n",
        "        # 4) Composite score and re-ranking within the group\n",
        "        comp = Z.dot(w)\n",
        "        gout = (\n",
        "            g.with_columns(pl.Series(\"ensemble_score\", comp))\n",
        "             .with_columns(\n",
        "                 pl.col(\"ensemble_score\")\n",
        "                   .rank(\"ordinal\", descending=True)\n",
        "                   .cast(pl.Int32)\n",
        "                   .alias(\"selected\")\n",
        "             )\n",
        "             .select([\"Id\", \"ranker_id\", \"selected\"])\n",
        "        )\n",
        "        out.append(gout)\n",
        "\n",
        "    final = pl.concat(out, how=\"vertical\")\n",
        "    print(\"\\n‚úÖ Sample:\")\n",
        "    print(final.head())\n",
        "\n",
        "    final.write_parquet(\"submission_ensemble_from_ranks.parquet\")\n",
        "    print(\"\\nüíæ Saved as: submission_ensemble_from_ranks.parquet\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WJa7bgJhw9l3",
        "outputId": "ede83e69-c6f6-4382-a910-224d68ef7c84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting ensemble.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile ensemble_em.py\n",
        "# %%\n",
        "# Label-free EM with Beta distributions on \"rank-only\" data:\n",
        "# - For each model: transform 'selected' -> percentile within each ranker_id group\n",
        "# - EM: P(u_k | y=c) ~ Beta(alpha_{k,c}, beta_{k,c}), u_k ‚àà (0,1]\n",
        "# - Compute posterior P(y=1 | u_1..u_m) and rank within each ranker_id\n",
        "#\n",
        "# Input: .parquet files with columns [Id, ranker_id, selected]\n",
        "# Output: submission_ensemble_em_beta_from_ranks.parquet (Id, ranker_id, selected)\n",
        "\n",
        "import polars as pl\n",
        "import numpy as np\n",
        "import re\n",
        "from math import lgamma\n",
        "import sys\n",
        "\n",
        "EPS = 1e-12\n",
        "\n",
        "FILES = [\n",
        "    \"submission_20250721083807_0.52244.parquet\",\n",
        "    \"submission_20250724032338_0.51345.parquet\",\n",
        "    \"submission_20250725083055_0.52391.parquet\",\n",
        "    \"submission_20250727084025_0.52795.parquet\",\n",
        "    \"submission_20250802074816_0.52603.parquet\",\n",
        "    \"submission_20250804001151_0.51244.parquet\",\n",
        "    \"submission_20250807032439_0.52538.parquet\",\n",
        "    \"submission_dl_ranker_0.48755.parquet\",\n",
        "]\n",
        "\n",
        "# -------------------- Utilities --------------------\n",
        "def load_rank_file(fp: str) -> pl.DataFrame:\n",
        "    \"\"\"Load a rank file with required columns.\"\"\"\n",
        "    return pl.read_parquet(fp).select([\"Id\", \"ranker_id\", \"selected\"])\n",
        "\n",
        "def to_percentile_per_ranker(df: pl.DataFrame, rank_col: str = \"selected\") -> pl.DataFrame:\n",
        "    \"\"\"\n",
        "    Convert integer ranks into descending percentiles within each ranker_id group:\n",
        "    - percentile = 1 for rank=1 (best), close to 0 for the worst rank.\n",
        "    \"\"\"\n",
        "    return (\n",
        "        df.with_columns(pl.len().over(\"ranker_id\").alias(\"n_in_group\"))\n",
        "          .with_columns(\n",
        "              (1.0 - (pl.col(rank_col) - 1) / (pl.col(\"n_in_group\") - 1 + 1e-9)).alias(\"percentile\")\n",
        "          )\n",
        "          .drop(\"n_in_group\")\n",
        "    )\n",
        "\n",
        "def clip01(x: np.ndarray) -> np.ndarray:\n",
        "    \"\"\"Clip values into the open interval (0,1) to avoid issues in log/Beta computations.\"\"\"\n",
        "    x = np.nan_to_num(x, nan=0.5, posinf=1.0, neginf=0.0)\n",
        "    return np.clip(x, 1e-6, 1.0 - 1e-6)\n",
        "\n",
        "# -------------------- Beta EM --------------------\n",
        "def log_beta_pdf(x: np.ndarray, a: float, b: float) -> np.ndarray:\n",
        "    \"\"\"Log Beta probability density function.\"\"\"\n",
        "    return (a - 1.0) * np.log(x + EPS) + (b - 1.0) * np.log(1.0 - x + EPS) - (\n",
        "        lgamma(a) + lgamma(b) - lgamma(a + b)\n",
        "    )\n",
        "\n",
        "def mom_alpha_beta(mean: float, var: float, floor: float = 1e-3) -> tuple[float, float]:\n",
        "    \"\"\"\n",
        "    Estimate Beta parameters (alpha, beta) using the method of moments.\n",
        "    If the variance is too large (t <= 0), default to near-uniform Beta.\n",
        "    \"\"\"\n",
        "    mu = float(np.clip(mean, 1e-4, 1 - 1e-4))\n",
        "    var = float(max(var, 1e-6))\n",
        "    t = mu * (1 - mu) / var - 1.0\n",
        "    if t <= 0:\n",
        "        return 1.0 + floor, 1.0 + floor\n",
        "    a = mu * t\n",
        "    b = (1 - mu) * t\n",
        "    return float(max(a, floor)), float(max(b, floor))\n",
        "\n",
        "class EMBeta:\n",
        "    \"\"\"\n",
        "    Beta EM model:\n",
        "    P(u_k | y=c) ~ Beta(alpha_{k,c}, beta_{k,c}), c ‚àà {0,1}\n",
        "    Prior P(y=1) = pi.\n",
        "    Parameters are estimated with weighted method-of-moments updates.\n",
        "    \"\"\"\n",
        "    def __init__(self, n_models: int, init: str = \"mean\", seed: int = 0):\n",
        "        self.m = n_models\n",
        "        self.pi = 0.5\n",
        "        self.alpha = np.ones((self.m, 2), dtype=float)\n",
        "        self.beta  = np.ones((self.m, 2), dtype=float)\n",
        "        self.rng = np.random.default_rng(seed)\n",
        "        self.init_mode = init\n",
        "\n",
        "    def initialize(self, S: np.ndarray) -> np.ndarray:\n",
        "        \"\"\"Initialize responsibilities gamma_i using mean or random start.\"\"\"\n",
        "        n, m = S.shape\n",
        "        if self.init_mode == \"rand\":\n",
        "            gamma = np.clip(self.rng.uniform(0.25, 0.75, size=n), 1e-3, 1 - 1e-3)\n",
        "        else:  # \"mean\"\n",
        "            gamma = np.clip(S.mean(axis=1), 1e-3, 1 - 1e-3)\n",
        "\n",
        "        self.pi = float(gamma.mean())\n",
        "\n",
        "        w1 = gamma\n",
        "        w0 = 1.0 - gamma\n",
        "        for k in range(m):\n",
        "            x = S[:, k]\n",
        "\n",
        "            sw1 = w1.sum() + EPS\n",
        "            mu1 = (w1 * x).sum() / sw1\n",
        "            var1 = (w1 * (x - mu1) ** 2).sum() / sw1\n",
        "            a1, b1 = mom_alpha_beta(mu1, var1)\n",
        "\n",
        "            sw0 = w0.sum() + EPS\n",
        "            mu0 = (w0 * x).sum() / sw0\n",
        "            var0 = (w0 * (x - mu0) ** 2).sum() / sw0\n",
        "            a0, b0 = mom_alpha_beta(mu0, var0)\n",
        "\n",
        "            self.alpha[k, 1], self.beta[k, 1] = a1, b1\n",
        "            self.alpha[k, 0], self.beta[k, 0] = a0, b0\n",
        "\n",
        "        return gamma\n",
        "\n",
        "    def e_step(self, S: np.ndarray) -> np.ndarray:\n",
        "        \"\"\"E-step: compute responsibilities Œ≥_i.\"\"\"\n",
        "        n, m = S.shape\n",
        "        ll0 = np.zeros(n, dtype=float)\n",
        "        ll1 = np.zeros(n, dtype=float)\n",
        "        for k in range(m):\n",
        "            x = S[:, k]\n",
        "            ll0 += log_beta_pdf(x, self.alpha[k, 0], self.beta[k, 0])\n",
        "            ll1 += log_beta_pdf(x, self.alpha[k, 1], self.beta[k, 1])\n",
        "        ll0 += np.log(1 - self.pi + EPS)\n",
        "        ll1 += np.log(self.pi + EPS)\n",
        "        mx = np.maximum(ll0, ll1)\n",
        "        p1 = np.exp(ll1 - mx)\n",
        "        p0 = np.exp(ll0 - mx)\n",
        "        gamma = p1 / (p1 + p0 + EPS)\n",
        "        return np.clip(gamma, 1e-6, 1 - 1e-6)\n",
        "\n",
        "    def m_step(self, S: np.ndarray, gamma: np.ndarray):\n",
        "        \"\"\"M-step: update pi, alpha, beta parameters.\"\"\"\n",
        "        self.pi = float(np.mean(gamma))\n",
        "        w1 = gamma\n",
        "        w0 = 1.0 - gamma\n",
        "        for k in range(self.m):\n",
        "            x = S[:, k]\n",
        "\n",
        "            sw1 = w1.sum() + EPS\n",
        "            mu1 = (w1 * x).sum() / sw1\n",
        "            var1 = (w1 * (x - mu1) ** 2).sum() / sw1\n",
        "            a1, b1 = mom_alpha_beta(mu1, var1)\n",
        "\n",
        "            sw0 = w0.sum() + EPS\n",
        "            mu0 = (w0 * x).sum() / sw0\n",
        "            var0 = (w0 * (x - mu0) ** 2).sum() / sw0\n",
        "            a0, b0 = mom_alpha_beta(mu0, var0)\n",
        "\n",
        "            self.alpha[k, 1], self.beta[k, 1] = a1, b1\n",
        "            self.alpha[k, 0], self.beta[k, 0] = a0, b0\n",
        "\n",
        "    def fit(self, S: np.ndarray, max_iters: int = 60, tol: float = 1e-5, verbose: bool = True):\n",
        "        \"\"\"Run EM until convergence or max_iters reached.\"\"\"\n",
        "        S = clip01(S)\n",
        "        gamma = self.initialize(S)\n",
        "        prev = gamma.copy()\n",
        "        for it in range(1, max_iters + 1):\n",
        "            gamma = self.e_step(S)\n",
        "            self.m_step(S, gamma)\n",
        "            delta = float(np.mean(np.abs(gamma - prev)))\n",
        "            if verbose:\n",
        "                print(f\"EM iter {it:02d} | pi={self.pi:.4f} | ŒîŒ≥={delta:.6f}\")\n",
        "            if delta < tol:\n",
        "                break\n",
        "            prev = gamma\n",
        "        return gamma\n",
        "\n",
        "# -------------------- Pipeline --------------------\n",
        "def main():\n",
        "    # Optional CLI arguments: --iters=, --tol=, --init=mean|rand\n",
        "    max_iters = 60\n",
        "    tol = 1e-5\n",
        "    init = \"mean\"\n",
        "    for arg in sys.argv[1:]:\n",
        "        if arg.startswith(\"--iters=\"):\n",
        "            max_iters = int(arg.split(\"=\")[1])\n",
        "        elif arg.startswith(\"--tol=\"):\n",
        "            tol = float(arg.split(\"=\")[1])\n",
        "        elif arg.startswith(\"--init=\"):\n",
        "            init = arg.split(\"=\")[1]\n",
        "\n",
        "    # 1) Build percentile table per model from rank files\n",
        "    dfs, colnames = [], []\n",
        "    for fp in FILES:\n",
        "        try:\n",
        "            df = load_rank_file(fp)\n",
        "        except Exception as e:\n",
        "            print(f\"‚ö†Ô∏è Skipping (cannot read): {fp} ({e})\")\n",
        "            continue\n",
        "\n",
        "        # Extract a label for the column from the file name\n",
        "        m = re.search(r\"_([\\d.]+)\\.parquet$\", fp)\n",
        "        tag = m.group(1) if m else re.sub(r\"\\W+\", \"\", fp.split(\"/\")[-1])\n",
        "\n",
        "        # Compute percentile, then KEEP ONLY Id, ranker_id, and the renamed percentile column\n",
        "        df_pct = (\n",
        "            to_percentile_per_ranker(df)\n",
        "            .select([\"Id\", \"ranker_id\", pl.col(\"percentile\").alias(f\"u_{tag}\")])\n",
        "        )\n",
        "        dfs.append(df_pct)\n",
        "        colnames.append(f\"u_{tag}\")\n",
        "\n",
        "    if not dfs:\n",
        "        print(\"‚ùå No valid rank files found.\")\n",
        "        return\n",
        "\n",
        "    # 2) Join on Id + ranker_id (no 'selected' columns to collide)\n",
        "    base = dfs[0]\n",
        "    for d in dfs[1:]:\n",
        "        base = base.join(d, on=[\"Id\", \"ranker_id\"])\n",
        "\n",
        "    # 3) Prepare matrix S (n, m) with percentiles in (0,1]\n",
        "    S = np.column_stack([clip01(base[c].to_numpy()) for c in colnames])\n",
        "    n, m = S.shape\n",
        "    print(f\"Detected {m} rankers over {n} items.\")\n",
        "\n",
        "    # 4) Run Beta EM globally, then re-rank per ranker_id using posterior\n",
        "    if m == 1:\n",
        "        post = clip01(S[:, 0])\n",
        "        print(\"Only one ranker ‚Üí using its percentile as posterior.\")\n",
        "    else:\n",
        "        em = EMBeta(n_models=m, init=init, seed=0)\n",
        "        post = em.fit(S, max_iters=max_iters, tol=tol, verbose=True)\n",
        "\n",
        "    out = (\n",
        "        base.with_columns(pl.Series(name=\"posterior\", values=post))\n",
        "            .with_columns(\n",
        "                pl.col(\"posterior\")\n",
        "                  .rank(\"ordinal\", descending=True)\n",
        "                  .cast(pl.Int32)\n",
        "                  .alias(\"selected\")\n",
        "            )\n",
        "            .select([\"Id\", \"ranker_id\", \"selected\"])\n",
        "    )\n",
        "\n",
        "    print(\"\\n‚úÖ Sample of final submission:\")\n",
        "    print(out.head())\n",
        "\n",
        "    out.write_parquet(\"submission_ensemble_em_beta_from_ranks.parquet\")\n",
        "    print(\"\\nüíæ Saved as: submission_ensemble_em_beta_from_ranks.parquet\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-PJsDQYxzGGX",
        "outputId": "c4a418f0-7ff7-48a1-d35c-5a33c0491a5f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing ensemble_em.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Stacking**"
      ],
      "metadata": {
        "id": "20-hwDQkIMoE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile create_stacked_features.py\n",
        "import polars as pl\n",
        "\n",
        "# 1. Read prediction files\n",
        "df_dl = pl.read_csv(\"validation_preds_dl.csv\")\n",
        "df_xgb = pl.read_csv(\"validation_preds_xgboost.csv\")\n",
        "\n",
        "# 2. Check that Ids and ranker_ids are aligned\n",
        "assert df_dl[\"Id\"].to_list() == df_xgb[\"Id\"].to_list(), \"‚ö†Ô∏è Ids are not in the same order\"\n",
        "assert df_dl[\"ranker_id\"].to_list() == df_xgb[\"ranker_id\"].to_list(), \"‚ö†Ô∏è ranker_ids are not identical\"\n",
        "\n",
        "# 3. Build the base combined DataFrame\n",
        "df_combined = pl.DataFrame({\n",
        "    \"Id\": df_dl[\"Id\"],\n",
        "    \"ranker_id\": df_dl[\"ranker_id\"],\n",
        "    \"selected_dl\": df_dl[\"selected\"],\n",
        "    \"selected_xgboost\": df_xgb[\"selected\"],\n",
        "    \"confidence_dl\": df_dl[\"confidence\"],\n",
        "    \"confidence_xgboost\": df_xgb[\"confidence\"],\n",
        "    \"label\": df_dl[\"label\"]\n",
        "})\n",
        "\n",
        "# 4. Add group size per ranker_id\n",
        "df_combined = df_combined.with_columns([\n",
        "    pl.len().over(\"ranker_id\").alias(\"group_size\")\n",
        "])\n",
        "\n",
        "# 5. Generate additional features\n",
        "df_combined = df_combined.with_columns([\n",
        "    # Differences\n",
        "    (pl.col(\"selected_dl\") - pl.col(\"selected_xgboost\")).alias(\"selected_diff\"),\n",
        "    (pl.col(\"confidence_dl\") - pl.col(\"confidence_xgboost\")).alias(\"confidence_diff\"),\n",
        "\n",
        "    # Mean and product\n",
        "    ((pl.col(\"confidence_dl\") + pl.col(\"confidence_xgboost\")) / 2).alias(\"confidence_mean\"),\n",
        "    (pl.col(\"confidence_dl\") * pl.col(\"confidence_xgboost\")).alias(\"confidence_product\"),\n",
        "\n",
        "    # Ratios\n",
        "    (pl.col(\"confidence_dl\") / (pl.col(\"confidence_xgboost\") + 1e-6)).alias(\"confidence_ratio\"),\n",
        "    (pl.col(\"selected_dl\") / (pl.col(\"selected_xgboost\") + 1e-6)).alias(\"selected_ratio\"),\n",
        "\n",
        "    # Inverse ranks\n",
        "    (1.0 / pl.col(\"selected_dl\")).alias(\"inv_rank_dl\"),\n",
        "    (1.0 / pl.col(\"selected_xgboost\")).alias(\"inv_rank_xgb\"),\n",
        "\n",
        "    # Agreement between ranks\n",
        "    (pl.col(\"selected_dl\") == pl.col(\"selected_xgboost\")).cast(pl.Int8).alias(\"rank_agreement\")\n",
        "])\n",
        "\n",
        "# 6. (Optional) Drop group size if not needed\n",
        "df_combined = df_combined.drop(\"group_size\")\n",
        "\n",
        "# 7. Save the extended feature set\n",
        "df_combined.write_csv(\"validation_stacking_features_extended.csv\")\n",
        "print(\"‚úÖ 'validation_stacking_features_extended.csv' created with extended features.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ErUBigyukDCd",
        "outputId": "00e1c0aa-410f-4ab1-c3ea-d3a788921d54"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing create_stacked_features.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile train_stacking.py\n",
        "import pandas as pd\n",
        "import polars as pl\n",
        "import numpy as np\n",
        "import torch\n",
        "import xgboost as xgb\n",
        "import joblib\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# -----------------------\n",
        "# Ranking Metrics\n",
        "# -----------------------\n",
        "\n",
        "def calc_group_metrics(df, k=3):\n",
        "    grouped = df.groupby(\"ranker_id\")\n",
        "    hitrate, ndcg, map3 = 0.0, 0.0, 0.0\n",
        "    count = 0\n",
        "\n",
        "    for _, group in grouped:\n",
        "        if len(group) <= 10:\n",
        "            continue\n",
        "\n",
        "        scores = torch.tensor(group[\"stacked_score\"].values, dtype=torch.float32)\n",
        "        labels = torch.tensor(group[\"label\"].values, dtype=torch.float32)\n",
        "        l = len(group)\n",
        "\n",
        "        _, topk_idx = torch.topk(scores, min(k, l))\n",
        "        if (labels[topk_idx] > 0).any():\n",
        "            hitrate += 1\n",
        "\n",
        "        _, idx_pred = torch.topk(scores, min(k, l))\n",
        "        _, idx_ideal = torch.topk(labels, min(k, l))\n",
        "\n",
        "        dcg = (labels[idx_pred] / torch.log2(torch.arange(2, 2 + len(idx_pred)).float())).sum()\n",
        "        idcg = (labels[idx_ideal] / torch.log2(torch.arange(2, 2 + len(idx_ideal)).float())).sum()\n",
        "        ndcg += (dcg / idcg).item() if idcg > 0 else 0.0\n",
        "\n",
        "        y_true = labels[idx_pred] > 0\n",
        "        if y_true.sum() > 0:\n",
        "            precisions = [(y_true[:j + 1].float().sum() / (j + 1)) for j in range(len(y_true)) if y_true[j]]\n",
        "            map3 += torch.stack(precisions).mean().item()\n",
        "\n",
        "        count += 1\n",
        "\n",
        "    return {\n",
        "        \"HitRate@3\": hitrate / count if count > 0 else 0.0,\n",
        "        \"NDCG@3\": ndcg / count if count > 0 else 0.0,\n",
        "        \"MAP@3\": map3 / count if count > 0 else 0.0\n",
        "    }\n",
        "\n",
        "# -----------------------\n",
        "# Training\n",
        "# -----------------------\n",
        "\n",
        "# 1. Load data\n",
        "df = pl.read_csv(\"validation_stacking_features_extended.csv\")\n",
        "pdf = df.to_pandas()\n",
        "\n",
        "# 2. Features\n",
        "feature_cols = [\n",
        "    \"confidence_dl\", \"confidence_xgboost\",\n",
        "    \"selected_dl\", \"selected_xgboost\",\n",
        "    \"selected_diff\", \"confidence_diff\",\n",
        "    \"confidence_mean\", \"confidence_product\",\n",
        "    \"confidence_ratio\", \"selected_ratio\",\n",
        "    \"inv_rank_dl\", \"inv_rank_xgb\",\n",
        "    \"rank_agreement\"\n",
        "]\n",
        "X = pdf[feature_cols]\n",
        "y = pdf[\"label\"]\n",
        "\n",
        "# 3. Grouped split\n",
        "unique_groups = pdf[\"ranker_id\"].unique()\n",
        "train_groups, val_groups = train_test_split(unique_groups, test_size=0.2, random_state=42)\n",
        "\n",
        "train_mask = pdf[\"ranker_id\"].isin(train_groups)\n",
        "val_mask = pdf[\"ranker_id\"].isin(val_groups)\n",
        "\n",
        "X_train = X[train_mask]\n",
        "y_train = y[train_mask]\n",
        "X_val = X[val_mask]\n",
        "y_val = y[val_mask]\n",
        "\n",
        "group_train = pdf[train_mask].groupby(\"ranker_id\").size().values\n",
        "group_val = pdf[val_mask].groupby(\"ranker_id\").size().values\n",
        "\n",
        "# 4. Train ranker\n",
        "model = xgb.XGBRanker(\n",
        "    objective=\"rank:ndcg\",\n",
        "    eval_metric=\"ndcg@3\",\n",
        "    tree_method=\"hist\",\n",
        "    learning_rate=0.01,\n",
        "    max_depth=8,\n",
        "    min_child_weight=5,\n",
        "    gamma=0.1,\n",
        "    subsample=0.8,\n",
        "    colsample_bytree=0.8,\n",
        "    random_state=42,\n",
        "    n_estimators=1500\n",
        ")\n",
        "\n",
        "model.fit(\n",
        "    X_train, y_train,\n",
        "    group=group_train,\n",
        "    eval_set=[(X_val, y_val)],\n",
        "    eval_group=[group_val],\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "# 5. Predict & re-rank\n",
        "pdf[\"stacked_score\"] = model.predict(X)\n",
        "pdf[\"selected\"] = (\n",
        "    pdf.groupby(\"ranker_id\")[\"stacked_score\"]\n",
        "    .rank(method=\"first\", ascending=False)\n",
        "    .astype(int)\n",
        ")\n",
        "\n",
        "# 6. Save predictions\n",
        "pl.from_pandas(pdf[[\"Id\", \"ranker_id\", \"stacked_score\", \"selected\", \"label\"]])\\\n",
        "    .write_csv(\"validation_preds_stacked.csv\")\n",
        "print(\"‚úÖ 'validation_preds_stacked.csv' saved.\")\n",
        "\n",
        "# 7. Evaluate metrics\n",
        "val_df = pdf[val_mask]\n",
        "val_out = val_df[[\"Id\", \"ranker_id\", \"stacked_score\", \"selected\", \"label\"]]\n",
        "metrics = calc_group_metrics(val_out, k=3)\n",
        "print(\"\\nüìä Ranking metrics on validation set:\")\n",
        "for m, v in metrics.items():\n",
        "    print(f\"‚Ä¢ {m}: {v:.4f}\")\n",
        "\n",
        "# 8. Save model\n",
        "joblib.dump(model, \"stacked_ranker.joblib\")\n",
        "print(\"‚úÖ Model saved to 'stacked_ranker.joblib'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PqUw839jXFDN",
        "outputId": "ffe594c1-9f7b-4efa-cf34-d1684fa0fa53"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting train_stacking.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile train_stacking.py\n",
        "import pandas as pd\n",
        "import polars as pl\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "import torch\n",
        "from collections import defaultdict\n",
        "import joblib\n",
        "import xgboost as xgb\n",
        "\n",
        "# -----------------------\n",
        "# Ranking Metrics\n",
        "# -----------------------\n",
        "\n",
        "def calc_group_metrics(df, k=3):\n",
        "    grouped = df.groupby(\"ranker_id\")\n",
        "    hitrate, ndcg, map3 = 0.0, 0.0, 0.0\n",
        "    count = 0\n",
        "\n",
        "    for _, group in grouped:\n",
        "        if len(group) <= 10:\n",
        "            continue\n",
        "\n",
        "        scores = torch.tensor(group[\"stacked_score\"].values, dtype=torch.float32)\n",
        "        labels = torch.tensor(group[\"label\"].values, dtype=torch.float32)\n",
        "        l = len(group)\n",
        "\n",
        "        # HitRate@k\n",
        "        _, topk_idx = torch.topk(scores, min(k, l))\n",
        "        if (labels[topk_idx] > 0).any():\n",
        "            hitrate += 1\n",
        "\n",
        "        # NDCG@k\n",
        "        _, idx_pred = torch.topk(scores, min(k, l))\n",
        "        _, idx_ideal = torch.topk(labels, min(k, l))\n",
        "\n",
        "        dcg = (labels[idx_pred] / torch.log2(torch.arange(2, 2 + len(idx_pred)).float())).sum()\n",
        "        idcg = (labels[idx_ideal] / torch.log2(torch.arange(2, 2 + len(idx_ideal)).float())).sum()\n",
        "        ndcg += (dcg / idcg).item() if idcg > 0 else 0.0\n",
        "\n",
        "        # MAP@k\n",
        "        y_true = labels[idx_pred] > 0\n",
        "        if y_true.sum() > 0:\n",
        "            precisions = [(y_true[:j+1].float().sum() / (j+1)) for j in range(len(y_true)) if y_true[j]]\n",
        "            map3 += torch.stack(precisions).mean().item()\n",
        "\n",
        "        count += 1\n",
        "\n",
        "    return {\n",
        "        \"HitRate@3\": hitrate / count if count > 0 else 0.0,\n",
        "        \"NDCG@3\": ndcg / count if count > 0 else 0.0,\n",
        "        \"MAP@3\": map3 / count if count > 0 else 0.0\n",
        "    }\n",
        "\n",
        "# -----------------------\n",
        "# Training\n",
        "# -----------------------\n",
        "\n",
        "# 1. Load data\n",
        "df = pl.read_csv(\"validation_stacking_features_extended.csv\")\n",
        "pdf = df.to_pandas()\n",
        "\n",
        "# 2. Define input features (all engineered features)\n",
        "feature_cols = [\n",
        "    \"confidence_dl\", \"confidence_xgboost\",\n",
        "    \"selected_dl\", \"selected_xgboost\",\n",
        "    \"selected_diff\", \"confidence_diff\",\n",
        "    \"confidence_mean\", \"confidence_product\",\n",
        "    \"confidence_ratio\", \"selected_ratio\",\n",
        "    \"inv_rank_dl\", \"inv_rank_xgb\",\n",
        "    \"rank_agreement\"\n",
        "]\n",
        "X = pdf[feature_cols]\n",
        "y = pdf[\"label\"]\n",
        "\n",
        "# 3. Define and train the model\n",
        "model = xgb.XGBClassifier(\n",
        "    n_estimators=1500,\n",
        "    learning_rate=0.01,\n",
        "    max_depth=8,\n",
        "    min_child_weight=5,\n",
        "    gamma=0.1,\n",
        "    subsample=0.8,\n",
        "    colsample_bytree=0.8,\n",
        "    scale_pos_weight=(y == 0).sum() / (y == 1).sum(),\n",
        "    n_jobs=-1,\n",
        "    random_state=42,\n",
        "    use_label_encoder=False,\n",
        "    eval_metric=\"logloss\"\n",
        ")\n",
        "model.fit(X, y)\n",
        "\n",
        "# 4. Predict and re-rank\n",
        "pdf[\"stacked_score\"] = model.predict_proba(X)[:, 1]\n",
        "\n",
        "pdf[\"selected\"] = (\n",
        "    pdf.groupby(\"ranker_id\")[\"stacked_score\"]\n",
        "    .rank(method=\"first\", ascending=False)\n",
        "    .astype(int)\n",
        ")\n",
        "\n",
        "# 5. Save results\n",
        "out = pdf[[\"Id\", \"ranker_id\", \"stacked_score\", \"selected\", \"label\"]]\n",
        "pl.from_pandas(out).write_csv(\"validation_preds_stacked.csv\")\n",
        "print(\"‚úÖ 'validation_preds_stacked.csv' saved.\")\n",
        "\n",
        "# 6. Evaluate\n",
        "metrics = calc_group_metrics(out, k=3)\n",
        "print(\"\\nüìä Ranking metrics on validation set:\")\n",
        "for m, v in metrics.items():\n",
        "    print(f\"‚Ä¢ {m}: {v:.4f}\")\n",
        "\n",
        "# Save model to disk\n",
        "joblib.dump(model, \"stacked_model.joblib\")\n",
        "print(\"‚úÖ Modelul a fost salvat ca 'stacked_logreg_model.joblib'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ukz2Zv_amaVX",
        "outputId": "3328cfda-6a93-4f35-90d9-66b01374ec14"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting train_stacking.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile predict_stacked.py\n",
        "import pandas as pd\n",
        "import polars as pl\n",
        "import numpy as np\n",
        "import joblib\n",
        "\n",
        "# 1. Load trained model\n",
        "model = joblib.load(\"stacked_logreg_model.joblib\")\n",
        "print(\"‚úÖ Model loaded from 'stacked_logreg_model.joblib'\")\n",
        "\n",
        "# 2. Load feature set (without labels)\n",
        "df = pl.read_csv(\"validation_stacking_features_extended.csv\")\n",
        "pdf = df.to_pandas()\n",
        "\n",
        "# 3. Define input features (must match training)\n",
        "feature_cols = [\n",
        "    \"confidence_dl\", \"confidence_xgboost\",\n",
        "    \"selected_dl\", \"selected_xgboost\",\n",
        "    \"selected_diff\", \"confidence_diff\",\n",
        "    \"confidence_mean\", \"confidence_product\",\n",
        "    \"confidence_ratio\", \"selected_ratio\",\n",
        "    \"inv_rank_dl\", \"inv_rank_xgb\",\n",
        "    \"rank_agreement\"\n",
        "]\n",
        "\n",
        "X = pdf[feature_cols]\n",
        "\n",
        "# 4. Predict scores\n",
        "pdf[\"stacked_score\"] = model.predict_proba(X)[:, 1]\n",
        "\n",
        "# 5. Re-rank within each ranker_id\n",
        "pdf[\"selected\"] = (\n",
        "    pdf.groupby(\"ranker_id\")[\"stacked_score\"]\n",
        "    .rank(method=\"first\", ascending=False)\n",
        "    .astype(int)\n",
        ")\n",
        "\n",
        "# 6. Save submission (only Id, ranker_id, selected)\n",
        "submission = pdf[[\"Id\", \"ranker_id\", \"selected\"]]\n",
        "pl.from_pandas(submission).write_parquet(\"submission_stacked.parquet\")\n",
        "print(\"‚úÖ submission_stacked.parquet saved.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hgPsKJ6N4pPf",
        "outputId": "132ca1dd-3908-4c3f-c15d-de5d9247c5ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing predict_stacked.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Check Val Differencies**"
      ],
      "metadata": {
        "id": "6ARgO8-HH0aD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile check.py\n",
        "import polars as pl\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from collections import Counter\n",
        "\n",
        "def hitrate_at_k(group_df, k=3):\n",
        "    topk = group_df.sort(\"score\", descending=True)[:k]\n",
        "    return (topk[\"label\"] > 0).any()\n",
        "\n",
        "def analyze_misses(df: pl.DataFrame, k=3, min_group_size=10):\n",
        "    misses = []\n",
        "    diff_counter = Counter()\n",
        "\n",
        "    for group_id, group_df in tqdm(df.group_by(\"ranker_id\"), desc=\"Evaluating HitRate@3\"):\n",
        "        if group_df.height < min_group_size:\n",
        "            continue\n",
        "\n",
        "        group_df = group_df.sort(\"score\", descending=True)\n",
        "        topk = group_df[:k]\n",
        "        label_row_df = group_df.filter(pl.col(\"label\") > 0)\n",
        "\n",
        "        if label_row_df.is_empty():\n",
        "            continue\n",
        "\n",
        "        if (topk[\"label\"] > 0).any():\n",
        "            continue\n",
        "\n",
        "        label_row = {col: label_row_df[col][0] for col in group_df.columns}\n",
        "        differences = []\n",
        "\n",
        "        for i, row in enumerate(topk.iter_rows(named=True)):\n",
        "            diff = {}\n",
        "            for col in group_df.columns:\n",
        "                if row[col] != label_row[col]:\n",
        "                    diff[col] = (label_row[col], row[col])\n",
        "                    diff_counter[col] += 1\n",
        "            differences.append((i + 1, diff))\n",
        "\n",
        "        misses.append({\n",
        "            \"ranker_id\": group_id,\n",
        "            \"topk_differences\": differences\n",
        "        })\n",
        "\n",
        "    return misses, diff_counter\n",
        "\n",
        "\n",
        "def main():\n",
        "    csv_path = \"validation_preds_dl_full.csv\"\n",
        "    df = pl.read_csv(csv_path)\n",
        "\n",
        "    required_cols = {\"ranker_id\", \"score\", \"label\"}\n",
        "    if not required_cols.issubset(set(df.columns)):\n",
        "        raise ValueError(f\"The CSV file must contain the following columns: {required_cols}\")\n",
        "\n",
        "    total_groups = 0\n",
        "    hit_groups = 0\n",
        "    for _, group_df in df.group_by(\"ranker_id\"):\n",
        "        if group_df.height < 10:\n",
        "            continue\n",
        "        total_groups += 1\n",
        "        if hitrate_at_k(group_df, k=3):\n",
        "            hit_groups += 1\n",
        "\n",
        "    hitrate = hit_groups / total_groups if total_groups else 0.0\n",
        "    print(f\"\\nüéØ HitRate@3: {hitrate:.4f} over {total_groups} valid groups\")\n",
        "\n",
        "    misses, diff_counter = analyze_misses(df, k=3, min_group_size=10)\n",
        "\n",
        "    with open(\"hitrate3_miss_analysis.txt\", \"w\") as f:\n",
        "        for miss in misses:\n",
        "            f.write(f\"Group: {miss['ranker_id']}\\n\")\n",
        "            f.write(\"‚ùå Differences from top 3 predictions compared to ground truth:\\n\")\n",
        "            for rank, diffs in miss[\"topk_differences\"]:\n",
        "                f.write(f\"  ‚Ü≥ Top {rank} differences:\\n\")\n",
        "                if not diffs:\n",
        "                    f.write(\"    (Identical to ground truth)\\n\")\n",
        "                else:\n",
        "                    for key, (true_val, pred_val) in diffs.items():\n",
        "                        f.write(f\"    {key}: ground_truth={true_val} | predicted={pred_val}\\n\")\n",
        "            f.write(\"\\n\" + \"-\" * 40 + \"\\n\")\n",
        "\n",
        "    print(\"üìÑ Group-wise differences saved to 'hitrate3_miss_analysis.txt'.\")\n",
        "\n",
        "    with open(\"hitrate3_diff_column_stats.txt\", \"w\") as f:\n",
        "        f.write(\"üìä Top Differing Columns (sorted by frequency):\\n\\n\")\n",
        "        for col, count in diff_counter.most_common():\n",
        "            f.write(f\"{col}: {count} differences\\n\")\n",
        "\n",
        "    print(\"üìä Column difference summary saved to 'hitrate3_diff_column_stats.txt'.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UMIXah8sH38m",
        "outputId": "8a8ca01b-99ca-414a-d8a4-5b0807972f33"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting check.py\n"
          ]
        }
      ]
    }
  ]
}